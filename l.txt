

ENGLISH
FREE AUDIO
website and app
www.dkefe.com
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
Author
Thomas Booth worked for 10 years as an English-language
teacher in Poland and Russia. He now lives in England, where
he works as an editor and English-language materials writer,
notably of course books and vocabulary textbooks.
ENGLISH
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
4
ContentsUS Editors Kayla Dugger, Jenny Siklos
Senior Editor Laura Sandford
Project Editor Thomas Booth
Senior Art Editors Amy Child, Anna Hall
Art Editors Raymond Bryant, Michelle Staples,
Jemma Westing
Illustrators Edward Byrne, Michael Parkin, Gus Scott
Project Manager Christine Stroyan
Jacket Designer Surabhi Wadhwa
Jacket Editor Claire Gell
Jacket Design Development Manager Sophia MTT
Producer, Pre-production Gillian Reid
Producers Alex Bell, Anna Vallarino
Publisher Andrew Macintyre
Art Director Karen Self
Publishing Director Jonathan Metcalf
DK India
Project Art Editor Sanjay Chauhan
Art Editor Meenal Goel
Assistant Art Editor Devika Khosla
Project Editor Nisha Shaw
Illustrator Arun Pottirayil
Jacket Designer Juhi Sheth
Managing Jackets Editor Saloni Singh
Pre-production Manager Balwant Singh
Senior DTP Designer Vishal Bhatia
Managing Art Editor Sudakshina Basu
Managing Editor Rohan Sinha
First American Edition, 2018
Published in the United States by DK Publishing,
345 Hudson Street, New York, New York 10014
18 19 20 21 22 10 9 8 7 6 5 4 3 2 1
001—305538—Jan/2018
Copyright © 2018 Dorling Kindersley Limited
DK, a Division of Penguin Random House LLC
All rights reserved.
Without limiting the rights under copyright reserved above, no
part of this publication may be reproduced, stored in or introduced
into a retrieval system, or transmitted in any form or by any means
(electronic, mechanical, photocopying, recording, or otherwise)
without the prior written permission of the copyright owner.
Published in Great Britain by Dorling Kindersley Limited.
A catalog record for this book is available from the
Library of Congress.
ISBN 978-1-4654-6483-5
DK books are available at special discounts when purchased in
bulk for sales promotions, premiums, fund-raising, or educational
use. For details, contact DK Publishing Special Markets, 345
Hudson Street, NewYork, New York 10014 or SpecialSales@dk.com.
Printed in China
A WORLD OF IDEAS:
SEE ALL THERE IS TO KNOW
www.dk.com
Countries and nationalities 10
Numbers 14
Time expressions 18
Daily routines 22
Describing things: facts 26
Describing things: opinions 30
Sharing information 34
Common English idioms 38
Around the house 42
Kitchen implements and toiletries 46
HOME
How to use this book 8
GETTING STARTED
5
Studying 102
Speaking a foreign language 106
Communication and beliefs 110
Crime and the law 114
The body 62
Clothes 66
Accessories and beauty products 70
Appearance 74
Personality traits 78
Feelings and moods 82
Family tree 86
Family and relationships 90
Baby equipment and toys 94
Education 98
PEOPLE
Chores and cleaning 50
Tools and gardening 54
Moving and renting 58
FOOD AND DRINK
Meat, fish, dairy, and snacks 118
Fruit and nuts 122
Vegetables 126
Bread, desserts, and condiments 130
Drinking and eating 134
Eating in and eating out 138
WORK
Jobs 142
Working conditions 146
6
Transportation and travel 182
Driving a car 186
Maps and directions 190
Travel and accommodation 194
Travel and tourism 198
TRAVEL
THE ENVIRONMENT
Weather and climate 210
Geographical features 214
Environmental concerns 218
ANIMALS
Pets and farm animals 222
Wild animals 226
Birds and bugs 230
Fish, whales, and sea creatures 234
Free time activities 238
Abilities and actions 242
ACTIVITIES
Industries and departments 150
Office equipment 154
Money and finance 158
Working 162
Meeting and presenting 166
Work and business idioms 170
Applying for a job 174
Workplace skills and abilities 178
Camping and cycling 202
Beach 206
7
Answers 322
Word list 340
Acknowledgments 360
ARTS AND THE MEDIA
Books and reading 258
Music 262
Movies and plays 266
TV 270
Media and celebrity 274
Sickness 278
Medicine and treatment 282
Healthy eating 286
Fitness and well-being 290
HEALTH
SCIENCE AND TECHNOLOGY
AROUND TOWN
Around town 294
Shopping 298
At the supermarket 302
Urban life 306
Technology and gadgets 310
Technology and the future 314
Science 318
Sports 246
Soccer 250
Sports equipment and venues 254
8
How to use this book
Teaching spreads
Each unit of English for Everyone: English Vocabulary Builder
consists of a teaching spread and a practice spread. Teaching
spreads give you an illustrated vocabulary list on a particular
topic. Practice spreads include a variety of exercises to reinforce
what you have learned. Supporting audio
for each teaching spread is available on
the website and app. The best way to
learn spoken vocabulary is to listen to the
audio and repeat each word and phrase
on the spread. If you have difficulty
understanding a word or phrase, look it
up in your dictionary or the word list at
the back of this book.
PRACTICE SPREAD
TEACHING SPREAD
258 259
BOOKS
READING AND GENRES
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
Unit number The book is
divided into units. The unit
number helps you keep
track of your progress.
Modules Most teaching spreads are
broken down into modules covering
different aspects of a topic.
Module number Every module is
identified with a unique number, so
you can easily locate the related audio.
Write-on lines You
are encouraged to
write your own
translations of English
words to create your
own reference pages.
Sample sentences
Some modules show
useful English phrases
in the context of a
sample sentence.
Definitions Idiomatic English
phrases are accompanied
by definitions.
Audio support All teaching modules are
supported by audio recordings to help you
recognize and pronounce spoken vocabulary.
Supporting graphics Visual cues
help you understand and
remember new vocabulary.
296 297
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
AROUND TOWN
Around town
9
Practice exercises
Each teaching spread is followed by exercises that help to fix
new words and phrases in your memory. Working through
the exercises will help you to remember what you have
learned and to use and recognize new English vocabulary.
Answers are provided for every exercise.
FREE AUDIO
website and app
www.dkefe.com
Space for writing You are
encouraged to write your answers
in the book for future reference.
Sample answer
The first question
of each exercise
is answered for
you, to help make
the task easy to
understand.
Supporting graphics Visual
cues are given to help you
understand the exercises.
Exercise number Each exercise is
identified with a unique number, so
you can easily locate answers.
Exercise instruction Each exercise
is introduced with a brief instruction,
telling you what you need to do.
Listening exercise This
symbol indicates that
you should listen to an
audio track in order to
answer the questions in
the exercise.
Audio
English for Everyone: English Vocabulary Builder
features extensive supporting audio resources. Every
word and phrase in the teaching spreads is recorded,
and you are encouraged to listen to the audio and
repeat the words and phrases out loud, until you are
confident you understand and can pronounce what
has been said.
LISTENING EXERCISES
This symbol indicates that you should
listen to an audio track in order to
answer the questions in the exercise.
SUPPORTING AUDIO
This symbol indicates that audio
recordings of the words and phrases in a
module are available for you to listen to.
Answers
This book is designed to make
it easy to monitor your progress.
Answers are provided for every
exercise, so you can see how well
you have understood and
remembered the vocabulary you
have learned.
Exercise numbers
Match these numbers
to the unique identifier
at the top-left corner
of each exercise.
Answers Find the answers
to every exercise printed
at the back of the book.
156
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
EACH
MISS
10
Countries and nationalities
COUNTRIES
11
NATIONALITIES
12
FIND EIGHT MORE COUNTRIES IN THE GRID THAT MATCH THE FLAGS
MARK THE CORRECT COUNTRY FOR EACH FLAG
13
WRITE THE WORDS FROM THE
PANEL IN THE CORRECT GROUPS
NATIONALITIESCOUNTRIES
WRITE THE CORRECT
COUNTRY UNDER EACH FLAG
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
14
Numbers
NUMBERS
ORDINAL NUMBERS
15
LARGE NUMBERS
FRACTIONS, DECIMALS, AND PERCENTAGES
16
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
MATCH THE NUMBERS
TO THE CORRECT WORDS
17
LISTEN TO THE AUDIO AND
MARK THE CORRECT NUMBER
FOR EACH WORD YOU HEAR
WRITE THE CORRECT WORDS
NEXT TO EACH NUMBER
WRITE THE CORRECT WORDS UNDER EACH FRACTION
18
Time expressions
THE CALENDAR
19
SEASONS AND FREQUENCY
20
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
21
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
22
DAILY ROUTINES
Daily routines
23
24
MARK THE CORRECT PICTURE FOR EACH EXPRESSION
MATCH THE PICTURES TO THE CORRECT EXPRESSIONS
25
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
26
Describing things: facts
COLORS (US) / COLOURS (UK)
MATERIALS
27
ADJECTIVES
28
REWRITE THE WORDS, CORRECTING THE SPELLINGS
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE WORDS FROM THE
PANEL NEXT TO THEIR OPPOSITES
29
MARK THE CORRECT PICTURE FOR EACH WORD
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
30
OPINION ADJECTIVES
Describing things: opinions
31
GOOD
BAD
32
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
NEGATIVEPOSITIVE
33
LISTEN TO THE AUDIO AND
WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD
UNDER EACH PICTURE
34
Sharing information
BUSINESS CARDS
CONTACT DETAILS
35
FORMS OF COMMUNICATION
SENDING EMAILS
36
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
37
WRITE THE CORRECT WORD UNDER EACH PICTURE
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
38
Common English idioms
COMMON ENGLISH IDIOMS
[to have a sudden loss of confidence] [to feel unwell, sick, or ill]
[to help someone with something] [alert, knowledgeable, or competent]
[a nuisance, annoying, or difficult] [to take care of or watch carefully]
[completely and utterly
in love with someone]
[to describe exactly what is causing
a situation or problem]
[to hear information or news
through gossip or rumor]
[under time pressure
to get something done]
39
[to be kind and good-natured] [to be unwilling to commit or make a decision]
[to not completely believe
something or someone]
[to confront the consequences
of your actions]
[to tease or fool someone]
[to tell a secret to someone who
shouldn’t know about it]
[someone who seeks and gets approval
from a person in a position of authority]
[to do something the easiest or shortest
way, at the expense of high standards]
[an overreaction or a lack of restraint] [to let yourself go or relax]
40
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE PICTURES TO THE CORRECT SENTENCES
41
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
42
Around the house
HOMES, ROOMS, AND FURNITURE
43
44
MATCH THE PICTURES
TO THE CORRECT WORDS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
45
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURES BELOW, THEN WRITE THE NAME OF EACH
OBJECT UNDER THE CORRECT ROOM
KITCHEN BATHROOM LIVING ROOM BEDROOM
46
KITCHEN IMPLEMENTS
Kitchen implements and toiletries
47
TOILETRIES AND BATHROOM EQUIPMENT
48
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT ROOM
MARK THE BEGINNING AND END OF EACH WORD IN THE CHAIN
OF LETTERS, THEN WRITE THE WORDS YOU FIND
BATHROOMKITCHEN
49
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
50
Chores and cleaning
HOUSEHOLD CHORES
51
LAUNDRY AND CLEANING
52
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
REWRITE THE WORDS OR EXPRESSIONS, CORRECTING THE SPELLINGS
53
MATCH THE EXPRESSIONS TO
THE CORRECT PICTURES
LISTEN TO THE AUDIO AND
WRITE THE EXPRESSION THAT IS
SHOWN IN EACH PICTURE
COMPLETE THE EXPRESSION
FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
54
Tools and gardening
TOOLS AND HOME IMPROVEMENT
55
HOME IMPROVEMENT VERBS
GARDENING EQUIPMENT
GARDENING VERBS
56
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
57
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
GARDENING
EQUIPMENTTOOLS
58
Moving and renting
ACCOMMODATION, MOVING, AND RENTING
59
USEFUL EXPRESSIONS
[money that a tenant pays to a landlord
before moving into a property]
[a letter describing your character
and ability to pay your rent]
[an informal party that you give after
moving into a new house or apartment]
[the rent covers the bills such as
electricity, water, and gas]
[houses and apartments that are for sale
or rented out]
[a part of town where most buildings
are houses or apartments]
[belonging to the area where you live]
[a person you share your house
or apartment with]
[a person who pays to live in your house]
[to announce to your landlord that
you wish to move out]
60
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
61
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
houses and apartments that are for sale or
rented out
a letter describing your character and ability
to pay rent
a part of town where most buildings are houses
or apartments
belonging to the area where you live
money that a tenant pays to a landlord before
moving into a property
the rent covers the bills such as electricity, water,
and gas
62
The body
PARTS OF THE BODY
63
VERBS
64
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FROM
THE PANEL FOR EACH LABEL
65
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
66
Clothes
CLOTHES
67
DESCRIBING CLOTHES AND STYLES
VERBS
68
WRITE THE
CORRECT WORD
UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE
THE CORRECT WORD FOR EACH LABEL
REWRITE THE WORDS, CORRECTING
THE SPELLINGS
69
FIND EIGHT MORE WORDS FOR DESCRIBING CLOTHES IN THE GRID
THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
70
ACCESSORIES
Accessories and beauty products
71
MAKE-UP AND BEAUTY PRODUCTS
SHOES
72
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
73
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
74
Appearance
HAIR
VERBS
75
APPEARANCE AND STYLE
EYES
76
WRITE THE CORRECT WORDS
UNDER EACH PICTURE
MATCH THE WORDS TO
THE CORRECT PICTURES
77
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
78
DESCRIBING PERSONALITY
Personality traits
79
80
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
WRITE THE CORRECT WORD UNDER EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
81
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
82
Feelings and moods
FEELINGS AND MOODS
83
84
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
85
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
WRITE THE WORDS FROM
THE PANEL NEXT TO THEIR
OPPOSITES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
86
Family tree
JAMAL’S FAMILY
DEBBIE’S FAMILY ANA’S FAMILY
87
GROWING UP
ROGER’S FAMILY LOGAN’S FAMILY
RELATIONSHIPS
88
FILL IN THE GAPS ON JAMAL’S FAMILY TREE
MATCH THE PICTURES TO THE CORRECT WORDS
89
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
FILL IN THE GAPS ON
LOGAN’S FAMILY TREE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
90
Family and relationships
[to have respect and admiration for someone]
[to have characteristics
of a parent or relative]
[to care for a child and teach them how to behave] [to develop from a child to an adult]
[to begin to love someone] [to end a romantic relationship]
[to have a good relationship
with someone]
[to stop being friends with someone,
often after an argument]
[to slowly become less friendly
or close to someone] [to become friendly with a person]
USEFUL EXPRESSIONS
91
[a friend who you know very well] [to share an interest or opinion]
[to have a child] [to be a common feature of a family]
[to meet someone unexpectedly] [to be strict about something]
[to agree with or have similar opinions
to someone]
[to like someone quickly
and easily]
[to speak out in support of someone]
[to have a very high opinion
of someone]
92
MATCH THE PICTURES TO THE CORRECT SENTENCES
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
93
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
94
Baby equipment and toys
EQUIPMENT AND CLOTHES
95
TOYS AND GAMES
96
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO,
THEN NUMBER THE PICTURES
IN THE ORDER YOU HEAR THEM
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
97
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE CORRECT
PLACES ON THE GRID
TOYSEQUIPMENT
98
SUBJECTS
Education
99
STUDYING AND EXAMS (NOUNS)
STUDYING AND EXAMS (VERBS)
100
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
101
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
WRITE THE CORRECT WORD
UNDER EACH PICTURE
102
Studying
USEFUL EXPRESSIONS
[to have a year away from education or work] [to register to start something]
[someone studying for a
first degree at college or university]
[study carried out following graduation
from a first degree]
[a student in their first year at
college or university]
[a period of time in an academic calendar,
during which classes are held]
[to be awarded a diploma / qualification
after college or university] [to go to lessons or lectures]
[to provide comments and advice on
how somebody is doing something]
[to answer questions or perform
actions to show how much you
know about something]
103
[to finish something within a given time] [to fail to finish something within a given time]
[grading based on work done
over a long period] [to perform excellently on a test]
[a first, rough version of a piece of written work]
[to consider and describe the similarities
and differences between things]
[completely different] [an obvious difference]
[a significant level of difference][surprisingly not alike]
104
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
105
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to fail to finish something within a given time
someone studying for a first degree at college or university
a first, rough version of a piece of written work
a student in their first year at college or university
grading based on work done over a long period
to perform excellently on a test
106
Speaking a foreign language
USEFUL EXPRESSIONS
[language that is not technically perfect,
but clear enough for basic communication]
[able to use a language easily,
without making many mistakes]
[a person who speaks a language
as their first language]
[able to speak two languages fluently] [the set of words that make up a language]
[the ability to understand
spoken language]
[not as fluent in a language
as you used to be]
[the way in which people from a
country or region pronounce a word]
[the way a specific word is spoken]
[the way in which you make
sentences from separate words]
107
[the ability to communicate
using spoken language]
[the ability to understand written materials]
[the ability to communicate
using written words]
[a shared language that allows people from
various countries to understand each other]
[a piece of writing that has been changed
from one language to another]
[difficulty communicating with someone
who speaks another language]
[to be able to express basic information
and ideas to people]
[to speak without making mistakes]
[to be able to learn something in little time]
[to be able to understand languages
without difficulty]
108
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
WRITE THE CORRECT EXPRESSION NEXT TO ITS DEFINITION
the way people from a country or region pronounce a word
able to speak two languages fluently
a person who speaks a language as their first language
the ability to communicate using spoken language
to speak without making mistakes
the set of words that make up a language
able to use a language easily, without making many mistakes
the way in which you make sentences from separate words
109
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
110
Communication and beliefs
USEFUL EXPRESSIONS
[to say something that is not true to
avoid upsetting someone] [to say something indirectly]
[to talk about other people,
often in a negative way]
[to think that something exists
or is true]
[to have an idea about
something with little evidence]
[to wish for good luck, or avoid bad luck] [to hope for something to happen]
[somebody who tells an authority
figure when another person has done
something wrong]
[to have a strong feeling that something
is not right]
[to say things that may not be true]
111
[a group of values] [a firm and unchangeable conviction]
[stories, sayings, and traditions
from a certain area or culture][good fortune with no skill involved]
[a single piece of good fortune]
[good fortune the first
time you do something]
[a positive / negative sign about
something that will happen]
[a modern story that is untrue,
but believed by many]
[a traditional story with magic,
usually written for children]
[information or news transmitted
by people telling other people]
112
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
113
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to hope for something to happen
good fortune with no skill involved
a modern story that is untrue, but believed by many
stories, sayings, and traditions from a certain area or culture
to talk about other people, often in a negative way
to wish for good luck, or avoid bad luck
114
Crime and the law
CRIME
PUNISHMENT AND THE LAW
115
USEFUL EXPRESSIONS
[to break the law] [to spend time in prison]
[to use the power of the law to take
and question somebody] [to make people obey a rule or a law]
[a lot of crimes happening suddenly
in the same area]
[crime committed in a public place]
[financial, nonviolent crime]
[to decide on a punishment in
accordance with the law]
[to decide officially that someone
has (not) broken the law]
[to come to a decision about
somebody’s guilt or innocence]
116
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
117
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
118
Meat, fish, dairy, and snacks
MEAT
FISH AND SEAFOOD
119
DAIRY
FAST FOOD AND LIGHT SNACKS
120
LOOK AT THE PICTURES BELOW, THEN WRITE THE ANSWERS UNDER THE
CORRECT HEADING
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
FAST FOODMEAT DAIRYSEAFOOD
121
MATCH THE PICTURES
TO THE CORRECT WORDS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
122
FRUIT
Fruit and nuts
123
NUTS AND DRIED FRUIT
124
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
125
CIRCLE THE WORD THAT DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
126
Vegetables
VEGETABLES
127
128
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
129
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
130
BREAD, PASTA, AND DESSERTS
Bread, desserts, and condiments
131
FLAVORINGS AND CONDIMENTS
132
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
133
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
134
Drinking and eating
DRINKS
FOOD AND DRINK CONTAINERS
135
FOOD AND DRINK: ADJECTIVES EATING AND DRINKING
136
MATCH THE WORDS TO THE
CORRECT PICTURES
FILL IN THE MISSING LETTERS
FOR EACH WORD
137
WRITE THE CORRECT VERB UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
138
Eating in and eating out
MEALS
FOOD PREPARATION
139
EATING OUT: VERBS
EATING OUT: NOUNS
140
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
141
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
142
Jobs
JOBS
143
144
MARK THE CORRECT JOB FOR THE PERSON IN EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN
THE CHAIN OF LETTERS
145
MATCH THE WORDS TO THE CORRECT PICTURES
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
146
Working conditions
EMPLOYMENT VERBS
147
PAY AND CONDITIONS
[an amount of money paid per hour]
[extras given to employees in
addition to their usual pay]
[an amount of money paid
per week or month]
[a fixed, regular payment, often
expressed as an annual sum]
[a new job at the same company that is
more senior or better paid]
[to lose your job because it is no
longer necessary]
[a reduction in pay]
[an increase in pay]
[additional pay for extra hours worked]
[money added to a person’s salary
as a reward for good performance]
148
FIND SEVEN MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT VERB UNDER EACH PICTURE
149
WRITE THE CORRECT WORD OR PHRASE NEXT TO ITS DEFINITION,
FILLING IN THE MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
extras given to employees in addition to their usual pay
an amount of money paid per week or month
a reduction in pay
an increase in pay
an amount of money paid per hour
additional pay for extra hours worked
150
Industries and departments
INDUSTRIES
151
DEPARTMENTS
[deals with organization and internal
and external communication]
[ensures that all manufacturing
stages run smoothly]
[researches and develops
future products for a company]
[buys goods and raw materials
for manufacturers and
other companies]
[deals with employee relations
and matters such as hiring staff]
[sells products to buyers
and outside markets]
[deals with money matters, from
paying bills to projecting sales]
[carries out cleaning, maintenance, and
building operation services]
[promotes products for
companies to the market]
[ensures that all contracts and
company activities are legal]
[presents and maintains a positive
public image for a company]
[sets up and maintains all
technological systems
in an organization]
152
MATCH THE WORDS TO THE
CORRECT PICTURES
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
153
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
THEY ARE MENTIONED
WRITE THE NAME OF THE DEPARTMENT NEXT TO ITS DEFINITION
ensures that all manufacturing stages run smoothly
deals with employee relations and matters such as hiring staff
deals with money matters, from paying bills to projecting sales
ensures that all contracts and company activities are legal
deals with organization and internal and external communication
presents and maintains a positive public image for a company
sells products to buyers and outside markets
promotes products for companies to the market
154
Office equipment
IN THE OFFICE
EQUIPMENT
155
STATIONERY
156
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
157
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
158
Money and finance
MONEY
159
FINANCE
[money coming into a business]
[to get into a situation where
you owe people money]
[the amount of money that is
available to spend on something ]
[to lose money by spending more
than you earn]
[extra money the bank allows you
to spend]
[the amount of one currency that you
get when you change it for another]
[to earn just enough to cover the
costs of producing a product]
[to no longer be able to exist
as a business]
[an amount of money spent] [a major decline in economic activity]
160
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
161
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
162
Working
USEFUL EXPRESSIONS
[a job with regular hours]
[to suddenly become more successful]
[knowledge and skill gained through
doing something yourself]
[a position with the lowest level
of responsibility or pay]
[to be forced to leave your job
for doing something wrong]
[the conditions in which you work]
[progression within a profession,
in a job, or through a series of jobs]
[a position without many
prospects for promotion]
[to lose your job because the company
can no longer give you work]
[to have a job]
163
[to stop doing a job voluntarily]
[to aim to achieve a particular goal]
[to employ someone]
[to be busy with a task or
many tasks]
[to do more than you are required to do]
[to deal with something directly]
[to make more progress than others]
[very busy with too much work]
[extremely busy]
[compromise]
164
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to make more progress than others
to suddenly become more successful
to employ someone
compromise
to stop doing a job voluntarily
a job with regular hours
165
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
166
Meeting and presenting
USEFUL EXPRESSIONS
[to go to a meeting]
[included in a list of things to discuss]
[a telephone call with a number
of people at the same time]
[a vote made by raising hands in
the air to show agreement]
[to present a formal talk
to an audience]
[not present]
[a group of people who manage
a business or organization]
[when everyone agrees]
[to answer questions]
[to write a record of what is said
during a meeting]
167
[to come to an agreement
about an issue]
[any matter discussed in a meeting
that is not on the agenda]
[the primary aim]
[a plan for achieving a particular goal]
[to give a brief summary]
[to look again at the written record
of a past meeting]
[to conclude or finish something]
[to disturb a meeting or say
something before someone
else has finished speaking]
[proposals for specific
action to be taken] [to have no time left for something]
168
MATCH THE PICTURES TO THE CORRECT SENTENCES
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
169
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
included in a list of things to discuss
to give a brief summary
to go to a meeting
the primary aim
to come to an agreement about an issue
not present
to have no time left for something
to present a formal talk to an audience
proposals for specific action to be taken
a plan for achieving a particular goal
170
Work and business idioms
WORKPLACE IDIOMS
[the normal daily routine at a company]
[administration, paperwork,
or rules and regulations]
[owing money or making a loss]
[it is your turn to do
or say something]
[to start something]
[a situation with no
negative outcome]
[to think about something
in an original way]
[to change the desired end result]
[to start work on something
that needs doing]
[to waste money]
171
BUSINESS IDIOMS
[ahead of your competitors
in a certain field]
[in agreement
about something]
[to do something strictly according
to the rules]
[to talk to someone briefly in order
to catch up or get an update]
[to confirm or settle an
agreement or contract]
[an increase or decrease in speed
from what is normal]
[a strategy worked out beforehand]
[simply and quickly]
[a rough estimate]
[to dominate a particular market]
172
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
173
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
174
Applying for a job
RÉSUMÉ HEADINGS
175
VERBS
USEFUL EXPRESSIONS
[a long list of achievements]
[having a lot of contact with customers]
[an expert understanding of something]
[highly skilled at something]
[taught how to do something]
[having control over someone or something]
176
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE RÉSUMÉ AND WRITE THE CORRECT WORD FROM THE
PANEL FOR EACH LABEL
177
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
WRITE THE CORRECT WORD UNDER EACH PICTURE
178
PROFESSIONAL ATTRIBUTES
Workplace skills and abilities
179
FOR THE WORKPLACE
180
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
181
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
MATCH THE PICTURES TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
182
FORMS OF TRANSPORTATION
Transportation and travel
183
VERBSTRAVEL
184
MATCH THE VERBS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
185
FIND NINE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
186
DRIVING VOCABULARY
Driving a car
187
VERBS
188
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
189
MARK THE CORRECT EXPRESSION FOR EACH PICTURE
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
190
Maps and directions
MAPS AND DIRECTIONS
191
PREPOSITIONS OF PLACE VERBS
192
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
WRITE THE CORRECT WORD UNDER EACH PICTURE
193
MATCH THE PICTURES
TO THE CORRECT VERBS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE
FOR EACH WORD YOU HEAR
194
Travel and accommodation
VERBS
GOING ON VACATION (US) / HOLIDAY (UK)
195
WHERE TO STAY
VERBS
196
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
MATCH THE PICTURES TO THE CORRECT VERBS
197
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
198
Travel and tourism
USEFUL EXPRESSIONS
[to go somewhere relaxing for a break]
[unique and unrepeatable]
[a feeling of confusion or distress
when visiting a different place or culture]
[in a bad condition through lack of
care or repair]
[a desire to travel or move]
[a place that attracts too
many tourists]
[to be sad because you miss
your home and family]
[a long way from other people,
buildings, and roads]
[not changed, damaged,
or built on by people]
[a desire for exciting experiences]
199
[to explore an area or place]
[to pause a trip in one
place before continuing]
[at a time of year when a tourist
destination is less popular]
[a stage in a trip from
one place to another]
[to feel excited about something
that is going to happen]
[to go to the station or airport to
say goodbye to someone]
[a vacation, particularly a short one]
[to find out how interesting
something is]
[to book something several days
or weeks before you need it]
[totally unable to find your way]
200
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
REWRITE THE SENTENCES, CORRECTING THE ERRORS
201
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
202
Camping and cycling
CAMPING
203
CYCLING
204
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE CORRECT WORD UNDER EACH PICTURE
205
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
206
Beach
AT THE BEACH
207
208
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
209
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
210
Weather and climate
WEATHER
211
TEMPERATURE ADJECTIVES
212
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT WORDS
213
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
214
GEOGRAPHICAL FEATURES
Geographical features
215
216
MARK THE BEGINNING AND ENDING OF EACH GEOGRAPHICAL FEATURE
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT WORD UNDER EACH PICTURE
217
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
218
Environmental concerns
USEFUL EXPRESSIONS
[the increase in the Earth’s temperature]
[gases that cause the greenhouse
effect, heating up the Earth]
[to use a supply of something,
such as fuel or energy]
[to deal with the problem of pollution]
[types of energy that do not
damage the environment]
[changes in the Earth’s weather patterns]
[fuels based on oil, coal, and gas]
[to lower the level of carbon dioxide
produced by your actions]
[energy that does not use fossil fuels]
[energy from sources that do
not run out]
219
[causing damage to the environment]
[energy created using sunlight]
[energy created using the wind]
[at risk of extinction]
[the act of damaging something
so badly that it cannot survive
or be repaired]
[very bad results]
[a panel that turns
sunlight into electricity]
[a place with many turbines for
generating wind power]
[no longer existing]
[permanent change that cannot
be undone]
220
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT SENTENCES
221
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT
DESCRIBE EACH PICTURE
222
Pets and farm animals
PETS AND FARM ANIMALS
223
ANIMAL VERBS ANIMAL EQUIPMENT
224
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
225
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
226
WILD ANIMALS
Wild animals
227
VERBS
228
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN IN
EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
229
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
230
Birds and bugs
BIRDS
231
INSECTS AND BUGS
VERBS FOR BIRDS AND BUGS
232
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
MATCH THE PICTURES TO THE CORRECT VERBS
BIRDSBUGS
233
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
MARK THE WORDS YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
234
Fish, whales, and sea creatures
FISH AND SEA CREATURES
235
WHALES
236
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
237
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
WRITE THE CORRECT WORD
UNDER EACH PICTURE
238
FREE TIME ACTIVITIES
Free time activities
239
240
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
MATCH THE ACTIVITIES TO THE CORRECT PICTURES
241
LISTEN TO THE AUDIO AND WRITE THE ACTIVITY THAT IS
SHOWN IN EACH PICTURE
WRITE THE CORRECT ACTIVITY UNDER EACH PICTURE
242
Abilities and actions
ABILITIES AND ACTIONS
243
244
LISTEN TO THE AUDIO, THEN NUMBER THE ACTIONS IN THE
ORDER YOU HEAR THEM
WRITE THE CORRECT ACTION UNDER EACH PICTURE
245
MATCH THE ACTIONS TO THE CORRECT PICTURES
MARK THE CORRECT PICTURE FOR EACH ACTION
246
SPORTS
Sports
247
ADVENTURE SPORTS
248
MARK THE BEGINNING AND ENDING OF EACH SPORT IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
249
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
250
Soccer
TIMINGS AND RULES
SOCCER GAME
251
VERBS
252
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
253
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE WORDS TO THE CORRECT PICTURES
254
EQUIPMENT
Sports equipment and venues
255
VENUES
256
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
257
REWRITE THE WORDS, CORRECTING THE SPELLINGS
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
VENUESEQUIPMENT
258
BOOKS
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
259
READING AND GENRES
260
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
261
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
262
Music
VERBS
MUSICAL INSTRUMENTS
263
MUSICAL GENRES
PERFORMANCE
264
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
265
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
266
Movies and plays
MOVIES
267
PLAYS AND SHOWS
268
MATCH THE PICTURES TO THE CORRECT WORDS
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
269
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
270
VERBS
WATCHING TELEVISION
TV
271
TV SHOWS AND CHANNELS
272
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE PICTURES
TO THE CORRECT WORDS
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
273
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
274
Media and celebrity
USEFUL EXPRESSIONS
[to make something more
dramatic or exciting than it is]
[to use something or someone
for your own gain]
[someone who is known by most people]
[to make somebody feel more
important than they are]
[the large text at the top of
a newspaper page]
[to reveal something hidden]
[to become a famous person]
[to be very famous]
[seen and well known by the public]
[news that is widely reported]
275
[the popular culture that surrounds
famous people]
[a competition with performances by
entertainers showcasing their skills]
[photographers who take pictures of
famous people without their consent]
[a carpet for important guests
to walk or stand on at an event]
[an interview that no other source
has obtained]
[the thing that somebody or something
is known for, often said jokingly]
[a show based on or around
real-life events]
[the first night of a show or movie]
[a very rapid rise, often in a career]
[designed or intended to get
your attention quickly]
276
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
277
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
278
Sickness
ADJECTIVES FOR SICKNESS
SICKNESS AND CONDITIONS
279
VERBS FOR SYMPTOMS
SYMPTOMS
ACCIDENTS AND INJURIES
280
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
281
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
INJURIESSICKNESS
282
Medicine and treatment
MEDICINE AND TREATMENT
283
FIRST AID
VERBS
284
MATCH THE WORDS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
285
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
286
Healthy eating
NUTRITION AND DIETS
287
USEFUL EXPRESSIONS
[the amount of food you eat in one meal]
[to eat or drink less of something]
[to stop eating or drinking something]
[to try to avoid gaining weight]
[unable to eat or drink something
without having a bad reaction]
[containing a large amount of something]
[containing a small amount of something]
[containing a lot of something healthy]
[to avoid eating too much of something]
[food that is quick and easy to make]
288
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
289
MARK THE SENTENCES THAT ARE CORRECT
REWRITE THE SENTENCES, CORRECTING THE ERRORS
290
Fitness and well-being
AT THE GYM
VERBS FOR FITNESS
291
WELL-BEING
FITNESS
292
MARK THE CORRECT WORD FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
293
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
294
AROUND TOWN
Around town
295
296
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
297
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
298
Shopping
STORES (US) / SHOPS (UK)
VERBS
299
USEFUL EXPRESSIONS
[searching for goods that are
cheaper than normal]
[an open-air market that sells
old or used items]
[looking at goods in store windows
without buying them]
[having only a small amount of
money to spend]
[to reduce prices dramatically]
[a low-quality product that costs
more than it should]
[a 50 percent reduction]
[a good price]
[costing too much]
[to compare prices at various stores]
300
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT WORD FOR EACH PICTURE
301
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
a good price
to reduce prices dramatically
having only a small amount of money to spend
an open-air market that sells old or used items
to compare prices at various stores
a low-quality product that costs more than it should
searching for goods that are cheaper than normal
costing too much
302
AT THE CHECKOUT
SUPERMARKET
At the supermarket
303
DEPARTMENT STORE
304
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
305
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
306
Urban life
USEFUL EXPRESSIONS
[the period of the day when most
people travel to or from work]
[a larger number of shops,
restaurants, and services]
[the frequency of crimes
in an area]
[a line of traffic that is unable
to move]
[buildings that have not been
repaired for many years]
[containing people or cultures
from around the world]
[an urban area that is outside the
center of a town or city]
[buildings that have been
important in history]
[outdoor areas with grass or vegetation]
[illegal damage to or
destruction of property]
307
[nighttime entertainment such
as bars, cafés, and nightclubs]
[a place that attracts large
numbers of tourists]
[harmful substances in air or water]
[how quickly people lead their lives]
[when there are too many
people in one place]
[repairs that are made to roads]
[a festival that often involves
people dancing in the street] [the chances you have of finding a job]
[active and full of energy]
[the basic services
that a city needs to run well]
308
FILL IN THE GAPS USING THE WORDS IN THE PANEL
MATCH THE PICTURES TO THE CORRECT SENTENCES
309
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
310
Technology and gadgets
DIGITAL TECHNOLOGY
311
VERBS
312
WRITE THE CORRECT WORD UNDER EACH PICTURE
MATCH THE VERBS TO THE CORRECT PICTURES
313
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
314
Technology and the future
USEFUL EXPRESSIONS
[to affect something powerfully] [inventiveness or creation of new ideas]
[to say what you think might
happen in the future]
[a huge change in ideas or methods]
[what will happen in the future]
[eventually, after a long time]
[an era based on digital information,
when technology is dominant]
[extremely modern and innovative]
[the way things are likely to
develop in the future]
[the most recent version of a product]
315
[an important discovery or achievement] [able to use computer technology effectively]
[very modern and up-to-date]
[a person who enjoys using
new technology]
[a person who dislikes or refuses
to use new technology]
[no longer needed or useful
because of a new invention]
[much more advanced than its competitors]
[to design something to work in the
future, even if technology changes]
[sure to happen at some
point in the future]
[the results will only become clear
in the future]
316
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
MATCH THE PICTURES TO THE CORRECT SENTENCES
317
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
318
SCIENCE AND SCIENTIFIC EQUIPMENT
319
VERBS
320
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS, CORRECTING THE SPELLINGS
321
MARK THE CORRECT WORD ILLUSTRATED IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
322
Answers
COUNTRIES:
Russia, United Kingdom / UK, Poland,
Pakistan, Japan
NATIONALITIES:
Russian, British, Polish,
Pakistani, Japanese
323
POSITIVE:
fantastic, breathtaking, incredible,
fun, amazing, exciting
NEGATIVE:
awful, disastrous, annoying,
nasty, disgusting, terrible
324
KITCHEN:
dishwasher, refrigerator / fridge,
stove (US) / cooker (UK),
cabinet (US) / cupboard (UK)
BATHROOM:
bathtub (US) / bath (UK), toilet,
sink, shower
LIVING ROOM:
armchair, cushion,
couch (US) / sofa (UK),
television / TV
BEDROOM:
bed, bedside table,
lamp, wardrobe
KITCHEN:
whisk, knife, frying pan,
bowl, plate, cup
BATHROOM:
mouthwash, conditioner, sponge,
shampoo, soap, toothbrush
TOOLS:
paintbrush, hammer, hacksaw,
plane, file, jigsaw
GARDENING EQUIPMENT:
hoe, rake, sprinkler,
hose, wheelbarrow, trowel
325
326
EQUIPMENT:
baby monitor, bottle, bib,
potty, high chair, wet wipe
TOYS:
spinning top, puppet,
building blocks, playing cards
kite, slide
327
MEAT:
sausages, chicken,
lamb, ham
SEAFOOD:
sardines, salmon,
lobster, sushi
DAIRY:
milk, fried egg,
butter, cheese
FAST FOOD:
hot dog, fries (US) / chips (UK),
pizza, kebab
328
329
330
331
332
333
334
BUGS:
moth, spider, wasp,
caterpillar, ant, snail
BIRDS:
hawk, vulture, penguin,
duck, swan, dove
335
336
EQUIPMENT:
skis, pool cue, fishing rod,
helmet, roller skates, baseball bat
VENUES:
tennis court, ice rink, stadium,
ski slope, golf course, running track
337
SICKNESS:
food poisoning, diabetes,
appendicitis, chickenpox,
mumps, cold
INJURIES:
broken bone, wound, bruise,
burn, sting, cut
338
339
340
artichokes 30
article 63
artist 34
ask directions 46
asparagus 30
assertive 18
assistant 35
asthma 68
ATM 38
attachment 7
attend a meeting 40
attend classes 24
attention to detail 43
attention-grabbing 67
attic 9
attract 78
aubergines 30
audience 65
August 3
aunt 20
Australia 1
author 63
auto repair shop 45
autobiography 63
autumn 3
avenue 46
avocados 30
awful 6
ax / axe 12
Bbaby 20
baby carriage 22
baby changing facilities 74
baby equipment 22
baby monitor 22
babygro 22
back up 76
backache 68
backpack 16, 49
bacon 28
bad 6
bad omen 26
badge 16
badminton 60
bag 32
bagel 31
bait 62
bake 33, 58
baker 73
balanced diet 70
balcony (building) 9
balcony (theater / theatre) 65
bald 17
ball 22, 61, 62
allergies 68, 70
all-inclusive 47
alternative energy 53
always 3
amazed 19
amazing 6
ambitious 43
ambulance 69
American 1
American football 60
amused 19
anemone 57
angry 19
ankle 14
annoyed 19
annoying 6
annual leave 35
annual vacation 35
ant 56
antelope 55
antiseptic 69
antiseptic wipes 69
anxious 19
any other business 40
AOB 40
apartment block 9
apartments 13, 47
appearance 17
appendicitis 68
appetizer 33
applause 65
apple 29
application form 42
apply for a job 42
appointment 69
apprentice 35
approachable 18
apricot 29
April 3
aquarium 54
archery 60
architect 34
architecture 23
Argentina 1
Argentinian 1
arm 14
armadillo 55
armband 62
armchair 9
aromatherapy 71
arrange flowers 58
arrest somebody 27
arrive late 4
arrogant 18
arrow 62
art 23
Numbers refer to the unit number.
Words separated by a forward slash
usually indicate the differences between
US and UK spelling.
Aabilities 59
able to drive 43
abseiling 60
absent 40
accent 25
accessories 16
accident 68
accommodation 13, 47
Accounts (department) 36
accurate 43
ache 68
across from 46
act 59
action movie 65
action points 40
actions 59
actor 34
acupuncture 71
adaptable 43
add 33, 59
adhesive bandage 69
adhesive tape 37, 69
administration 43
Administration (department) 36
adults 20
advertising industry 36
adverts 66
aerobics 71
aeroplane 44
aerospace industry 36
afternoon 3
aftershave 16
against the clock 8
agriculture 36
ahead 46
ahead of the game 41
air bed 49
air mattress 49
airplane 44
airport 44, 72
alarm goes off 4
album 64
Alice band 16
Allen keys 12
allergic to something 70
Word list
341
ball is in your court 41
ballet 65
balloon 22
ballpark figure 41
banana 29
band 64
bandage 69
bank 38, 73
bank loan 38
bank statement 38
bar (goalpost) 61
bar (pub) 33, 72
barbeque 49
bargain 74
bargain-hunting 73
bark 54
baseball 60
baseball bat 62
basement 9, 74
basil 31
basket 49, 54, 74
basketball 60
bat 55
bath 4, 9
bathrobe 15
bathroom 9
bathroom equipment 10
bathtub 9
battery 76, 78
be booked 61
be delayed 47
be laid off 35
be on the fence 8
be sent off 61
beach 50, 52, 58
beach ball 50
beak 56
beaker 78
beans 30
bear 55
beard 17
beautiful 6, 17
beauty 16, 74
beaver 55
become a celebrity 67
bed 4, 9
bed and breakfast 47
bedroom 9
bedside table 9
bee 56
beef 28
beer 32
beetle 56
beginner’s luck 26
behind 46
beliefs 26
believe in something 26
belt 16
bend in the road 46
benefits 35
bestseller 63
between 46
bib 22
bicycle 44, 49
bicycle lane 49
big 5
bike 44, 49
bike rack 49
bilingual 25
bill 33
bills 13, 38
bin 9, 37
bin liner 11
binder clip 37
biography 63
biologist 78
biology 23, 78
bird seed 54
birds 56
birdwatching 58
biscuit 31
bison 55
bite 32, 68
bitter 32
black 5
black hair 17
blackberries 29
blackcurrants 29
bleach 11
bleat 54
bleed 68
blender 10
blink 14
blizzard 51
block 46
block of flats 9
blond hair 17
blood test 69
blouse 15
blow 59
blue 5
blue eyes 17
blue whale 57
blueberries 29
blush (action) 14
blush / blusher (make-up) 16
boar 55
board a plane 47
board games 22, 58
board of directors 40
boarding pass 47
boat 44
bodyboarding 50
body, parts of 14
bodysuit 22
boil 33, 78
boiled egg 28
boiling 51
boiling point 51
bolt 12
bonnet (car) 45
bonus 35
book 63
book a holiday 47
book a vacation 47
book club 58
book in advance 48
bookcase 9
booked 61
bookshop 73
bookstore 73
boot (car) 45
boot camp 71
booties 22
boots 16
bored 19
boring 6
bottle 22, 32
bottle opener 10
bottom of the career ladder 39
boutique 73
bow (archery) 62
bow (gesture) 14
bow tie 16
bowl (container) 10, 32
bowling 60
bowling pins 62
box 32
box office 65
boxer shorts 15
boxes 13
boxing 60
boxing gloves 62
boxing ring 62
boy 20
boyfriend 20
bra 15
bracelet 16
brakes 45, 49
brave 18
Brazil 1
Brazilian 1
bread 31
break down 45
break even 38
break up with someone 21
breakfast 4, 33
breakfast TV 66
342
breakthrough 77
breast 28
breathe 14
breathtaking 6
bribery 27
bridge 72
briefcase 16
brilliant 6
bring someone up 21
bring up someone 21
British 1
broccoli 30
broil 33
broken bone 68
brooch 16
broom 11
brother 20
brother-in-law 20
brown 5
brown eyes 17
brown hair 17
browse the internet 58
bruise 68
brunch 33
brush 11
brush your hair 4
brush your teeth 4
bucket 11
bucket and spade 50
buckle 16
budget 38
buffalo 55
buffet 33
buggy 22
bugs 56
build a fire 49
building blocks 22
building bricks 22
bulb 76
bull 54
bulletin board 37
bump into someone 21
bungalow 13
bungee jumping 60
Bunsen burner 78
burger 28
burglary 27
burn 68, 78
burrow 55
bus 44
bus station 72
bus stop 44
business 41
business as usual 41
business card 7
business studies 23
businesslike attitude 43
businessman 34
businesswoman 34
busk 64
butcher 34, 73
butter 28
butterfly 56
butternut squash 30
button 15
buy 73
buy groceries 4
buzz 56
Ccabbage 30
cabin 47
cabinet 9
cable TV 66
café 4, 33, 72
cage 54
cake 31
calcium 70
calendar 3, 37
call a friend 4
call friends 58
call in sick 35
call your family 4
calm 18, 19, 43
calorie-controlled diet 70
calories 70
camel 44, 55
camera 76
camper van 49
campfire 49
camping 49, 58
camping stove 49
campsite 49
can 32
can opener 10
Canada 1
Canadian 1
candy 31
canoeing 60
canyon 52
cap 16
car 45
car accident 45
car park 45
car theft 27
car wash 45
caravan 49
carbohydrates 70
carbonated 32
cards 58
career path 39
career summary 42
caring 18
carnival 75
carrier bag 74
carrots 30
carry 59
carton 32
cartoon 65, 66
cash machine 38
cash register 38, 74
cashew nut 29
cashier 74
cast 65
castle 72
casual 17
cat 54
catch 59
catch a train 44
catch the bus 4
catch the train 4
catch-up TV 66
catering industry 36
caterpillar 56
cauliflower 30
cautious 18
cave 52
celebrity 67
celebrity culture 67
cell phone 37
cell phone number 7
cello 64
cells 78
Celsius 51
cemetery 72
century 3
cereal 31
chain 49
chair 9, 37
chalet 47
change (clothes) 15
change a lightbulb 12
change channel 66
change money 38
change of pace 41
change the sheets 11
changing mat 22
changing room 71, 74
changing table 22
channel 66
chapter 63
chat show 66
check (payment) 38
check (restaurant) 33
check in 47
check out 47
check out something 48
check something out 48
check the oil 45
check the tires / tyres 45
343
check your emails 4
checked / checkered 15
checkout 74
cheek 14
cheerful 19
cheese 28
cheesecake 31
cheetah 55
chef 33, 34
chemical industry 36
chemicals 78
chemist 78
chemistry 23, 78
cheque 38
cherries 29
chess 58
chest 14
chest of drawers 9
chew 32
chicken 28, 54, 56
chickenpox 68
child-care provider 34
children 20
children’s department 74
children’s show 66
children’s TV 66
chili / chilli flakes 31
chill out 71
chilled 32
chilly 51
chin 14
China 1
Chinese 1
chipmunk 55
chips 28
chives 31
chocolate 31
choir 64
cholesterol 70
choose 73
chop 33
chopping board 10
chopsticks 10
chores 11
church 72
chutney 31
cilantro 31
cinema 65, 72
circle 65
circuit training 71
city 7, 72
city centre 72
claim to fame 67
clam 57
clap 14
clarinet 64
class 23
classical 64
classroom 23
claw(s) 54, 56, 57
clean 5
clean the bathroom 11
clean the windows 11
clean up 11
cleaner 34
cleaning 11
cleaning fluid 11
clear distinction 24
clear the table 4, 11
click 76
click with someone 21
client 35
cliff 52
climate 51
climate change 53
climb 59
climbing frame 22
clinch the deal 41
clinic 69
clipboard 37
cloning 78
close friend 21
closed 74
cloth 11
clothes 15
clothes line 11
cloud 51
cloudy 51
coach 44
coat 15
cockpit 44
cockroach 56
coconut 29
cod 28
coffee 4, 32
coins 38
cola 32
colander 10
cold (sickness) 68
cold (temperature) 5, 51
cold feet 8
collaborate 42
collar (pet) 54
collar (shirt) 15
colleague 35
collect stamps 58
college 23
coloring / colouring book 63
colors / colours 5
comb 16
comedy 65, 66
comic 63
commercial break 66
commercial district 72
commit a crime 27
commuters 44
company 35
company name 7
compare and contrast 24
compass 46
competitive 43
compose 64
composer 64
computer 37
computer desk 76
computer literate 77
computing 43
concert 58, 64
concert hall 72
condiments 31
conditioner 10
conduct 64
conductor 64
conference call 40
confident 18, 19, 43
confused 19
confusing 6
considerate 18
construction industry 36
construction worker 34
consume 53
contact 7
containers 32
continuous assessment 24
convenience food 70
convenient 74
conversational 25
cook 58
cook dinner 4
cookbook 63
cooker 9
cookie 31
cooking show 66
cool 51, 78
cool down 71
coordinate 42
copy 59
coriander 31
corkscrew 10
corn 30
corner 46, 61
corner kick 61
corner the market 41
correction fluid 37
cosmetics 74
cosmopolitan 75
costume drama 66
costumes 65
cot 22
cottage 13
cottage cheese 28
344
cotton 15
cotton pads 69
cotton wool 69
couch 9
couch potato 66
cough 14, 68
counseling / counselling 71
count 59
countries 1
country 64
countryside 52
courgettes 30
course book 63
cousin 20
cover 63
cover / covering letter 42
cow 54
co-worker 35
crab 28, 50, 57
cranberries 29
crawl 59
cream (colour) 5
cream (dairy) 28
creative 43
credit card 38
crib 22
cricket 60
crime 27, 66
crime drama 65
crime fiction 63
crime rate 75
crime wave 27
criminal record 27
crisps 28
critical 18
croak 54
crockery 10
crocodile 55
croissant 31
crossroads 46
cross-trainer 71
crow (bird) 56
crow (cockerel) 54
cruise 47
cry 14
crystals 78
cucumbers 30
cuff 15
cufflinks 16
culture shock 48
cup 10
cupboard 9
cupcake 31
curious 19
curly hair 17
currant 29
currency 38
current affairs 66
curtain 65
cushion 9
customer 74
customer service 43, 74
customer-focused 43
cut (food preparation) 33
cut (wound) 68
cut corners 8
cut down on something 70
cutlery 10
cutting board 10
cutting-edge 77
cycle pump 49
cycling 49, 60
cycling helmet 49
cycling trails 49
Czech Republic 1
Ddad 20
daily 3
dairy 28, 70
dairy-free 70
dance 59, 64
dark green 5
dark skin 17
data analysis 43
date 29
daughter 20
day 3
day off 35
dead-end job 39
debit card 38
debt 38
decade 3
December 3
decide 59
decimals 2
decision-making 43
deck chair 50
deep 5
deep breathing 71
deer 55
defender 61
degree (qualification) 23, 24
degrees (temperature) 51
delayed 47
delete 7, 76
delicatessen 73
delicious 6, 32
delighted 19
denim 5, 15
dental floss 10
dentist 34
deodorant 10
department store 74
departments (workplace) 36
departure gate 47
deposit 13
depressed 19
derelict buildings 75
desert 52
design and technology 23
designer 34
designer labels 74
desk 9, 37
desktop computer 76
desserts 31, 33
destruction 53
detached houses 13
determined 43
detox 70
diabetes 68
dialog / dialogue 65
diaper 22
diarrhea / diarrhoea 68
diary 37
dictionary 63
diesel 45
dig 59
digital age 77
dine 32
dining room 9
dinner 4, 33
dinnerware 10
diploma 23
dire consequences 53
direct flight 47
direction 46
director 65
dirty 5
disappointed 19
disappointing 6
disastrous 6
discus 60
disgusted 19
disgusting 6, 32
dishes 4, 11
dishonest 18
dishwasher 9
dishwashing liquid 11
dissolve 78
distance 46
distracted 19
diving 60
diving board 62
DNA 78
do 59
do exercise 58
do homework 4
do karaoke 58
do pottery 58
345
do puzzles 58
do something by the book 41
do the dishes 4, 11
do the gardening 58
do the housework 4
do the ironing 11
do the laundry 11
do the weeding 12
do up 15
do yoga 58
doctor 34, 69
doctor’s surgery 69
documentary 66
dog 54
doghouse 54
doll 22
dollhouse / doll’s house 22
dolphin 57
donkey 54
door 9
dorm 47
double room 47
dove 56
download 76
downpour 51
downstairs 9
downtown 72
draft 7
drama 23, 65, 66
draw (art) 58
draw (sports result) 61
drawer 37
drawing pin 37
dress 15
dresser 9
dressing gown 15
drift apart 21
drill 12
drink 32
drink tea or coffee 4
drink water 69
drive 4
drive a car 44
driver 34
driver’s licence / license 45
driving 45
drop a hint 26
drop someone off 45
drought 51
drug dealing 27
drum 64
dry 51
dry cleaners 73
dry the dishes 11
dry your hair 4
drying clip 11
duck 54, 56
dummy 22
dumplings 31
duplex 13
dust 11
duster 11
dustpan 11
Eeagle 56
ear 14
earn 35
earphones 76
earrings 16
ears 54
east 46
eat 32
eat breakfast 4
eat dinner 4
eat lunch 4
eat something in moderation 70
eccentric 18
economic downturn 38
economics 23
ecstatic 19
eczema 68
education 23, 36, 42
eel 57
efficient 43
egg 28
egg white 28
eggplants 30
Egypt 1
Egyptian 1
eight 2
eighteen 2
eighth 2
eighty 2
elbow 14
electric guitar 64
electric shock 78
electrical appliances 74
electrician 34
electronics industry 36
elegant 17
elephant 55
elevator 74
eleven 2
eleventh 2
elliptical 71
email 7
email address 7
embarrassed 19
employee 35
employer 35
employment 35
encore 65
encyclopedia 63
endangered 53
energetic 43
energy 70
energy drink 32
energy industry 36
enforce the law 27
engine 44, 45
engineer 34
engineering 23
English 23
enrol on 24
enroll in 24
en-suite bathroom 47
entertainment industry 36
enthusiastic 18
entrée 33
envelope 37
environment 53
episode 66
eraser 37
e-reader 63, 76
escalator 74
essay 23
estate agent 13
evaporate 78
evening 3
evening class 58
every day 3
every other day 3
exam 23
exchange 73
exchange business cards 7
exchange rate 38
excited 19
exciting 6
exclusive interview 67
excursion 47
exercise 58, 69, 71
exercise bike 71
exercise book 23
exercise class 71
exercise mat 71
exhausted 19
exit 74
expenditure 38
experiment 78
exploit 67
expose 67
extinct 53
extraordinary 6
eyebrow 14
eyelashes 14
eyeliner 16
eyes 14, 17
eyeshadow 16
346
Ffabric 5
face 14
face the music 8
face wash 10
facial hair 17
Facilities (department) 36
factory 72
Fahrenheit 51
fail 23
fair skin 17
fairy tale 26
fall (action) 59
fall (season) 3
fall in love with someone 21
fall out with someone 21
families 20, 21
fans 61
fantastic 6
fantasy 63
far 5
farm animals 54
farmer 34
farming 36
farmland 52
fashion designer 34
fashion industry 36
fast food 28, 33
fast learner 43
fasten 15
fast-paced 75
father 20
feather 56
February 3
feed the cat 4
feed the dog 4
feed the pets 11
feedback 24
feel better 69
feel homesick 48
feel under the weather 8
feelings 19
female 20
ferret 54
ferry 44
festival 64
fever 68
fiber / fibre 70
fiction 63
field (land) 52
field (sports) 61, 62
fifteen 2
fifth 2
fifty 2
fifty percent off 73
fig 29
file 12
files 37
filing cabinet 37
fill out a form 42
fill up 45
film 65
film star 65
fin 57
final whistle 61
finance 38
Finance (department) 36
finance industry 36
find somebody guilty 27
find somebody not guilty 27
fine 27
finger 14
finish work 4
fire station 72
fired 39
firefighter 34
first 2
first aid kit 69
first draft 24
first floor 74
first name 7
fish 28, 54, 57
fish dealer 73
fish slice 10
fish tank 54
fishing 60
fishing industry 36
fishing rod 62
fishmonger 73
fit 15, 73
fit a carpet 12
fitness 71
five 2
fix a puncture 49
fixed menu 33
flag 61
flamingo 56
flap 56
flashlight 49
flask 32, 49
flat tire / tyre 45
flats 13
flavorings 31
flea market 73
flexible 43
flick through 63
flight attendant 34
flip through 63
flip-flops 16, 50
flippers 50, 62
float 62, 78
flood 51
florist 73
flour 31
flu 68
fluent in (languages) 25, 43
flute 64
fly 56, 59
fly a kite 58
fog 51
foggy 51
fold clothes 11
folders 37
folding chair 49
folding table 49
folklore 26
food court 74
food industry 36
food poisoning 68
food stall 33
foot 14
football 60
football boots 62
footpath 46
foraging 58
forehead 14
forest 52
fork (cutlery) 10
fork (gardening) 12
formal 17
fortnight 3
forty 2
forward (email action) 7
forward (soccer player) 61
fossil fuels 53
foundation 16
fountain 72
four 2
fourteen 2
fourth 2
fox 55
fractions 2
frame 49
France 1
fraud 27
freckles 17
free time activities 58
freeway 46
freeze 78
freezer 9
freezing 51
freezing point 51
French 1
fresh 32
fresher 24
freshman 24
Friday 3
fridge 9
fried egg 28
friendly 18
347
friends 4
fries 28
frightened 19
frightening 6
frizzy hair 17
frog 55
front desk 47
frost 51
frosty 51
frown 14
fruit 29
fruit salad 31
frustrated 19
fry 33
frying pan 10
fuel 45
full time 61
fun 6
funny 18
fur 54
furious 19
furnished 13
furniture 9
future-proof 77
Ggadgets 76
gain weight 69
gale 51
gallop 54
game plan 41
game show 66
games 22
garage 45
garbage bag 11
garden 9
gardener 34
gardening 12, 58
garlic 30
gas station 45, 72, 78
gasoline 45
gazelle 55
gear 49
gecko 54
generous 18
genetic engineering 78
geographical features 52
geography 23
geology 23
gerbil 54
German 1
Germany 1
get a degree 24
get ahead 39
get along with someone 21
get away from it all 48
get changed 15
get cold feet 8
get down to business 41
get dressed 4
get fired 35
get in a taxi 44
get into debt 38
get off a bike 49
get off a bus 44
get on a bike 49
get on a bus 44
get on with someone 21
get out of a taxi 44
get the ball rolling 41
get up 4
get your hair cut 17
getaway 48
geyser 52
gill 57
ginger 31
giraffe 55
girl 20
girlfriend 20
give a presentation 40
give and take 39
give birth 21
give notice 13
give someone a lift 44
give someone a ride 44
give someone feedback on something 24
give something up 70
give up something 70
glacier 52
glamorous 17
glass 5, 32
glasses 16
glide 56
global warming 53
gloves 16
glowing reviews 63
gluten-free 70
go abroad 47
go ahead 46
go birdwatching 58
go camping 58
go foraging 58
go home 4
go jogging 58
go left 46
go on a cruise 47
go on a holiday 47
go on a vacation 47
go on an excursion 47
go on holiday 58
go on maternity leave 35
go on vacation 58
go out 4, 38, 58
go past 46
go right 46
go shopping 58
go sightseeing 47
go straight on 46
go the extra mile 39
go to a book club 58
go to a café 4
go to a concert 58
go to a party 58
go to an evening class 58
go to bed 4
go to school 4
go to somebody’s head 67
go to the beach 58
go to the gym 58
go to the shops 11
go to the store 11
go to work 4
goalkeeper 61
goalpost 61
goat 54
goatee 17
goggles 62
golden raisin 29
golf 60
golf club 62
golf course 62
gone off 32
good 6
good deal 73
good ear for languages 25
good omen 26
good source of something 70
goose 54, 56
gooseberries 29
gorilla 55
gossip 26
gossip magazine 63
government building 72
GPS 76
graduate 23, 24
graffiti 27
grammar 25
grandchildren 20
granddaughter 20
grandson 20
grapefruit 29
grapes 29
grassland 52
grate 33
grateful 6, 19
grater 10
gray / grey 5
gray / grey eyes 17
gray / grey hair 17
great 6
348
greater choice 75
Greece 1
Greek 1
green 5
green energy sources 53
green eyes 17
green spaces 75
greengrocer 73
greenhouse gases 53
grill 33
grin 14
ground floor 74
groundsheet 49
group 64
grow up 21
grow your hair 17
guarantee 74
guava 29
guesthouse 47
guidebook 47, 63
guided tour 47
guilty 27
guinea pig 54
guitar 64
guitar player 64
gulp 32
guy rope 49
guyline 49
gym 58, 71
gymnastics 60, 62
Hhacking 27
hacksaw 12
haggle 73
hailstone 51
hair 17
hair band 16
hair cut 17
hair dye 16
hair gel 16
hair spray 16
hairbrush 16
hairdresser 34
half 2
half time 61
ham 28
hammer 12
hamster 54
hand 14
handbag 16
handkerchief 16
handlebar 49
handsome 17
hands-on experience 39
hang clothes 11
hang gliding 60
happy 19
hard drive 76
hard shoulder 46
hardback 63
hardware store 73
hardworking 43
harmful to the environment 53
harmless 6
harmonica 64
harness 62
hat 16
hatch 56
have a bath 4
have a break 4
have a car accident 45
have a day off 35
have a good ear for languages 25
have a heart of gold 8
have a picnic 58
have a shower 4
have a sneaking suspicion 26
have an impact on something 77
have an interview 42
have breakfast 4
have dinner 4
have lunch 4
have serious doubts 26
have serious misgivings 26
have something in common 21
have tea or coffee 4
have your hair cut 17
have your hands full 39
have your name in lights 67
hawk 56
hay fever 68
hazel eyes 17
hazelnut 29
head 14
head over heels 8
headache 68
headlight 45
headline 63
headline news 67
headquarters 35
headset 37
heal 69
healthcare 36
healthy eating 70
hear something on the grapevine 8
heart of gold 8
heart rate 71
heat 78
heatwave 51
heavy 5
hedge 52
helicopter 44
helmet 62
herbal tea 32
herbs 31
here 46
hero 65
hex keys 12
high 5
high blood pressure 68
high chair 22
high heels 16
high in something 70
high jump 60
high tide 52
highbrow 63
highlighter 37
hike 58
hill 52
hip 14
hip-hop 64
hippopotamus 55
hiss 54
historic buildings 75
historic quarter 72
history 23
hit 59
hit the nail on the head 8
hitchhike 44
hockey 60
hockey stick 62
hoe 12
hold 59
hold a position 39
hold your breath 14
hole punch 37
holiday 47, 58
home furnishings 74
home improvements 12
homework 4, 23
honest 18, 43
honey 31
hood (car) 45
hood (clothing) 15
hook 62
hooliganism 27
hoot 56
hop 54
hopelessly lost 48
horoscope 63
horrible 6
horror 65
horse 44, 54
horse riding 60
hose 12
hospital 69, 72
hospitality 36
host 66
hostel 47
349
hot 5, 32
hot air balloon 44, 51
hot chocolate 32
hot dog 28
hot drink container 32, 49
hot tub 71
hotel 47, 72
hour 3
hourly 3
hourly rate 35
house 9
house number 7
household chores 11
household name 67
housemate 13
house-warming party 13
housework 4
Human Resources / HR (department) 36
humidity 51
hummingbird 56
humor / humour 63
humpback whale 57
hundred 2
hunt 55
hurdles 62
hurricane 51
hurt 68
husband 20
hypothesis 78
Iice 51
ice cream 31
ice hockey 60
ice rink 62
ice skates 62
ice tea 32
iceberg 52
iced 32
icy 51
iguana 54
ill 31, 68
illustration 63
immature 18
impact 77
impatient 18
important 6
impulsive 18
in a nutshell 41
in front of 46
in the long run 77
in the public eye 67
in the red 41
inbox 7
including utilities 13
income 38
incredible 6
independent 43
in-depth knowledge 42
India 1
Indian 1
indicate 45
indicator 45
indigestion 68
Indonesia 1
industries 36
infection 68
information technology 23
Information Technology (department) 36
infrastructure 75
inhaler 69
initiative 43
injection 69
injury time 61
innovation 77
innovative 43
insect repellent 49
insects 56
insensitive 18
insomnia 68
insurance 45
intelligent 18
interest rate 38
interested 19
interesting 6
interests 42
intern 35
interpersonal skills 43
interrupt 40
intersection 46
interview 42, 66
intrigued 19
introduce yourself 7
invoice 38
iron 70
iron a shirt 4, 11
ironing 11
ironing board 11
irreversible change 53
irritated 19
irritating 6
island 52
IT 43
IT (department) 36
itchy 68
itchy feet 48
Jjacket 15
jaguar 55
jam 31
janitor 34
January 3
Japan 1
Japanese 1
jar 32
javelin 60
jazz 64
jealous 19
jeans 15
jellyfish 57
jet ski 50
jewelers / jewellers 73
jewelry / jewellery 16
jigsaw (tool) 12
jigsaw puzzle 22
job ad / advert 42
job title 7
jobs 34, 42
jockey shorts 15
jog 71
jogging 58
journalism 36
journalist 34
judge 27, 34
judo 60
juice 32
July 3
jump 59
jump rope 22, 71
jumper 15
junction 46
June 3
junk mail 7
jury 27
Kkangaroo 55
karaoke 58
kayaking 60
kebab 28
keep an eye on 8
keep fit 71
kennel 54
ketchup 31
kettle 10
key 46
key skills 42
keyboard 64, 76
keys 13
kick 59, 61
kickoff 61
350
killer whale 57
kilometer / kilometre 46
kind 18
kitchen 9
kitchen implements 10
kitchen knife 10
kitchenware 74
kite 22, 50
kiwi (bird) 56
kiwi fruit 29
knee 14
knickers 15
knife 10
knit 58
knock on wood 26
koala 55
Llaboratory 23, 78
laces 16
ladder 12
ladle 10
ladybird 56
ladybug 56
laid-back 18
laid off 35, 39
lake 52
lamb 28
lamp 9, 37
land at the airport 47
landlord 13
language barrier 25
languages 23, 25
laptop 37, 76
last name 7
latest model 77
latin 64
laugh 14
laundry 11
laundry basket 11
laundry detergent 11
laundry service 47
law 23, 27
law court 27, 72
lawn 9
lawn mower 12
lawyer 27, 34
lazy 18
lead (electrical) 76
lead (for a pet) 54
leadership 43
lease 13
leash 54
leather 5, 15
leave the house 4
leave work 4
lecture 23
lecturer 23
leeks 30
left 46
leg 14, 28
leg of a journey 48
leg of a trip 48
Legal (department) 36
leggings 15
legs 54
legumes 70
leisure center / centre 72
lemon 29
lemonade 32
lemongrass 31
lend a hand 8
leopard 55
let the cat out of the bag 8
let your hair down 8
letter 7, 37
lettuce 30
level 12
librarian 34
library 23, 72
lick 14, 59
lie down 69
life preserver 50
life ring 50
lifeguard 50
lifejacket 62
lift 44, 59, 74
light 5, 9
light shower 51
lighting 51, 74
light-years ahead 77
lime 29
line 74
linesman 61
lingerie 74
lingua franca 25
lion 55
lips 14
lipstick 16
liquid 78
listen 59, 64
listen to music 58
listen to the radio 4
listening 25
litter box 54
litter tray 54
little 5
lively nightlife 75
living room 9
lizard 55
llama 54
load the dishwasher 11
lobster 28, 57
local 13
lock 49
locker room 71
lockers 71
locust 56
lodger 13
log in 76
log out 76
lonely 19
long 5
long hair 17
long jump 60
look around 48
look forward to something 48
look up to someone 21
loose 5
lorry 44
lose 61
lose weight 69
loud 5
lovely 6
low 5
low in something 70
low tide 52
loyalty card 74
lucky 19
luggage 47
lunch 4, 33
lychees 29
lyrics 64
Mmackerel 28
mad 19
made redundant 35, 39
magnet 78
magnificent 6
mail 7
main character 65
main course 33
main objective 40
main road 46
make 59
make a loss 38
make a reservation 33, 47
make a wish 26
make curtains 12
make friends with someone 21
make models 58
make predictions 77
make the bed 4, 11
make yourself understood 25
male 20
manager 35, 42, 61
mandarin 29
mango 29
351
manufacturing industry 36
maps 46
marbles 22
March 3
margarine 28
Marketing (department) 36
marmalade 31
mascara 16
mascot 61
mash 33
massage 71
materials 5
maternity leave 35
math / maths 23
mature 18
May 3
mayonnaise 31
meadow 52
meals 33, 58
mean 18
measles 68
meat 28
mechanic 34, 45
media 67
medical treatment 69
medication / medicine (healthcare) 69
medicine (subject) 23
mediocre 6
meditate 71
medium height 17
meerkat 55
meet a deadline 24
meet friends 58
meetings 40
melon 29
melt 78
memo 7
memory card 76
men’s wear 74
menu 33
meow 54
meringue 31
metal 5
meteoric rise 67
meter / metre 46
Mexican 1
Mexico 1
microphone 64
microscope 78
microwave 10
middle name 7
middle-aged 17
midfielder 61
migraine 68
mild 51
mile 46
milk 28
milkshake 32
millennium 3
million 2
mince 33
minerals 70
mining industry 36
mint 31
minus 51
minute 3
miserable 19
miss a deadline 24
miss a train 44
mix 33
mobile 22
mobile banking 38
mobile number 7
mobile phone 37
moisturizer 10, 16
mole (animal) 55
mole (skin) 17
molecules 78
molt / moult 54
mom 20
Monday 3
money 38
Mongolia 1
Mongolian 1
mongoose 55
monkey 55
monkey wrench 12
month 3
monthly 3
moods 19
moose 55
mop the floor 11
moped 44
morning 3
mortar 10, 78
mortgage 38
Moses basket 22
mosque 72
mosquito 56
moth 56
mother 20
motivated 43
motor home 49
motor racing 60
motorbike / motorcycle 44
motorway 46
mountain 52
mountain bike 49
mountain range 52
mouse (animal) 54
mouse (computer) 76
mouse mat 76
mouse pad 76
mousse 31
moustache 17
mouth 14
mouthwash 10
move 59
move in 13
move out 13
move the goalposts 41
movie 65
movie star 65
movie theater 65, 72
moving 13
moving truck 13
mow the lawn 12
mug 10
mugging 27
multiplex 65
mum 20
mumps 68
museum 72
mushrooms 30
music 23, 64
music channel 66
music store 64
musical 65
musical instrument 58
musician 34
mussel 28, 57
mustache 17
mustard 31
Nnail 12
nail polish 16
name 7
napkin 33
nappy 22
narrow 5
nasty 6
nationalities 1
native speaker 25
nature documentary 66
nature writing 63
navy blue 5
near 5
neck 14
necklace 16
nectarine 29
negotiate 42
negotiating 43
nephew 20
nervous 18, 19
net 61, 62
Netherlands 1
never 3
New Zealand 1
news 66
352
news anchor 66
newspaper 63
newspaper headline 67
newsreader 66
next to 46
nibble 32
nice 6
niece 20
night 3
nightclub 72
nine 2
nineteen 2
nine-to-five 39
nine-to-five job 35
ninety 2
ninety-nine percent 2
ninth 2
no vacancies 47
nod 14
non-carbonated 32
non-fiction 63
noodles 31
north 46
northeast 46
northwest 46
nose 14
nosebleed 68
nostrils 14
not guilty 27
note 7
notepad 37
notes 38
notice board 37
nought point five 2
novel 63
November 3
numbers 2
numeracy 43
nurse 34, 69
nursery 22
nuts 12, 29
Ooars 62
oasis 52
observe 78
obsolete 77
ocean 52
October 3
octopus 28, 57
odd 6
off (food) 32
off the beaten path 48
off the beaten track 48
off, percent 73
office building 72
office equipment 37
Office Services (department) 36
often 3
oil (car) 45
oil (cooking) 31
ointment 69
old 17
old-fashioned 6
olive skin 17
omelet / omelette 28
on a tight budget 73
on the agenda 40
on the ball 8
on the corner 46
on the fence 8
on the left 46
on the right 46
on the same page 41
once a week 3
once-in-a-lifetime 48
one 2
one hundred 2
one million 2
one percent 2
one point seven 2
one thousand 2
one-way street 46
one-way ticket 47
onions 30
online banking 38
online chat 7
online shopping 74
only a matter of time 77
only child 20
only time will tell 77
open 74
opening night 67
open-plan 13
opera 64, 65
opera house 65
operation 69
opinions 6
opposite 46
optimistic 18
orange (colour) 5
orange (fruit) 29
orangeade 32
orchestra 64
orchestra pit 65
orchestra seating 65
order 33
organization 43
organize 42
organized 43
ostrich 56
otter 57
out of date 77
out of season 48
outbox 7
outgoing 18
outlay 38
outstanding 6
over the top 8
overcast 51
overcrowding 75
overdraft 38
overpriced 73
overtake 45
overtime 4, 35
owl 56
oyster 28, 57
PPA 34
pace of life 75
pacifier 22
pack 13, 59
pack your bags 47
packet 32
paddle 62
page 63
page-turner 63
pail and shovel 50
pain 68
pain in the neck 8
painful 68
painkillers 69
paint 12, 58
paint a room 12
paint the house 12
paintbrush 12
pajamas 15
Pakistan 1
Pakistani 1
pale green 5
pale skin 17
pancakes 31
panda 55
panties 15
pants 15
pantyhose 15
paparazzi 67
papaya 29
paper 5
paper clips 37
paperback 63
paragliding 60
paramedic 34, 69
park (recreation area) 72
park (vehicle) 45
parking attendant 45
parking lot 45
parking meter 45
353
parking space 13
parking ticket 45
parrot 54, 56
parsley 31
partner 20
part-time 35
party 58
pass (overtake) 45
pass (succeed) 23
pass with flying colors / colours 24
passengers 44
passion fruit 29
passionate 18
passport 47
passport control 47
past 46
pasta 31
patient (hospital) 69
patient (personality trait) 18, 43
pavement 46
paws 54
pay 35, 73
pay cut 35
pay rise 35
pay separately 33
peach 29
peak 52
peanut 29
peanut butter 31
pear 29
peas 30
peck 56
pedal 49
pedestrian crossing 45
pedestrianized street 46
pedestrians 44
peel 33
peeler 10
peg 11
pelican 56
pen 37
penalty 61
penalty spot 61
pencil 37
pencil sharpener 37
penguin 56
pepper 31
peppers 30
percentages 2, 73
perform 64
performance 65
perfume 16
perfumery 74
period drama 66
permanent 35
personal assistant 34
personal statement 42
personal trainer 71
personality traits 18
perspire 14
pescatarian 70
pestle 10, 78
pestle and mortar 10
petrol 45
petrol station 45, 72
petroleum engineering 36
pets 54
pharmaceutical industry 36
pharmacy 72
Philippines 1
philosophy 23
phone 37
phone call 7
photocopier 37
photographer 34
phrasebook 47
physical education 23
physical therapy 69
physicist 78
physics 23, 78
physiotherapy 69
pick someone up 45
pick something up quickly 25
pickpocketing 27
picnic 58
picnic basket 50
picnic blanket 50
pig 54
pigeon 56
Pilates 71
pills 69
pilot 34
pin 16
PIN 38
pineapple 29
pink 5
pistachio 29
pitch (sports) 61, 62
pitch a tent 49
pizza 28
plain (adjective) 15
plain (landscape) 52
plan your route 46
plane 12
planner 37
plant bulbs 12
plaster 69
plaster the walls 12
plastic 5
plate 10
plateau 52
platform 44
play (action) 59
play a musical instrument 58
play board games 58
play cards 58
play chess 58
play the trumpet 64
play video games 58
playground 22
playing cards 22
playpen 22
plays (performance) 65
pleasant 6
pleased 19
pliers 12
plot 63
plug in 76
plum 29
plumber 34
poach 33
poached egg 28
pocket 15
point 59
Poland 1
polar bear 55
polar opposites 24
polar region 52
police 27
police officer 34
police station 72
Polish 1
polish 11
polite 18
polka dot 15
pollution 75
pomegranate 29
pond 52
ponytail 17
pool 60
pool cue 62
pop 64
popcorn 65
pork 28
porpoise 57
port 44
portfolio 42
portion 70
Portugal 1
Portuguese 1
post 7
post office 72
postcode 7
postgraduate 24
potatoes 30
pothole 49
pottery 58
potty 22
pour 33, 78
power cord 76
PR 36
354
practical 43
practice / practise 64
pram 22
prawn 28
prescription 69
presentation 40
presenter 66
press-up 71
pretty 6
preview 66
price tag 74
print 7
printer 37
prison 27
problem-solving 43
processed food 70
Production (department) 36
professional 43
professional achievements 42
professional attributes 43
professor 23
proficient in 42
program / programme 65
programme (TV) 66
project management 43
projector 37
promotion 35
pronunciation 25
property 13, 36
props 65
protein 70
proud 19
proven track record 42
prowl 55
prune trees 12
psychologist 34
psychology 23
Public Relations 36
public speaking 43
pudding 33
puddle 51
pull 59
pulling your leg 8
pulses 70
punctual 43
puppet 22
Purchasing (department) 36
pure luck 26
purple 5
purr 54
purse 16, 38
push 59
push-up 71
put on (clothes) 15
put on make-up 4
put the children to bed 4
put up shelves 12
put your foot down 21
puzzles 58, 63
pyjamas 15
Qquack 54
qualification 23
quarter 2
queue 74
quiet 5
quince 29
quiz show 66
Rrabbit 54
rabbit hutch 54
raccoon 55
racing bike 49
rain 51
rain forest / rainforest 52
rainbow 51
raincoat 15
raindrop 51
rainy 51
raise 35
raisin 29
rake 12
ranch house 13
rap 64
rapids 52
raspberries 29
rattle 22
ray 57
razor 10
reach a consensus 40
reach a verdict 27
reaction 78
read 58
read a map 46
read a newspaper 4
reading 25, 63
real estate 13, 36
reality show 67
reality TV 66
realtor 13
reasonable 18
receipt 38, 74
reception 47
receptionist 34
record 64, 66, 78
recover 69
recruitment agency 42
recycling bin 11
recycling industry 36
red 5
red card 61
red carpet 67
red hair 17
red tape 41
redcurrants 29
reduce your carbon footprint 53
reference (landlord) 13
references (employer) 42
reflector 49
reflexology 71
refrigerator 9
refund 73
rehearse 64
relationships 21
relax 71
relaxed 19
relaxing 6
reliable 18, 43
remarkable 6
remember 59
remote 66
removal van 13
renewable energy 53
rent 13
rent a cottage 47
renting 13
repair 59
repel 78
reply 7
reply all 7
reporter 66
Republic of Ireland 1
research 43
Research and Development / R & D 36
residential area 13
resit 23
respectable 6
responsible 43
responsible for 42
rest 69
restaurant 33, 72
results 78
resuscitate 69
retire 35
return ticket 47
review 23
review the minutes 40
revise 23
revolution 77
rhinoceros 55
rice 31
ride 44, 59
ride a bike 44
ride a horse 44, 58
right 46
ring 16
rip-off 73
355
river 52
road sign 45
road work / roadworks 75
roadmap 46
roar 55
roast 33
robbery 27
rock (music) 64
rock climbing 60
rocks 52
ROI 1
roll (action) 33
roll (bread) 31
roller (paint) 12
roller skates 62
roller-skating 60
rolling pin 10
romance 63
romantic comedy 65
romper suit 22
roof 9
room service 47
room with a view 47
roomer 13
roommate 13
rooms 9
round-trip ticket 47
router 76
row houses 13
rowing 60
rowing machine 71
rubber 37
rubber band 37
rubber gloves 11
rucksack 16, 49
rude 18
rug 9
rugby 60
ruler 37
run 59, 71
run in the family 21
run out of time 40
run-down 48
running 60
running a marathon 60
running track 62
runny nose 68
rush hour 75
Russia 1
Russian 1
rusty 25
Ssad 19
saddle 49
safe 47
safety goggles 78
safety pin 69
sailing 60
salad 28
salary 35
sale 74
Sales (department) 36
sales assistant 34
salmon 28, 57
salt 31, 70
salty 32
sand 50
sand dune 52
sandals 16
sandbox 22
sandcastle 50
sandpit 22
sandstorm 51
sandwich 28
sardines 28
satellite TV 66
satire 66
satnav 76
saturated fat 70
Saturday 3
saucepan 10
sauna 71
sausages 28
save 38
savory / savoury 32
saw 12
saxophone 64
scale (fish) 57
scales (measure) 46, 69
scallops 28
scanner 37
scared 19
scarf 16
school 4, 23
school of fish 57
science 23, 78
science fiction 63, 65
scientist 34, 78
scissors 10, 37, 69
score a goal 61
scouring pad 11
scrambled eggs 28
scratch 54
screen 65, 66, 76
screw 12
screwdriver 12
script 65
scrub the floor 11
scuba diving 60
sea 50, 52
sea creatures 57
sea lion 57
sea urchin 57
seafood platter 28
seagull 56
seahorse 57
seal 57
seasons 3, 66
seatbelt 45
second 2
second floor 74
secretive 18
security 61
security guard 34
see 59
see a play 58
see eye to eye with someone 21
see off somebody 48
see somebody off 48
seesaw 22
self-help 63
selfish 18
sell 73
semester 24
semi-detached houses 13
send 7
sensationalize 67
sensitive 18
sent off 61
sentence somebody to something 27
September 3
series 66
serious 18, 19
serious doubts 26
serious misgivings 26
serve a sentence 27
service charge 33
service the car 45
service-oriented 42
set menu 33
set of beliefs 26
set off 45
set the table 11
set your sights on something 39
sets 65
seven 2
seventeen 2
seventh 2
seventy 2
sew 58
shake 59
shake your head 14
shallow 5
shampoo 10
shape 12
shape of things to come 77
shark 57
sharp 5
shave 4, 17
356
shaving foam 10
shears 12
sheep 54
shell 28, 50, 57
shelves 74
shin 14
ship 44
shipping industry 36
shirt 15
shiver 14
shocked 19
shocking 6
shoe shop 73
shoe store 73
shoes 16
shop 11, 72
shop around 73
shoplifting 27
shopping 58, 73
shopping bag 74
shopping cart 74
shopping channel 66
shopping mall 72
shopping trolley 74
short 5, 17
short hair 17
shorts 15
shoulder (body) 14
shoulder (road) 46
shoulder-length hair 17
shout 59
show of hands 40
shower 4, 9
shower block 49
shower gel 10
shows 65, 66
shredder 37
shrimp 28, 57
shrug 14
shuttlecock 62
shy 18
sick 68
side 33
side order 33
sideburns 17
sidewalk 46
sieve 10
sigh 14
sightseeing 47
signal 45
signature 7
signpost 46
silk 5, 15
silly 18
silverware 10
simmer 33
sing 56, 59, 64
sing in a choir 58
Singapore 1
singer 64
single room 47
sink (action) 78
sink (household fixture) 9
sip 32
sister 20
sister-in-law 20
sit an exam 23
sit down 59
sit on the fence 8
sitcom 66
sit-up 71
six 2
sixteen 2
sixth 2
sixty 2
skateboard 62
skateboarding 60
skating 60
ski slope 62
skiing 60
skip 71
skipping rope 22, 71
skirt 15
skis 62
skydiving 60
skyscraper 72
slash prices 73
sleep well 71
sleeping bag 49
sleeve 15
slice 33
slide 22
slippers 16
sloth 55
Slovakia 1
slow down 45
small 5
smart 17
smartwatch 76
smell 59
smile 14
smog 51
smoothie 32
smuggling 27
snack 28, 33
snail 56
snake 55
sneakers 16
sneaking suspicion 26
sneeze 14, 68
sniff 54
snore 14
snorkel and mask 50
snorkeling / snorkelling 60
snort 54
snow 51
snowboard 62
snowboarding 60
snowdrift 51
snowed under 39
snowflake 51
snowstorm 51
snowsuit 22
snowy 51
soap 10
soap opera 66
soccer 60, 61
soccer cleats 62
social networking 7
socks 15
sofa 9
soft toy 22
solar panel 53
solar power 53
solid 78
solo 64
sometimes 3
son 20
sorbet 31
sore 68
sore throat 68
soul 64
soup 28
sour 32
south 46
South Africa 1
South Korea 1
southeast 46
southwest 46
soy sauce 31
spa 71
spaghetti 31
Spain 1
spam 7
Spanish 1
spanner 12
sparkling 32
spatula 10
speak 59
speak accurately 25
speaking 25
special 6
special effects 65
special offer 74
specials (menu) 33
speed camera 45
speed limit 45
speed up 45
speeding 27
spell 59
sperm whale 57
357
spices 31
spicy 32
spider 56
spinach 30
spine 63
spinning top 22
spirit level 12
splinter 68
split the bill 33
split the check 33
sponge 10, 11
spoon 10
sports 60, 62
sports center / centre 72
sports drink 32
sports programme 66
sports show 66
spotted 15
sprain 68
spread a rumor / rumour 26
spring 3
sprinkler 12
squash 60
squat 71
squeak 54
squid 28, 57
stadium 62
staff 35
stage 65
stair gate 22
stairs 9
stalls 65
stand up 59
standing ovation 65
stapler 37
staples 37
starfish 57
starfruit 29
start a rumor / rumour 26
start work 4
starter 33
state 7
state-of-the-art 77
static electricity 78
stationery 37
stay (at) home 58
stay in a hotel 47
steam 78
steam room 71
steering wheel 45
step down 39
stepbrother 20
stepmom 20
stepmother 20
stepmum 20
stepsister 20
stethoscope 69
steward 61
stick up for someone 21
sticky notes 37
stifling 51
still (drink) 32
sting 56, 68
stir 33
stitches 69
stock exchange 38
stomach 14
stomachache / stomach ache 68
stop at 46
stop off 48
stoppage time 61
stopwatch 62
storage 13
store 11, 72
stork 56
storm 51
stormy 51
stove 9
straight hair 17
straight on 46
strange 6
strategy 40
strawberries 29
stream 52
street address 7
street crime 27
street map 46, 72
street market 73
stress 68
stressed 19
stretch 71
striker 61
strikingly different 24
striped 15
stroke of luck 26
stroller 22
strong 32
stubble 17
student 23
study 9
study a subject 23
studying 23, 24
stuffed animal 22
stunning 6
stunt 65
style your hair 17
styles 15, 17
stylist 34
subject 7
substitutes 61
subtitles 66
subtract 59
suburb 75
suck 14
sugar 31, 70
suit (clothing) 15
suit (someone) 15
suitcase 47
sultana 29
sum up 40
summer 3
sun 51
sunbathing 50
sun cream 50
Sunday 3
sunglasses 16
sunny 51
sunscreen 50
superb 6
superfoods 70
supermarket 74
supervise 42
supportive 18
surf the internet 58
surfboard 62
surfing 50, 60
surgeon 34
surprised 19
sushi 28
swallow 32
swamp 52
swan 56
sweat 14
sweater 15
sweep the floor 11
sweet 32
sweet potatoes 30
sweetcorn 30
sweets 31
swimming 60
swimming cap 62
swimming gear 62
swimming pool 62, 72
swimming trunks 50, 62
swimsuit 50, 62
swing 55
swings 22
swollen 68
swoop 56
swordfish 57
symptoms 68
synagogue 72
syringe 69
Ttable 9
table tennis 60
tablet (gadget) 76
tablets (medicine) 69
tackle 61
358
tackle pollution 53
tackle something head-on 39
tail (airplane / aeroplane) 44
tail (animal) 54, 55
take a bath 4
take a flight 44
take a shower 4
take a test 24
take a year off 24
take a year out 24
take after someone 21
take an exam 24
take away 33
take minutes 40
take off 15, 39
take on someone 39
take out 33
take out the rubbish 4, 11
take out the trash 4, 11
take photos 58
take questions 40
take someone on 39
take something with a pinch of salt 8
take the bus 44
take the first left 46
take the second right 46
take the train 44
talent show 67
talented 18
talk 59
talk show 66
talkative 18
tall 17
tambourine 64
tan / tanned skin 17
tandem 49
tape measure 12
tapir 55
taste 32, 59
tasty 32
tattletale 26
taxi 44
taxi driver 34
taxi rank 44
taxi stand 44
tea 4, 32
teacher 23, 34
teacher’s pet 8
team player 43
teamwork 43
technology 23, 76, 77
technophile 77
technophobe 77
teddy bear 22
teenagers 20
teeth 14
telephone 37
telephone manner 43
television 9, 66 see also TV
tell a white lie 26
telltale 26
temperature 51, 68
temple 72
temporary 35
ten 2
tenancy agreement 13
tenant 13
tennis 60
tennis court 62
tennis racket 62
tent 49
tent peg 49
tent pole 49
tenth 2
term 24
terraced houses 13
terrarium 54
terrible 6
terrified 19
test 23
test results 69
test tubes 78
text message 7
textbook 23, 63
Thailand 1
theater / theatre 65, 72
there 46
thermometer 69
thesis 23
thick 5
thigh 14
thin 5
think 59
think outside the box 41
think the world of someone 21
third 2
thirst for adventure 48
thirteen 2
thirty 2
thousand 2
three 2
three times a week 3
thrilled 19
thriller 65, 66
thrilling 6
throw 59
throw money down the drain 41
throw-in 61
thumb 14
thumbtack 37
thunder 51
thundery 51
Thursday 3
ticket 44
tidy 11
tie (clothing) 15
tie (sports result) 61
tie your hair back 17
tiger 55
tight 5
tights 15
tile the bathroom 12
till 38, 74
time 3
time management 43
tin 32
tin opener 10
tip 33
tire 45, 49
tired 19
tiring 6
title 7
toast 31
toaster 10
toddler 20
toe 14
toilet 9
toilet block 49
toilet paper 10
toiletries 10
tomatoes 30
tonsillitis 68
tool box 12
tools 12
tooth 14
toothbrush 10
torch 49
tornado 51
tortoise 54
toucan 56
touch base 41
touch wood 26
tour guide 34
tourism 48
tourism industry 36
tourist attraction 75
tourist information 72
tourist office 72
tourist trap 48
towel 9, 50
town 72
town hall 72
town square 72
toy shop 73
toy store 73
toys 22
traffic jam 45, 75
traffic lights 45
tragedy 65
train 44, 71
train driver 34
359
train set 22
train station 44, 72
trained in 42
trainers 16
tram 44
transfer money 38
translation 25
transportation 44
transportation industry 36
trash 7
trash can 9, 37
travel 44, 47, 48
travel agent 34
travel writing 63
trays 37
treadmill 71
treatment 69
trial 27
trim a hedge 12
triplets 20
trombone 64
trousers 15
trout 57
trowel 12
truck 44
trumpet 64
trunk 45, 55
try on 73
t-shirt 15
Tuesday 3
tumble dryer 11
tuna 57
turkey 54
Turkey 1
Turkish 1
turn / turning 46
turn left 46
turn off 66, 76
turn on 66, 76
turn right 46
turn signal 45
turn up the volume 66
turtle 57
tusk 55
TV 9, 66
TV guide 63, 66
TV schedule 66
TV set 66
tweezers 69
twelfth 2
twelve 2
twentieth 2
twenty 2
twenty-first 2
twenty-one 2
twenty-two 2
twice a week 3
twin beds 47
twins 20
two 2
two hundred 2
two weeks 3
tyre 45, 49
UUAE 1
ugly 6
UK 1
umbrella 16
unanimous agreement 40
unapproachable 18
unblock the sink 12
uncle 20
unclog the sink 12
undergraduate 24
understand 59
undo 15
unenthusiastic 19
unfasten 15
unfriendly 18
unfurnished 13
unhappy 19
unicycle 49
uniform 15
unimpressed 19
United Arab Emirates 1
United Kingdom 1
United States of America 1
university 23
unkind 18
unload the dishwasher 11
unpack 13
unpleasant 6
unreasonable 18
unreliable 18
unsaturated fat 70
unshakable belief 26
unspoiled 48
up 15
up to your ears 39
up to your eyeballs 39
upload 76
upmarket 74
upset 19
upstairs 9
urban life 75
urban myth 26
US 1
USB drive 76
useful 6
useless 6
usher 65
usually 3
Vvacancies 47
vacation 47, 58
vacuum cleaner 11
vacuum the carpet 11
valley 52
van 44
vandalism 27, 75
vegan 70
vegetables 30
vegetarian 70
vet 34
veterinary medicine 23
vice / vise 12
video games 58
video on demand 66
view a house 13
villa 47
village 72
villain 65
vinegar 31
violin 64
virus 68
visit a gallery 58
visit a museum 58
vitamins 70
vocabulary 25
voicemail 7
volcano 52
volleyball 60
volunteer 42
vomit 68
vulture 56
Wwages 35
waist 14
waiter 33, 34
waiting room 69
waitress 33, 34
wake up 4
walk 44, 58
walk the dog 4
walking boots 49
walking holiday 47
walking vacation 47
wallet 16, 38
walnut 29
walrus 57
want 73
wardrobe 9
warm 51
warm up 71
wash the car 11
wash the dishes 4
360
The publisher would like to thank:
Sarah Edwards, Carrie Lewis, Daniel Mills, Aisvarya Misra, and Christine Stroyan for editorial assistance; Rabia Ahmad, Debjyoti
Mukherjee, and Sonakshi Singh for design assistance; Simon Mumford for national flags; Viola Wang for additional illustration;
Steph Lewis for proofreading; Elizabeth Wise for indexing; Christine Stroyan for audio recording management; and ID Audio for
audio recording and production.
wash your face 4
wash your hair 4
washing line 11
washing machine 11
washing up liquid 11
wasp 56
watch 16
watch a movie 58
watch television / TV 4, 58
watch your weight 70
water 32
water cooler 37
water the flowers 12
water the plants 11
waterfall 52
watermelon 29
waterproofs 49
wave (gesture) 14
wave (water) 50, 52
wavy hair 17
wear 15
weather 51, 66
weather forecast 66
website 7
Wednesday 3
weeding 12
week 3
weekend 3
weekly 3
weights 71
well-being 71
west 46
western 65
wet 51
wet suit 50
wet wipe 22
whales 57
what the future holds 77
wheel 45
wheel clamp 45
wheelbarrow 12
whisk (action) 33
whisk (equipment) 10
whiskers 54
whisper 59
white 5
white-collar crime 27
wide 5
wide range 74
widow 20
widower 20
wife 20
Wi-Fi 76
wild animals 55
wind 51
wind farm 53
wind power 53
windbreak 50
window 9
window seat 47
window shopping 73
windsurfing 50, 60
windy 51
wine 32
wing (airplane / aeroplane) 44
wing (bird) 28, 56
wink 14
winter 3
win-win situation 41
wipers 45
wire 76
wireless 76
withdraw money 38
witness 27
wok 10
wolf 55
women’s wear 74
wonderful 6
wood (landscape) 52
wood (material) 5
wooden spoon 10
woodpecker 56
wool 5
woolen / woollen 15
word of mouth 26
work 4, 59
work from home 35
work full-time 35
work opportunities 75
work out 71
work overtime 4
work part-time 35
work shifts 35
work well under pressure 43
working 39, 41
working environment 39
workplace 43
world of difference 24
worm 56
worried 19
wound 68
wrap (sandwich) 28
wrap up 40
wrench 12
wrinkles 17
write 58
writer 34
writing 25
written communication 43
XX-ray 69
Yyacht 44
yak 55
yard (garden) 9
yard (measurement) 46
yawn 14
year 3
yellow 5
yellow card 61
yoga 58, 71
yogurt 28
yolk 28
young 17
yo-yo 22
Zzebra 55
zip / zipper 15, 16
zip code 7
zucchini 30
Acknowledgments



ENGLISH
FREE AUDIO
website and app
www.dkefe.com
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
Author
Thomas Booth worked for 10 years as an English-language
teacher in Poland and Russia. He now lives in England, where
he works as an editor and English-language materials writer,
notably of course books and vocabulary textbooks.
ENGLISH
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
4
ContentsUS Editors Kayla Dugger, Jenny Siklos
Senior Editor Laura Sandford
Project Editor Thomas Booth
Senior Art Editors Amy Child, Anna Hall
Art Editors Raymond Bryant, Michelle Staples,
Jemma Westing
Illustrators Edward Byrne, Michael Parkin, Gus Scott
Project Manager Christine Stroyan
Jacket Designer Surabhi Wadhwa
Jacket Editor Claire Gell
Jacket Design Development Manager Sophia MTT
Producer, Pre-production Gillian Reid
Producers Alex Bell, Anna Vallarino
Publisher Andrew Macintyre
Art Director Karen Self
Publishing Director Jonathan Metcalf
DK India
Project Art Editor Sanjay Chauhan
Art Editor Meenal Goel
Assistant Art Editor Devika Khosla
Project Editor Nisha Shaw
Illustrator Arun Pottirayil
Jacket Designer Juhi Sheth
Managing Jackets Editor Saloni Singh
Pre-production Manager Balwant Singh
Senior DTP Designer Vishal Bhatia
Managing Art Editor Sudakshina Basu
Managing Editor Rohan Sinha
First American Edition, 2018
Published in the United States by DK Publishing,
345 Hudson Street, New York, New York 10014
18 19 20 21 22 10 9 8 7 6 5 4 3 2 1
001—305538—Jan/2018
Copyright © 2018 Dorling Kindersley Limited
DK, a Division of Penguin Random House LLC
All rights reserved.
Without limiting the rights under copyright reserved above, no
part of this publication may be reproduced, stored in or introduced
into a retrieval system, or transmitted in any form or by any means
(electronic, mechanical, photocopying, recording, or otherwise)
without the prior written permission of the copyright owner.
Published in Great Britain by Dorling Kindersley Limited.
A catalog record for this book is available from the
Library of Congress.
ISBN 978-1-4654-6483-5
DK books are available at special discounts when purchased in
bulk for sales promotions, premiums, fund-raising, or educational
use. For details, contact DK Publishing Special Markets, 345
Hudson Street, NewYork, New York 10014 or SpecialSales@dk.com.
Printed in China
A WORLD OF IDEAS:
SEE ALL THERE IS TO KNOW
www.dk.com
Countries and nationalities 10
Numbers 14
Time expressions 18
Daily routines 22
Describing things: facts 26
Describing things: opinions 30
Sharing information 34
Common English idioms 38
Around the house 42
Kitchen implements and toiletries 46
HOME
How to use this book 8
GETTING STARTED
5
Studying 102
Speaking a foreign language 106
Communication and beliefs 110
Crime and the law 114
The body 62
Clothes 66
Accessories and beauty products 70
Appearance 74
Personality traits 78
Feelings and moods 82
Family tree 86
Family and relationships 90
Baby equipment and toys 94
Education 98
PEOPLE
Chores and cleaning 50
Tools and gardening 54
Moving and renting 58
FOOD AND DRINK
Meat, fish, dairy, and snacks 118
Fruit and nuts 122
Vegetables 126
Bread, desserts, and condiments 130
Drinking and eating 134
Eating in and eating out 138
WORK
Jobs 142
Working conditions 146
6
Transportation and travel 182
Driving a car 186
Maps and directions 190
Travel and accommodation 194
Travel and tourism 198
TRAVEL
THE ENVIRONMENT
Weather and climate 210
Geographical features 214
Environmental concerns 218
ANIMALS
Pets and farm animals 222
Wild animals 226
Birds and bugs 230
Fish, whales, and sea creatures 234
Free time activities 238
Abilities and actions 242
ACTIVITIES
Industries and departments 150
Office equipment 154
Money and finance 158
Working 162
Meeting and presenting 166
Work and business idioms 170
Applying for a job 174
Workplace skills and abilities 178
Camping and cycling 202
Beach 206
7
Answers 322
Word list 340
Acknowledgments 360
ARTS AND THE MEDIA
Books and reading 258
Music 262
Movies and plays 266
TV 270
Media and celebrity 274
Sickness 278
Medicine and treatment 282
Healthy eating 286
Fitness and well-being 290
HEALTH
SCIENCE AND TECHNOLOGY
AROUND TOWN
Around town 294
Shopping 298
At the supermarket 302
Urban life 306
Technology and gadgets 310
Technology and the future 314
Science 318
Sports 246
Soccer 250
Sports equipment and venues 254
8
How to use this book
Teaching spreads
Each unit of English for Everyone: English Vocabulary Builder
consists of a teaching spread and a practice spread. Teaching
spreads give you an illustrated vocabulary list on a particular
topic. Practice spreads include a variety of exercises to reinforce
what you have learned. Supporting audio
for each teaching spread is available on
the website and app. The best way to
learn spoken vocabulary is to listen to the
audio and repeat each word and phrase
on the spread. If you have difficulty
understanding a word or phrase, look it
up in your dictionary or the word list at
the back of this book.
PRACTICE SPREAD
TEACHING SPREAD
258 259
BOOKS
READING AND GENRES
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
Unit number The book is
divided into units. The unit
number helps you keep
track of your progress.
Modules Most teaching spreads are
broken down into modules covering
different aspects of a topic.
Module number Every module is
identified with a unique number, so
you can easily locate the related audio.
Write-on lines You
are encouraged to
write your own
translations of English
words to create your
own reference pages.
Sample sentences
Some modules show
useful English phrases
in the context of a
sample sentence.
Definitions Idiomatic English
phrases are accompanied
by definitions.
Audio support All teaching modules are
supported by audio recordings to help you
recognize and pronounce spoken vocabulary.
Supporting graphics Visual cues
help you understand and
remember new vocabulary.
296 297
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
AROUND TOWN
Around town
9
Practice exercises
Each teaching spread is followed by exercises that help to fix
new words and phrases in your memory. Working through
the exercises will help you to remember what you have
learned and to use and recognize new English vocabulary.
Answers are provided for every exercise.
FREE AUDIO
website and app
www.dkefe.com
Space for writing You are
encouraged to write your answers
in the book for future reference.
Sample answer
The first question
of each exercise
is answered for
you, to help make
the task easy to
understand.
Supporting graphics Visual
cues are given to help you
understand the exercises.
Exercise number Each exercise is
identified with a unique number, so
you can easily locate answers.
Exercise instruction Each exercise
is introduced with a brief instruction,
telling you what you need to do.
Listening exercise This
symbol indicates that
you should listen to an
audio track in order to
answer the questions in
the exercise.
Audio
English for Everyone: English Vocabulary Builder
features extensive supporting audio resources. Every
word and phrase in the teaching spreads is recorded,
and you are encouraged to listen to the audio and
repeat the words and phrases out loud, until you are
confident you understand and can pronounce what
has been said.
LISTENING EXERCISES
This symbol indicates that you should
listen to an audio track in order to
answer the questions in the exercise.
SUPPORTING AUDIO
This symbol indicates that audio
recordings of the words and phrases in a
module are available for you to listen to.
Answers
This book is designed to make
it easy to monitor your progress.
Answers are provided for every
exercise, so you can see how well
you have understood and
remembered the vocabulary you
have learned.
Exercise numbers
Match these numbers
to the unique identifier
at the top-left corner
of each exercise.
Answers Find the answers
to every exercise printed
at the back of the book.
156
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
EACH
MISS
10
Countries and nationalities
COUNTRIES
11
NATIONALITIES
12
FIND EIGHT MORE COUNTRIES IN THE GRID THAT MATCH THE FLAGS
MARK THE CORRECT COUNTRY FOR EACH FLAG
13
WRITE THE WORDS FROM THE
PANEL IN THE CORRECT GROUPS
NATIONALITIESCOUNTRIES
WRITE THE CORRECT
COUNTRY UNDER EACH FLAG
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
14
Numbers
NUMBERS
ORDINAL NUMBERS
15
LARGE NUMBERS
FRACTIONS, DECIMALS, AND PERCENTAGES
16
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
MATCH THE NUMBERS
TO THE CORRECT WORDS
17
LISTEN TO THE AUDIO AND
MARK THE CORRECT NUMBER
FOR EACH WORD YOU HEAR
WRITE THE CORRECT WORDS
NEXT TO EACH NUMBER
WRITE THE CORRECT WORDS UNDER EACH FRACTION
18
Time expressions
THE CALENDAR
19
SEASONS AND FREQUENCY
20
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
21
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
22
DAILY ROUTINES
Daily routines
23
24
MARK THE CORRECT PICTURE FOR EACH EXPRESSION
MATCH THE PICTURES TO THE CORRECT EXPRESSIONS
25
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
26
Describing things: facts
COLORS (US) / COLOURS (UK)
MATERIALS
27
ADJECTIVES
28
REWRITE THE WORDS, CORRECTING THE SPELLINGS
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE WORDS FROM THE
PANEL NEXT TO THEIR OPPOSITES
29
MARK THE CORRECT PICTURE FOR EACH WORD
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
30
OPINION ADJECTIVES
Describing things: opinions
31
GOOD
BAD
32
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
NEGATIVEPOSITIVE
33
LISTEN TO THE AUDIO AND
WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD
UNDER EACH PICTURE
34
Sharing information
BUSINESS CARDS
CONTACT DETAILS
35
FORMS OF COMMUNICATION
SENDING EMAILS
36
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
37
WRITE THE CORRECT WORD UNDER EACH PICTURE
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
38
Common English idioms
COMMON ENGLISH IDIOMS
[to have a sudden loss of confidence] [to feel unwell, sick, or ill]
[to help someone with something] [alert, knowledgeable, or competent]
[a nuisance, annoying, or difficult] [to take care of or watch carefully]
[completely and utterly
in love with someone]
[to describe exactly what is causing
a situation or problem]
[to hear information or news
through gossip or rumor]
[under time pressure
to get something done]
39
[to be kind and good-natured] [to be unwilling to commit or make a decision]
[to not completely believe
something or someone]
[to confront the consequences
of your actions]
[to tease or fool someone]
[to tell a secret to someone who
shouldn’t know about it]
[someone who seeks and gets approval
from a person in a position of authority]
[to do something the easiest or shortest
way, at the expense of high standards]
[an overreaction or a lack of restraint] [to let yourself go or relax]
40
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE PICTURES TO THE CORRECT SENTENCES
41
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
42
Around the house
HOMES, ROOMS, AND FURNITURE
43
44
MATCH THE PICTURES
TO THE CORRECT WORDS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
45
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURES BELOW, THEN WRITE THE NAME OF EACH
OBJECT UNDER THE CORRECT ROOM
KITCHEN BATHROOM LIVING ROOM BEDROOM
46
KITCHEN IMPLEMENTS
Kitchen implements and toiletries
47
TOILETRIES AND BATHROOM EQUIPMENT
48
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT ROOM
MARK THE BEGINNING AND END OF EACH WORD IN THE CHAIN
OF LETTERS, THEN WRITE THE WORDS YOU FIND
BATHROOMKITCHEN
49
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
50
Chores and cleaning
HOUSEHOLD CHORES
51
LAUNDRY AND CLEANING
52
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
REWRITE THE WORDS OR EXPRESSIONS, CORRECTING THE SPELLINGS
53
MATCH THE EXPRESSIONS TO
THE CORRECT PICTURES
LISTEN TO THE AUDIO AND
WRITE THE EXPRESSION THAT IS
SHOWN IN EACH PICTURE
COMPLETE THE EXPRESSION
FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
54
Tools and gardening
TOOLS AND HOME IMPROVEMENT
55
HOME IMPROVEMENT VERBS
GARDENING EQUIPMENT
GARDENING VERBS
56
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
57
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
GARDENING
EQUIPMENTTOOLS
58
Moving and renting
ACCOMMODATION, MOVING, AND RENTING
59
USEFUL EXPRESSIONS
[money that a tenant pays to a landlord
before moving into a property]
[a letter describing your character
and ability to pay your rent]
[an informal party that you give after
moving into a new house or apartment]
[the rent covers the bills such as
electricity, water, and gas]
[houses and apartments that are for sale
or rented out]
[a part of town where most buildings
are houses or apartments]
[belonging to the area where you live]
[a person you share your house
or apartment with]
[a person who pays to live in your house]
[to announce to your landlord that
you wish to move out]
60
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
61
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
houses and apartments that are for sale or
rented out
a letter describing your character and ability
to pay rent
a part of town where most buildings are houses
or apartments
belonging to the area where you live
money that a tenant pays to a landlord before
moving into a property
the rent covers the bills such as electricity, water,
and gas
62
The body
PARTS OF THE BODY
63
VERBS
64
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FROM
THE PANEL FOR EACH LABEL
65
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
66
Clothes
CLOTHES
67
DESCRIBING CLOTHES AND STYLES
VERBS
68
WRITE THE
CORRECT WORD
UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE
THE CORRECT WORD FOR EACH LABEL
REWRITE THE WORDS, CORRECTING
THE SPELLINGS
69
FIND EIGHT MORE WORDS FOR DESCRIBING CLOTHES IN THE GRID
THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
70
ACCESSORIES
Accessories and beauty products
71
MAKE-UP AND BEAUTY PRODUCTS
SHOES
72
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
73
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
74
Appearance
HAIR
VERBS
75
APPEARANCE AND STYLE
EYES
76
WRITE THE CORRECT WORDS
UNDER EACH PICTURE
MATCH THE WORDS TO
THE CORRECT PICTURES
77
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
78
DESCRIBING PERSONALITY
Personality traits
79
80
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
WRITE THE CORRECT WORD UNDER EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
81
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
82
Feelings and moods
FEELINGS AND MOODS
83
84
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
85
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
WRITE THE WORDS FROM
THE PANEL NEXT TO THEIR
OPPOSITES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
86
Family tree
JAMAL’S FAMILY
DEBBIE’S FAMILY ANA’S FAMILY
87
GROWING UP
ROGER’S FAMILY LOGAN’S FAMILY
RELATIONSHIPS
88
FILL IN THE GAPS ON JAMAL’S FAMILY TREE
MATCH THE PICTURES TO THE CORRECT WORDS
89
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
FILL IN THE GAPS ON
LOGAN’S FAMILY TREE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
90
Family and relationships
[to have respect and admiration for someone]
[to have characteristics
of a parent or relative]
[to care for a child and teach them how to behave] [to develop from a child to an adult]
[to begin to love someone] [to end a romantic relationship]
[to have a good relationship
with someone]
[to stop being friends with someone,
often after an argument]
[to slowly become less friendly
or close to someone] [to become friendly with a person]
USEFUL EXPRESSIONS
91
[a friend who you know very well] [to share an interest or opinion]
[to have a child] [to be a common feature of a family]
[to meet someone unexpectedly] [to be strict about something]
[to agree with or have similar opinions
to someone]
[to like someone quickly
and easily]
[to speak out in support of someone]
[to have a very high opinion
of someone]
92
MATCH THE PICTURES TO THE CORRECT SENTENCES
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
93
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
94
Baby equipment and toys
EQUIPMENT AND CLOTHES
95
TOYS AND GAMES
96
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO,
THEN NUMBER THE PICTURES
IN THE ORDER YOU HEAR THEM
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
97
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE CORRECT
PLACES ON THE GRID
TOYSEQUIPMENT
98
SUBJECTS
Education
99
STUDYING AND EXAMS (NOUNS)
STUDYING AND EXAMS (VERBS)
100
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
101
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
WRITE THE CORRECT WORD
UNDER EACH PICTURE
102
Studying
USEFUL EXPRESSIONS
[to have a year away from education or work] [to register to start something]
[someone studying for a
first degree at college or university]
[study carried out following graduation
from a first degree]
[a student in their first year at
college or university]
[a period of time in an academic calendar,
during which classes are held]
[to be awarded a diploma / qualification
after college or university] [to go to lessons or lectures]
[to provide comments and advice on
how somebody is doing something]
[to answer questions or perform
actions to show how much you
know about something]
103
[to finish something within a given time] [to fail to finish something within a given time]
[grading based on work done
over a long period] [to perform excellently on a test]
[a first, rough version of a piece of written work]
[to consider and describe the similarities
and differences between things]
[completely different] [an obvious difference]
[a significant level of difference][surprisingly not alike]
104
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
105
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to fail to finish something within a given time
someone studying for a first degree at college or university
a first, rough version of a piece of written work
a student in their first year at college or university
grading based on work done over a long period
to perform excellently on a test
106
Speaking a foreign language
USEFUL EXPRESSIONS
[language that is not technically perfect,
but clear enough for basic communication]
[able to use a language easily,
without making many mistakes]
[a person who speaks a language
as their first language]
[able to speak two languages fluently] [the set of words that make up a language]
[the ability to understand
spoken language]
[not as fluent in a language
as you used to be]
[the way in which people from a
country or region pronounce a word]
[the way a specific word is spoken]
[the way in which you make
sentences from separate words]
107
[the ability to communicate
using spoken language]
[the ability to understand written materials]
[the ability to communicate
using written words]
[a shared language that allows people from
various countries to understand each other]
[a piece of writing that has been changed
from one language to another]
[difficulty communicating with someone
who speaks another language]
[to be able to express basic information
and ideas to people]
[to speak without making mistakes]
[to be able to learn something in little time]
[to be able to understand languages
without difficulty]
108
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
WRITE THE CORRECT EXPRESSION NEXT TO ITS DEFINITION
the way people from a country or region pronounce a word
able to speak two languages fluently
a person who speaks a language as their first language
the ability to communicate using spoken language
to speak without making mistakes
the set of words that make up a language
able to use a language easily, without making many mistakes
the way in which you make sentences from separate words
109
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
110
Communication and beliefs
USEFUL EXPRESSIONS
[to say something that is not true to
avoid upsetting someone] [to say something indirectly]
[to talk about other people,
often in a negative way]
[to think that something exists
or is true]
[to have an idea about
something with little evidence]
[to wish for good luck, or avoid bad luck] [to hope for something to happen]
[somebody who tells an authority
figure when another person has done
something wrong]
[to have a strong feeling that something
is not right]
[to say things that may not be true]
111
[a group of values] [a firm and unchangeable conviction]
[stories, sayings, and traditions
from a certain area or culture][good fortune with no skill involved]
[a single piece of good fortune]
[good fortune the first
time you do something]
[a positive / negative sign about
something that will happen]
[a modern story that is untrue,
but believed by many]
[a traditional story with magic,
usually written for children]
[information or news transmitted
by people telling other people]
112
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
113
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to hope for something to happen
good fortune with no skill involved
a modern story that is untrue, but believed by many
stories, sayings, and traditions from a certain area or culture
to talk about other people, often in a negative way
to wish for good luck, or avoid bad luck
114
Crime and the law
CRIME
PUNISHMENT AND THE LAW
115
USEFUL EXPRESSIONS
[to break the law] [to spend time in prison]
[to use the power of the law to take
and question somebody] [to make people obey a rule or a law]
[a lot of crimes happening suddenly
in the same area]
[crime committed in a public place]
[financial, nonviolent crime]
[to decide on a punishment in
accordance with the law]
[to decide officially that someone
has (not) broken the law]
[to come to a decision about
somebody’s guilt or innocence]
116
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
117
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
118
Meat, fish, dairy, and snacks
MEAT
FISH AND SEAFOOD
119
DAIRY
FAST FOOD AND LIGHT SNACKS
120
LOOK AT THE PICTURES BELOW, THEN WRITE THE ANSWERS UNDER THE
CORRECT HEADING
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
FAST FOODMEAT DAIRYSEAFOOD
121
MATCH THE PICTURES
TO THE CORRECT WORDS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
122
FRUIT
Fruit and nuts
123
NUTS AND DRIED FRUIT
124
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
125
CIRCLE THE WORD THAT DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
126
Vegetables
VEGETABLES
127
128
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
129
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
130
BREAD, PASTA, AND DESSERTS
Bread, desserts, and condiments
131
FLAVORINGS AND CONDIMENTS
132
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
133
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
134
Drinking and eating
DRINKS
FOOD AND DRINK CONTAINERS
135
FOOD AND DRINK: ADJECTIVES EATING AND DRINKING
136
MATCH THE WORDS TO THE
CORRECT PICTURES
FILL IN THE MISSING LETTERS
FOR EACH WORD
137
WRITE THE CORRECT VERB UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
138
Eating in and eating out
MEALS
FOOD PREPARATION
139
EATING OUT: VERBS
EATING OUT: NOUNS
140
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
141
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
142
Jobs
JOBS
143
144
MARK THE CORRECT JOB FOR THE PERSON IN EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN
THE CHAIN OF LETTERS
145
MATCH THE WORDS TO THE CORRECT PICTURES
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
146
Working conditions
EMPLOYMENT VERBS
147
PAY AND CONDITIONS
[an amount of money paid per hour]
[extras given to employees in
addition to their usual pay]
[an amount of money paid
per week or month]
[a fixed, regular payment, often
expressed as an annual sum]
[a new job at the same company that is
more senior or better paid]
[to lose your job because it is no
longer necessary]
[a reduction in pay]
[an increase in pay]
[additional pay for extra hours worked]
[money added to a person’s salary
as a reward for good performance]
148
FIND SEVEN MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT VERB UNDER EACH PICTURE
149
WRITE THE CORRECT WORD OR PHRASE NEXT TO ITS DEFINITION,
FILLING IN THE MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
extras given to employees in addition to their usual pay
an amount of money paid per week or month
a reduction in pay
an increase in pay
an amount of money paid per hour
additional pay for extra hours worked
150
Industries and departments
INDUSTRIES
151
DEPARTMENTS
[deals with organization and internal
and external communication]
[ensures that all manufacturing
stages run smoothly]
[researches and develops
future products for a company]
[buys goods and raw materials
for manufacturers and
other companies]
[deals with employee relations
and matters such as hiring staff]
[sells products to buyers
and outside markets]
[deals with money matters, from
paying bills to projecting sales]
[carries out cleaning, maintenance, and
building operation services]
[promotes products for
companies to the market]
[ensures that all contracts and
company activities are legal]
[presents and maintains a positive
public image for a company]
[sets up and maintains all
technological systems
in an organization]
152
MATCH THE WORDS TO THE
CORRECT PICTURES
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
153
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
THEY ARE MENTIONED
WRITE THE NAME OF THE DEPARTMENT NEXT TO ITS DEFINITION
ensures that all manufacturing stages run smoothly
deals with employee relations and matters such as hiring staff
deals with money matters, from paying bills to projecting sales
ensures that all contracts and company activities are legal
deals with organization and internal and external communication
presents and maintains a positive public image for a company
sells products to buyers and outside markets
promotes products for companies to the market
154
Office equipment
IN THE OFFICE
EQUIPMENT
155
STATIONERY
156
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
157
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
158
Money and finance
MONEY
159
FINANCE
[money coming into a business]
[to get into a situation where
you owe people money]
[the amount of money that is
available to spend on something ]
[to lose money by spending more
than you earn]
[extra money the bank allows you
to spend]
[the amount of one currency that you
get when you change it for another]
[to earn just enough to cover the
costs of producing a product]
[to no longer be able to exist
as a business]
[an amount of money spent] [a major decline in economic activity]
160
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
161
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
162
Working
USEFUL EXPRESSIONS
[a job with regular hours]
[to suddenly become more successful]
[knowledge and skill gained through
doing something yourself]
[a position with the lowest level
of responsibility or pay]
[to be forced to leave your job
for doing something wrong]
[the conditions in which you work]
[progression within a profession,
in a job, or through a series of jobs]
[a position without many
prospects for promotion]
[to lose your job because the company
can no longer give you work]
[to have a job]
163
[to stop doing a job voluntarily]
[to aim to achieve a particular goal]
[to employ someone]
[to be busy with a task or
many tasks]
[to do more than you are required to do]
[to deal with something directly]
[to make more progress than others]
[very busy with too much work]
[extremely busy]
[compromise]
164
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to make more progress than others
to suddenly become more successful
to employ someone
compromise
to stop doing a job voluntarily
a job with regular hours
165
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
166
Meeting and presenting
USEFUL EXPRESSIONS
[to go to a meeting]
[included in a list of things to discuss]
[a telephone call with a number
of people at the same time]
[a vote made by raising hands in
the air to show agreement]
[to present a formal talk
to an audience]
[not present]
[a group of people who manage
a business or organization]
[when everyone agrees]
[to answer questions]
[to write a record of what is said
during a meeting]
167
[to come to an agreement
about an issue]
[any matter discussed in a meeting
that is not on the agenda]
[the primary aim]
[a plan for achieving a particular goal]
[to give a brief summary]
[to look again at the written record
of a past meeting]
[to conclude or finish something]
[to disturb a meeting or say
something before someone
else has finished speaking]
[proposals for specific
action to be taken] [to have no time left for something]
168
MATCH THE PICTURES TO THE CORRECT SENTENCES
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
169
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
included in a list of things to discuss
to give a brief summary
to go to a meeting
the primary aim
to come to an agreement about an issue
not present
to have no time left for something
to present a formal talk to an audience
proposals for specific action to be taken
a plan for achieving a particular goal
170
Work and business idioms
WORKPLACE IDIOMS
[the normal daily routine at a company]
[administration, paperwork,
or rules and regulations]
[owing money or making a loss]
[it is your turn to do
or say something]
[to start something]
[a situation with no
negative outcome]
[to think about something
in an original way]
[to change the desired end result]
[to start work on something
that needs doing]
[to waste money]
171
BUSINESS IDIOMS
[ahead of your competitors
in a certain field]
[in agreement
about something]
[to do something strictly according
to the rules]
[to talk to someone briefly in order
to catch up or get an update]
[to confirm or settle an
agreement or contract]
[an increase or decrease in speed
from what is normal]
[a strategy worked out beforehand]
[simply and quickly]
[a rough estimate]
[to dominate a particular market]
172
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
173
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
174
Applying for a job
RÉSUMÉ HEADINGS
175
VERBS
USEFUL EXPRESSIONS
[a long list of achievements]
[having a lot of contact with customers]
[an expert understanding of something]
[highly skilled at something]
[taught how to do something]
[having control over someone or something]
176
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE RÉSUMÉ AND WRITE THE CORRECT WORD FROM THE
PANEL FOR EACH LABEL
177
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
WRITE THE CORRECT WORD UNDER EACH PICTURE
178
PROFESSIONAL ATTRIBUTES
Workplace skills and abilities
179
FOR THE WORKPLACE
180
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
181
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
MATCH THE PICTURES TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
182
FORMS OF TRANSPORTATION
Transportation and travel
183
VERBSTRAVEL
184
MATCH THE VERBS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
185
FIND NINE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
186
DRIVING VOCABULARY
Driving a car
187
VERBS
188
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
189
MARK THE CORRECT EXPRESSION FOR EACH PICTURE
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
190
Maps and directions
MAPS AND DIRECTIONS
191
PREPOSITIONS OF PLACE VERBS
192
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
WRITE THE CORRECT WORD UNDER EACH PICTURE
193
MATCH THE PICTURES
TO THE CORRECT VERBS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE
FOR EACH WORD YOU HEAR
194
Travel and accommodation
VERBS
GOING ON VACATION (US) / HOLIDAY (UK)
195
WHERE TO STAY
VERBS
196
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
MATCH THE PICTURES TO THE CORRECT VERBS
197
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
198
Travel and tourism
USEFUL EXPRESSIONS
[to go somewhere relaxing for a break]
[unique and unrepeatable]
[a feeling of confusion or distress
when visiting a different place or culture]
[in a bad condition through lack of
care or repair]
[a desire to travel or move]
[a place that attracts too
many tourists]
[to be sad because you miss
your home and family]
[a long way from other people,
buildings, and roads]
[not changed, damaged,
or built on by people]
[a desire for exciting experiences]
199
[to explore an area or place]
[to pause a trip in one
place before continuing]
[at a time of year when a tourist
destination is less popular]
[a stage in a trip from
one place to another]
[to feel excited about something
that is going to happen]
[to go to the station or airport to
say goodbye to someone]
[a vacation, particularly a short one]
[to find out how interesting
something is]
[to book something several days
or weeks before you need it]
[totally unable to find your way]
200
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
REWRITE THE SENTENCES, CORRECTING THE ERRORS
201
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
202
Camping and cycling
CAMPING
203
CYCLING
204
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE CORRECT WORD UNDER EACH PICTURE
205
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
206
Beach
AT THE BEACH
207
208
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
209
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
210
Weather and climate
WEATHER
211
TEMPERATURE ADJECTIVES
212
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT WORDS
213
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
214
GEOGRAPHICAL FEATURES
Geographical features
215
216
MARK THE BEGINNING AND ENDING OF EACH GEOGRAPHICAL FEATURE
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT WORD UNDER EACH PICTURE
217
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
218
Environmental concerns
USEFUL EXPRESSIONS
[the increase in the Earth’s temperature]
[gases that cause the greenhouse
effect, heating up the Earth]
[to use a supply of something,
such as fuel or energy]
[to deal with the problem of pollution]
[types of energy that do not
damage the environment]
[changes in the Earth’s weather patterns]
[fuels based on oil, coal, and gas]
[to lower the level of carbon dioxide
produced by your actions]
[energy that does not use fossil fuels]
[energy from sources that do
not run out]
219
[causing damage to the environment]
[energy created using sunlight]
[energy created using the wind]
[at risk of extinction]
[the act of damaging something
so badly that it cannot survive
or be repaired]
[very bad results]
[a panel that turns
sunlight into electricity]
[a place with many turbines for
generating wind power]
[no longer existing]
[permanent change that cannot
be undone]
220
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT SENTENCES
221
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT
DESCRIBE EACH PICTURE
222
Pets and farm animals
PETS AND FARM ANIMALS
223
ANIMAL VERBS ANIMAL EQUIPMENT
224
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
225
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
226
WILD ANIMALS
Wild animals
227
VERBS
228
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN IN
EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
229
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
230
Birds and bugs
BIRDS
231
INSECTS AND BUGS
VERBS FOR BIRDS AND BUGS
232
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
MATCH THE PICTURES TO THE CORRECT VERBS
BIRDSBUGS
233
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
MARK THE WORDS YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
234
Fish, whales, and sea creatures
FISH AND SEA CREATURES
235
WHALES
236
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
237
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
WRITE THE CORRECT WORD
UNDER EACH PICTURE
238
FREE TIME ACTIVITIES
Free time activities
239
240
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
MATCH THE ACTIVITIES TO THE CORRECT PICTURES
241
LISTEN TO THE AUDIO AND WRITE THE ACTIVITY THAT IS
SHOWN IN EACH PICTURE
WRITE THE CORRECT ACTIVITY UNDER EACH PICTURE
242
Abilities and actions
ABILITIES AND ACTIONS
243
244
LISTEN TO THE AUDIO, THEN NUMBER THE ACTIONS IN THE
ORDER YOU HEAR THEM
WRITE THE CORRECT ACTION UNDER EACH PICTURE
245
MATCH THE ACTIONS TO THE CORRECT PICTURES
MARK THE CORRECT PICTURE FOR EACH ACTION
246
SPORTS
Sports
247
ADVENTURE SPORTS
248
MARK THE BEGINNING AND ENDING OF EACH SPORT IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
249
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
250
Soccer
TIMINGS AND RULES
SOCCER GAME
251
VERBS
252
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
253
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE WORDS TO THE CORRECT PICTURES
254
EQUIPMENT
Sports equipment and venues
255
VENUES
256
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
257
REWRITE THE WORDS, CORRECTING THE SPELLINGS
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
VENUESEQUIPMENT
258
BOOKS
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
259
READING AND GENRES
260
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
261
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
262
Music
VERBS
MUSICAL INSTRUMENTS
263
MUSICAL GENRES
PERFORMANCE
264
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
265
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
266
Movies and plays
MOVIES
267
PLAYS AND SHOWS
268
MATCH THE PICTURES TO THE CORRECT WORDS
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
269
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
270
VERBS
WATCHING TELEVISION
TV
271
TV SHOWS AND CHANNELS
272
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE PICTURES
TO THE CORRECT WORDS
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
273
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
274
Media and celebrity
USEFUL EXPRESSIONS
[to make something more
dramatic or exciting than it is]
[to use something or someone
for your own gain]
[someone who is known by most people]
[to make somebody feel more
important than they are]
[the large text at the top of
a newspaper page]
[to reveal something hidden]
[to become a famous person]
[to be very famous]
[seen and well known by the public]
[news that is widely reported]
275
[the popular culture that surrounds
famous people]
[a competition with performances by
entertainers showcasing their skills]
[photographers who take pictures of
famous people without their consent]
[a carpet for important guests
to walk or stand on at an event]
[an interview that no other source
has obtained]
[the thing that somebody or something
is known for, often said jokingly]
[a show based on or around
real-life events]
[the first night of a show or movie]
[a very rapid rise, often in a career]
[designed or intended to get
your attention quickly]
276
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
277
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
278
Sickness
ADJECTIVES FOR SICKNESS
SICKNESS AND CONDITIONS
279
VERBS FOR SYMPTOMS
SYMPTOMS
ACCIDENTS AND INJURIES
280
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
281
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
INJURIESSICKNESS
282
Medicine and treatment
MEDICINE AND TREATMENT
283
FIRST AID
VERBS
284
MATCH THE WORDS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
285
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
286
Healthy eating
NUTRITION AND DIETS
287
USEFUL EXPRESSIONS
[the amount of food you eat in one meal]
[to eat or drink less of something]
[to stop eating or drinking something]
[to try to avoid gaining weight]
[unable to eat or drink something
without having a bad reaction]
[containing a large amount of something]
[containing a small amount of something]
[containing a lot of something healthy]
[to avoid eating too much of something]
[food that is quick and easy to make]
288
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
289
MARK THE SENTENCES THAT ARE CORRECT
REWRITE THE SENTENCES, CORRECTING THE ERRORS
290
Fitness and well-being
AT THE GYM
VERBS FOR FITNESS
291
WELL-BEING
FITNESS
292
MARK THE CORRECT WORD FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
293
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
294
AROUND TOWN
Around town
295
296
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
297
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
298
Shopping
STORES (US) / SHOPS (UK)
VERBS
299
USEFUL EXPRESSIONS
[searching for goods that are
cheaper than normal]
[an open-air market that sells
old or used items]
[looking at goods in store windows
without buying them]
[having only a small amount of
money to spend]
[to reduce prices dramatically]
[a low-quality product that costs
more than it should]
[a 50 percent reduction]
[a good price]
[costing too much]
[to compare prices at various stores]
300
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT WORD FOR EACH PICTURE
301
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
a good price
to reduce prices dramatically
having only a small amount of money to spend
an open-air market that sells old or used items
to compare prices at various stores
a low-quality product that costs more than it should
searching for goods that are cheaper than normal
costing too much
302
AT THE CHECKOUT
SUPERMARKET
At the supermarket
303
DEPARTMENT STORE
304
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
305
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
306
Urban life
USEFUL EXPRESSIONS
[the period of the day when most
people travel to or from work]
[a larger number of shops,
restaurants, and services]
[the frequency of crimes
in an area]
[a line of traffic that is unable
to move]
[buildings that have not been
repaired for many years]
[containing people or cultures
from around the world]
[an urban area that is outside the
center of a town or city]
[buildings that have been
important in history]
[outdoor areas with grass or vegetation]
[illegal damage to or
destruction of property]
307
[nighttime entertainment such
as bars, cafés, and nightclubs]
[a place that attracts large
numbers of tourists]
[harmful substances in air or water]
[how quickly people lead their lives]
[when there are too many
people in one place]
[repairs that are made to roads]
[a festival that often involves
people dancing in the street] [the chances you have of finding a job]
[active and full of energy]
[the basic services
that a city needs to run well]
308
FILL IN THE GAPS USING THE WORDS IN THE PANEL
MATCH THE PICTURES TO THE CORRECT SENTENCES
309
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
310
Technology and gadgets
DIGITAL TECHNOLOGY
311
VERBS
312
WRITE THE CORRECT WORD UNDER EACH PICTURE
MATCH THE VERBS TO THE CORRECT PICTURES
313
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
314
Technology and the future
USEFUL EXPRESSIONS
[to affect something powerfully] [inventiveness or creation of new ideas]
[to say what you think might
happen in the future]
[a huge change in ideas or methods]
[what will happen in the future]
[eventually, after a long time]
[an era based on digital information,
when technology is dominant]
[extremely modern and innovative]
[the way things are likely to
develop in the future]
[the most recent version of a product]
315
[an important discovery or achievement] [able to use computer technology effectively]
[very modern and up-to-date]
[a person who enjoys using
new technology]
[a person who dislikes or refuses
to use new technology]
[no longer needed or useful
because of a new invention]
[much more advanced than its competitors]
[to design something to work in the
future, even if technology changes]
[sure to happen at some
point in the future]
[the results will only become clear
in the future]
316
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
MATCH THE PICTURES TO THE CORRECT SENTENCES
317
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
318
SCIENCE AND SCIENTIFIC EQUIPMENT
319
VERBS
320
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS, CORRECTING THE SPELLINGS
321
MARK THE CORRECT WORD ILLUSTRATED IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
322
Answers
COUNTRIES:
Russia, United Kingdom / UK, Poland,
Pakistan, Japan
NATIONALITIES:
Russian, British, Polish,
Pakistani, Japanese
323
POSITIVE:
fantastic, breathtaking, incredible,
fun, amazing, exciting
NEGATIVE:
awful, disastrous, annoying,
nasty, disgusting, terrible
324
KITCHEN:
dishwasher, refrigerator / fridge,
stove (US) / cooker (UK),
cabinet (US) / cupboard (UK)
BATHROOM:
bathtub (US) / bath (UK), toilet,
sink, shower
LIVING ROOM:
armchair, cushion,
couch (US) / sofa (UK),
television / TV
BEDROOM:
bed, bedside table,
lamp, wardrobe
KITCHEN:
whisk, knife, frying pan,
bowl, plate, cup
BATHROOM:
mouthwash, conditioner, sponge,
shampoo, soap, toothbrush
TOOLS:
paintbrush, hammer, hacksaw,
plane, file, jigsaw
GARDENING EQUIPMENT:
hoe, rake, sprinkler,
hose, wheelbarrow, trowel
325
326
EQUIPMENT:
baby monitor, bottle, bib,
potty, high chair, wet wipe
TOYS:
spinning top, puppet,
building blocks, playing cards
kite, slide
327
MEAT:
sausages, chicken,
lamb, ham
SEAFOOD:
sardines, salmon,
lobster, sushi
DAIRY:
milk, fried egg,
butter, cheese
FAST FOOD:
hot dog, fries (US) / chips (UK),
pizza, kebab
328
329
330
331
332
333
334
BUGS:
moth, spider, wasp,
caterpillar, ant, snail
BIRDS:
hawk, vulture, penguin,
duck, swan, dove
335
336
EQUIPMENT:
skis, pool cue, fishing rod,
helmet, roller skates, baseball bat
VENUES:
tennis court, ice rink, stadium,
ski slope, golf course, running track
337
SICKNESS:
food poisoning, diabetes,
appendicitis, chickenpox,
mumps, cold
INJURIES:
broken bone, wound, bruise,
burn, sting, cut
338
339
340
artichokes 30
article 63
artist 34
ask directions 46
asparagus 30
assertive 18
assistant 35
asthma 68
ATM 38
attachment 7
attend a meeting 40
attend classes 24
attention to detail 43
attention-grabbing 67
attic 9
attract 78
aubergines 30
audience 65
August 3
aunt 20
Australia 1
author 63
auto repair shop 45
autobiography 63
autumn 3
avenue 46
avocados 30
awful 6
ax / axe 12
Bbaby 20
baby carriage 22
baby changing facilities 74
baby equipment 22
baby monitor 22
babygro 22
back up 76
backache 68
backpack 16, 49
bacon 28
bad 6
bad omen 26
badge 16
badminton 60
bag 32
bagel 31
bait 62
bake 33, 58
baker 73
balanced diet 70
balcony (building) 9
balcony (theater / theatre) 65
bald 17
ball 22, 61, 62
allergies 68, 70
all-inclusive 47
alternative energy 53
always 3
amazed 19
amazing 6
ambitious 43
ambulance 69
American 1
American football 60
amused 19
anemone 57
angry 19
ankle 14
annoyed 19
annoying 6
annual leave 35
annual vacation 35
ant 56
antelope 55
antiseptic 69
antiseptic wipes 69
anxious 19
any other business 40
AOB 40
apartment block 9
apartments 13, 47
appearance 17
appendicitis 68
appetizer 33
applause 65
apple 29
application form 42
apply for a job 42
appointment 69
apprentice 35
approachable 18
apricot 29
April 3
aquarium 54
archery 60
architect 34
architecture 23
Argentina 1
Argentinian 1
arm 14
armadillo 55
armband 62
armchair 9
aromatherapy 71
arrange flowers 58
arrest somebody 27
arrive late 4
arrogant 18
arrow 62
art 23
Numbers refer to the unit number.
Words separated by a forward slash
usually indicate the differences between
US and UK spelling.
Aabilities 59
able to drive 43
abseiling 60
absent 40
accent 25
accessories 16
accident 68
accommodation 13, 47
Accounts (department) 36
accurate 43
ache 68
across from 46
act 59
action movie 65
action points 40
actions 59
actor 34
acupuncture 71
adaptable 43
add 33, 59
adhesive bandage 69
adhesive tape 37, 69
administration 43
Administration (department) 36
adults 20
advertising industry 36
adverts 66
aerobics 71
aeroplane 44
aerospace industry 36
afternoon 3
aftershave 16
against the clock 8
agriculture 36
ahead 46
ahead of the game 41
air bed 49
air mattress 49
airplane 44
airport 44, 72
alarm goes off 4
album 64
Alice band 16
Allen keys 12
allergic to something 70
Word list
341
ball is in your court 41
ballet 65
balloon 22
ballpark figure 41
banana 29
band 64
bandage 69
bank 38, 73
bank loan 38
bank statement 38
bar (goalpost) 61
bar (pub) 33, 72
barbeque 49
bargain 74
bargain-hunting 73
bark 54
baseball 60
baseball bat 62
basement 9, 74
basil 31
basket 49, 54, 74
basketball 60
bat 55
bath 4, 9
bathrobe 15
bathroom 9
bathroom equipment 10
bathtub 9
battery 76, 78
be booked 61
be delayed 47
be laid off 35
be on the fence 8
be sent off 61
beach 50, 52, 58
beach ball 50
beak 56
beaker 78
beans 30
bear 55
beard 17
beautiful 6, 17
beauty 16, 74
beaver 55
become a celebrity 67
bed 4, 9
bed and breakfast 47
bedroom 9
bedside table 9
bee 56
beef 28
beer 32
beetle 56
beginner’s luck 26
behind 46
beliefs 26
believe in something 26
belt 16
bend in the road 46
benefits 35
bestseller 63
between 46
bib 22
bicycle 44, 49
bicycle lane 49
big 5
bike 44, 49
bike rack 49
bilingual 25
bill 33
bills 13, 38
bin 9, 37
bin liner 11
binder clip 37
biography 63
biologist 78
biology 23, 78
bird seed 54
birds 56
birdwatching 58
biscuit 31
bison 55
bite 32, 68
bitter 32
black 5
black hair 17
blackberries 29
blackcurrants 29
bleach 11
bleat 54
bleed 68
blender 10
blink 14
blizzard 51
block 46
block of flats 9
blond hair 17
blood test 69
blouse 15
blow 59
blue 5
blue eyes 17
blue whale 57
blueberries 29
blush (action) 14
blush / blusher (make-up) 16
boar 55
board a plane 47
board games 22, 58
board of directors 40
boarding pass 47
boat 44
bodyboarding 50
body, parts of 14
bodysuit 22
boil 33, 78
boiled egg 28
boiling 51
boiling point 51
bolt 12
bonnet (car) 45
bonus 35
book 63
book a holiday 47
book a vacation 47
book club 58
book in advance 48
bookcase 9
booked 61
bookshop 73
bookstore 73
boot (car) 45
boot camp 71
booties 22
boots 16
bored 19
boring 6
bottle 22, 32
bottle opener 10
bottom of the career ladder 39
boutique 73
bow (archery) 62
bow (gesture) 14
bow tie 16
bowl (container) 10, 32
bowling 60
bowling pins 62
box 32
box office 65
boxer shorts 15
boxes 13
boxing 60
boxing gloves 62
boxing ring 62
boy 20
boyfriend 20
bra 15
bracelet 16
brakes 45, 49
brave 18
Brazil 1
Brazilian 1
bread 31
break down 45
break even 38
break up with someone 21
breakfast 4, 33
breakfast TV 66
342
breakthrough 77
breast 28
breathe 14
breathtaking 6
bribery 27
bridge 72
briefcase 16
brilliant 6
bring someone up 21
bring up someone 21
British 1
broccoli 30
broil 33
broken bone 68
brooch 16
broom 11
brother 20
brother-in-law 20
brown 5
brown eyes 17
brown hair 17
browse the internet 58
bruise 68
brunch 33
brush 11
brush your hair 4
brush your teeth 4
bucket 11
bucket and spade 50
buckle 16
budget 38
buffalo 55
buffet 33
buggy 22
bugs 56
build a fire 49
building blocks 22
building bricks 22
bulb 76
bull 54
bulletin board 37
bump into someone 21
bungalow 13
bungee jumping 60
Bunsen burner 78
burger 28
burglary 27
burn 68, 78
burrow 55
bus 44
bus station 72
bus stop 44
business 41
business as usual 41
business card 7
business studies 23
businesslike attitude 43
businessman 34
businesswoman 34
busk 64
butcher 34, 73
butter 28
butterfly 56
butternut squash 30
button 15
buy 73
buy groceries 4
buzz 56
Ccabbage 30
cabin 47
cabinet 9
cable TV 66
café 4, 33, 72
cage 54
cake 31
calcium 70
calendar 3, 37
call a friend 4
call friends 58
call in sick 35
call your family 4
calm 18, 19, 43
calorie-controlled diet 70
calories 70
camel 44, 55
camera 76
camper van 49
campfire 49
camping 49, 58
camping stove 49
campsite 49
can 32
can opener 10
Canada 1
Canadian 1
candy 31
canoeing 60
canyon 52
cap 16
car 45
car accident 45
car park 45
car theft 27
car wash 45
caravan 49
carbohydrates 70
carbonated 32
cards 58
career path 39
career summary 42
caring 18
carnival 75
carrier bag 74
carrots 30
carry 59
carton 32
cartoon 65, 66
cash machine 38
cash register 38, 74
cashew nut 29
cashier 74
cast 65
castle 72
casual 17
cat 54
catch 59
catch a train 44
catch the bus 4
catch the train 4
catch-up TV 66
catering industry 36
caterpillar 56
cauliflower 30
cautious 18
cave 52
celebrity 67
celebrity culture 67
cell phone 37
cell phone number 7
cello 64
cells 78
Celsius 51
cemetery 72
century 3
cereal 31
chain 49
chair 9, 37
chalet 47
change (clothes) 15
change a lightbulb 12
change channel 66
change money 38
change of pace 41
change the sheets 11
changing mat 22
changing room 71, 74
changing table 22
channel 66
chapter 63
chat show 66
check (payment) 38
check (restaurant) 33
check in 47
check out 47
check out something 48
check something out 48
check the oil 45
check the tires / tyres 45
343
check your emails 4
checked / checkered 15
checkout 74
cheek 14
cheerful 19
cheese 28
cheesecake 31
cheetah 55
chef 33, 34
chemical industry 36
chemicals 78
chemist 78
chemistry 23, 78
cheque 38
cherries 29
chess 58
chest 14
chest of drawers 9
chew 32
chicken 28, 54, 56
chickenpox 68
child-care provider 34
children 20
children’s department 74
children’s show 66
children’s TV 66
chili / chilli flakes 31
chill out 71
chilled 32
chilly 51
chin 14
China 1
Chinese 1
chipmunk 55
chips 28
chives 31
chocolate 31
choir 64
cholesterol 70
choose 73
chop 33
chopping board 10
chopsticks 10
chores 11
church 72
chutney 31
cilantro 31
cinema 65, 72
circle 65
circuit training 71
city 7, 72
city centre 72
claim to fame 67
clam 57
clap 14
clarinet 64
class 23
classical 64
classroom 23
claw(s) 54, 56, 57
clean 5
clean the bathroom 11
clean the windows 11
clean up 11
cleaner 34
cleaning 11
cleaning fluid 11
clear distinction 24
clear the table 4, 11
click 76
click with someone 21
client 35
cliff 52
climate 51
climate change 53
climb 59
climbing frame 22
clinch the deal 41
clinic 69
clipboard 37
cloning 78
close friend 21
closed 74
cloth 11
clothes 15
clothes line 11
cloud 51
cloudy 51
coach 44
coat 15
cockpit 44
cockroach 56
coconut 29
cod 28
coffee 4, 32
coins 38
cola 32
colander 10
cold (sickness) 68
cold (temperature) 5, 51
cold feet 8
collaborate 42
collar (pet) 54
collar (shirt) 15
colleague 35
collect stamps 58
college 23
coloring / colouring book 63
colors / colours 5
comb 16
comedy 65, 66
comic 63
commercial break 66
commercial district 72
commit a crime 27
commuters 44
company 35
company name 7
compare and contrast 24
compass 46
competitive 43
compose 64
composer 64
computer 37
computer desk 76
computer literate 77
computing 43
concert 58, 64
concert hall 72
condiments 31
conditioner 10
conduct 64
conductor 64
conference call 40
confident 18, 19, 43
confused 19
confusing 6
considerate 18
construction industry 36
construction worker 34
consume 53
contact 7
containers 32
continuous assessment 24
convenience food 70
convenient 74
conversational 25
cook 58
cook dinner 4
cookbook 63
cooker 9
cookie 31
cooking show 66
cool 51, 78
cool down 71
coordinate 42
copy 59
coriander 31
corkscrew 10
corn 30
corner 46, 61
corner kick 61
corner the market 41
correction fluid 37
cosmetics 74
cosmopolitan 75
costume drama 66
costumes 65
cot 22
cottage 13
cottage cheese 28
344
cotton 15
cotton pads 69
cotton wool 69
couch 9
couch potato 66
cough 14, 68
counseling / counselling 71
count 59
countries 1
country 64
countryside 52
courgettes 30
course book 63
cousin 20
cover 63
cover / covering letter 42
cow 54
co-worker 35
crab 28, 50, 57
cranberries 29
crawl 59
cream (colour) 5
cream (dairy) 28
creative 43
credit card 38
crib 22
cricket 60
crime 27, 66
crime drama 65
crime fiction 63
crime rate 75
crime wave 27
criminal record 27
crisps 28
critical 18
croak 54
crockery 10
crocodile 55
croissant 31
crossroads 46
cross-trainer 71
crow (bird) 56
crow (cockerel) 54
cruise 47
cry 14
crystals 78
cucumbers 30
cuff 15
cufflinks 16
culture shock 48
cup 10
cupboard 9
cupcake 31
curious 19
curly hair 17
currant 29
currency 38
current affairs 66
curtain 65
cushion 9
customer 74
customer service 43, 74
customer-focused 43
cut (food preparation) 33
cut (wound) 68
cut corners 8
cut down on something 70
cutlery 10
cutting board 10
cutting-edge 77
cycle pump 49
cycling 49, 60
cycling helmet 49
cycling trails 49
Czech Republic 1
Ddad 20
daily 3
dairy 28, 70
dairy-free 70
dance 59, 64
dark green 5
dark skin 17
data analysis 43
date 29
daughter 20
day 3
day off 35
dead-end job 39
debit card 38
debt 38
decade 3
December 3
decide 59
decimals 2
decision-making 43
deck chair 50
deep 5
deep breathing 71
deer 55
defender 61
degree (qualification) 23, 24
degrees (temperature) 51
delayed 47
delete 7, 76
delicatessen 73
delicious 6, 32
delighted 19
denim 5, 15
dental floss 10
dentist 34
deodorant 10
department store 74
departments (workplace) 36
departure gate 47
deposit 13
depressed 19
derelict buildings 75
desert 52
design and technology 23
designer 34
designer labels 74
desk 9, 37
desktop computer 76
desserts 31, 33
destruction 53
detached houses 13
determined 43
detox 70
diabetes 68
dialog / dialogue 65
diaper 22
diarrhea / diarrhoea 68
diary 37
dictionary 63
diesel 45
dig 59
digital age 77
dine 32
dining room 9
dinner 4, 33
dinnerware 10
diploma 23
dire consequences 53
direct flight 47
direction 46
director 65
dirty 5
disappointed 19
disappointing 6
disastrous 6
discus 60
disgusted 19
disgusting 6, 32
dishes 4, 11
dishonest 18
dishwasher 9
dishwashing liquid 11
dissolve 78
distance 46
distracted 19
diving 60
diving board 62
DNA 78
do 59
do exercise 58
do homework 4
do karaoke 58
do pottery 58
345
do puzzles 58
do something by the book 41
do the dishes 4, 11
do the gardening 58
do the housework 4
do the ironing 11
do the laundry 11
do the weeding 12
do up 15
do yoga 58
doctor 34, 69
doctor’s surgery 69
documentary 66
dog 54
doghouse 54
doll 22
dollhouse / doll’s house 22
dolphin 57
donkey 54
door 9
dorm 47
double room 47
dove 56
download 76
downpour 51
downstairs 9
downtown 72
draft 7
drama 23, 65, 66
draw (art) 58
draw (sports result) 61
drawer 37
drawing pin 37
dress 15
dresser 9
dressing gown 15
drift apart 21
drill 12
drink 32
drink tea or coffee 4
drink water 69
drive 4
drive a car 44
driver 34
driver’s licence / license 45
driving 45
drop a hint 26
drop someone off 45
drought 51
drug dealing 27
drum 64
dry 51
dry cleaners 73
dry the dishes 11
dry your hair 4
drying clip 11
duck 54, 56
dummy 22
dumplings 31
duplex 13
dust 11
duster 11
dustpan 11
Eeagle 56
ear 14
earn 35
earphones 76
earrings 16
ears 54
east 46
eat 32
eat breakfast 4
eat dinner 4
eat lunch 4
eat something in moderation 70
eccentric 18
economic downturn 38
economics 23
ecstatic 19
eczema 68
education 23, 36, 42
eel 57
efficient 43
egg 28
egg white 28
eggplants 30
Egypt 1
Egyptian 1
eight 2
eighteen 2
eighth 2
eighty 2
elbow 14
electric guitar 64
electric shock 78
electrical appliances 74
electrician 34
electronics industry 36
elegant 17
elephant 55
elevator 74
eleven 2
eleventh 2
elliptical 71
email 7
email address 7
embarrassed 19
employee 35
employer 35
employment 35
encore 65
encyclopedia 63
endangered 53
energetic 43
energy 70
energy drink 32
energy industry 36
enforce the law 27
engine 44, 45
engineer 34
engineering 23
English 23
enrol on 24
enroll in 24
en-suite bathroom 47
entertainment industry 36
enthusiastic 18
entrée 33
envelope 37
environment 53
episode 66
eraser 37
e-reader 63, 76
escalator 74
essay 23
estate agent 13
evaporate 78
evening 3
evening class 58
every day 3
every other day 3
exam 23
exchange 73
exchange business cards 7
exchange rate 38
excited 19
exciting 6
exclusive interview 67
excursion 47
exercise 58, 69, 71
exercise bike 71
exercise book 23
exercise class 71
exercise mat 71
exhausted 19
exit 74
expenditure 38
experiment 78
exploit 67
expose 67
extinct 53
extraordinary 6
eyebrow 14
eyelashes 14
eyeliner 16
eyes 14, 17
eyeshadow 16
346
Ffabric 5
face 14
face the music 8
face wash 10
facial hair 17
Facilities (department) 36
factory 72
Fahrenheit 51
fail 23
fair skin 17
fairy tale 26
fall (action) 59
fall (season) 3
fall in love with someone 21
fall out with someone 21
families 20, 21
fans 61
fantastic 6
fantasy 63
far 5
farm animals 54
farmer 34
farming 36
farmland 52
fashion designer 34
fashion industry 36
fast food 28, 33
fast learner 43
fasten 15
fast-paced 75
father 20
feather 56
February 3
feed the cat 4
feed the dog 4
feed the pets 11
feedback 24
feel better 69
feel homesick 48
feel under the weather 8
feelings 19
female 20
ferret 54
ferry 44
festival 64
fever 68
fiber / fibre 70
fiction 63
field (land) 52
field (sports) 61, 62
fifteen 2
fifth 2
fifty 2
fifty percent off 73
fig 29
file 12
files 37
filing cabinet 37
fill out a form 42
fill up 45
film 65
film star 65
fin 57
final whistle 61
finance 38
Finance (department) 36
finance industry 36
find somebody guilty 27
find somebody not guilty 27
fine 27
finger 14
finish work 4
fire station 72
fired 39
firefighter 34
first 2
first aid kit 69
first draft 24
first floor 74
first name 7
fish 28, 54, 57
fish dealer 73
fish slice 10
fish tank 54
fishing 60
fishing industry 36
fishing rod 62
fishmonger 73
fit 15, 73
fit a carpet 12
fitness 71
five 2
fix a puncture 49
fixed menu 33
flag 61
flamingo 56
flap 56
flashlight 49
flask 32, 49
flat tire / tyre 45
flats 13
flavorings 31
flea market 73
flexible 43
flick through 63
flight attendant 34
flip through 63
flip-flops 16, 50
flippers 50, 62
float 62, 78
flood 51
florist 73
flour 31
flu 68
fluent in (languages) 25, 43
flute 64
fly 56, 59
fly a kite 58
fog 51
foggy 51
fold clothes 11
folders 37
folding chair 49
folding table 49
folklore 26
food court 74
food industry 36
food poisoning 68
food stall 33
foot 14
football 60
football boots 62
footpath 46
foraging 58
forehead 14
forest 52
fork (cutlery) 10
fork (gardening) 12
formal 17
fortnight 3
forty 2
forward (email action) 7
forward (soccer player) 61
fossil fuels 53
foundation 16
fountain 72
four 2
fourteen 2
fourth 2
fox 55
fractions 2
frame 49
France 1
fraud 27
freckles 17
free time activities 58
freeway 46
freeze 78
freezer 9
freezing 51
freezing point 51
French 1
fresh 32
fresher 24
freshman 24
Friday 3
fridge 9
fried egg 28
friendly 18
347
friends 4
fries 28
frightened 19
frightening 6
frizzy hair 17
frog 55
front desk 47
frost 51
frosty 51
frown 14
fruit 29
fruit salad 31
frustrated 19
fry 33
frying pan 10
fuel 45
full time 61
fun 6
funny 18
fur 54
furious 19
furnished 13
furniture 9
future-proof 77
Ggadgets 76
gain weight 69
gale 51
gallop 54
game plan 41
game show 66
games 22
garage 45
garbage bag 11
garden 9
gardener 34
gardening 12, 58
garlic 30
gas station 45, 72, 78
gasoline 45
gazelle 55
gear 49
gecko 54
generous 18
genetic engineering 78
geographical features 52
geography 23
geology 23
gerbil 54
German 1
Germany 1
get a degree 24
get ahead 39
get along with someone 21
get away from it all 48
get changed 15
get cold feet 8
get down to business 41
get dressed 4
get fired 35
get in a taxi 44
get into debt 38
get off a bike 49
get off a bus 44
get on a bike 49
get on a bus 44
get on with someone 21
get out of a taxi 44
get the ball rolling 41
get up 4
get your hair cut 17
getaway 48
geyser 52
gill 57
ginger 31
giraffe 55
girl 20
girlfriend 20
give a presentation 40
give and take 39
give birth 21
give notice 13
give someone a lift 44
give someone a ride 44
give someone feedback on something 24
give something up 70
give up something 70
glacier 52
glamorous 17
glass 5, 32
glasses 16
glide 56
global warming 53
gloves 16
glowing reviews 63
gluten-free 70
go abroad 47
go ahead 46
go birdwatching 58
go camping 58
go foraging 58
go home 4
go jogging 58
go left 46
go on a cruise 47
go on a holiday 47
go on a vacation 47
go on an excursion 47
go on holiday 58
go on maternity leave 35
go on vacation 58
go out 4, 38, 58
go past 46
go right 46
go shopping 58
go sightseeing 47
go straight on 46
go the extra mile 39
go to a book club 58
go to a café 4
go to a concert 58
go to a party 58
go to an evening class 58
go to bed 4
go to school 4
go to somebody’s head 67
go to the beach 58
go to the gym 58
go to the shops 11
go to the store 11
go to work 4
goalkeeper 61
goalpost 61
goat 54
goatee 17
goggles 62
golden raisin 29
golf 60
golf club 62
golf course 62
gone off 32
good 6
good deal 73
good ear for languages 25
good omen 26
good source of something 70
goose 54, 56
gooseberries 29
gorilla 55
gossip 26
gossip magazine 63
government building 72
GPS 76
graduate 23, 24
graffiti 27
grammar 25
grandchildren 20
granddaughter 20
grandson 20
grapefruit 29
grapes 29
grassland 52
grate 33
grateful 6, 19
grater 10
gray / grey 5
gray / grey eyes 17
gray / grey hair 17
great 6
348
greater choice 75
Greece 1
Greek 1
green 5
green energy sources 53
green eyes 17
green spaces 75
greengrocer 73
greenhouse gases 53
grill 33
grin 14
ground floor 74
groundsheet 49
group 64
grow up 21
grow your hair 17
guarantee 74
guava 29
guesthouse 47
guidebook 47, 63
guided tour 47
guilty 27
guinea pig 54
guitar 64
guitar player 64
gulp 32
guy rope 49
guyline 49
gym 58, 71
gymnastics 60, 62
Hhacking 27
hacksaw 12
haggle 73
hailstone 51
hair 17
hair band 16
hair cut 17
hair dye 16
hair gel 16
hair spray 16
hairbrush 16
hairdresser 34
half 2
half time 61
ham 28
hammer 12
hamster 54
hand 14
handbag 16
handkerchief 16
handlebar 49
handsome 17
hands-on experience 39
hang clothes 11
hang gliding 60
happy 19
hard drive 76
hard shoulder 46
hardback 63
hardware store 73
hardworking 43
harmful to the environment 53
harmless 6
harmonica 64
harness 62
hat 16
hatch 56
have a bath 4
have a break 4
have a car accident 45
have a day off 35
have a good ear for languages 25
have a heart of gold 8
have a picnic 58
have a shower 4
have a sneaking suspicion 26
have an impact on something 77
have an interview 42
have breakfast 4
have dinner 4
have lunch 4
have serious doubts 26
have serious misgivings 26
have something in common 21
have tea or coffee 4
have your hair cut 17
have your hands full 39
have your name in lights 67
hawk 56
hay fever 68
hazel eyes 17
hazelnut 29
head 14
head over heels 8
headache 68
headlight 45
headline 63
headline news 67
headquarters 35
headset 37
heal 69
healthcare 36
healthy eating 70
hear something on the grapevine 8
heart of gold 8
heart rate 71
heat 78
heatwave 51
heavy 5
hedge 52
helicopter 44
helmet 62
herbal tea 32
herbs 31
here 46
hero 65
hex keys 12
high 5
high blood pressure 68
high chair 22
high heels 16
high in something 70
high jump 60
high tide 52
highbrow 63
highlighter 37
hike 58
hill 52
hip 14
hip-hop 64
hippopotamus 55
hiss 54
historic buildings 75
historic quarter 72
history 23
hit 59
hit the nail on the head 8
hitchhike 44
hockey 60
hockey stick 62
hoe 12
hold 59
hold a position 39
hold your breath 14
hole punch 37
holiday 47, 58
home furnishings 74
home improvements 12
homework 4, 23
honest 18, 43
honey 31
hood (car) 45
hood (clothing) 15
hook 62
hooliganism 27
hoot 56
hop 54
hopelessly lost 48
horoscope 63
horrible 6
horror 65
horse 44, 54
horse riding 60
hose 12
hospital 69, 72
hospitality 36
host 66
hostel 47
349
hot 5, 32
hot air balloon 44, 51
hot chocolate 32
hot dog 28
hot drink container 32, 49
hot tub 71
hotel 47, 72
hour 3
hourly 3
hourly rate 35
house 9
house number 7
household chores 11
household name 67
housemate 13
house-warming party 13
housework 4
Human Resources / HR (department) 36
humidity 51
hummingbird 56
humor / humour 63
humpback whale 57
hundred 2
hunt 55
hurdles 62
hurricane 51
hurt 68
husband 20
hypothesis 78
Iice 51
ice cream 31
ice hockey 60
ice rink 62
ice skates 62
ice tea 32
iceberg 52
iced 32
icy 51
iguana 54
ill 31, 68
illustration 63
immature 18
impact 77
impatient 18
important 6
impulsive 18
in a nutshell 41
in front of 46
in the long run 77
in the public eye 67
in the red 41
inbox 7
including utilities 13
income 38
incredible 6
independent 43
in-depth knowledge 42
India 1
Indian 1
indicate 45
indicator 45
indigestion 68
Indonesia 1
industries 36
infection 68
information technology 23
Information Technology (department) 36
infrastructure 75
inhaler 69
initiative 43
injection 69
injury time 61
innovation 77
innovative 43
insect repellent 49
insects 56
insensitive 18
insomnia 68
insurance 45
intelligent 18
interest rate 38
interested 19
interesting 6
interests 42
intern 35
interpersonal skills 43
interrupt 40
intersection 46
interview 42, 66
intrigued 19
introduce yourself 7
invoice 38
iron 70
iron a shirt 4, 11
ironing 11
ironing board 11
irreversible change 53
irritated 19
irritating 6
island 52
IT 43
IT (department) 36
itchy 68
itchy feet 48
Jjacket 15
jaguar 55
jam 31
janitor 34
January 3
Japan 1
Japanese 1
jar 32
javelin 60
jazz 64
jealous 19
jeans 15
jellyfish 57
jet ski 50
jewelers / jewellers 73
jewelry / jewellery 16
jigsaw (tool) 12
jigsaw puzzle 22
job ad / advert 42
job title 7
jobs 34, 42
jockey shorts 15
jog 71
jogging 58
journalism 36
journalist 34
judge 27, 34
judo 60
juice 32
July 3
jump 59
jump rope 22, 71
jumper 15
junction 46
June 3
junk mail 7
jury 27
Kkangaroo 55
karaoke 58
kayaking 60
kebab 28
keep an eye on 8
keep fit 71
kennel 54
ketchup 31
kettle 10
key 46
key skills 42
keyboard 64, 76
keys 13
kick 59, 61
kickoff 61
350
killer whale 57
kilometer / kilometre 46
kind 18
kitchen 9
kitchen implements 10
kitchen knife 10
kitchenware 74
kite 22, 50
kiwi (bird) 56
kiwi fruit 29
knee 14
knickers 15
knife 10
knit 58
knock on wood 26
koala 55
Llaboratory 23, 78
laces 16
ladder 12
ladle 10
ladybird 56
ladybug 56
laid-back 18
laid off 35, 39
lake 52
lamb 28
lamp 9, 37
land at the airport 47
landlord 13
language barrier 25
languages 23, 25
laptop 37, 76
last name 7
latest model 77
latin 64
laugh 14
laundry 11
laundry basket 11
laundry detergent 11
laundry service 47
law 23, 27
law court 27, 72
lawn 9
lawn mower 12
lawyer 27, 34
lazy 18
lead (electrical) 76
lead (for a pet) 54
leadership 43
lease 13
leash 54
leather 5, 15
leave the house 4
leave work 4
lecture 23
lecturer 23
leeks 30
left 46
leg 14, 28
leg of a journey 48
leg of a trip 48
Legal (department) 36
leggings 15
legs 54
legumes 70
leisure center / centre 72
lemon 29
lemonade 32
lemongrass 31
lend a hand 8
leopard 55
let the cat out of the bag 8
let your hair down 8
letter 7, 37
lettuce 30
level 12
librarian 34
library 23, 72
lick 14, 59
lie down 69
life preserver 50
life ring 50
lifeguard 50
lifejacket 62
lift 44, 59, 74
light 5, 9
light shower 51
lighting 51, 74
light-years ahead 77
lime 29
line 74
linesman 61
lingerie 74
lingua franca 25
lion 55
lips 14
lipstick 16
liquid 78
listen 59, 64
listen to music 58
listen to the radio 4
listening 25
litter box 54
litter tray 54
little 5
lively nightlife 75
living room 9
lizard 55
llama 54
load the dishwasher 11
lobster 28, 57
local 13
lock 49
locker room 71
lockers 71
locust 56
lodger 13
log in 76
log out 76
lonely 19
long 5
long hair 17
long jump 60
look around 48
look forward to something 48
look up to someone 21
loose 5
lorry 44
lose 61
lose weight 69
loud 5
lovely 6
low 5
low in something 70
low tide 52
loyalty card 74
lucky 19
luggage 47
lunch 4, 33
lychees 29
lyrics 64
Mmackerel 28
mad 19
made redundant 35, 39
magnet 78
magnificent 6
mail 7
main character 65
main course 33
main objective 40
main road 46
make 59
make a loss 38
make a reservation 33, 47
make a wish 26
make curtains 12
make friends with someone 21
make models 58
make predictions 77
make the bed 4, 11
make yourself understood 25
male 20
manager 35, 42, 61
mandarin 29
mango 29
351
manufacturing industry 36
maps 46
marbles 22
March 3
margarine 28
Marketing (department) 36
marmalade 31
mascara 16
mascot 61
mash 33
massage 71
materials 5
maternity leave 35
math / maths 23
mature 18
May 3
mayonnaise 31
meadow 52
meals 33, 58
mean 18
measles 68
meat 28
mechanic 34, 45
media 67
medical treatment 69
medication / medicine (healthcare) 69
medicine (subject) 23
mediocre 6
meditate 71
medium height 17
meerkat 55
meet a deadline 24
meet friends 58
meetings 40
melon 29
melt 78
memo 7
memory card 76
men’s wear 74
menu 33
meow 54
meringue 31
metal 5
meteoric rise 67
meter / metre 46
Mexican 1
Mexico 1
microphone 64
microscope 78
microwave 10
middle name 7
middle-aged 17
midfielder 61
migraine 68
mild 51
mile 46
milk 28
milkshake 32
millennium 3
million 2
mince 33
minerals 70
mining industry 36
mint 31
minus 51
minute 3
miserable 19
miss a deadline 24
miss a train 44
mix 33
mobile 22
mobile banking 38
mobile number 7
mobile phone 37
moisturizer 10, 16
mole (animal) 55
mole (skin) 17
molecules 78
molt / moult 54
mom 20
Monday 3
money 38
Mongolia 1
Mongolian 1
mongoose 55
monkey 55
monkey wrench 12
month 3
monthly 3
moods 19
moose 55
mop the floor 11
moped 44
morning 3
mortar 10, 78
mortgage 38
Moses basket 22
mosque 72
mosquito 56
moth 56
mother 20
motivated 43
motor home 49
motor racing 60
motorbike / motorcycle 44
motorway 46
mountain 52
mountain bike 49
mountain range 52
mouse (animal) 54
mouse (computer) 76
mouse mat 76
mouse pad 76
mousse 31
moustache 17
mouth 14
mouthwash 10
move 59
move in 13
move out 13
move the goalposts 41
movie 65
movie star 65
movie theater 65, 72
moving 13
moving truck 13
mow the lawn 12
mug 10
mugging 27
multiplex 65
mum 20
mumps 68
museum 72
mushrooms 30
music 23, 64
music channel 66
music store 64
musical 65
musical instrument 58
musician 34
mussel 28, 57
mustache 17
mustard 31
Nnail 12
nail polish 16
name 7
napkin 33
nappy 22
narrow 5
nasty 6
nationalities 1
native speaker 25
nature documentary 66
nature writing 63
navy blue 5
near 5
neck 14
necklace 16
nectarine 29
negotiate 42
negotiating 43
nephew 20
nervous 18, 19
net 61, 62
Netherlands 1
never 3
New Zealand 1
news 66
352
news anchor 66
newspaper 63
newspaper headline 67
newsreader 66
next to 46
nibble 32
nice 6
niece 20
night 3
nightclub 72
nine 2
nineteen 2
nine-to-five 39
nine-to-five job 35
ninety 2
ninety-nine percent 2
ninth 2
no vacancies 47
nod 14
non-carbonated 32
non-fiction 63
noodles 31
north 46
northeast 46
northwest 46
nose 14
nosebleed 68
nostrils 14
not guilty 27
note 7
notepad 37
notes 38
notice board 37
nought point five 2
novel 63
November 3
numbers 2
numeracy 43
nurse 34, 69
nursery 22
nuts 12, 29
Ooars 62
oasis 52
observe 78
obsolete 77
ocean 52
October 3
octopus 28, 57
odd 6
off (food) 32
off the beaten path 48
off the beaten track 48
off, percent 73
office building 72
office equipment 37
Office Services (department) 36
often 3
oil (car) 45
oil (cooking) 31
ointment 69
old 17
old-fashioned 6
olive skin 17
omelet / omelette 28
on a tight budget 73
on the agenda 40
on the ball 8
on the corner 46
on the fence 8
on the left 46
on the right 46
on the same page 41
once a week 3
once-in-a-lifetime 48
one 2
one hundred 2
one million 2
one percent 2
one point seven 2
one thousand 2
one-way street 46
one-way ticket 47
onions 30
online banking 38
online chat 7
online shopping 74
only a matter of time 77
only child 20
only time will tell 77
open 74
opening night 67
open-plan 13
opera 64, 65
opera house 65
operation 69
opinions 6
opposite 46
optimistic 18
orange (colour) 5
orange (fruit) 29
orangeade 32
orchestra 64
orchestra pit 65
orchestra seating 65
order 33
organization 43
organize 42
organized 43
ostrich 56
otter 57
out of date 77
out of season 48
outbox 7
outgoing 18
outlay 38
outstanding 6
over the top 8
overcast 51
overcrowding 75
overdraft 38
overpriced 73
overtake 45
overtime 4, 35
owl 56
oyster 28, 57
PPA 34
pace of life 75
pacifier 22
pack 13, 59
pack your bags 47
packet 32
paddle 62
page 63
page-turner 63
pail and shovel 50
pain 68
pain in the neck 8
painful 68
painkillers 69
paint 12, 58
paint a room 12
paint the house 12
paintbrush 12
pajamas 15
Pakistan 1
Pakistani 1
pale green 5
pale skin 17
pancakes 31
panda 55
panties 15
pants 15
pantyhose 15
paparazzi 67
papaya 29
paper 5
paper clips 37
paperback 63
paragliding 60
paramedic 34, 69
park (recreation area) 72
park (vehicle) 45
parking attendant 45
parking lot 45
parking meter 45
353
parking space 13
parking ticket 45
parrot 54, 56
parsley 31
partner 20
part-time 35
party 58
pass (overtake) 45
pass (succeed) 23
pass with flying colors / colours 24
passengers 44
passion fruit 29
passionate 18
passport 47
passport control 47
past 46
pasta 31
patient (hospital) 69
patient (personality trait) 18, 43
pavement 46
paws 54
pay 35, 73
pay cut 35
pay rise 35
pay separately 33
peach 29
peak 52
peanut 29
peanut butter 31
pear 29
peas 30
peck 56
pedal 49
pedestrian crossing 45
pedestrianized street 46
pedestrians 44
peel 33
peeler 10
peg 11
pelican 56
pen 37
penalty 61
penalty spot 61
pencil 37
pencil sharpener 37
penguin 56
pepper 31
peppers 30
percentages 2, 73
perform 64
performance 65
perfume 16
perfumery 74
period drama 66
permanent 35
personal assistant 34
personal statement 42
personal trainer 71
personality traits 18
perspire 14
pescatarian 70
pestle 10, 78
pestle and mortar 10
petrol 45
petrol station 45, 72
petroleum engineering 36
pets 54
pharmaceutical industry 36
pharmacy 72
Philippines 1
philosophy 23
phone 37
phone call 7
photocopier 37
photographer 34
phrasebook 47
physical education 23
physical therapy 69
physicist 78
physics 23, 78
physiotherapy 69
pick someone up 45
pick something up quickly 25
pickpocketing 27
picnic 58
picnic basket 50
picnic blanket 50
pig 54
pigeon 56
Pilates 71
pills 69
pilot 34
pin 16
PIN 38
pineapple 29
pink 5
pistachio 29
pitch (sports) 61, 62
pitch a tent 49
pizza 28
plain (adjective) 15
plain (landscape) 52
plan your route 46
plane 12
planner 37
plant bulbs 12
plaster 69
plaster the walls 12
plastic 5
plate 10
plateau 52
platform 44
play (action) 59
play a musical instrument 58
play board games 58
play cards 58
play chess 58
play the trumpet 64
play video games 58
playground 22
playing cards 22
playpen 22
plays (performance) 65
pleasant 6
pleased 19
pliers 12
plot 63
plug in 76
plum 29
plumber 34
poach 33
poached egg 28
pocket 15
point 59
Poland 1
polar bear 55
polar opposites 24
polar region 52
police 27
police officer 34
police station 72
Polish 1
polish 11
polite 18
polka dot 15
pollution 75
pomegranate 29
pond 52
ponytail 17
pool 60
pool cue 62
pop 64
popcorn 65
pork 28
porpoise 57
port 44
portfolio 42
portion 70
Portugal 1
Portuguese 1
post 7
post office 72
postcode 7
postgraduate 24
potatoes 30
pothole 49
pottery 58
potty 22
pour 33, 78
power cord 76
PR 36
354
practical 43
practice / practise 64
pram 22
prawn 28
prescription 69
presentation 40
presenter 66
press-up 71
pretty 6
preview 66
price tag 74
print 7
printer 37
prison 27
problem-solving 43
processed food 70
Production (department) 36
professional 43
professional achievements 42
professional attributes 43
professor 23
proficient in 42
program / programme 65
programme (TV) 66
project management 43
projector 37
promotion 35
pronunciation 25
property 13, 36
props 65
protein 70
proud 19
proven track record 42
prowl 55
prune trees 12
psychologist 34
psychology 23
Public Relations 36
public speaking 43
pudding 33
puddle 51
pull 59
pulling your leg 8
pulses 70
punctual 43
puppet 22
Purchasing (department) 36
pure luck 26
purple 5
purr 54
purse 16, 38
push 59
push-up 71
put on (clothes) 15
put on make-up 4
put the children to bed 4
put up shelves 12
put your foot down 21
puzzles 58, 63
pyjamas 15
Qquack 54
qualification 23
quarter 2
queue 74
quiet 5
quince 29
quiz show 66
Rrabbit 54
rabbit hutch 54
raccoon 55
racing bike 49
rain 51
rain forest / rainforest 52
rainbow 51
raincoat 15
raindrop 51
rainy 51
raise 35
raisin 29
rake 12
ranch house 13
rap 64
rapids 52
raspberries 29
rattle 22
ray 57
razor 10
reach a consensus 40
reach a verdict 27
reaction 78
read 58
read a map 46
read a newspaper 4
reading 25, 63
real estate 13, 36
reality show 67
reality TV 66
realtor 13
reasonable 18
receipt 38, 74
reception 47
receptionist 34
record 64, 66, 78
recover 69
recruitment agency 42
recycling bin 11
recycling industry 36
red 5
red card 61
red carpet 67
red hair 17
red tape 41
redcurrants 29
reduce your carbon footprint 53
reference (landlord) 13
references (employer) 42
reflector 49
reflexology 71
refrigerator 9
refund 73
rehearse 64
relationships 21
relax 71
relaxed 19
relaxing 6
reliable 18, 43
remarkable 6
remember 59
remote 66
removal van 13
renewable energy 53
rent 13
rent a cottage 47
renting 13
repair 59
repel 78
reply 7
reply all 7
reporter 66
Republic of Ireland 1
research 43
Research and Development / R & D 36
residential area 13
resit 23
respectable 6
responsible 43
responsible for 42
rest 69
restaurant 33, 72
results 78
resuscitate 69
retire 35
return ticket 47
review 23
review the minutes 40
revise 23
revolution 77
rhinoceros 55
rice 31
ride 44, 59
ride a bike 44
ride a horse 44, 58
right 46
ring 16
rip-off 73
355
river 52
road sign 45
road work / roadworks 75
roadmap 46
roar 55
roast 33
robbery 27
rock (music) 64
rock climbing 60
rocks 52
ROI 1
roll (action) 33
roll (bread) 31
roller (paint) 12
roller skates 62
roller-skating 60
rolling pin 10
romance 63
romantic comedy 65
romper suit 22
roof 9
room service 47
room with a view 47
roomer 13
roommate 13
rooms 9
round-trip ticket 47
router 76
row houses 13
rowing 60
rowing machine 71
rubber 37
rubber band 37
rubber gloves 11
rucksack 16, 49
rude 18
rug 9
rugby 60
ruler 37
run 59, 71
run in the family 21
run out of time 40
run-down 48
running 60
running a marathon 60
running track 62
runny nose 68
rush hour 75
Russia 1
Russian 1
rusty 25
Ssad 19
saddle 49
safe 47
safety goggles 78
safety pin 69
sailing 60
salad 28
salary 35
sale 74
Sales (department) 36
sales assistant 34
salmon 28, 57
salt 31, 70
salty 32
sand 50
sand dune 52
sandals 16
sandbox 22
sandcastle 50
sandpit 22
sandstorm 51
sandwich 28
sardines 28
satellite TV 66
satire 66
satnav 76
saturated fat 70
Saturday 3
saucepan 10
sauna 71
sausages 28
save 38
savory / savoury 32
saw 12
saxophone 64
scale (fish) 57
scales (measure) 46, 69
scallops 28
scanner 37
scared 19
scarf 16
school 4, 23
school of fish 57
science 23, 78
science fiction 63, 65
scientist 34, 78
scissors 10, 37, 69
score a goal 61
scouring pad 11
scrambled eggs 28
scratch 54
screen 65, 66, 76
screw 12
screwdriver 12
script 65
scrub the floor 11
scuba diving 60
sea 50, 52
sea creatures 57
sea lion 57
sea urchin 57
seafood platter 28
seagull 56
seahorse 57
seal 57
seasons 3, 66
seatbelt 45
second 2
second floor 74
secretive 18
security 61
security guard 34
see 59
see a play 58
see eye to eye with someone 21
see off somebody 48
see somebody off 48
seesaw 22
self-help 63
selfish 18
sell 73
semester 24
semi-detached houses 13
send 7
sensationalize 67
sensitive 18
sent off 61
sentence somebody to something 27
September 3
series 66
serious 18, 19
serious doubts 26
serious misgivings 26
serve a sentence 27
service charge 33
service the car 45
service-oriented 42
set menu 33
set of beliefs 26
set off 45
set the table 11
set your sights on something 39
sets 65
seven 2
seventeen 2
seventh 2
seventy 2
sew 58
shake 59
shake your head 14
shallow 5
shampoo 10
shape 12
shape of things to come 77
shark 57
sharp 5
shave 4, 17
356
shaving foam 10
shears 12
sheep 54
shell 28, 50, 57
shelves 74
shin 14
ship 44
shipping industry 36
shirt 15
shiver 14
shocked 19
shocking 6
shoe shop 73
shoe store 73
shoes 16
shop 11, 72
shop around 73
shoplifting 27
shopping 58, 73
shopping bag 74
shopping cart 74
shopping channel 66
shopping mall 72
shopping trolley 74
short 5, 17
short hair 17
shorts 15
shoulder (body) 14
shoulder (road) 46
shoulder-length hair 17
shout 59
show of hands 40
shower 4, 9
shower block 49
shower gel 10
shows 65, 66
shredder 37
shrimp 28, 57
shrug 14
shuttlecock 62
shy 18
sick 68
side 33
side order 33
sideburns 17
sidewalk 46
sieve 10
sigh 14
sightseeing 47
signal 45
signature 7
signpost 46
silk 5, 15
silly 18
silverware 10
simmer 33
sing 56, 59, 64
sing in a choir 58
Singapore 1
singer 64
single room 47
sink (action) 78
sink (household fixture) 9
sip 32
sister 20
sister-in-law 20
sit an exam 23
sit down 59
sit on the fence 8
sitcom 66
sit-up 71
six 2
sixteen 2
sixth 2
sixty 2
skateboard 62
skateboarding 60
skating 60
ski slope 62
skiing 60
skip 71
skipping rope 22, 71
skirt 15
skis 62
skydiving 60
skyscraper 72
slash prices 73
sleep well 71
sleeping bag 49
sleeve 15
slice 33
slide 22
slippers 16
sloth 55
Slovakia 1
slow down 45
small 5
smart 17
smartwatch 76
smell 59
smile 14
smog 51
smoothie 32
smuggling 27
snack 28, 33
snail 56
snake 55
sneakers 16
sneaking suspicion 26
sneeze 14, 68
sniff 54
snore 14
snorkel and mask 50
snorkeling / snorkelling 60
snort 54
snow 51
snowboard 62
snowboarding 60
snowdrift 51
snowed under 39
snowflake 51
snowstorm 51
snowsuit 22
snowy 51
soap 10
soap opera 66
soccer 60, 61
soccer cleats 62
social networking 7
socks 15
sofa 9
soft toy 22
solar panel 53
solar power 53
solid 78
solo 64
sometimes 3
son 20
sorbet 31
sore 68
sore throat 68
soul 64
soup 28
sour 32
south 46
South Africa 1
South Korea 1
southeast 46
southwest 46
soy sauce 31
spa 71
spaghetti 31
Spain 1
spam 7
Spanish 1
spanner 12
sparkling 32
spatula 10
speak 59
speak accurately 25
speaking 25
special 6
special effects 65
special offer 74
specials (menu) 33
speed camera 45
speed limit 45
speed up 45
speeding 27
spell 59
sperm whale 57
357
spices 31
spicy 32
spider 56
spinach 30
spine 63
spinning top 22
spirit level 12
splinter 68
split the bill 33
split the check 33
sponge 10, 11
spoon 10
sports 60, 62
sports center / centre 72
sports drink 32
sports programme 66
sports show 66
spotted 15
sprain 68
spread a rumor / rumour 26
spring 3
sprinkler 12
squash 60
squat 71
squeak 54
squid 28, 57
stadium 62
staff 35
stage 65
stair gate 22
stairs 9
stalls 65
stand up 59
standing ovation 65
stapler 37
staples 37
starfish 57
starfruit 29
start a rumor / rumour 26
start work 4
starter 33
state 7
state-of-the-art 77
static electricity 78
stationery 37
stay (at) home 58
stay in a hotel 47
steam 78
steam room 71
steering wheel 45
step down 39
stepbrother 20
stepmom 20
stepmother 20
stepmum 20
stepsister 20
stethoscope 69
steward 61
stick up for someone 21
sticky notes 37
stifling 51
still (drink) 32
sting 56, 68
stir 33
stitches 69
stock exchange 38
stomach 14
stomachache / stomach ache 68
stop at 46
stop off 48
stoppage time 61
stopwatch 62
storage 13
store 11, 72
stork 56
storm 51
stormy 51
stove 9
straight hair 17
straight on 46
strange 6
strategy 40
strawberries 29
stream 52
street address 7
street crime 27
street map 46, 72
street market 73
stress 68
stressed 19
stretch 71
striker 61
strikingly different 24
striped 15
stroke of luck 26
stroller 22
strong 32
stubble 17
student 23
study 9
study a subject 23
studying 23, 24
stuffed animal 22
stunning 6
stunt 65
style your hair 17
styles 15, 17
stylist 34
subject 7
substitutes 61
subtitles 66
subtract 59
suburb 75
suck 14
sugar 31, 70
suit (clothing) 15
suit (someone) 15
suitcase 47
sultana 29
sum up 40
summer 3
sun 51
sunbathing 50
sun cream 50
Sunday 3
sunglasses 16
sunny 51
sunscreen 50
superb 6
superfoods 70
supermarket 74
supervise 42
supportive 18
surf the internet 58
surfboard 62
surfing 50, 60
surgeon 34
surprised 19
sushi 28
swallow 32
swamp 52
swan 56
sweat 14
sweater 15
sweep the floor 11
sweet 32
sweet potatoes 30
sweetcorn 30
sweets 31
swimming 60
swimming cap 62
swimming gear 62
swimming pool 62, 72
swimming trunks 50, 62
swimsuit 50, 62
swing 55
swings 22
swollen 68
swoop 56
swordfish 57
symptoms 68
synagogue 72
syringe 69
Ttable 9
table tennis 60
tablet (gadget) 76
tablets (medicine) 69
tackle 61
358
tackle pollution 53
tackle something head-on 39
tail (airplane / aeroplane) 44
tail (animal) 54, 55
take a bath 4
take a flight 44
take a shower 4
take a test 24
take a year off 24
take a year out 24
take after someone 21
take an exam 24
take away 33
take minutes 40
take off 15, 39
take on someone 39
take out 33
take out the rubbish 4, 11
take out the trash 4, 11
take photos 58
take questions 40
take someone on 39
take something with a pinch of salt 8
take the bus 44
take the first left 46
take the second right 46
take the train 44
talent show 67
talented 18
talk 59
talk show 66
talkative 18
tall 17
tambourine 64
tan / tanned skin 17
tandem 49
tape measure 12
tapir 55
taste 32, 59
tasty 32
tattletale 26
taxi 44
taxi driver 34
taxi rank 44
taxi stand 44
tea 4, 32
teacher 23, 34
teacher’s pet 8
team player 43
teamwork 43
technology 23, 76, 77
technophile 77
technophobe 77
teddy bear 22
teenagers 20
teeth 14
telephone 37
telephone manner 43
television 9, 66 see also TV
tell a white lie 26
telltale 26
temperature 51, 68
temple 72
temporary 35
ten 2
tenancy agreement 13
tenant 13
tennis 60
tennis court 62
tennis racket 62
tent 49
tent peg 49
tent pole 49
tenth 2
term 24
terraced houses 13
terrarium 54
terrible 6
terrified 19
test 23
test results 69
test tubes 78
text message 7
textbook 23, 63
Thailand 1
theater / theatre 65, 72
there 46
thermometer 69
thesis 23
thick 5
thigh 14
thin 5
think 59
think outside the box 41
think the world of someone 21
third 2
thirst for adventure 48
thirteen 2
thirty 2
thousand 2
three 2
three times a week 3
thrilled 19
thriller 65, 66
thrilling 6
throw 59
throw money down the drain 41
throw-in 61
thumb 14
thumbtack 37
thunder 51
thundery 51
Thursday 3
ticket 44
tidy 11
tie (clothing) 15
tie (sports result) 61
tie your hair back 17
tiger 55
tight 5
tights 15
tile the bathroom 12
till 38, 74
time 3
time management 43
tin 32
tin opener 10
tip 33
tire 45, 49
tired 19
tiring 6
title 7
toast 31
toaster 10
toddler 20
toe 14
toilet 9
toilet block 49
toilet paper 10
toiletries 10
tomatoes 30
tonsillitis 68
tool box 12
tools 12
tooth 14
toothbrush 10
torch 49
tornado 51
tortoise 54
toucan 56
touch base 41
touch wood 26
tour guide 34
tourism 48
tourism industry 36
tourist attraction 75
tourist information 72
tourist office 72
tourist trap 48
towel 9, 50
town 72
town hall 72
town square 72
toy shop 73
toy store 73
toys 22
traffic jam 45, 75
traffic lights 45
tragedy 65
train 44, 71
train driver 34
359
train set 22
train station 44, 72
trained in 42
trainers 16
tram 44
transfer money 38
translation 25
transportation 44
transportation industry 36
trash 7
trash can 9, 37
travel 44, 47, 48
travel agent 34
travel writing 63
trays 37
treadmill 71
treatment 69
trial 27
trim a hedge 12
triplets 20
trombone 64
trousers 15
trout 57
trowel 12
truck 44
trumpet 64
trunk 45, 55
try on 73
t-shirt 15
Tuesday 3
tumble dryer 11
tuna 57
turkey 54
Turkey 1
Turkish 1
turn / turning 46
turn left 46
turn off 66, 76
turn on 66, 76
turn right 46
turn signal 45
turn up the volume 66
turtle 57
tusk 55
TV 9, 66
TV guide 63, 66
TV schedule 66
TV set 66
tweezers 69
twelfth 2
twelve 2
twentieth 2
twenty 2
twenty-first 2
twenty-one 2
twenty-two 2
twice a week 3
twin beds 47
twins 20
two 2
two hundred 2
two weeks 3
tyre 45, 49
UUAE 1
ugly 6
UK 1
umbrella 16
unanimous agreement 40
unapproachable 18
unblock the sink 12
uncle 20
unclog the sink 12
undergraduate 24
understand 59
undo 15
unenthusiastic 19
unfasten 15
unfriendly 18
unfurnished 13
unhappy 19
unicycle 49
uniform 15
unimpressed 19
United Arab Emirates 1
United Kingdom 1
United States of America 1
university 23
unkind 18
unload the dishwasher 11
unpack 13
unpleasant 6
unreasonable 18
unreliable 18
unsaturated fat 70
unshakable belief 26
unspoiled 48
up 15
up to your ears 39
up to your eyeballs 39
upload 76
upmarket 74
upset 19
upstairs 9
urban life 75
urban myth 26
US 1
USB drive 76
useful 6
useless 6
usher 65
usually 3
Vvacancies 47
vacation 47, 58
vacuum cleaner 11
vacuum the carpet 11
valley 52
van 44
vandalism 27, 75
vegan 70
vegetables 30
vegetarian 70
vet 34
veterinary medicine 23
vice / vise 12
video games 58
video on demand 66
view a house 13
villa 47
village 72
villain 65
vinegar 31
violin 64
virus 68
visit a gallery 58
visit a museum 58
vitamins 70
vocabulary 25
voicemail 7
volcano 52
volleyball 60
volunteer 42
vomit 68
vulture 56
Wwages 35
waist 14
waiter 33, 34
waiting room 69
waitress 33, 34
wake up 4
walk 44, 58
walk the dog 4
walking boots 49
walking holiday 47
walking vacation 47
wallet 16, 38
walnut 29
walrus 57
want 73
wardrobe 9
warm 51
warm up 71
wash the car 11
wash the dishes 4
360
The publisher would like to thank:
Sarah Edwards, Carrie Lewis, Daniel Mills, Aisvarya Misra, and Christine Stroyan for editorial assistance; Rabia Ahmad, Debjyoti
Mukherjee, and Sonakshi Singh for design assistance; Simon Mumford for national flags; Viola Wang for additional illustration;
Steph Lewis for proofreading; Elizabeth Wise for indexing; Christine Stroyan for audio recording management; and ID Audio for
audio recording and production.
wash your face 4
wash your hair 4
washing line 11
washing machine 11
washing up liquid 11
wasp 56
watch 16
watch a movie 58
watch television / TV 4, 58
watch your weight 70
water 32
water cooler 37
water the flowers 12
water the plants 11
waterfall 52
watermelon 29
waterproofs 49
wave (gesture) 14
wave (water) 50, 52
wavy hair 17
wear 15
weather 51, 66
weather forecast 66
website 7
Wednesday 3
weeding 12
week 3
weekend 3
weekly 3
weights 71
well-being 71
west 46
western 65
wet 51
wet suit 50
wet wipe 22
whales 57
what the future holds 77
wheel 45
wheel clamp 45
wheelbarrow 12
whisk (action) 33
whisk (equipment) 10
whiskers 54
whisper 59
white 5
white-collar crime 27
wide 5
wide range 74
widow 20
widower 20
wife 20
Wi-Fi 76
wild animals 55
wind 51
wind farm 53
wind power 53
windbreak 50
window 9
window seat 47
window shopping 73
windsurfing 50, 60
windy 51
wine 32
wing (airplane / aeroplane) 44
wing (bird) 28, 56
wink 14
winter 3
win-win situation 41
wipers 45
wire 76
wireless 76
withdraw money 38
witness 27
wok 10
wolf 55
women’s wear 74
wonderful 6
wood (landscape) 52
wood (material) 5
wooden spoon 10
woodpecker 56
wool 5
woolen / woollen 15
word of mouth 26
work 4, 59
work from home 35
work full-time 35
work opportunities 75
work out 71
work overtime 4
work part-time 35
work shifts 35
work well under pressure 43
working 39, 41
working environment 39
workplace 43
world of difference 24
worm 56
worried 19
wound 68
wrap (sandwich) 28
wrap up 40
wrench 12
wrinkles 17
write 58
writer 34
writing 25
written communication 43
XX-ray 69
Yyacht 44
yak 55
yard (garden) 9
yard (measurement) 46
yawn 14
year 3
yellow 5
yellow card 61
yoga 58, 71
yogurt 28
yolk 28
young 17
yo-yo 22
Zzebra 55
zip / zipper 15, 16
zip code 7
zucchini 30
Acknowledgments

I wrote this book because I believe you should be able to learn what your computer does. You should be able
to make your software do what you want it to do (within the reasonable limits of its capabilities, of course).
The key to attaining this power lies in understanding the fundamentals of what the software does and how it
works, and that’s what this book is all about. You should never have to fight with a computer.
Linux is a great platform for learning because it doesn’t try to hide anything from you. In particular, most
system configuration can be found in plaintext files that are easy enough to read. The only tricky part is
figuring out which parts are responsible for what and how it all fits together.
Who Should Read This Book?
Your interest in learning how Linux works may have come from any number of sources. In the professional
realm, operations and DevOps folks need to know nearly everything that you’ll find in this book. Linux
software architects and developers should also know this material in order to make the best use of the operating
system. Researchers and students, often left to run their own Linux systems, will also find that this book
provides useful explanations for why things are set up the way they are.
Then there are the tinkerers—people who just love to play around with their computers for fun, profit, or both.
Want to know why certain things work while others don’t? Want to know what happens if you move something
around? You’re probably a tinkerer.
Prerequisites
Although Linux is beloved by programmers, you do not need to be a programmer to read this book; you need
only basic computer-user knowledge. That is, you should be able to bumble around a GUI (especially the
installer and settings interface for a Linux distribution) and know what files and directories (folders) are. You
should also be prepared to check additional documentation on your system and on the Web. As mentioned
earlier, the most important thing you need is to be ready and willing to play around with your computer.
How to Read This Book
Building the requisite knowledge is a challenge in tackling any technical subject. When explaining how
software systems work, things can get really complicated. Too much detail bogs down the reader and makes
the important stuff difficult to grasp (the human brain just can’t process so many new concepts at once), but
too little detail leaves the reader in the dark and unprepared for later material.
I’ve designed most chapters to tackle the most important material first: the basic information that you’ll need
in order to progress. In places, I’ve simplified things in order to keep focus. As a chapter progresses, you’ll
see much more detail, especially in the last few sections. Do you need to know those bits right away? In most
cases, no, as I often note. If your eyes start to glaze over when faced with a lot of extra details about stuff that
you only just learned, don’t hesitate to skip ahead to the next chapter or just take a break. The nitty-gritty will
still be there waiting for you.
A Hands-On Approach
However you choose to proceed through this book, you should have a Linux machine in front of you,
preferably one that you’re confident abusing with experiments. You might prefer to play around with a virtual
installation—I used VirtualBox to test much of the material in this book. You should have superuser (root)
www.EBooksWorld.ir
access, but you should use a regular user account most of the time. You’ll mostly work at the command line,
in a terminal window or a remote session. If you haven’t worked much in this environment, no problem;
Chapter 2 will bring you up to speed.
Commands in this book will typically look like this:
$ ls /
[some output]
Enter the text in bold; the non-bolded text that follows is what the machine spits back. The $ is the prompt for
your regular user account. If you see a # as a prompt, you should be superuser. (More on that in Chapter 2.)
How This Book is Organized
I’ve grouped the book’s chapters into three basic parts. The first is introductory, giving you a bird’s-eye view
of the system and then offering hands-on experience with some tools you’ll need for as long as you run Linux.
Next, you’ll explore each part of the system in more detail, from device management to network configuration,
following the general order in which the system starts. Finally, you’ll get a tour of some pieces of a running
system, learn some essential skills, and get some insight into the tools that programmers use.
With the exception of Chapter 2, most of the early chapters heavily involve the Linux kernel, but you’ll work
your way into user space as the book progresses. (If you don’t know what I’m talking about here, don’t worry;
I’ll explain in Chapter 1.)
The material here is meant to be as distribution-agnostic as possible. Having said this, it can be tedious to
cover all variations in systems software, so I’ve tried to cover the two major distribution families: Debian
(including Ubuntu) and RHEL/Fedora/CentOS. It’s also focused on desktop and server installations. There is
a significant amount of carryover into embedded systems, such as Android and OpenWRT, but it’s up to you
to discover the differences on those platforms.
What’s New in the Second Edition?
The first edition of this book dealt primarily with the user-centric side of a Linux system. It focused on
understanding how the parts worked and how to get them humming. At that time, many parts of Linux were
difficult to install and configure properly.
This is happily no longer the case thanks to the hard work of the people who write software and create Linux
distributions. With this in mind, I have omitted some older and perhaps less relevant material (such as a
detailed explanation of printing) in favor of an expanded discussion of the Linux kernel’s role in every Linux
distribution. You probably interact with the kernel more than you realize, and I’ve taken special care to note
where.
Of course, so much of the original subject matter in this book has changed over the years, and I’ve taken pains
to sort through the material in the first edition in search of updates. Of particular interest is how Linux boots
and how it manages devices. I’ve also taken care to rearrange material to match the interests and needs of
current readers.
One thing that hasn’t changed is the size of this book. I want to give you the stuff that you need to get on the
fast track, and that includes explaining certain details along the way that can be hard to grasp, but I don’t want
you to have to become a weightlifter in order to pick up this book. When you’re on top of the important
subjects here, you should have no trouble seeking out and understanding more details.
I’ve also omitted some of the historical information that was in the first edition, primarily to keep you focused.
If you’re interested in Linux and how it relates to the history of Unix, pick up Peter H. Salus’s The Daemon,
www.EBooksWorld.ir
the Gnu, and the Penguin (Reed Media Services, 2008)—it does a great job of explaining how the software
we use has evolved over time.
A Note on Terminology
There’s a fair amount of debate over the names of certain elements of operating systems. Even “Linux” itself
is game for this—should it be “Linux,” or should it be “GNU/Linux” to reflect that the operating system also
contains pieces from the GNU Project? Throughout this book, I’ve tried to use the most common, least
awkward names possible.
www.EBooksWorld.ir
Acknowledgments
Thanks go to everyone who helped with the first edition: James Duncan, Douglas N. Arnold, Bill Fenner, Ken
Hornstein, Scott Dickson, Dan Ehrlich, Felix Lee, Scott Schwartz, Gregory P. Smith, Dan Sully, Karol Jurado,
and Gina Steele. For the second edition, I’d especially like to thank Jordi Gutiérrez Hermoso for his excellent
technical review work; his suggestions and corrections have been invaluable. Thanks also to Dominique
Poulain and Donald Karon for providing some excellent early-access feedback, and to Hsinju Hsieh for putting
up with me during the process of revising this book.
Finally, I’d like to thank my developmental editor, Bill Pollock, and my production editor, Laurel Chun. Serena
Yang, Alison Law, and everyone else at No Starch Press have done their usual outstanding job at getting this
new edition on track.
www.EBooksWorld.ir
Chapter 1. The Big Picture
At first glance, a modern operating system such as Linux is very complicated, with a dizzying number of
pieces simultaneously running and communicating. For example, a web server can talk to a database server,
which could in turn use a shared library that many other programs use. But how does it all work?
The most effective way to understand how an operating system works is through abstraction—a fancy way of
saying that you can ignore most of the details. For example, when you ride in a car, you normally don’t need
to think about details such as the mounting bolts that hold the motor inside the car or the people who build
and maintain the road upon which the car drives. If you’re a passenger in a car, all you really need to know is
what the car does (transports you somewhere else) and a few basics about how to use it (how to operate the
door and seat belt).
But if you’re driving a car, you need to know more. You need to learn how to operate the controls (such as the
steering wheel and accelerator pedal) and what to do when something goes wrong.
For example, let’s say that the car ride is rough. Now you can break up the abstraction of “a car that rolls on a
road” into three parts: a car, a road, and the way that you’re driving. This helps isolate the problem: If the road
is bumpy, you don’t blame the car or the way that you’re driving it. Instead, you may want to find out why the
road has deteriorated or, if the road is new, why the construction workers did a lousy job.
Software developers use abstraction as a tool when building an operating system and its applications. There
are many terms for an abstracted subdivision in computer software, including subsystem, module, and
package—but we’ll use the term component in this chapter because it’s simple. When building a software
component, developers typically don’t think much about the internal structure of other components, but they
do care about what other components they can use and how to use them.
This chapter provides a high-level overview of the components that make up a Linux system. Although each
one has a tremendous number of technical details in its internal makeup, we’re going to ignore these details
and concentrate on what the components do in relation to the whole system.
1.1 Levels and Layers of Abstraction in a Linux System
Using abstraction to split computing systems into components makes things easier to understand, but it doesn’t
work without organization. We arrange components into layers or levels. A layer or level is a classification (or
grouping) of a component according to where that component sits between the user and the hardware. Web
browsers, games, and such sit at the top layer; at the bottom layer we have the memory in the computer
hardware—the 0s and 1s. The operating system occupies most of the layers in between.
A Linux system has three main levels. Figure 1-1 shows these levels and some of the components inside each
level. The hardware is at the base. Hardware includes the memory as well as one or more central processing
units (CPUs) to perform computation and to read from and write to memory. Devices such as disks and
network interfaces are also part of the hardware.
The next level up is the kernel, which is the core of the operating system. The kernel is software residing in
memory that tells the CPU what to do. The kernel manages the hardware and acts primarily as an interface
between the hardware and any running program.
Processes—the running programs that the kernel manages—collectively make up the system’s upper level,
www.EBooksWorld.ir
called user space. (A more specific term for process is user process, regardless of whether a user directly
interacts with the process. For example, all web servers run as user processes.)
Figure 1-1. General Linux system organization
There is a critical difference between the ways that the kernel and user processes run: The kernel runs in kernel
mode, and the user processes run in user mode. Code running in kernel mode has unrestricted access to the
processor and main memory. This is a powerful but dangerous privilege that allows a kernel process to easily
crash the entire system. The area that only the kernel can access is called kernel space.
User mode, in comparison, restricts access to a (usually quite small) subset of memory and safe CPU
operations. User space refers to the parts of main memory that the user processes can access. If a process
makes a mistake and crashes, the consequences are limited and can be cleaned up by the kernel. This means
that if your web browser crashes, it probably won’t take down the scientific computation that you’ve been
running in the background for days.
In theory, a user process gone haywire can’t cause serious damage to the rest of the system. In reality, it
depends on what you consider “serious damage,” as well as the particular privileges of the process, because
some processes are allowed to do more than others. For example, can a user process completely wreck the
data on a disk? With the correct permissions, yes—and you may consider this to be fairly dangerous. There
are safeguards to prevent this, however, and most processes simply aren’t allowed to wreak havoc in this
manner.
1.2 Hardware: Understanding Main Memory
Of all of the hardware on a computer system, main memory is perhaps the most important. In its most raw
form, main memory is just a big storage area for a bunch of 0s and 1s. Each 0 or 1 is called a bit. This is where
the running kernel and processes reside—they’re just big collections of bits. All input and output from
peripheral devices flows through main memory, also as a bunch of bits. A CPU is just an operator on memory;
it reads its instructions and data from the memory and writes data back out to the memory.
www.EBooksWorld.ir
You’ll often hear the term state in reference to memory, processes, the kernel, and other parts of a computer
system. Strictly speaking, a state is a particular arrangement of bits. For example, if you have four bits in your
memory, 0110, 0001, and 1011 represent three different states.
When you consider that a single process can easily consist of millions of bits in memory, it’s often easier to
use abstract terms when talking about states. Instead of describing a state using bits, you describe what
something has done or is doing at the moment. For example, you might say “the process is waiting for input”
or “the process is performing Stage 2 of its startup.”
NOTE
Because it’s common to refer to the state in abstract terms rather than to the actual bits, the term
image refers to a particular physical arrangement of bits.
1.3 The Kernel
Why are we talking about main memory and states? Nearly everything that the kernel does revolves around
main memory. One of the kernel’s tasks is to split memory into many subdivisions, and it must maintain certain
state information about those subdivisions at all times. Each process gets its own share of memory, and the
kernel must ensure that each process keeps to its share.
The kernel is in charge of managing tasks in four general system areas:
o Processes. The kernel is responsible for determining which processes are allowed to use the CPU.
o Memory. The kernel needs to keep track of all memory—what is currently allocated to a particular process,
what might be shared between processes, and what is free.
o Device drivers. The kernel acts as an interface between hardware (such as a disk) and processes. It’s
usually the kernel’s job to operate the hardware.
o System calls and support. Processes normally use system calls to communicate with the kernel.
We’ll now briefly explore each of these areas.
NOTE
If you’re interested in the detailed workings of a kernel, two good textbooks are Operating System
Concepts, 9th edition, by Abraham Silberschatz, Peter B. Galvin, and Greg Gagne (Wiley, 2012)
and Modern Operating Systems, 4th edition, by Andrew S. Tanenbaum and Herbert Bos (Prentice
Hall, 2014).
1.3.1 Process Management
Process management describes the starting, pausing, resuming, and terminating of processes. The concepts
behind starting and terminating processes are fairly straightforward, but describing how a process uses the
CPU in its normal course of operation is a bit more complex.
On any modern operating system, many processes run “simultaneously.” For example, you might have a web
browser and a spreadsheet open on a desktop computer at the same time. However, things are not as they
appear: The processes behind these applications typically do not run at exactly the same time.
Consider a system with a one-core CPU. Many processes may be able to use the CPU, but only one process
may actually use the CPU at any given time. In practice, each process uses the CPU for a small fraction of a
second, then pauses; then another process uses the CPU for another small fraction of a second; then another
process takes a turn, and so on. The act of one process giving up control of the CPU to another process is
called a context switch.
Each piece of time—called a time slice—gives a process enough time for significant computation (and indeed,
www.EBooksWorld.ir
a process often finishes its current task during a single slice). However, because the slices are so small, humans
can’t perceive them, and the system appears to be running multiple processes at the same time (a capability
known as multitasking).
The kernel is responsible for context switching. To understand how this works, let’s think about a situation in
which a process is running in user mode but its time slice is up. Here’s what happens:
1. The CPU (the actual hardware) interrupts the current process based on an internal timer, switches into
kernel mode, and hands control back to the kernel.
2. The kernel records the current state of the CPU and memory, which will be essential to resuming the
process that was just interrupted.
3. The kernel performs any tasks that might have come up during the preceding time slice (such as
collecting data from input and output, or I/O, operations).
4. The kernel is now ready to let another process run. The kernel analyzes the list of processes that are ready
to run and chooses one.
5. The kernel prepares the memory for this new process, and then prepares the CPU.
6. The kernel tells the CPU how long the time slice for the new process will last.
7. The kernel switches the CPU into user mode and hands control of the CPU to the process.
The context switch answers the important question of when the kernel runs. The answer is that it runs between
process time slices during a context switch.
In the case of a multi-CPU system, things become slightly more complicated because the kernel doesn’t need
to relinquish control of its current CPU in order to allow a process to run on a different CPU. However, to
maximize the usage of all available CPUs, the kernel typically does so anyway (and may use certain tricks to
grab a little more CPU time for itself).
1.3.2 Memory Management
Because the kernel must manage memory during a context switch, it has a complex job of memory
management. The kernel’s job is complicated because the following conditions must hold:
o The kernel must have its own private area in memory that user processes can’t access.
o Each user process needs its own section of memory.
o One user process may not access the private memory of another process.
o User processes can share memory.
o Some memory in user processes can be read-only.
o The system can use more memory than is physically present by using disk space as auxiliary.
Fortunately for the kernel, there is help. Modern CPUs include a memory management unit (MMU) that
enables a memory access scheme called virtual memory. When using virtual memory, a process does not
directly access the memory by its physical location in the hardware. Instead, the kernel sets up each process
to act as if it had an entire machine to itself. When the process accesses some of its memory, the MMU
intercepts the access and uses a memory address map to translate the memory location from the process into
an actual physical memory location on the machine. The kernel must still initialize and continuously maintain
and alter this memory address map. For example, during a context switch, the kernel has to change the map
from the outgoing process to the incoming process.
NOTE
The implementation of a memory address map is called a page table.
www.EBooksWorld.ir
You’ll learn more about how to view memory performance in Chapter 8.
1.3.3 Device Drivers and Management
The kernel’s role with devices is pretty simple. A device is typically accessible only in kernel mode because
improper access (such as a user process asking to turn off the power) could crash the machine. Another
problem is that different devices rarely have the same programming interface, even if the devices do the same
thing, such as two different network cards. Therefore, device drivers have traditionally been part of the kernel,
and they strive to present a uniform interface to user processes in order to simplify the software developer’s
job.
1.3.4 System Calls and Support
There are several other kinds of kernel features available to user processes. For example, system calls (or
syscalls) perform specific tasks that a user process alone cannot do well or at all. For example, the acts of
opening, reading, and writing files all involve system calls.
Two system calls, fork() and exec(), are important to understanding how processes start up:
o fork() When a process calls fork(), the kernel creates a nearly identical copy of the process.
o exec() When a process calls exec(program), the kernel starts program, replacing the current
process.
Other than init (see Chapter 6), all user processes on a Linux system start as a result of fork(), and most of
the time, you also run exec() to start a new program instead of running a copy of an existing process. A
very simple example is any program that you run at the command line, such as the ls command to show the
contents of a directory. When you enter ls into a terminal window, the shell that’s running inside the terminal
window calls fork() to create a copy of the shell, and then the new copy of the shell calls exec(ls) to
run ls. Figure 1-2 shows the flow of processes and system calls for starting a program like ls.
Figure 1-2. Starting a new process
NOTE
System calls are normally denoted with parentheses. In the example shown in Figure 1-2, the
process asking the kernel to create another process must perform a fork() system call. This
notation derives from the way the call would be written in the C programming language. You don’t
need to know C to understand this book; just remember that a system call is an interaction
between a process and the kernel. In addition, this book simplifies certain groups of system calls.
For example, exec() refers to an entire family of system calls that all perform a similar task but
differ in programming.
The kernel also supports user processes with features other than traditional system calls, the most common of
which are pseudodevices. Pseudo-devices look like devices to user processes, but they’re implemented purely
in software. As such, they don’t technically need to be in the kernel, but they are usually there for practical
reasons. For example, the kernel random number generator device (/dev/random) would be difficult to
implement securely with a user process.
NOTE
Technically, a user process that accesses a pseudodevice still has to use a system call to open the
www.EBooksWorld.ir
device, so processes can’t entirely avoid system calls.
1.4 User Space
As mentioned earlier, the main memory that the kernel allocates for user processes is called user space.
Because a process is simply a state (or image) in memory, user space also refers to the memory for the entire
collection of running processes. (You may also hear the more informal term userland used for user space.)
Most of the real action on a Linux system happens in user space. Although all processes are essentially equal
from the kernel’s point of view, they perform different tasks for users. There is a rudimentary service level (or
layer) structure to the kinds of system components that user processes represent. Figure 1-3 shows how an
example set of components fit together and interact on a Linux system. Basic services are at the bottom level
(closest to the kernel), utility services are in the middle, and applications that users touch are at the top.
Figure 1-3 is a greatly simplified diagram because only six components are shown, but you can see that the
components at the top are closest to the user (the user interface and web browser); the components in the
middle level has a mail server that the web browser uses; and there are several smaller components at the
bottom.
Figure 1-3. Process types and interactions
The bottom level tends to consist of small components that perform single, uncomplicated tasks. The middle
level has larger components such as mail, print, and database services. Finally, components at the top level
perform complicated tasks that the user often controls directly. Components also use other components.
Generally, if one component wants to use another, the second component is either at the same service level or
below.
However, Figure 1-3 is only an approximation of the arrangement of user space. In reality, there are no rules
in user space. For example, most applications and services write diagnostic messages known as logs. Most
programs use the standard syslog service to write log messages, but some prefer to do all of the logging
themselves.
In addition, it’s difficult to categorize some user-space components. Server components such as web and
database servers can be considered very high-level applications because their tasks are often complicated, so
you might place these at the top level in Figure 1-3. However, user applications may depend on these servers
to perform tasks that they’d rather not do themselves, so you could also make a case for placing them at the
middle level.
www.EBooksWorld.ir
1.5 Users
The Linux kernel supports the traditional concept of a Unix user. A user is an entity that can run processes and
own files. A user is associated with a username. For example, a system could have a user named billyjoe.
However, the kernel does not manage the usernames; instead, it identifies users by simple numeric identifiers
called userids. (You’ll learn more about how the usernames correspond to userids in Chapter 7.)
Users exist primarily to support permissions and boundaries. Every user-space process has a user owner, and
processes are said to run as the owner. A user may terminate or modify the behavior of its own processes
(within certain limits), but it cannot interfere with other users’ processes. In addition, users may own files and
choose whether they share them with other users.
A Linux system normally has a number of users in addition to the ones that correspond to the real human
beings who use the system. You’ll read about these in more detail in Chapter 3, but the most important user to
know about is root. The root user is an exception to the preceding rules because root may terminate and alter
another user’s processes and read any file on the local system. For this reason, root is known as the superuser.
A person who can operate as root is said to have root access and is an administrator on a traditional Unix
system.
NOTE
Operating as root can be dangerous. It can be difficult to identify and correct mistakes because the
system will let you do anything, even if what you’re doing is harmful to the system. For this reason,
system designers constantly try to make root access as unnecessary as possible, for example, by
not requiring root access to switch between wireless networks on a notebook. In addition, as
powerful as the root user is, it still runs in the operating system’s user mode, not kernel mode.
Groups are sets of users. The primary purpose of groups is to allow a user to share file access to other users
in a group.
1.6 Looking Forward
So far, you’ve seen what makes up a running Linux system. User processes make up the environment that you
directly interact with; the kernel manages processes and hardware. Both the kernel and processes reside in
memory.
This is great background information, but you can’t learn the details of a Linux system by reading about it
alone; you need to get your hands dirty. The next chapter starts your journey by teaching you some user-space
basics. Along the way, you’ll learn about a major part of the Linux system that this chapter doesn’t discuss—
long-term storage (disks, files, etc.). After all, you need to store your programs and data somewhere.
www.EBooksWorld.ir
Chapter 2. Basic Commands and Directory Hierarchy
This chapter is a guide to the Unix commands and utilities that will be referenced throughout this book. This
is preliminary material, and you may already know a substantial amount of it. Even if you think you’re up to
speed, take a few seconds to flip through the chapter just to make sure, especially when it comes to the
directory hierarchy material in 2.19 Linux Directory Hierarchy Essentials.
Why Unix commands? Isn’t this a book about how Linux works? It is, of course, but Linux is a Unix flavor
at heart. You’ll see the word Unix in this chapter more than Linux because you can take what you learn straight
over to Solaris, BSD, and other Unix-flavored systems. I’ve attempted to avoid covering too many Linux-
specific user interface extensions, not only to give you a better background for using the other operating
systems, but also because these extensions tend to be unstable. You’ll be able to adapt to new Linux releases
much more quickly if you know the core commands.
NOTE
For more details about Unix for beginners than you’ll find here, consider reading The Linux
Command Line (No Starch Press, 2012), UNIX for the Impatient (Addison-Wesley Professional,
1995), and Learning the UNIX Operating System, 5th edition (O’Reilly, 2001).
2.1 The Bourne Shell: /bin/sh
The shell is one of the most important parts of a Unix system. A shell is a program that runs commands, like
the ones that users enter. The shell also serves as a small programming environment. Unix programmers often
break common tasks into little components and use the shell to manage tasks and piece things together.
Many important parts of the system are actually shell scripts—text files that contain a sequence of shell
commands. If you’ve worked with MS-DOS previously, you can think of shell scripts as very powerful .BAT
files. Because they’re important, Chapter 11 is devoted entirely to shell scripts.
As you progress through this book and gain practice, you’ll add to your knowledge of manipulating commands
using the shell. One of the best things about the shell is that if you make a mistake, you can easily see what
you typed to find out what went wrong, and then try again.
There are many different Unix shells, but all derive several of their features from the Bourne shell (/bin/sh), a
standard shell developed at Bell Labs for early versions of Unix. Every Unix system needs the Bourne shell
in order to function correctly, as you will see throughout this book.
Linux uses an enhanced version of the Bourne shell called bash or the “Bourne-again” shell. The bash shell
is the default shell on most Linux distributions, and /bin/sh is normally a link to bash on a Linux system. You
should use the bash shell when running the examples in this book.
NOTE
You may not have bash as your default shell if you’re using this chapter as a guide for a Unix
account at an organization where you’re not the system administrator. You can change your shell
with chsh or ask your system administrator for help.
www.EBooksWorld.ir
2.2 Using the Shell
When you install Linux, you should create at least one regular user in addition to the root user; this will be
your personal account. For this chapter, you should log in as the regular user.
2.2.1 The Shell Window
After logging in, open a shell window (often referred to as a terminal). The easiest way to do so from a GUI
like Gnome or Ubuntu’s Unity is to open a terminal application, which starts a shell inside a new window.
Once you’ve opened a shell, it should display a prompt at the top that usually ends with a dollar sign ($). On
Ubuntu, that prompt should look like name@host:path$, and on Fedora, it’s [name@host path]$. If
you’re familiar with Windows, the shell window will look something like a DOS command prompt; the
Terminal application in OS X is essentially the same as a Linux shell window.
This book contains many commands that you will type at a shell prompt. They all begin with a single $ to
denote the shell prompt. For example, type this command (just the part in bold, not the $) and press ENTER:
$ echo Hello there.
NOTE
Many shell commands in this book start with #. You should run these as the superuser (root).
These commands usually require extra caution.
Now enter this command:
$ cat /etc/passwd
This command displays the contents of the /etc/passwd system information file and then returns your shell
prompt. Don’t worry about what this file does right now; you’ll learn all about it later, in Chapter 7.
2.2.2 cat
The cat command is one of the easiest Unix commands to understand; it simply outputs the contents of one
or more files. The general syntax of the cat command is as follows:
$ cat file1 file2 ...
When you run this command, cat prints the contents of file1, file2, and any other files that you specify
(denoted by ...), and then exits. The command is called cat because it performs concatenation when it
prints the contents of more than one file.
2.2.3 Standard Input and Standard Output
We’ll use cat to briefly explore Unix input and output (I/O). Unix processes use I/O streams to read and write
data. Processes read data from input streams and write data to output streams. Streams are very flexible. For
example, the source of an input stream can be a file, a device, a terminal, or even the output stream from
another process.
To see an input stream at work, enter cat (with no filenames) and press ENTER. This time, you won’t get your
shell prompt back because cat is still running. Now type anything and press ENTER at the end of each line.
The cat command repeats any line that you type. Once you’re sufficiently bored, press CTRL-D on an empty
line to terminate cat and return to the shell prompt.
The reason cat adopted an interactive behavior has to do with streams. Because you did not specify an input
filename, cat read from the standard input stream provided by the Linux kernel rather than a stream
connected to a file. In this case, the standard input was connected to the terminal in which you ran cat.
www.EBooksWorld.ir
NOTE
Pressing CTRL-D on an empty line stops the current standard input entry from the terminal (and
often terminates a program). Don’t confuse this with CTRL-C, which terminates a program
regardless of its input or output.
Standard output is similar. The kernel gives each process a standard output stream where it can write its output.
The cat command always writes its output to the standard output. When you ran cat in the terminal, the
standard output was connected to that terminal, so that’s where you saw the output.
Standard input and output are often abbreviated as stdin and stdout. Many commands operate as cat does; if
you don’t specify an input file, the command reads from stdin. Output is a little different. Some commands
(like cat) send output only to stdout, but others have the option to send output directly to files.
There is a third standard I/O stream called standard error. You’ll see it in 2.14.1 Standard Error.
One of the best features of standard streams is that you can easily manipulate them to read and write to places
other than the terminal, as you’ll learn in 2.14 Shell Input and Output. In particular, you’ll learn how to connect
streams to files and other processes.
2.3 Basic Commands
Now let’s look at some more Unix commands. Most of the following programs take multiple arguments, and
some have so many options and formats that an unabridged listing would be pointless. This is a simplified list
of the basic commands; you don’t need all of the details just yet.
2.3.1 ls
The ls command lists the contents of a directory. The default is the current directory. Use ls -l for a
detailed (long) listing and ls -F to display file type information. (For more on the file types and permissions
displayed in the left column below, see 2.17 File Modes and Permissions.) Here is a sample long listing; it
includes the owner of the file (column 3), the group (column 4), the file size (column 5), and the modification
date/time (between column 5 and the filename):
$ ls -l
total 3616
-rw-r--r-- 1 juser users 3804 Apr 30 2011 abusive.c
-rw-r--r-- 1 juser users 4165 May 26 2010 battery.zip
-rw-r--r-- 1 juser users 131219 Oct 26 2012 beav_1.40-13.tar.gz
-rw-r--r-- 1 juser users 6255 May 30 2010 country.c
drwxr-xr-x 2 juser users 4096 Jul 17 20:00 cs335
-rwxr-xr-x 1 juser users 7108 Feb 2 2011 dhry
-rw-r--r-- 1 juser users 11309 Oct 20 2010 dhry.c
-rw-r--r-- 1 juser users 56 Oct 6 2012 doit
drwxr-xr-x 6 juser users 4096 Feb 20 13:51 dw
drwxr-xr-x 3 juser users 4096 May 2 2011 hough-stuff
You’ll learn more about the d in column 1 of this output in 2.17 File Modes and Permissions.
www.EBooksWorld.ir
2.3.2 cp
In its simplest form, cp copies files. For example, to copy file1 to file2, enter this:
$ cp file1 file2
To copy a number of files to a directory (folder) named dir, try this instead:
$ cp file1 ... fileN dir
2.3.3 mv
The mv (move) command is like cp. In its simplest form, it renames a file. For example, to rename file1 to
file2, enter this:
$ mv file1 file2
You can also use mv to move a number of files to a different directory:
$ mv file1 ... fileN dir
2.3.4 touch
The touch command creates a file. If the file already exists, touch does not change it, but it does update
the file’s modification time stamp printed with the ls -l command. For example, to create an empty file,
enter this:
$ touch file
Then run ls -l on that file. You should see output like the following, where the date and time ➊ indicate
when you ran touch:
$ ls -l file
-rw-r--r-- 1 juser users 0 May 21 18:32➊ file
2.3.5 rm
To delete (remove) a file, use rm. After you remove a file, it’s gone from your system and generally cannot be
undeleted.
$ rm file
2.3.6 echo
The echo command prints its arguments to the standard output:
$ echo Hello again.
Hello again.
The echo command is very useful for finding expansions of shell globs (“wildcards” such as *) and variables
(such as $HOME), which you will encounter later in this chapter.
2.4 Navigating Directories
Unix has a directory hierarchy that starts at /, sometimes called the root directory. The directory separator is
the slash (/), not the backslash (\). There are several standard subdirectories in the root directory, such as /usr,
as you’ll learn in 2.19 Linux Directory Hierarchy Essentials.
www.EBooksWorld.ir
When you refer to a file or directory, you specify a path or pathname. When a path starts with / (such as
/usr/lib), it’s a full or absolute path.
A path component identified by two dots (..) specifies the parent of a directory. For example, if you’re working
in /usr/lib, the path .. would refer to /usr. Similarly, ../bin would refer to /usr/bin.
One dot (.) refers to the current directory; for example, if you’re in /usr/lib, the path . is still /usr/lib, and ./X11
is /usr/lib/X11. You won’t have to use . very often because most commands default to the current directory if
a path doesn’t start with / (you could just use X11 instead of ./X11 in the preceding example).
A path not beginning with / is called a relative path. Most of the time, you’ll work with relative pathnames,
because you’ll already be in the directory you need to be in or somewhere close by.
Now that you have a sense of the basic directory mechanics, here are some essential directory commands.
2.4.1 cd
The current working directory is the directory that a process (such as the shell) is currently in. The cd
command changes the shell’s current working directory:
$ cd dir
If you omit dir, the shell returns to your home directory, the directory you started in when you first logged
in.
2.4.2 mkdir
The mkdir command creates a new directory dir:
$ mkdir dir
2.4.3 rmdir
The rmdir command removes the directory dir:
$ rmdir dir
If dir isn’t empty, this command fails. However, if you’re impatient, you probably don’t want to laboriously
delete all the files and subdirectories inside dir first. You can use rm -rf dir to delete a directory and its
contents, but be careful! This is one of the few commands that can do serious damage, especially if you run it
as the superuser. The -r option specifies recursive delete to repeatedly delete everything inside dir, and -f
forces the delete operation. Don’t use the -rf flags with globs such as a star (*). And above all, always
double-check your command before you run it.
2.4.4 Shell Globbing (Wildcards)
The shell can match simple patterns to file and directory names, a process known as globbing. This is similar
to the concept of wildcards in other systems. The simplest of these is the glob character *, which tells the shell
to match any number of arbitrary characters. For example, the following command prints a list of files in the
current directory:
$ echo *
The shell matches arguments containing globs to filenames, substitutes the filenames for those arguments, and
then runs the revised command line. The substitution is called expansion because the shell substitutes all
matching filenames. Here are some ways to use * to expand filenames:
o at* expands to all filenames that start with at.
o *at expands to all filenames that end with at.
www.EBooksWorld.ir
o *at* expands to all filenames that contain at.
If no files match a glob, the shell performs no expansion, and the command runs with literal characters such
as *. For example, try a command such as echo *dfkdsafh.
NOTE
If you’re used to MS-DOS, you might instinctively type *.* to match all files. Break this habit now.
In Linux and other versions of Unix, you must use * to match all files. In the Unix shell, *.*
matches only files and directories that contain the dot (.) character in their names. Unix filenames
do not need extensions and often do not carry them.
Another shell glob character, the question mark (?), instructs the shell to match exactly one arbitrary character.
For example, b?at matches boat and brat.
If you don’t want the shell to expand a glob in a command, enclose the glob in single quotes (''). For example,
the command echo '*' prints a star. You will find this handy for a few of the commands described in the
next section, such as grep and find. (You’ll learn more much about quoting in 11.2 Quoting and Literals.)
NOTE
It is important to remember that the shell performs expansions before running commands, and
only then. Therefore, if a * makes it to a command without expanding, the shell will do nothing
more with it; it’s up to the command to decide what it wants to do.
There is more to a modern shell’s pattern-matching capabilities, but * and ? are what you need to know now.
2.5 Intermediate Commands
The following sections describe the most essential intermediate Unix commands.
2.5.1 grep
The grep command prints the lines from a file or input stream that match an expression. For example, to
print the lines in the /etc/passwd file that contain the text root, enter this:
$ grep root /etc/passwd
The grep command is extraordinarily handy when operating on multiple files at once because it prints the
filename in addition to the matching line. For example, if you want to check every file in /etc that contains the
word root, you could use this command:
$ grep root /etc/*
Two of the most important grep options are -i (for case-insensitive matches) and -v (which inverts the
search, that is, prints all lines that don’t match). There is also a more powerful variant called egrep (which
is just a synonym for grep -E).
grep understands patterns known as regular expressions that are grounded in computer science theory and
are very common in Unix utilities. Regular expressions are more powerful than wildcard-style patterns, and
they have a different syntax. There are two important things to remember about regular expressions:
o .* matches any number of characters (like the * in wildcards).
o . matches one arbitrary character.
NOTE
The grep(1) manual page contains a detailed description of regular expressions, but it can be a
little difficult to read. To learn more, you can read Mastering Regular Expressions, 3rd edition
(O’Reilly, 2006), or see the regular expressions chapter of Programming Perl, 4th edition (O’Reilly,
www.EBooksWorld.ir
2012). If you like math and are interested in where regular expressions come from, look up
Introduction to Automata Theory, Languages, and Computation, 3rd edition (Prentice Hall, 2006).
2.5.2 less
The less command comes in handy when a file is really big or when a command’s output is long and scrolls
off the top of the screen.
To page through a big file like /usr/share/dict/words, use the command less /usr/share/dict/words.
When running less, you’ll see the contents of the file one screenful at a time. Press the spacebar to go
forward in the file and the b key to skip back one screenful. To quit, type q.
NOTE
The less command is an enhanced version of an older program named more. Most Linux
desktops and servers have less, but it’s not standard on many embedded systems and other
Unix systems. So if you ever run into a situation when you can’t use less, try more.
You can also search for text inside less. For example, to search forward for a word, type /word, and to
search backward, use ?word. When you find a match, press n to continue searching.
As you’ll learn in 2.14 Shell Input and Output, you can send the standard output of nearly any program directly
to another program’s standard input. This is exceptionally useful when you have a command with a lot of
output to sift through and you’d like to use something like less to view the output. Here’s an example of
sending the output of a grep command to less:
$ grep ie /usr/share/dict/words | less
Try this command out for yourself. You’ll probably use less like this a lot.
2.5.3 pwd
The pwd (print working directory) program simply outputs the name of the current working directory. You
may be wondering why you need this when most Linux distributions set up accounts with the current working
directory in the prompt. There are two reasons.
First, not all prompts include the current working directory, and you may even want to get rid of it in your
own prompt because it takes up a lot of space. If you do so, you need pwd.
Second, the symbolic links that you’ll learn about in 2.17.2 Symbolic Links can sometimes obscure the true
full path of the current working directory. You’ll use pwd -P to eliminate this confusion.
2.5.4 diff
To see the differences between two text files, use diff:
$ diff file1 file2
Several options can control the format of the output, and the default output format is often the most
comprehensible for human beings. However, most programmers prefer the output from diff -u when they
need to send the output to someone else because automated tools can make better use of it.
2.5.5 file
If you see a file and are unsure of its format, try using the file command to see if the system can guess:
$ file file
You may be surprised by how much this innocent-looking command can do.
www.EBooksWorld.ir
2.5.6 find and locate
It’s frustrating when you know that a certain file is in a directory tree somewhere but you just don’t know
where. Run find to find file in dir:
$ find dir -name file -print
Like most programs in this section, find is capable of some fancy stuff. However, don’t try options such as
-exec before you know the form shown here by heart and why you need the -name and -print options.
The find command accepts special pattern-matching characters such as *, but you must enclose them in
single quotes ('*')to protect the special characters from the shell’s own globbing feature. (Recall from 2.4.4
Shell Globbing (Wildcards) that the shell expands globs before running commands.)
Most systems also have a locate command for finding files. Rather than searching for a file in real time,
locate searches an index that the system builds periodically. Searching with locate is much faster than
find, but if the file you’re looking for is newer than the index, locate won’t find it.
2.5.7 head and tail
To quickly view a portion of a file or stream of data, use the head and tail commands. For example, head
/etc/passwd shows the first 10 lines of the password file, and tail /etc/passwd shows the last 10
lines.
To change the number of lines to display, use the -n option, where n is the number of lines you want to see
(for example, head -5 /etc/passwd). To print lines starting at line n, use tail +n.
2.5.8 sort
The sort command quickly puts the lines of a text file in alphanumeric order. If the file’s lines start with
numbers and you want to sort in numerical order, use the -n option. The -r option reverses the order of the
sort.
2.6 Changing Your Password and Shell
Use the passwd command to change your password. You’ll be asked for your old password and then
prompted for your new password twice. Choose a password that does not include real words in any language
and don’t try to combine words.
One of the easiest ways to create a good password is to pick a sentence, produce an acronym from it, and then
modify the acronym with a number or some punctuation. Then all you need to do is remember the sentence.
You can change your shell with the chsh command (to an alternative such as ksh or tcsh), but keep in
mind that this book assumes that you’re running bash.
2.7 Dot Files
Change to your home directory, take a look around with ls, and then run ls -a. Do you see the difference
in the output? When you run ls without the -a, you won’t see the configuration files called dot files. These
are files and directories whose names begin with a dot (.). Common dot files are .bashrc and .login, and there
are dot directories, too, such as .ssh.
There is nothing special about dot files or directories. Some programs don’t show them by default so that you
won’t see a complete mess when listing the contents of your home directory. For example, ls doesn’t list dot
files unless you use the -a option. In addition, shell globs don’t match dot files unless you explicitly use a
pattern such as .*.
www.EBooksWorld.ir
NOTE
You can run into problems with globs because .* matches . and .. (the current and parent
directories). You may wish to use a pattern such as .[^.]* or .??* to get all dot files except the
current and parent directories.
2.8 Environment and Shell Variables
The shell can store temporary variables, called shell variables, containing the values of text strings. Shell
variables are very useful for keeping track of values in scripts, and some shell variables control the way the
shell behaves. (For example, the bash shell reads the PS1 variable before displaying the prompt.)
To assign a value to a shell variable, use the equal sign (=). Here’s a simple example:
$ STUFF=blah
The preceding example sets the value of the variable named STUFF to blah. To access this variable, use
$STUFF (for example, try running echo $STUFF). You’ll learn about the many uses of shell variables in
Chapter 11.
An environment variable is like a shell variable, but it’s not specific to the shell. All processes on Unix systems
have environment variable storage. The main difference between environment and shell variables is that the
operating system passes all of your shell’s environment variables to programs that the shell runs, whereas shell
variables cannot be accessed in the commands that you run.
Assign an environment variable with the shell’s export command. For example, if you’d like to make the
$STUFF shell variable into an environment variable, use the following:
$ STUFF=blah
$ export STUFF
Environment variables are useful because many programs read them for configuration and options. For
example, you can put your favorite less command-line options in the LESS environment variable, and less
will use those options when you run it. (Many manual pages contain a section marked ENVIRONMENT that
describes these variables.)
2.9 The Command Path
PATH is a special environment variable that contains the command path (or path for short). A command path
is a list of system directories that the shell searches when trying to locate a command. For example, when you
run ls, the shell searches the directories listed in PATH for the ls program. If programs with the same name
appear in several directories in the path, the shell runs the first matching program.
If you run echo $PATH, you’ll see that the path components are separated by colons (:). For example:
$ echo $PATH
/usr/local/bin:/usr/bin:/bin
To tell the shell to look in more places for programs, change the PATH environment variable. For example, by
using this command, you can add a directory dir to the beginning of the path so that the shell looks in dir
before looking in any of the other PATH directories.
$ PATH=dir:$PATH
Or you can append a directory name to the end of the PATH variable, causing the shell to look in dir last:
www.EBooksWorld.ir
$ PATH=$PATH:dir
NOTE
Be careful when modifying the path because you can accidentally wipe out your entire path if you
mistype $PATH. If this happens, don’t panic! The damage isn’t permanent; you can just start a new
shell. (For a lasting effect, you need to mistype it when editing a certain configuration file, and
even then it isn’t difficult to rectify.) One of the easiest ways to return to normal is to close the
current terminal window and start another.
2.10 Special Characters
When discussing Linux with others, you should know a few names for some of the special characters that
you’ll encounter. If you’re amused by this sort of thing, see the “Jargon File”
(http://www.catb.org/jargon/html/) or its printed companion, The New Hacker’s Dictionary (MIT Press, 1996).
Table 2-1 describes a select set of the special characters, many of which you’ve already seen in this chapter.
Some utilities, such as the Perl programming language, use almost all of these special characters! (Keep in
mind that these are the American names for the characters.)
Table 2-1. Special Characters
Character Name(s) Uses
* asterisk, star Regular expression, glob character
. dot Current directory, file/hostname delimiter
! bang Negation, command history
| pipe Command pipes
/ (forward) slash Directory delimiter, search command
\ backslash Literals, macros (never directories)
$ dollar Variable denotation, end of line
' tick, (single) quote Literal strings
` backtick, backquote Command substitution
" double quote Semi-literal strings
^ caret Negation, beginning of line
~ tilde, squiggle Negation, directory shortcut
# hash, sharp, pound Comments, preprocessor, substitutions
[ ] (square) brackets Ranges
www.EBooksWorld.ir
Character Name(s) Uses
{ } braces, (curly) brackets Statement blocks, ranges
_ underscore, under Cheap substitute for a space
NOTE
You will often see control characters marked with a caret; for example, ^C for ctrl-c.
2.11 Command-Line Editing
As you play with the shell, notice that you can edit the command line using the left and right arrow keys, as
well as page through previous commands using the up and down arrows. This is standard on most Linux
systems.
However, it’s a good idea to forget about the arrow keys and use control key sequences instead. If you learn
the ones listed in Table 2-2, you’ll find that you’re better able to enter text in the many Unix programs that
use these standard keystrokes.
Table 2-2. Command-Line Keystrokes
Keystroke Action
CTRL-B Move the cursor left
CTRL-F Move the cursor right
CTRL-P View the previous command (or move the cursor up)
CTRL-N View the next command (or move the cursor down)
CTRL-A Move the cursor to the beginning of the line
CTRL-E Move the cursor to the end of the line
CTRL-W Erase the preceding word
CTRL-U Erase from cursor to beginning of line
CTRL-K Erase from cursor to end of line
CTRL-Y Paste erased text (for example, from CTRL-U)
2.12 Text Editors
Speaking of editing, it’s time to learn an editor. To get serious with Unix, you must be able to edit text files
without damaging them. Most parts of the system use plaintext configuration files (like the ones in /etc). It’s
not difficult to edit files, but you will do it so often that you need a powerful tool for the job.
You should try to learn one of the two de facto standard Unix text editors, vi and Emacs. Most Unix wizards
www.EBooksWorld.ir
are religious about their choice of editor, but don’t listen to them. Just choose for yourself. If you choose one
that matches the way that you work, you’ll find it easier to learn. Basically, the choice comes down to this:
o If you want an editor that can do almost anything and has extensive online help, and you don’t mind doing
some extra typing to get these features, try Emacs.
o If speed is everything, give vi a shot; it “plays” a bit like a video game.
Learning the vi and Vim Editors: Unix Text Processing, 7th edition (O’Reilly, 2008) can tell you everything
you need to know about vi. For Emacs, use the online tutorial: Start Emacs, press CTRL-H, and then type T. Or
read GNU Emacs Manual (Free Software Foundation, 2011).
You might be tempted to experiment with a friendlier editor when you first start out, such as Pico or one of
the myriad GUI editors out there, but if you tend to make a habit out of the first thing that you use, you don’t
want to go down this route.
NOTE
Editing text is where you’ll first start to see a difference between the terminal and the GUI. Editors
such as vi run inside the terminal window, using the standard terminal I/O interface. GUI editors
start their own window and present their own interface, independent of terminals. Emacs runs in a
GUI by default but will run in a terminal window as well.
2.13 Getting Online Help
Linux systems come with a wealth of documentation. For basic commands, the manual pages (or man pages)
will tell you what you need to know. For example, to see the manual page for the ls command, run man as
follows:
$ man ls
Most manual pages concentrate primarily on reference information, perhaps with some examples and cross-
references, but that’s about it. Don’t expect a tutorial, and don’t expect an engaging literary style.
When programs have many options, the manual page often lists the options in some systematic way (for
example, in alphabetical order), but it won’t tell you what the important ones are. If you’re patient, you can
usually find what you need to know in the man page. If you’re impatient, ask a friend—or pay someone to be
your friend so that you can ask him or her.
To search for a manual page by keyword, use the -k option:
$ man -k keyword
This is helpful if you don’t quite know the name of the command that you want. For example, if you’re looking
for a command to sort something, run:
$ man -k sort
--snip--
comm (1) - compare two sorted files line by line
qsort (3) - sorts an array
sort (1) - sort lines of text files
sortm (1) - sort messages
tsort (1) - perform topological sort
www.EBooksWorld.ir
--snip--
The output includes the manual page name, the manual section (see below), and a quick description of what
the manual page contains.
NOTE
If you have any questions about the commands described in the previous sections, you may be
able to find the answers by using the man command.
Manual pages are referenced by numbered sections. When someone refers to a manual page, the section
number appears in parentheses next to the name, like ping(8), for example. Table 2-3 lists the sections and
their numbers.
Table 2-3. Online Manual Sections
Section Description
1 User commands
2 System calls
3 Higher-level Unix programming library documentation
4 Device interface and driver information
5 File descriptions (system configuration files)
6 Games
7 File formats, conventions, and encodings (ASCII, suffixes, and so on)
8 System commands and servers
Sections 1, 5, 7, and 8 should be good supplements to this book. Section 4 may be of marginal use, and Section
6 would be great if only it were a little larger. You probably won’t be able to use Section 3 if you aren’t a
programmer, but you may be able to understand some of the material in Section 2 once you’ve read more
about system calls in this book.
You can select a manual page by section, which is sometimes important because man displays the first manual
page that it finds when matching a particular search term. For example, to read the /etc/passwd file description
(as opposed to the passwd command), you can insert the section number before the page name:
$ man 5 passwd
Manual pages cover the essentials, but there are many more ways to get online help. If you’re just looking for
a certain option for a command, try entering a command name followed by --help or -h (the option varies
from command to command). You may get a deluge (as in the case of ls --help), or you may find just
what you’re looking for.
Some time ago, the GNU Project decided that it didn’t like manual pages very much and switched to another
format called info (or texinfo). Often this documentation goes further than a typical manual page does, but it
is sometimes more complex. To access an info manual, use info with the command name:
$ info command
www.EBooksWorld.ir
Some packages dump their available documentation into /usr/share/doc with no regard for online manual
systems such as man or info. See this directory on your system if you find yourself searching for
documentation. And of course, search the Internet.
2.14 Shell Input and Output
Now that you’re familiar with basic Unix commands, files, and directories, you’re ready to learn how to
redirect standard input and output. Let’s start with standard output.
To send the output of command to a file instead of the terminal, use the > redirection character:
$ command > file
The shell creates file if it does not already exist. If file exists, the shell erases (clobbers) the original file
first. (Some shells have parameters that prevent clobbering. For example, enter set -C to avoid clobbering
in bash.)
You can append the output to the file instead of overwriting it with the >> redirection syntax:
$ command >> file
This is a handy way to collect output in one place when executing sequences of related commands.
To send the standard output of a command to the standard input of another command, use the pipe character
(|). To see how this works, try these two commands:
$ head /proc/cpuinfo
$ head /proc/cpuinfo | tr a-z A-Z
You can send output through as many piped commands as you wish; just add another pipe before each
additional command.
2.14.1 Standard Error
Occasionally, you may redirect standard output but find that the program still prints something to the terminal.
This is called standard error (stderr); it’s an additional output stream for diagnostics and debugging. For
example, this command produces an error:
$ ls /fffffffff > f
After completion, f should be empty, but you still see the following error message on the terminal as standard
error:
ls: cannot access /fffffffff: No such file or directory
You can redirect the standard error if you like. For example, to send standard output to f and standard error to
e, use the 2> syntax, like this:
$ ls /fffffffff > f 2> e
The number 2 specifies the stream ID that the shell modifies. Stream ID 1 is standard output (the default), and
2 is standard error.
You can also send the standard error to the same place as stdout with the >& notation. For example, to send
both standard output and standard error to the file named f, try this command:
$ ls /fffffffff > f 2>&1
www.EBooksWorld.ir
2.14.2 Standard Input Redirection
To channel a file to a program’s standard input, use the < operator:
$ head < /proc/cpuinfo
You will occasionally run into a program that requires this type of redirection, but because most Unix
commands accept filenames as arguments, this isn’t very common. For example, the preceding command
could have been written as head /proc/cpuinfo.
2.15 Understanding Error Messages
When you encounter a problem on a Unix-like system such as Linux, you must read the error message. Unlike
messages from other operating systems, Unix errors usually tell you exactly what went wrong.
2.15.1 Anatomy of a UNIX Error Message
Most Unix programs generate and report the same basic error messages, but there can be subtle differences
between the output of any two programs. Here’s an example that you’ll certainly encounter in some form or
other:
$ ls /dsafsda
ls: cannot access /dsafsda: No such file or directory
There are three components to this message:
o The program name, ls. Some programs omit this identifying information, which can be annoying when
writing shell scripts, but it’s not really a big deal.
o The filename, /dsafsda, which is a more specific piece of information. There’s a problem with this path.
o The error No such file or directory indicates the problem with the filename.
Putting it all together, you get something like “ls tried to open /dsafsda but couldn’t because it doesn’t
exist.” This may seem obvious, but these messages can get a little confusing when you run a shell script that
includes an erroneous command under a different name.
When troubleshooting errors, always address the first error first. Some programs report that they can’t do
anything before reporting a host of other problems. For example, say you run a fictitious program called
scumd and you see this error message:
scumd: cannot access /etc/scumd/config: No such file or directory
Following this is a huge list of other error messages that looks like a complete catastrophe. Don’t let those
other errors distract you. You probably just need to create /etc/scumd/config.
NOTE
Don’t confuse error messages with warning messages. Warnings often look like errors, but they
contain the word warning. A warning usually means something is wrong but the program will try to
continue running anyway. To fix a problem noted in a warning message, you may have to hunt
down a process and kill it before doing anything else. (You’ll learn about listing and killing
processes in 2.16 Listing and Manipulating Processes.)
2.15.2 Common Errors
Many errors that you’ll encounter in Unix programs result from things that can go wrong with files and
processes. Here’s an error message hit parade:
www.EBooksWorld.ir
No such file or directory
This is the number one error. You tried to access a file that doesn’t exist. Because the Unix file I/O system
doesn’t discriminate between files and directories, this error message occurs everywhere. You get it when you
try to read a file that does not exist, when you try to change to a directory that isn’t there, when you try to
write to a file in a directory that doesn’t exist, and so on.
File exists
In this case, you probably tried to create a file that already exists. This is common when you try to create a
directory with the same name as a file.
Not a directory, Is a directory
These messages pop up when you try to use a file as a directory or a directory as a file. For example:
$ touch a
$ touch a/b
touch: a/b: Not a directory
Notice that the error message only applies to the a part of a/b. When you encounter this problem, you may
need to dig around a little to find the path component that is being treated like a directory.
No space left on device
You’re out of disk space.
Permission denied
You get this error when you attempt to read or write to a file or directory that you’re not allowed to access
(you have insufficient privileges). This error also shows when you try to execute a file that does not have the
execute bit set (even if you can read the file). You’ll read more about permissions in 2.17 File Modes and
Permissions.
Operation not permitted
This usually happens when you try to kill a process that you don’t own.
Segmentation fault, Bus error
A segmentation fault essentially means that the person who wrote the program that you just ran screwed up
somewhere. The program tried to access a part of memory that it was not allowed to touch, and the operating
system killed it. Similarly, a bus error means that the program tried to access some memory in a particular
way that it shouldn’t. When you get one of these errors, you might be giving a program some input that it did
not expect.
2.16 Listing and Manipulating Processes
Recall from Chapter 1 that a process is a running program. Each process on the system has a numeric process
ID (PID). For a quick listing of running processes, just run ps on the command line. You should get a list like
this one:
$ ps
PID TTY STAT TIME COMMAND
520 p0 S 0:00 -bash
545 ? S 3:59 /usr/X11R6/bin/ctwm -W
www.EBooksWorld.ir
548 ? S 0:10 xclock -geometry -0-0
2159 pd SW 0:00 /usr/bin/vi lib/addresses
31956 p3 R 0:00 ps
The fields are as follows:
o PID. The process ID.
o TTY. The terminal device where the process is running. More about this later.
o STAT. The process status, that is, what the process is doing and where its memory resides. For example, S
means sleeping and R means running. (See the ps(1) manual page for a description of all the symbols.)
o TIME. The amount of CPU time in minutes and seconds that the process has used so far. In other words,
the total amount of time that the process has spent running instructions on the processor.
o COMMAND. This one might seem obvious, but be aware that a process can change this field from its
original value.
2.16.1 Command Options
The ps command has many options. To make things more confusing, you can specify options in three different
styles—Unix, BSD, and GNU. Many people find the BSD style to be the most comfortable (perhaps because
it involves less typing), so we’ll use the BSD style in this book. Here are some of the most useful option
combinations:
ps x Show all of your running processes.
ps ax Show all processes on the system, not just the ones you own.
ps u Include more detailed information on processes.
ps w Show full command names, not just what fits on one line.
As with other programs, you can combine options, as in ps aux and ps auxw. To check on a specific
process, add its PID to the argument list of the ps command. For example, to inspect the current shell process,
you could use ps u $$, because $$ is a shell variable that evaluates to the current shell’s PID. (You’ll find
information on the administration commands top and lsof in Chapter 8. These can be useful for locating
processes, even when doing something other than system maintenance.)
2.16.2 Killing Processes
To terminate a process, send it a signal with the kill command. A signal is a message to a process from the
kernel. When you run kill, you’re asking the kernel to send a signal to another process. In most cases, all
you need to do is this:
$ kill pid
There are many types of signals. The default is TERM, or terminate. You can send different signals by adding
an extra option to kill. For example, to freeze a process instead of terminating it, use the STOP signal:
$ kill -STOP pid
A stopped process is still in memory, ready to pick up where it left off. Use the CONT signal to continue
running the process again:
www.EBooksWorld.ir
$ kill -CONT pid
NOTE
Using ctrl-c to terminate a process that is running in the current terminal is the same as using
kill to end the process with the INT (interrupt) signal.
The most brutal way to terminate a process is with the KILL signal. Other signals give the process a chance
to clean up after itself, but KILL does not. The operating system terminates the process and forcibly removes
it from memory. Use this as a last resort.
You should not kill processes indiscriminately, especially if you don’t know what they’re doing. You may be
shooting yourself in the foot.
You may see other users entering numbers instead of names with kill; for example, kill -9 instead of
kill -KILL. This is because the kernel uses numbers to denote the different signals; you can use kill
this way if you know the number of the signal that you want to send.
2.16.3 Job Control
Shells also support job control, which is a way to send TSTP (similar to STOP) and CONT signals to programs
by using various keystrokes and commands. For example, you can send a TSTP signal with CTRL-Z, then start
the process again by entering fg (bring to foreground) or bg (move to background; see the next section). But
despite its utility and the habits of many experienced users, job control is not necessary and can be confusing
for beginners: It’s common for users to press CTRL-Z instead of CTRL-c, forget about what they were running,
and eventually end up with numerous suspended processes hanging around.
HINT
To see if you’ve accidentally suspended any processes on your current terminal, run the jobs
command.
If you want to run multiple shells, run each program in a separate terminal window, put noninteractive
processes in the background (as explained in the next section), or learn to use the screen program.
2.16.4 Background Processes
Normally, when you run a Unix command from the shell, you don’t get the shell prompt back until the program
finishes executing. However, you can detach a process from the shell and put it in the “background” with the
ampersand (&); this gives you the prompt back. For example, if you have a large file that you need to
decompress with gunzip (you’ll see this in 2.18 Archiving and Compressing Files), and you want to do some
other stuff while it’s running, run a command like this one:
$ gunzip file.gz &
The shell should respond by printing the PID of the new background process, and the prompt should return
immediately so that you can continue working. The process will continue to run after you log out, which
comes in particularly handy if you have to run a program that does a lot of number crunching for a while.
(Depending on your setup, the shell might notify you when the process completes.)
The dark side of running background processes is that they may expect to work with the standard input (or
worse, read directly from the terminal). If a program tries to read something from the standard input when it’s
in the background, it can freeze (try fg to bring it back) or terminate. Also, if the program writes to the
standard output or standard error, the output can appear in the terminal window with no regard for anything
else running there, meaning that you can get unexpected output when you’re working on something else.
The best way to make sure that a background process doesn’t bother you is to redirect its output (and possibly
input) as described in 2.14 Shell Input and Output.
www.EBooksWorld.ir
If spurious output from background processes gets in your way, learn how to redraw the content of your
terminal window. The bash shell and most full-screen interactive programs support CTRL-L to redraw the
entire screen. If a program is reading from the standard input, CTRL-R usually redraws the current line, but
pressing the wrong sequence at the wrong time can leave you in an even worse situation than before. For
example, entering CTRL-R at the bash prompt puts you in reverse isearch mode (press ESC to exit).
2.17 File Modes and Permissions
Every Unix file has a set of permissions that determine whether you can read, write, or run the file. Running
ls -l displays the permissions. Here’s an example of such a display:
-rw-r--r--➊ 1 juser somegroup 7041 Mar 26 19:34 endnotes.html
The file’s mode ➊ represents the file’s permissions and some extra information. There are four parts to the
mode, as illustrated in Figure 2-1.
The first character of the mode is the file type. A dash (-) in this position, as in the example, denotes a regular
file, meaning that there’s nothing special about the file. This is by far the most common kind of file. Directories
are also common and are indicated by a d in the file type slot. (3.1 Device Files lists the remaining file types.)
Figure 2-1. The pieces of a file mode
The rest of a file’s mode contains the permissions, which break down into three sets: user, group, and other,
in that order. For example, the rw- characters in the example are the user permissions, the r-- characters
that follow are the group permissions, and the final r-- characters are the other permissions.
Each permission set can contain four basic representations:
r Means that the file is readable.
w Means that the file is writable.
x Means that the file is executable (you can run it as a program).
- Means nothing.
The user permissions (the first set) pertain to the user who owns the file. In the preceding example, that’s
juser. The second set, group permissions, are for the file’s group (somegroup in the example). Any user
in that group can take advantage of these permissions. (Use the groups command to see what group you’re
in, and see 7.3.5 Working with Groups for more information.)
Everyone else on the system has access according to the third set, the other permissions, which are sometimes
called world permissions.
NOTE
Each read, write, and execute permission slot is sometimes called a permission bit. Therefore, you
may hear people refer to parts of the permissions as “the read bits.”
Some executable files have an s in the user permissions listing instead of an x. This indicates that the
www.EBooksWorld.ir
executable is setuid, meaning that when you execute the program, it runs as though the file owner is the user
instead of you. Many programs use this setuid bit to run as root in order to get the privileges they need to
change system files. One example is the passwd program, which needs to change the /etc/passwd file.
2.17.1 Modifying Permissions
To change permissions, use the chmod command. First, pick the set of permissions that you want to change,
and then pick the bit to change. For example, to add group (g) and world (o, for “other”) read (r) permissions
to file, you could run these two commands:
$ chmod g+r file
$ chmod o+r file
Or you could do it all in one shot:
$ chmod go+r file
To remove these permissions, use go-r instead of go+r.
NOTE
Obviously, you shouldn’t make files world-writable because doing so gives anyone on your system
the ability to change them. But would this allow anyone connected to the Internet to change your
files? Probably not, unless your system has a network security hole. In that case, file permissions
won’t help you anyway.
You may sometimes see people changing permissions with numbers, for example:
$ chmod 644 file
This is called an absolute change because it sets all permission bits at once. To understand how this works,
you need to know how to represent the permission bits in octal form (each numeral represents a number in
base 8 and corresponds to a permission set). See the chmod(1) manual page or info manual for more.
You don’t really need to know how to construct absolute modes; just memorize the modes that you use most
often. Table 2-4 lists the most common ones.
Table 2-4. Absolute Permission Modes
Mode Meaning Used For
644 user: read/write; group, other: read files
600 user: read/write; group, other: none files
755 user: read/write/execute; group, other: read/execute directories, programs
700 user: read/write/execute; group, other: none directories, programs
711 user: read/write/execute; group, other: execute directories
Directories also have permissions. You can list the contents of a directory if it’s readable, but you can only
access a file in a directory if the directory is executable. (One common mistake people make when setting the
permissions of directories is to accidentally remove the execute permission when using absolute modes.)
Finally, you can specify a set of default permissions with the umask shell command, which applies a
www.EBooksWorld.ir
predefined set of permissions to any new file you create. In general, use umask 022 if you want everyone
to be able to see all of the files and directories that you create, and use umask 077 if you don’t. (You’ll need
to put the umask command with the desired mode in one of your startup files to make your new default
permissions apply to later sessions, as discussed in Chapter 13.)
2.17.2 Symbolic Links
A symbolic link is a file that points to another file or a directory, effectively creating an alias (like a shortcut
in Windows). Symbolic links offer quick access to obscure directory paths.
In a long directory listing, symbolic links look like this (notice the l as the file type in the file mode):
lrwxrwxrwx 1 ruser users 11 Feb 27 13:52 somedir -> /home/origdir
If you try to access somedir in this directory, the system gives you /home/origdir instead. Symbolic links are
simply names that point to other names. Their names and the paths to which they point don’t have to mean
anything. For example, /home/origdir doesn’t even need to exist.
In fact, if /home/origdir does not exist, any program that accesses somedir reports that somedir doesn’t exist
(except for ls somedir, a command that stupidly informs you that somedir is somedir). This can be baffling
because you can see something named somedir right in front of your eyes.
This is not the only way that symbolic links can be confusing. Another problem is that you can’t identify the
characteristics of a link target just by looking at the name of the link; you must follow the link to see if it goes
to a file or directory. Your system may also have links that point to other links, which are called chained
symbolic links.
2.17.3 Creating Symbolic Links
To create a symbolic link from target to linkname, use ln -s:
$ ln -s target linkname
The linkname argument is the name of the symbolic link, the target argument is the path of the file or
directory that the link points to, and the -s flag specifies a symbolic link (see the warning that follows).
When making a symbolic link, check the command twice before you run it because several things can go
wrong. For example, if you reverse the order of the arguments (ln -s linkname target), you’re in for
some fun if linkname is a directory that already exists. If this is the case (and it quite often is), ln creates a
link named target inside linkname, and the link will point to itself unless linkname is a full path. If something
goes wrong when you create a symbolic link to a directory, check that directory for errant symbolic links and
remove them.
Symbolic links can also cause headaches when you don’t know that they exist. For example, you can easily
edit what you think is a copy of a file but is actually a symbolic link to the original.
WARNING
Don’t forget the -s option when creating a symbolic link. Without it, ln creates a hard link, giving
an additional real filename to a single file. The new filename has the status of the old one; it points
(links) directly to the file data instead of to another filename as a symbolic link does. Hard links can
be even more confusing than symbolic links. Unless you understand the material in 4.5 Inside a
Traditional Filesystem, avoid using them.
With all of these warnings regarding symbolic links, why would anyone bother to use them? Because they
offer a convenient way to organize and share files, as well as patch up small problems.
www.EBooksWorld.ir
2.18 Archiving and Compressing Files
Now that you’ve learned about files, permissions, and possible errors, you need to master gzip and tar.
2.18.1 gzip
The program gzip (GNU Zip) is one of the current standard Unix compression programs. A file that ends
with .gz is a GNU Zip archive. Use gunzip file.gz to uncompress <file>.gz and remove the suffix; to
compress it again, use gzip file.
2.18.2 tar
Unlike the zip programs for other operating systems, gzip does not create archives of files; that is, it doesn’t
pack multiple files and directories into one file. To create an archive, use tar instead:
$ tar cvf archive.tar file1 file2 ...
Archives created by tar usually have a .tar suffix (this is by convention; it isn’t required). For example, in
the command above, file1, file2, and so on are the names of the files and directories that you wish to
archive in <archive>.tar. The c flag activates create mode. The r and f flags have more specific roles.
The v flag activates verbose diagnostic output, causing tar to print the names of the files and directories in
the archive when it encounters them. Adding another v causes tar to print details such as file size and
permissions. If you don’t want tar to tell you what it’s doing, omit the v flag.
The f flag denotes the file option. The next argument on the command line after the f flag must be the archive
file for tar to create (in the preceding example, it is <archive>.tar). You must use this option followed by a
filename at all times, except with tape drives. To use standard input or output, enter a dash (-) instead of the
filename.
Unpacking tar files
To unpack a .tar file with tar use the x flag:
$ tar xvf archive.tar
In this command, the x flag puts tar into extract (unpack) mode. You can extract individual parts of the
archive by entering the names of the parts at the end of the command line, but you must know their exact
names. (To find out for sure, see the table-of-contents mode described shortly.)
NOTE
When using extract mode, remember that tar does not remove the archived .tar file after
extracting its contents.
Table-of-Contents Mode
Before unpacking, it’s usually a good idea to check the contents of a .tar file with the table-of-contents mode
by using the t flag instead of the x flag. This mode verifies the archive’s basic integrity and prints the names
of all files inside. If you don’t test an archive before unpacking it, you can end up dumping a huge mess of
files into the current directory, which can be really difficult to clean up.
When you check an archive with the t mode, verify that everything is in a rational directory structure; that is,
all file pathnames in the archive should start with the same directory. If you’re unsure, create a temporary
directory, change to it, and then extract. (You can always use mv * .. if the archive didn’t create a mess.)
When unpacking, consider using the p option to preserve permissions. Use this in extract mode to override
your umask and get the exact permissions specified in the archive. The p option is the default when working
as the superuser. If you’re having trouble with permissions and ownership when unpacking an archive as the
www.EBooksWorld.ir
superuser, make sure that you are waiting until the command terminates and you get the shell prompt back.
Although you may only want to extract a small part of an archive, tar must run through the whole thing, and
you must not interrupt the process because it sets the permissions only after checking the entire archive.
Commit all of the tar options and modes in this section to memory. If you’re having trouble, make some
flash cards. This may sound like grade-school, but it’s very important to avoid careless mistakes with this
command.
2.18.3 Compressed Archives (.tar.gz)
Many beginners find it confusing that archives are normally found compressed, with filenames ending
in .tar.gz. To unpack a compressed archive, work from the right side to the left; get rid of the .gz first and then
worry about the .tar. For example, these two commands decompress and unpack <file>.tar.gz:
$ gunzip file.tar.gz
$ tar xvf file.tar
When starting out, you can do this one step at a time, first running gunzip to decompress and then tar to
verify and unpack. To create a compressed archive, do the reverse; run tar first and gzip second. Do this
frequently enough, and you’ll soon memorize how the archiving and compression process works. You’ll also
get tired of all of the typing and start to look for shortcuts. Let’s take a look at those now.
2.18.4 zcat
The method shown above isn’t the fastest or most efficient way to invoke tar on a compressed archive, and
it wastes disk space and kernel I/O time. A better way is to combine archival and compression functions with
a pipeline. For example, this command pipeline unpacks <file>.tar.gz:
$ zcat file.tar.gz | tar xvf -
The zcat command is the same as gunzip -dc. The -d option decompresses and the -c option sends the
result to standard output (in this case, to the tar command).
Because it’s so common to use zcat, the version of tar that comes with Linux has a shortcut. You can use
z as an option to automatically invoke gzip on the archive; this works both for extracting an archive (with
the x or t modes in tar) and creating one (with c). For example, use the following to verify a compressed
archive:
$ tar ztvf file.tar.gz
However, you should try to master the longer form before taking the shortcut.
NOTE
A .tgz file is the same as a .tar.gz file. The suffix is meant to fit into FAT (MS-DOS-based)
filesystems.
2.18.5 Other Compression Utilities
Another compression program in Unix is bzip2, whose compressed files end with .bz2. While marginally
slower than gzip, bzip2 often compacts text files a little more, and it is therefore increasingly popular in
the distribution of source code. The decompressing program to use is bunzip2, and the options of both
components are close enough to those of gzip that you don’t need to learn anything new. The bzip2
compression/decompression option for tar is j.
A new compression program named xz is also gaining popularity. The corresponding decompression program
is unxz, and the arguments are similar to those of gzip.
www.EBooksWorld.ir
Most Linux distributions come with zip and unzip programs that are compatible with the zip archives on
Windows systems. They work on the usual .zip files as well as self-extracting archives ending in .exe. But if
you encounter a file that ends in .Z, you have found a relic created by the compress program, which was
once the Unix standard. The gunzip program can unpack these files, but gzip won’t create them.
2.19 Linux Directory Hierarchy Essentials
Now that you know how to examine files, change directories, and read manual pages, you’re ready to start
exploring your system files. The details of the Linux directory structure are outlined in the Filesystem
Hierarchy Standard, or FHS (http://www.pathname.com/fhs/), but a brief walkthrough should suffice for now.
Figure 2-2 offers a simplified overview of the hierarchy, showing some of the directories under /, /usr, and
/var. Notice that the directory structure under /usr contains some of the same directory names as /.
Figure 2-2. Linux directory hierarchy
Here are the most important subdirectories in root:
o /bin Contains ready-to-run programs (also known as an executables), including most of the basic Unix
commands such as ls and cp. Most of the programs in /bin are in binary format, having been created by a
C compiler, but some are shell scripts in modern systems.
o /dev Contains device files. You’ll learn more about these in Chapter 3.
o /etc This core system configuration directory (pronounced EHT-see) contains the user password, boot,
device, networking, and other setup files. Many items in /etc are specific to the machine’s hardware. For
example, the /etc/X11 directory contains graphics card and window system configurations.
o /home Holds personal directories for regular users. Most Unix installations conform to this standard.
o /lib An abbreviation for library, this directory holds library files containing code that executables can use.
There are two types of libraries: static and shared. The /lib directory should contain only shared libraries,
but other lib directories, such as /usr/lib, contain both varieties as well as other auxiliary files. (We’ll
discuss shared libraries in more detail in Chapter 15.)
o /proc Provides system statistics through a browsable directory-and-file interface. Much of the /proc
subdirectory structure on Linux is unique, but many other Unix variants have similar features. The /proc
directory contains information about currently running processes as well as some kernel parameters.
o /sys This directory is similar to /proc in that it provides a device and system interface. You’ll read more
about /sys in Chapter 3.
o /sbin The place for system executables. Programs in /sbin directories relate to system management, so
regular users usually do not have /sbin components in their command paths. Many of the utilities found
here will not work if you’re not running them as root.
www.EBooksWorld.ir
o /tmp A storage area for smaller, temporary files that you don’t care much about. Any user may read to and
write from /tmp, but the user may not have permission to access another user’s files there. Many programs
use this directory as a workspace. If something is extremely important, don’t put it in /tmp because most
distributions clear /tmp when the machine boots and some even remove its old files periodically. Also, don’t
let /tmp fill up with garbage because its space is usually shared with something critical (like the rest of /, for
example).
o /usr Although pronounced “user,” this subdirectory has no user files. Instead, it contains a large directory
hierarchy, including the bulk of the Linux system. Many of the directory names in /usr are the same as those
in the root directory (like /usr/bin and /usr/lib), and they hold the same type of files. (The reason that the
root directory does not contain the complete system is primarily historic—in the past, it was to keep space
requirements low for the root.)
o /var The variable subdirectory, where programs record runtime information. System logging, user tracking,
caches, and other files that system programs create and manage are here. (You’ll notice a /var/tmp directory
here, but the system doesn’t wipe it on boot.)
2.19.1 Other Root Subdirectories
There are a few other interesting subdirectories in the root directory:
o /boot Contains kernel boot loader files. These files pertain only to the very first stage of the Linux startup
procedure; you won’t find information about how Linux starts up its services in this directory. See
Chapter 5 for more about this.
o /media A base attachment point for removable media such as flash drives that is found in many
distributions.
o /opt This may contain additional third-party software. Many systems don’t use /opt.
2.19.2 The /usr Directory
The /usr directory may look relatively clean at first glance, but a quick look at /usr/bin and /usr/lib reveals
that there’s a lot here; /usr is where most of the user-space programs and data reside. In addition to /usr/bin,
/usr/sbin, and /usr/lib, /usr contains the following:
o /include Holds header files used by the C compiler.
o /info Contains GNU info manuals (see 2.13 Getting Online Help).
o /local Is where administrators can install their own software. Its structure should look like that of / and /usr.
o /man Contains manual pages.
o /share Contains files that should work on other kinds of Unix machines with no loss of functionality. In the
past, networks of machines would share this directory, but a true /share directory is becoming rare because
there are no space issues on modern disks. Maintaining a /share directory is often just a pain. In any case,
/man, /info, and some other subdirectories are often found here.
2.19.3 Kernel Location
On Linux systems, the kernel is normally in /vmlinuz or /boot/vmlinuz. A boot loader loads this file into
memory and sets it in motion when the system boots. (You’ll find details on the boot loader in Chapter 5.)
Once the boot loader runs and sets the kernel in motion, the main kernel file is no longer used by the running
system. However, you’ll find many modules that the kernel can load and unload on demand during the course
of normal system operation. Called loadable kernel modules, they are located under /lib/modules.
www.EBooksWorld.ir
2.20 Running Commands as the Superuser
Before going any further, you should learn how to run commands as the superuser. You probably already know
that you can run the su command and enter the root password to start a root shell. This practice works, but it
has certain disadvantages:
o You have no record of system-altering commands.
o You have no record of the users who performed system-altering commands.
o You don’t have access to your normal shell environment.
o You have to enter the root password.
2.20.1 sudo
Most larger distributions use a package called sudo to allow administrators to run commands as root when
they are logged in as themselves. For example, in Chapter 7, you’ll learn about using vipw to edit the
/etc/passwd file. You could do it like this:
$ sudo vipw
When you run this command, sudo logs this action with the syslog service under the local2 facility. You’ll
also learn more about system logs in Chapter 7.
2.20.2 /etc/sudoers
Of course, the system doesn’t let just any user run commands as the superuser; you must configure the
privileged users in your /etc/sudoers file. The sudo package has many options (that you’ll probably never
use), which makes the syntax in /etc/sudoers somewhat complicated. For example, this file gives user1 and
user2 the power to run any command as root without having to enter a password:
User_Alias ADMINS = user1, user2
ADMINS ALL = NOPASSWD: ALL
root ALL=(ALL) ALL
The first line defines an ADMINS user alias with the two users, and the second line grants the privileges. The
ALL = NOPASSWD: ALL part means that the users in the ADMINS alias can use sudo to execute commands
as root. The second ALL means “any command.” The first ALL means “any host.” (If you have more than one
machine, you can set different kinds of access for each machine or group of machines, but we won’t cover
that feature.)
The root ALL=(ALL) ALL simply means that the superuser may also use sudo to run any command on
any host. The extra (ALL) means that the superuser may also run commands as any other user. You can
extend this privilege to the ADMINS users by adding (ALL) to the /etc/sudoers line, as shown at ➊:
ADMINS ALL = (ALL)➊ NOPASSWD: ALL
NOTE
Use the visudo command to edit /etc/sudoers. This command checks for file syntax errors after
you save the file.
www.EBooksWorld.ir
That’s it for sudo for now. If you need to use its more advanced features, see the sudoers(5) and sudo(8)
manual pages. (The actual mechanics of user switching are covered in Chapter 7.)
2.21 Looking Forward
You should now know how to do the following at the command line: run programs, redirect output, interact
with files and directories, view process listings, view manual pages, and generally make your way around the
user space of a Linux system. You should also be able to run commands as the superuser. You may not yet
know much about the internal details of user-space components or what goes on in the kernel, but with the
basics of files and processes under your belt, you’re on your way. In the next few chapters, you’ll be working
with both kernel and user-space system components using the command-line tools that you just learned.
www.EBooksWorld.ir
Chapter 3. Devices
This chapter is a basic tour of the kernel-provided device infrastructure in a functioning Linux system.
Throughout the history of Linux, there have been many changes to how the kernel presents devices to the user.
We’ll begin by looking at the traditional system of device files to see how the kernel provides device
configuration information through sysfs. Our goal is to be able to extract information about the devices on a
system in order to understand a few rudimentary operations. Later chapters will cover interacting with specific
kinds of devices in greater detail.
It’s important to understand how the kernel interacts with user space when presented with new devices. The
udev system enables user-space programs to automatically configure and use new devices. You’ll see the basic
workings of how the kernel sends a message to a user-space process through udev, as well as what the process
does with it.
3.1 Device Files
It is easy to manipulate most devices on a Unix system because the kernel presents many of the device I/O
interfaces to user processes as files. These device files are sometimes called device nodes. Not only can a
programmer use regular file operations to work with a device, but some devices are also accessible to standard
programs like cat, so you don’t have to be a programmer to use a device. However, there is a limit to what
you can do with a file interface, so not all devices or device capabilities are accessible with standard file I/O.
Linux uses the same design for device files as do other Unix flavors. Device files are in the /dev directory, and
running ls /dev reveals more than a few files in /dev. So how do you work with devices?
To get started, consider this command:
$ echo blah blah > /dev/null
As does any command with redirected output, this sends some stuff from the standard output to a file. However,
the file is /dev/null, a device, and the kernel decides what to do with any data written to this device. In the case
of /dev/null, the kernel simply ignores the input and throws away the data.
To identify a device and view its permissions, use ls -l:
Example 3-1. Device files
$ ls -l
brw-rw---- 1 root disk 8, 1 Sep 6 08:37 sda1
crw-rw-rw- 1 root root 1, 3 Sep 6 08:37 null
prw-r--r-- 1 root root 0 Mar 3 19:17 fdata
srw-rw-rw- 1 root root 0 Dec 18 07:43 log
Note the first character of each line (the first character of the file’s mode) in Example 3-1. If this character is
b, c, p, or s, the file is a device. These letters stand for block, character, pipe, and socket, respectively, as
described in more detail below.
Block device
o Programs access data from a block device in fixed chunks. The sda1 in the preceding example is a disk
device, a type of block device. Disks can be easily split up into blocks of data. Because a block device’s
www.EBooksWorld.ir
total size is fixed and easy to index, processes have random access to any block in the device with the help
of the kernel.
Character device
o Character devices work with data streams. You can only read characters from or write characters to
character devices, as previously demonstrated with /dev/null. Character devices don’t have a size; when you
read from or write to one, the kernel usually performs a read or write operation on the device. Printers
directly attached to your computer are represented by character devices. It’s important to note that during
character device interaction, the kernel cannot back up and reexamine the data stream after it has passed
data to a device or process.
Pipe device
o Named pipes are like character devices, with another process at the other end of the I/O stream instead of a
kernel driver.
Socket device
o Sockets are special-purpose interfaces that are frequently used for interprocess communication. They’re
often found outside of the /dev directory. Socket files represent Unix domain sockets; you’ll learn more
about those in Chapter 10.
The numbers before the dates in the first two lines of Example 3-1 are the major and minor device numbers
that help the kernel identify the device. Similar devices usually have the same major number, such as sda3
and sdb1 (both of which are hard disk partitions).
NOTE
Not all devices have device files because the block and character device I/O interfaces are not
appropriate in all cases. For example, network interfaces don’t have device files. It is theoretically
possible to interact with a network interface using a single character device, but because it would
be exceptionally difficult, the kernel uses other I/O interfaces.
3.2 The sysfs Device Path
The traditional Unix /dev directory is a convenient way for user processes to reference and interface with
devices supported by the kernel, but it’s also a very simplistic scheme. The name of the device in /dev tells
you a little about the device, but not a lot. Another problem is that the kernel assigns devices in the order in
which they are found, so a device may have a different name between reboots.
To provide a uniform view for attached devices based on their actual hardware attributes, the Linux kernel
offers the sysfs interface through a system of files and directories. The base path for devices is /sys/devices.
For example, the SATA hard disk at /dev/sda might have the following path in sysfs:
/sys/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/s
da
As you can see, this path is quite long compared with the /dev/sda filename, which is also a directory. But you
can’t really compare the two paths because they have different purposes. The /dev file is there so that user
processes can use the device, whereas the /sys/devices path is used to view information and manage the device.
If you list the contents of a device path such as the preceding one, you’ll see something like the following:
alignment_offs
et
discard_alignme
nt holders
removabl
e size
ueven
t
www.EBooksWorld.ir
bdi events
infligh
t ro slaves
capability events_async power sda1 stat
dev
events_poll_mse
cs queue sda2
subsyste
m
device ext_range range sda5 trace
The files and subdirectories here are meant to be read primarily by programs rather than humans, but you can
get an idea of what they contain and represent by looking at an example such as the /dev file. Running cat
dev in this directory displays the numbers 8:0, which happen to be the major and minor device numbers of
/dev/sda.
There are a few shortcuts in the /sys directory. For example, /sys/block should contain all of the block devices
available on a system. However, those are just symbolic links; run ls -l /sys/block to reveal the true
sysfs paths.
It can be difficult to find the sysfs location of a device in /dev. Use the udevadm command to show the path
and other attributes:
$ udevadm info --query=all --name=/dev/sda
NOTE
The udevadm program is in /sbin; you can put this directory at the end of your path if it’s not
already there.
You’ll find more details about udevadm and the entire udev system in 3.5 udev.
3.3 dd and Devices
The program dd is extremely useful when working with block and character devices. This program’s sole
function is to read from an input file or stream and write to an output file or stream, possibly doing some
encoding conversion on the way.
dd copies data in blocks of a fixed size. Here’s how to use dd with a character device and some common
options:
$ dd if=/dev/zero of=new_file bs=1024 count=1
As you can see, the dd option format differs from the option formats of most other Unix commands; it’s based
on an old IBM Job Control Language (JCL) style. Rather than use the dash (-) character to signal an option,
you name an option and set its value to something with the equals (=) sign. The preceding example copies a
single 1024-byte block from /dev/zero (a continuous stream of zero bytes) to new_file.
These are the important dd options:
o if=file The input file. The default is the standard input.
o of=file The output file. The default is the standard output.
o bs=size The block size. dd reads and writes this many bytes of data at a time. To abbreviate large chunks
of data, you can use b and k to signify 512 and 1024 bytes, respectively. Therefore, the example above
could read bs=1k instead of bs=1024.
www.EBooksWorld.ir
o ibs=size, obs=size The input and output block sizes. If you can use the same block size for both
input and output, use the bs option; if not, use ibs and obs for input and output, respectively.
o count=num The total number of blocks to copy. When working with a huge file—or with a device that
supplies an endless stream of data, such as /dev/zero—you want dd to stop at a fixed point or you could
waste a lot of disk space, CPU time, or both. Use count with the skip parameter to copy a small piece
from a large file or device.
o skip=
o num Skip past the first num blocks in the input file or stream and do not copy them to the output.
WARNING
dd is very powerful, so make sure you know what you’re doing when you run it. It’s very easy to
corrupt files and data on devices by making a careless mistake. It often helps to write the output to
a new file if you’re not sure what it will do.
3.4 Device Name Summary
It can sometimes be difficult to find the name of a device (for example, when partitioning a disk). Here are a
few ways to find out what it is:
o Query udevd using udevadm (see 3.5 udev).
o Look for the device in the /sys directory.
o Guess the name from the output of the dmesg command (which prints the last few kernel messages) or the
kernel system log file (see 7.2 System Logging). This output might contain a description of the devices on
your system.
o For a disk device that is already visible to the system, you can check the output of the mount command.
o Run cat /proc/devices to see the block and character devices for which your system currently has
drivers. Each line consists of a number and name. The number is the major number of the device as
described in 3.1 Device Files. If you can guess the device from the name, look in /dev for the character or
block devices with the corresponding major number, and you’ve found the device files.
Among these methods, only the first is reliable, but it does require udev. If you get into a situation where udev
is not available, try the other methods but keep in mind that the kernel might not have a device file for your
hardware.
The following sections list the most common Linux devices and their naming conventions.
3.4.1 Hard Disks: /dev/sd*
Most hard disks attached to current Linux systems correspond to device names with an sd prefix, such as
/dev/sda, /dev/sdb, and so on. These devices represent entire disks; the kernel makes separate device files,
such as /dev/sda1 and /dev/sda2, for the partitions on a disk.
The naming convention requires a little explanation. The sd portion of the name stands for SCSI disk. Small
Computer System Interface (SCSI) was originally developed as a hardware and protocol standard for
communication between devices such as disks and other peripherals. Although traditional SCSI hardware isn’t
used in most modern machines, the SCSI protocol is everywhere due to its adaptability. For example, USB
storage devices use it to communicate. The story on SATA disks is a little more complicated, but the Linux
kernel still uses SCSI commands at a certain point when talking to them.
To list the SCSI devices on your system, use a utility that walks the device paths provided by sysfs. One of
the most succinct tools is lsscsi. Here is what you can expect when you run it:
www.EBooksWorld.ir
$ lsscsi
[0:0:0:0]➊ disk➋ ATA WDC WD3200AAJS-2 01.0 /dev/sda➌
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0
[2:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdb
The first column ➊ identifies the address of the device on the system, the second ➋ describes what kind of
device it is, and the last ➌ indicates where to find the device file. Everything else is vendor information.
Linux assigns devices to device files in the order in which its drivers encounter devices. So in the previous
example, the kernel found the disk first, the optical drive second, and the flash drive last.
Unfortunately, this device assignment scheme has traditionally caused problems when reconfiguring hardware.
Say, for example, that you have a system with three disks: /dev/sda, /dev/sdb, and /dev/sdc. If /dev/sdb explodes
and you must remove the disk so that the machine can work again, the former /dev/sdc moves to /dev/sdb, and
there is no longer a /dev/sdc. If you were referring to the device names directly in the fstab file (see 4.2.8 The
/etc/fstab Filesystem Table), you’d have to make some changes to that file in order to get things (mostly) back
to normal. To solve this problem, most modern Linux systems use the Universally Unique Identifier (UUID,
see 4.2.4 Filesystem UUID) for persistent disk device access.
This discussion has barely scratched the surface of how to use disks and other storage devices on Linux
systems. See Chapter 4 for more information about using disks. Later in this chapter, we’ll examine how SCSI
support works in the Linux kernel.
3.4.2 CD and DVD Drives: /dev/sr*
Linux recognizes most optical storage drives as the SCSI devices /dev/sr0, /dev/sr1, and so on. However, if
the drive uses an older interface, it might show up as a PATA device, as discussed below. The /dev/sr* devices
are read only, and they are used only for reading from discs. For the write and rewrite capabilities of optical
devices, you’ll use the “generic” SCSI devices such as /dev/sg0.
3.4.3 PATA Hard Disks: /dev/hd*
The Linux block devices /dev/hda, /dev/hdb, /dev/hdc, and /dev/hdd are common on older versions of the
Linux kernel and with older hardware. These are fixed assignments based on the master and slave devices on
interfaces 0 and 1. At times, you might find a SATA drive recognized as one of these disks. This means that
the SATA drive is running in a compatibility mode, which hinders performance. Check your BIOS settings to
see if you can switch the SATA controller to its native mode.
3.4.4 Terminals: /dev/tty*, /dev/pts/*, and /dev/tty
Terminals are devices for moving characters between a user process and an I/O device, usually for text output
to a terminal screen. The terminal device interface goes back a long way, to the days when terminals were
typewriter-based devices.
Pseudoterminal devices are emulated terminals that understand the I/O features of real terminals. But rather
than talk to a real piece of hardware, the kernel presents the I/O interface to a piece of software, such as the
shell terminal window that you probably type most of your commands into.
Two common terminal devices are /dev/tty1 (the first virtual console) and /dev/pts/0 (the first pseudoterminal
device). The /dev/pts directory itself is a dedicated filesystem.
The /dev/tty device is the controlling terminal of the current process. If a program is currently reading from
and writing to a terminal, this device is a synonym for that terminal. A process does not need to be attached to
www.EBooksWorld.ir
a terminal.
Display Modes and Virtual Consoles
Linux has two primary display modes: text mode and an X Window System server (graphics mode, usually via
a display manager). Although Linux systems traditionally booted in text mode, most distributions now use
kernel parameters and interim graphical display mechanisms (bootsplashes such as plymouth) to completely
hide text mode as the system is booting. In such cases, the system switches over to full graphics mode near
the end of the boot process.
Linux supports virtual consoles to multiplex the display. Each virtual console may run in graphics or text
mode. When in text mode, you can switch between consoles with an ALT-Function key combination—for
example, ALT-F1 takes you to /dev/tty1, ALT-F2 goes to /dev/tty2, and so on. Many of these may be occupied
by a getty process running a login prompt, as described in 7.4 getty and login.
A virtual console used by the X server in graphics mode is slightly different. Rather than getting a virtual
console assignment from the init configuration, an X server takes over a free virtual console unless directed
to use a specific virtual console. For example, if you have getty processes running on tty1 and tty2, a new
X server takes over tty3. In addition, after the X server puts a virtual console into graphics mode, you must
normally press a CTRL-ALT-Function key combination to switch to another virtual console instead of the
simpler ALT-Function key combination.
The upshot of all of this is that if you want to see your text console after your system boots, press CTRL-ALT-
F1. To return to the X11 session, press ALT-F2, ALT-F3, and so on, until you get to the X session.
If you run into trouble switching consoles due to a malfunctioning input mechanism or some other
circumstance, you can try to force the system to change consoles with the chvt command. For example, to
switch to tty1, run the following as root:
# chvt 1
3.4.5 Serial Ports: /dev/ttyS*
Older RS-232 type and similar serial ports are special terminal devices. You can’t do much on the command
line with serial port devices because there are too many settings to worry about, such as baud rate and flow
control.
The port known as COM1 on Windows is /dev/ttyS0; COM2 is /dev/ttyS1; and so on. Plug-in USB serial
adapters show up with USB and ACM with the names /dev/ttyUSB0, /dev/ttyACM0, /dev/ttyUSB1,
/dev/ttyACM1, and so on.
3.4.6 Parallel Ports: /dev/lp0 and /dev/lp1
Representing an interface type that has largely been replaced by USB, the unidirectional parallel port devices
/dev/lp0 and /dev/lp1 correspond to LPT1: and LPT2: in Windows. You can send files (such as a file to be
printed) directly to a parallel port with the cat command, but you might need to give the printer an extra form
feed or reset afterward. A print server such as CUPS is much better at handling interaction with a printer.
The bidirectional parallel ports are /dev/parport0 and /dev/parport1.
3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
Linux has two sets of audio devices. There are separate devices for the Advanced Linux Sound Architecture
(ALSA) system interface and the older Open Sound System (OSS). The ALSA devices are in the /dev/snd
directory, but it’s difficult to work with them directly. Linux systems that use ALSA support OSS backward-
compatible devices if the OSS kernel support is currently loaded.
Some rudimentary operations are possible with the OSS dsp and audio devices. For example, the computer
www.EBooksWorld.ir
plays any WAV file that you send to /dev/dsp. However, the hardware may not do what you expect due to
frequency mismatches. Furthermore, on most systems, the device is often busy as soon as you log in.
NOTE
Linux sound is a messy subject due to the many layers involved. We’ve just talked about the
kernel-level devices, but typically there are user-space servers such as pulse-audio that manage
audio from different sources and act as intermediaries between the sound devices and other user-
space processes.
3.4.8 Creating Device Files
In modern Linux systems, you do not create your own device files; this is done with devtmpfs and udev (see
3.5 udev). However, it is instructive to see how it was once done, and on a rare occasion, you might need to
create a named pipe.
The mknod command creates one device. You must know the device name as well as its major and minor
numbers. For example, creating /dev/sda1 is a matter of using the following command:
# mknod /dev/sda1 b 8 2
The b 8 2 specifies a block device with a major number 8 and a minor number 2. For character or named
pipe devices, use c or p instead of b (omit the major and minor numbers for named pipes).
As mentioned earlier, the mknod command is useful only for creating the occasional named pipe. At one time,
it was also sometimes useful for creating missing devices in single-user mode during system recovery.
In older versions of Unix and Linux, maintaining the /dev directory was a challenge. With every significant
kernel upgrade or driver addition, the kernel could support more kinds of devices, meaning that there would
be a new set of major and minor numbers to be assigned to device filenames. Maintaining this was difficult,
so each system had a MAKEDEV program in /dev to create groups of devices. When you upgraded your system,
you would try to find an update to MAKEDEV and then run it in order to create new devices.
This static system became ungainly, so a replacement was in order. The first attempt to fix it was devfs, a
kernel-space implementation of /dev that contained all of the devices that the current kernel supported.
However, there were a number of limitations, which led to the development of udev and devtmpfs.
3.5 udev
We’ve already talked about how unnecessary complexity in the kernel is dangerous because you can too easily
introduce system instability. Device file management is an example: You can create device files in user space,
so why would you do this in the kernel? The Linux kernel can send notifications to a user-space process (called
udevd) upon detecting a new device on the system (for example, when someone attaches a USB flash drive).
The user-space process on the other end examines the new device’s characteristics, creates a device file, and
then performs any device initialization.
That was the theory. Unfortunately, in practice, there is a problem with this approach—device files are
necessary early in the boot procedure, so udevd must start early. To create device files, udevd could not
depend on any devices that it was supposed to create, and it would need to perform its initial startup very
quickly so that the rest of the system wouldn’t get held up waiting for udevd to start.
3.5.1 devtmpfs
The devtmpfs filesystem was developed in response to the problem of device availability during boot (see 4.2
Filesystems for more details on filesystems). This filesystem is similar to the older devfs support, but it’s
simplified. The kernel creates device files as necessary, but it also notifies udevd that a new device is
www.EBooksWorld.ir
available. Upon receiving this signal, udevd does not create the device files, but it does perform device
initialization and process notification. Additionally, it creates a number of symbolic links in /dev to further
identify devices. You can find examples in the directory /dev/disk/by-id, where each attached disk has one or
more entries.
For example, consider this typical disk:
lrwxrwxrwx 1 root root 9 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD-
WMAV2FU80671 -> ../../sda
lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD-
WMAV2FU80671-part1 ->
../../sda1
lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD-
WMAV2FU80671-part2 ->
../../sda2
lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD-
WMAV2FU80671-part5 ->
../../sda5
udevd names the links by interface type, and then by manufacturer and model information, serial number,
and partition (if applicable).
But how does udevd know which symbolic links to create, and how does it create them? The next section
describes how udevd does its work. However, you don’t need to know that to continue on with the book. In
fact, if this is your first time looking at Linux devices, you’re encouraged to move to the next chapter to start
learning about how to use disks.
3.5.2 udevd Operation and Configuration
The udevd daemon operates as follows:
1. The kernel sends udevd a notification event, called a uevent, through an internal network link.
2. udevd loads all of the attributes in the uevent.
3. udevd parses its rules, and it takes actions or sets more attributes based on those rules.
An incoming uevent that udevd receives from the kernel might look like this:
ACTION=change
DEVNAME=sde
DEVPATH=/devices/pci0000:00/0000:00:1a.0/usb1/1-1/1-1.2/1-
1.2:1.0/host4/
target4:0:0/4:0:0:3/block/sde
DEVTYPE=disk
DISK_MEDIA_CHANGE=1
MAJOR=8
MINOR=64
www.EBooksWorld.ir
SEQNUM=2752
SUBSYSTEM=block
UDEV_LOG=3
You can see here that there is a change to a device. After receiving the uevent, udevd knows the sysfs device
path and a number of other attributes associated with the properties, and it is now ready to start processing
rules.
The rules files are in the /lib/udev/rules.d and /etc/udev/rules.d directories. The rules in /lib are the defaults,
and the rules in /etc are overrides. A full explanation of the rules would be tedious, and you can learn much
more from the udev(7) manual page, but let’s look at the symbolic links from the /dev/sda example in 3.5.1
devtmpfs. Those links were defined by rules in /lib/udev/rules.d/60-persistent-storage.rules. Inside, you’ll see
the following lines:
# ATA devices using the "scsi" subsystem
KERNEL=="sd*[!0-9]|sr*", ENV{ID_SERIAL}!="?*", SUBSYSTEMS=="scsi",
ATTRS{vendor}=="ATA",
IMPORT{program}="ata_id --export $tempnode"
# ATA/ATAPI devices (SPC-3 or later) using the "scsi" subsystem
KERNEL=="sd*[!0-9]|sr*", ENV{ID_SERIAL}!="?*", SUBSYSTEMS=="scsi",
ATTRS{type}=="5", ATTRS{scsi_level}=="[6-9]*",
IMPORT{program}="ata_id --export $tempnode"
These rules match ATA disks presented through the kernel’s SCSI subsystem (see 3.6 In-Depth: SCSI and the
Linux Kernel). You can see that there are a few rules to catch different ways that the devices may be
represented, but the idea is that udevd will try to match a device starting with sd or sr but without a number
(with the KERNEL=="sd*[!0-9]|sr*" expression), as well as a subsystem (SUBSYSTEMS=="scsi"),
and finally, some other attributes. If all of those conditional expressions are true, udevd moves to the next
expression:
IMPORT{program}="ata_id --export $tempnode"
This is not a conditional, but rather, a directive to import variables from the /lib/udev/ata_id command. If you
have such a disk, try it yourself on the command line:
$ sudo /lib/udev/ata_id --export /dev/sda
ID_ATA=1
ID_TYPE=disk
ID_BUS=ata
ID_MODEL=WDC_WD3200AAJS-22L7A0
ID_MODEL_ENC=WDC\x20WD3200AAJS22L7A0\x20\x20\x20\x20\x20\x20\x20\x20\x
20\x20
\x20\x20\x20\x20\x20\x20\x20\x20\x20
ID_REVISION=01.03E10
ID_SERIAL=WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671
www.EBooksWorld.ir
--snip--
The import now sets the environment so that all of the variable names in this output are set to the values shown.
For example, any rule that follows will now recognize ENV{ID_TYPE} as disk.
Of particular note is ID_SERIAL. In each of the rules, this conditional appears second:
ENV{ID_SERIAL}!="?*"
This means that ID_SERIAL is true only if is not set. Therefore, if it is set, the conditional is false, the entire
current rule is false, and udevd moves to the next rule.
So what’s the point? The object of these two rules (and many around them in the file) is to find the serial
number of the disk device. With ENV{ID_SERIAL} set, udevd can now evaluate this rule:
KERNEL=="sd*|sr*|cciss*", ENV{DEVTYPE}=="disk", ENV{ID_SERIAL}=="?*",
SYMLINK+="disk/by-id/$env{ID_BUS}-$env{ID_SERIAL}"
You can see that this rule requires ENV{ID_SERIAL} to be set, and it has one directive:
SYMLINK+="disk/by-id/$env{ID_BUS}-$env{ID_SERIAL}"
Upon encountering this directive, udevd adds a symbolic link for the incoming device. So now you know
where the device symbolic links came from!
You may be wondering how to tell a conditional expression from a directive. Conditionals are denoted by two
equal signs (==) or a bang equal (!=), and directives by a single equal sign (=), a plus equal (+=), or a colon
equal (:=).
3.5.3 udevadm
The udevadm program is an administration tool for udevd. You can reload udevd rules and trigger events,
but perhaps the most powerful features of udevadm are the ability to search for and explore system devices
and the ability to monitor uevents as udevd receives them from the kernel. The only trick is that the command
syntax can get a bit involved.
Let’s start by examining a system device. Returning to the example in 3.5.2 udevd Operation and
Configuration, in order to look at all of the udev attributes used and generated in conjunction with the rules
for a device such as /dev/sda, run the following command:
$ udevadm info --query=all –-name=/dev/sda
The output looks like this:
P:
/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda
N: sda
S: disk/by-id/ata-WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671
S: disk/by-id/scsi-SATA_WDC_WD3200AAJS-_WD-WMAV2FU80671
S: disk/by-id/wwn-0x50014ee057faef84 S: disk/by-path/pci-0000:00:1f.2-
scsi-0:0:0:0
E: DEVLINKS=/dev/disk/by-id/ata-WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671
/dev/disk/by-id/scsi
-SATA_WDC_WD3200AAJS-_WD-WMAV2FU80671 /dev/disk/by-id/wwn-
www.EBooksWorld.ir
0x50014ee057faef84 /dev/disk/by
-path/pci-0000:00:1f.2-scsi-0:0:0:0
E: DEVNAME=/dev/sda
E:
DEVPATH=/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/blo
ck/sda
E: DEVTYPE=disk
E: ID_ATA=1
E: ID_ATA_DOWNLOAD_MICROCODE=1
E: ID_ATA_FEATURE_SET_AAM=1
--snip--
The prefix in each line indicates an attribute or other characteristic of the device. In this case, the P: at the
top is the sysfs device path, the N: is the device node (that is, the name given to the /dev file), S: indicates a
symbolic link to the device node that udevd placed in /dev according to its rules, and E: is additional device
information extracted in the udevd rules. (There was far more output in this example than was necessary to
show here; try the command for yourself to get a feel for what it does.)
3.5.4 Monitoring Devices
To monitor uevents with udevadm, use the monitor command:
$ udevadm monitor
Output (for example, when you insert a flash media device) looks like this abbreviated sample:
KERNEL[658299.569485] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2 (usb)
KERNEL[658299.569667] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0 (usb)
KERNEL[658299.570614] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0/host15
(scsi)
KERNEL[658299.570645] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0/
host15/scsi_host/host15 (scsi_host)
UDEV [658299.622579] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2 (usb)
UDEV [658299.623014] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0 (usb)
UDEV [658299.623673] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0/host15
(scsi)
www.EBooksWorld.ir
UDEV [658299.623690] add /devices/pci0000:00/0000:00:1d.0/usb2/2-
1/2-1.2/2-1.2:1.0/
host15/scsi_host/host15 (scsi_host)
--snip--
There are two copies of each message in this output because the default behavior is to print both the incoming
message from the kernel (marked with KERNEL) and the message that udevd sends out to other programs
when it’s finished processing and filtering the event. To see only kernel events, add the --kernel option,
and to see only outgoing events, use --udev. To see the whole incoming uevent, including the attributes as
shown in 3.5.2 udevd Operation and Configuration, use the --property option.
You can also filter events by subsystem. For example, to see only kernel messages pertaining to changes in
the SCSI subsystem, use this command:
$ udevadm monitor --kernel --subsystem-match=scsi
For more on udevadm, see the udevadm(8) manual page.
There’s much more to udev. For example, the D-Bus system for interprocess communication has a daemon
called udisks-daemon that listens to the outgoing udevd events in order to automatically attach disks and
to further notify other desktop software that a new disk is now available.
3.6 In-Depth: SCSI and the Linux Kernel
In this section, we’ll take a look at the SCSI support in the Linux kernel as a way to explore part of the Linux
kernel architecture. You don’t need to know any of this information in order to use disks, so if you’re in a
hurry to use one, move on to Chapter 4. In addition, the material here is more advanced and theoretical in
nature that what you’ve seen so far, so if you want to stay hands-on, you should definitely skip to the next
chapter.
Let’s begin with a little background. The traditional SCSI hardware setup is a host adapter linked with a chain
of devices over an SCSI bus, as shown in Figure 3-1. The host adapter is attached to a computer. The host
adapter and devices each have an SCSI ID, and there can be 8 or 16 IDs per bus, depending on the SCSI
version. You might hear the term SCSI target used to refer to a device and its SCSI ID.
Figure 3-1. SCSI Bus with host adapter and devices
The host adapter communicates with the devices through the SCSI command set in a peer-to-peer relationship;
the devices send responses back to the host adapter. The computer is not directly attached to the device chain,
so it must go through the host adapter in order to communicate with disks and other devices. Typically, the
computer sends SCSI commands to the host adapter to relay to the devices, and the devices relay responses
back through the host adapter.
Newer versions of SCSI, such as Serial Attached SCSI (SAS), offer exceptional performance, but you probably
won’t find true SCSI devices in most machines. You’ll more often encounter USB storage devices that use
www.EBooksWorld.ir
SCSI commands. In addition, devices supporting ATAPI (such as CD/DVD-ROM drives) use a version of the
SCSI command set.
SATA disks also appear on your system as SCSI devices by means of a translation layer in libata (see 3.6.2
SCSI and ATA). Some SATA controllers (especially high-performance RAID controllers) perform this
translation in hardware.
How does this all fit together? Consider the devices shown on the following system:
$ lsscsi
[0:0:0:0] disk ATA WDC WD3200AAJS-2 01.0 /dev/sda
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0
[2:0:0:0] disk USB2.0 CardReader CF 0100 /dev/sdb
[2:0:0:1] disk USB2.0 CardReader SM XD 0100 /dev/sdc
[2:0:0:2] disk USB2.0 CardReader MS 0100 /dev/sdd
[2:0:0:3] disk USB2.0 CardReader SD 0100 /dev/sde
[3:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdf
The numbers in brackets are, from left to right, the SCSI host adapter number, the SCSI bus number, the device
SCSI ID, and the LUN (logical unit number, a further subdivision of a device). In this example, there are four
attached adapters (scsi0, scsi1, scsi2, and scsi3), each of which has a single bus (all with bus number 0), and
just one device on each bus (all with target 0). The USB card reader at 2:0:0 has four logical units, though—
one for each kind of flash card that can be inserted. The kernel has assigned a different device file to each
logical unit.
Figure 3-2 illustrates the driver and interface hierarchy inside the kernel for this particular system
configuration, from the individual device drivers up to the block drivers. It does not include the SCSI generic
(sg) drivers.
www.EBooksWorld.ir
Figure 3-2. Linux SCSI subsystem schematic
Although this is a large structure and may look overwhelming at first, the data flow in the figure is very linear.
Let’s begin dissecting it by looking at the SCSI subsystem and its three layers of drivers:
www.EBooksWorld.ir
o The top layer handles operations for a class of device. For example, the sd (SCSI disk) driver is at this
layer; it knows how to translate requests from the kernel block device interface into disk-specific
commands in the SCSI protocol, and vice versa.
o The middle layer moderates and routes the SCSI messages between the top and bottom layers, and keeps
track of all of the SCSI buses and devices attached to the system.
o The bottom layer handles hardware-specific actions. The drivers here send outgoing SCSI protocol
messages to specific host adapters or hardware, and they extract incoming messages from the hardware.
The reason for this separation from the top layer is that although SCSI messages are uniform for a device
class (such as the disk class), different kinds of host adapters have varying procedures for sending the same
messages.
The top and bottom layers contain many different drivers, but it’s important to remember that, for any given
device file on your system, the kernel uses one top-layer driver and one lower-layer driver. For the disk at
/dev/sda in our example, the kernel uses the sd top-layer driver and the ATA bridge lower-layer driver.
There are times when you might use more than one upper-layer driver for one hardware device (see 3.6.3
Generic SCSI Devices). For true hardware SCSI devices, such as a disk attached to an SCSI host adapter or a
hardware RAID controller, the lower-layer drivers talk directly to the hardware below. However, for most
hardware that you find attached to the SCSI subsystem, it’s a different story.
3.6.1 USB Storage and SCSI
In order for the SCSI subsystem to talk to common USB storage hardware, as shown in Figure 3-2, the kernel
needs more than just a lower-layer SCSI driver. The USB flash drive represented by /dev/sdf understands SCSI
commands, but to actually communicate with the drive, the kernel needs to know how to talk through the USB
system.
In the abstract, USB is quite similar to SCSI—it has device classes, buses, and host controllers. Therefore, it
should be no surprise that the Linux kernel includes a three-layer USB subsystem that closely resembles the
SCSI subsystem, with device-class drivers at the top, a bus management core in the middle, and host controller
drivers at the bottom. Much as the SCSI subsystem passes SCSI commands between its components, the USB
subsystem passes USB messages between its components. There’s even an lsusb command that is similar
to lsscsi.
The part we’re really interested in here is the USB storage driver at the top. This driver acts as a translator. On
one side, the driver speaks SCSI, and on the other, it speaks USB. Because the storage hardware includes SCSI
commands inside its USB messages, the driver has a relatively easy job: It mostly repackages data.
With both the SCSI and USB subsystems in place, you have almost everything you need to talk to the flash
drive. The final missing link is the lower-layer driver in the SCSI subsystem because the USB storage driver
is a part of the USB subsystem, not the SCSI subsystem. (For organizational reasons, the two subsystems
should not share a driver.) To get the subsystems to talk to one another, a simple, lower-layer SCSI bridge
driver connects to the USB subsystem’s storage driver.
3.6.2 SCSI and ATA
The SATA hard disk and optical drive shown in Figure 3-2 both use the same SATA interface. To connect the
SATA-specific drivers of the kernel to the SCSI subsystem, the kernel employs a bridge driver, as with the
USB drives, but with a different mechanism and additional complications. The optical drive speaks ATAPI, a
version of SCSI commands encoded in the ATA protocol. However, the hard disk does not use ATAPI and
does not encode any SCSI commands!
The Linux kernel uses part of a library called libata to reconcile SATA (and ATA) drives with the SCSI
subsystem. For the ATAPI-speaking optical drives, this is a relatively simple task of packaging and extracting
www.EBooksWorld.ir
SCSI commands into and from the ATA protocol. But for the hard disk, the task is much more complicated
because the library must do a full command translation.
The job of the optical drive is similar to typing an English book into a computer. You don’t need to understand
what the book is about in order to do this job, nor do you even need to understand English. But the task for
the hard disk is more like reading a German book and typing it into the computer as an English translation. In
this case, you need to understand both languages as well as the book’s content.
Despite this difficulty, libata performs this task and makes it possible to attach the SCSI subsystem to
ATA/SATA interfaces and devices. (There are typically more drivers involved than just the one SATA host
driver shown in Figure 3-2, but they’re not shown for the sake of simplicity.)
3.6.3 Generic SCSI Devices
When a user-space process communicates with the SCSI subsystem, it normally does so through the block
device layer and/or another other kernel service that sits on top of an SCSI device class driver (like sd or sr).
In other words, most user processes never need to know anything about SCSI devices or their commands.
However, user processes can bypass device class drivers and give SCSI protocol commands directly to devices
through their generic devices. For example, consider the system described in 3.6 In-Depth: SCSI and the Linux
Kernel, but this time, take a look at what happens when you add the -g option to lsscsi in order to show
the generic devices:
$ lsscsi -g
[0:0:0:0] disk ATA WDC WD3200AAJS-2 01.0 /dev/sda ➊/dev/sg0
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0 /dev/sg1
[2:0:0:0] disk USB2.0 CardReader CF 0100 /dev/sdb /dev/sg2
[2:0:0:1] disk USB2.0 CardReader SM XD 0100 /dev/sdc /dev/sg3
[2:0:0:2] disk USB2.0 CardReader MS 0100 /dev/sdd /dev/sg4
[2:0:0:3] disk USB2.0 CardReader SD 0100 /dev/sde /dev/sg5
[3:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdf /dev/sg6
In addition to the usual block device file, each entry lists an SCSI generic device file in the last column at ➊.
For example, the generic device for the optical drive at /dev/sr0 is /dev/sg1.
Why would you want to use an SCSI generic device? The answer has to do with the complexity of code in the
kernel. As tasks get more complicated, it’s better to leave them out of the kernel. Consider CD/DVD writing
and reading. Not only is writing significantly more difficult than reading, but no critical system services
depend on the action of writing. A user-space program might do the writing a little more inefficiently than a
kernel service, but that program will be far easier to build and maintain than a kernel service, and bugs will
not threaten kernel space. Therefore, to write to an optical disc in Linux, you run a program that talks to a
generic SCSI device, such as /dev/sg1. Due to the relative simplicity of reading compared to writing, however,
you still read from the device using the specialized sr optical device driver in the kernel.
3.6.4 Multiple Access Methods for a Single Device
The two points of access (sr and sg) for an optical drive from user space are illustrated for the Linux SCSI
subsystem in Figure 3-3 (any drivers below the SCSI lower layer have been omitted). Process A reads from
the drive using the sr driver, and process B writes to the drive with the sg driver. However, processes such as
these two would not normally run simultaneously to access the same device.
www.EBooksWorld.ir
Figure 3-3. Optical device driver schematic
In Figure 3-3, process A reads from the block device. But do user processes really read data this way? Normally,
the answer is no, not directly. There are more layers on top of the block devices and even more points of access
for hard disks, as you’ll learn in the next chapter.
www.EBooksWorld.ir
Chapter 4. Disks and Filesystems
In Chapter 3, we discussed some of the top-level disk devices that the kernel makes available. In this chapter,
we’ll discuss in detail how to work with disks on a Linux system. You’ll learn how to partition disks, create
and maintain the filesystems that go inside disk partitions, and work with swap space.
Recall that disk devices have names like /dev/sda, the first SCSI subsystem disk. This kind of block device
represents the entire disk, but there are many different components and layers inside a disk.
Figure 4-1 illustrates the schematic of a typical Linux disk (note that the figure is not to scale). As you progress
through this chapter, you’ll learn where each piece fits in.
Figure 4-1. Typical Linux disk schematic
Partitions are subdivisions of the whole disk. On Linux, they’re denoted with a number after the whole block
device, and therefore have device names such as /dev/sda1 and /dev/sdb3. The kernel presents each partition
as a block device, just as it would an entire disk. Partitions are defined on a small area of the disk called a
partition table.
NOTE
Multiple data partitions were once common on systems with large disks because older PCs could
boot only from certain parts of the disk. Also, administrators used partitions to reserve a certain
amount of space for operating system areas; for example, they didn’t want users to be able to fill
up the entire system and prevent critical services from working. This practice is not unique to Unix;
you’ll still find many new Windows systems with several partitions on a single disk. In addition,
www.EBooksWorld.ir
most systems have a separate swap partition.
Although the kernel makes it possible for you to access both an entire disk and one of its partitions at the same
time, you would not normally do so, unless you were copying the entire disk.
The next layer after the partition is the filesystem, the database of files and directories that you’re accustomed
to interacting with in user space. We’ll explore filesystems in 4.2 Filesystems.
As you can see in Figure 4-1, if you want to access the data in a file, you need to get the appropriate partition
location from the partition table and then search the filesystem database on that partition for the desired file
data.
To access data on a disk, the Linux kernel uses the system of layers shown in Figure 4-2. The SCSI subsystem
and everything else described in 3.6 In-Depth: SCSI and the Linux Kernel are represented by a single box.
(Notice that you can work with the disk through the filesystem as well as directly through the disk devices.
You’ll do both in this chapter.)
To get a handle on how everything fits together, let’s start at the bottom with partitions.
www.EBooksWorld.ir
Figure 4-2. Kernel schematic for disk access
4.1 Partitioning Disk Devices
There are many kinds of partition tables. The traditional table is the one found inside the Master Boot Record
(MBR). A newer standard starting to gain traction is the Globally Unique Identifier Partition Table (GPT).
Here is an overview of the many Linux partitioning tools available:
o parted A text-based tool that supports both MBR and GPT.
o gparted A graphical version of parted.
o fdisk The traditional text-based Linux disk partitioning tool. fdisk does not support GPT.
o gdisk A version of fdisk that supports GPT but not MBR.
Because it supports both MBR and GPT, we’ll use parted in this book. However, many people prefer the
fdisk interface, and there’s nothing wrong with that.
NOTE
Although parted can create and resize filesystems, you shouldn’t use it for filesystem
manipulation because you can easily get confused. There is a critical difference between
partitioning and filesystem manipulation. The partition table defines simple boundaries on the disk,
whereas a filesystem is a much more involved data system. For this reason, we’ll use parted for
partitioning but use separate utilities for creating filesystems (see 4.2.2 Creating a Filesystem).
Even the parted documentation encourages you to create filesystems separately.
4.1.1 Viewing a Partition Table
You can view your system’s partition table with parted -l. Here is sample output from two disk devices
with two different kinds of partition tables:
# parted -l
Model: ATA WDC WD3200AAJS-2 (scsi)
Disk /dev/sda: 320GB
Sector size (logical/physical): 512B/512B
Partition Table: msdos
Number Start End Size Type File system Flags
1 1049kB 316GB 316GB primary ext4 boot
2 316GB 320GB 4235MB extended
5 316GB 320GB 4235MB logical linux-swap(v1)
Model: FLASH Drive UT_USB20 (scsi)
Disk /dev/sdf: 4041MB
Sector size (logical/physical): 512B/512B
Partition Table: gpt
www.EBooksWorld.ir
Number Start End Size File system Name Flags
1 17.4kB 1000MB 1000MB myfirst
2 1000MB 4040MB 3040MB mysecond
The first device, /dev/sda, uses the traditional MBR partition table (called “msdos” by parted), and the
second contains a GPT table. Notice that there are different parameters for each partition table, because the
tables themselves are different. In particular, there is no Name column for the MBR table because names don’t
exist under that scheme. (I arbitrarily chose the names myfirst and mysecond in the GPT table.)
The MBR table in this example contains primary, extended, and logical partitions. A primary partition is a
normal subdivision of the disk; partition 1 is such a partition. The basic MBR has a limit of four primary
partitions, so if you want more than four, you designate one partition as an extended partition. Next, you
subdivide the extended partition into logical partitions that the operating system can use as it would any other
partition. In this example, partition 2 is an extended partition that contains logical partition 5.
NOTE
The filesystem that parted lists is not necessarily the system ID field defined in most MBR
entries. The MBR system ID is just a number; for example, 83 is a Linux partition and 82 is Linux
swap. Therefore, parted attempts to determine a filesystem on its own. If you absolutely must
know the system ID for an MBR, use fdisk -l.
Initial Kernel Read
When initially reading the MBR table, the Linux kernel produces the following debugging output (remember
that you can view this with dmesg):
sda: sda1 sda2 < sda5 >
The sda2 < sda5 > output indicates that /dev/sda2 is an extended partition containing one logical partition,
/dev/sda5. You’ll normally ignore extended partitions because you’ll typically want to access only the logical
partitions inside.
4.1.2 Changing Partition Tables
Viewing partition tables is a relatively simple and harmless operation. Altering partition tables is also relatively
easy, but there are risks involved in making this kind of change to the disk. Keep the following in mind:
o Changing the partition table makes it quite difficult to recover any data on partitions that you delete because
it changes the initial point of reference for a filesystem. Make sure that you have a backup if the disk you’re
partitioning contains critical data.
o Ensure that no partitions on your target disk are currently in use. This is a concern because most Linux
distributions automatically mount any detected filesystem. (See 4.2.3 Mounting a Filesystem for more on
mounting and unmounting.)
When you’re ready, choose your partitioning program. If you’d like to use parted, you can use the
command-line parted utility or a graphical interface such as gparted; for an fdisk-style interface, use
gdisk if you’re using GPT partitioning. These utilities all have online help and are easy to learn. (Try using
them on a flash device or something similar if you don’t have any spare disks.)
That said, there is a major difference in the way that fdisk and parted work. With fdisk, you design
your new partition table before making the actual changes to the disk; fdisk only makes the changes as you
exit the program. But with parted, partitions are created, modified, and removed as you issue the commands.
You don’t get the chance to review the partition table before you change it.
www.EBooksWorld.ir
These differences are also important to understanding how these two utilities interact with the kernel. Both
fdisk and parted modify the partitions entirely in user space; there is no need to provide kernel support
for rewriting a partition table because user space can read and modify all of a block device.
Eventually, though, the kernel must read the partition table in order to present the partitions as block devices.
The fdisk utility uses a relatively simple method: After modifying the partition table, fdisk issues a single
system call on the disk to tell the kernel that it should reread the partition table. The kernel then generates
debugging output that you can view with dmesg. For example, if you create two partitions on /dev/sdf, you’ll
see this:
sdf: sdf1 sdf2
In comparison, the parted tools do not use this disk-wide system call. Instead, they signal the kernel when
individual partitions are altered. After processing a single partition change, the kernel does not produce the
preceding debugging output.
There are a few ways to see the partition changes:
o Use udevadm to watch the kernel event changes. For example, udevadm monitor --kernel will
show the old partition devices being removed and the new ones being added.
o Check /proc/partitions for full partition information.
o Check /sys/block/device/ for altered partition system interfaces or /dev for altered partition devices.
If you absolutely must be sure that you have modified a partition table, you can perform the old-style system
call that fdisk uses by using the blockdev command. For example, to force the kernel to reload the
partition table on /dev/sdf, run this:
# blockdev --rereadpt /dev/sdf
At this point, you have all you need to know about partitioning disks. However, if you’re interested in learning
a few more details about disks, read on. Otherwise, skip ahead to 4.2 Filesystems to learn about putting a file-
system on the disk.
4.1.3 Disk and Partition Geometry
Any device with moving parts introduces complexity into a software system because there are physical
elements that resist abstraction. A hard disk is no exception; even though you can think of a hard disk as a
block device with random access to any block, there are serious performance consequences if you aren’t
careful about how you lay out data on the disk. Consider the physical properties of the simple single-platter
disk illustrated in Figure 4-3.
The disk consists of a spinning platter on a spindle, with a head attached to a moving arm that can sweep
across the radius of the disk. As the disk spins underneath the head, the head reads data. When the arm is in
one position, the head can only read data from a fixed circle. This circle is called a cylinder because larger
disks have more than one platter, all stacked and spinning around the same spindle. Each platter can have one
or two heads, for the top and/or bottom of the platter, and all heads are attached to the same arm and move in
concert. Because the arm moves, there are many cylinders on the disk, from small ones around the center to
large ones around the periphery of the disk. Finally, you can divide a cylinder into slices called sectors. This
way of thinking about the disk geometry is called CHS, for cylinder-head-sector.
www.EBooksWorld.ir
Figure 4-3. Top-down view of a hard disk
NOTE
A track is a part of a cylinder that a single head accesses, so in Figure 4-3, a cylinder is also a
track. You probably don’t need to worry about tracks.
The kernel and the various partitioning programs can tell you what a disk reports as its number of cylinders
(and sectors, which are slices of cylinders). However, on a modern hard disk, the reported values are fiction!
The traditional addressing scheme that uses CHS doesn’t scale with modern disk hardware, nor does it account
for the fact that you can put more data into outer cylinders than inner cylinders. Disk hardware supports
Logical Block Addressing (LBA) to simply address a location on the disk by a block number, but remnants of
CHS remain. For example, the MBR partition table contains CHS information as well as LBA equivalents,
and some boot loaders are still dumb enough to believe the CHS values (don’t worry—most Linux boot loaders
use the LBA values).
Nevertheless, the idea of cylinders has been important to partitioning because cylinders are ideal boundaries
for partitions. Reading a data stream from a cylinder is very fast because the head can continuously pick up
data as the disk spins. A partition arranged as a set of adjacent cylinders also allows for fast continuous data
access because the head doesn’t need to move very far between cylinders.
Some partitioning programs complain if you don’t place your partitions precisely on cylinder boundaries.
Ignore this; there’s little you can do because the reported CHS values of modern disks simply aren’t true. The
disk’s LBA scheme ensures that your partitions are where they’re supposed to be.
4.1.4 Solid-State Disks (SSDs)
Storage devices with no moving parts, such as solid-state disks (SSDs), are radically different from spinning
disks in terms of their access characteristics. For these, random access is not a problem because there’s no
head to sweep across a platter, but certain factors affect performance.
One of the most significant factors affecting the performance of SSDs is partition alignment. When you read
data from an SSD, you read it in chunks— typically 4096 bytes at a time—and the read must begin at a
multiple of that same size. So if your partition and its data do not lie on a 4096-byte boundary, you may have
to do two reads instead of one for small, common operations, such as reading the contents of a directory.
Many partitioning utilities (parted and gparted, for example) include functionality to put newly created
www.EBooksWorld.ir
partitions at the proper offsets from the beginning of the disks, so you may never need to worry about improper
partition alignment. However, if you’re curious about where your partitions begin and just want to make sure
that they begin on a boundary, you can easily find this information by looking in /sys/block. Here’s an example
for a partition /dev/sdf2:
$ cat /sys/block/sdf/sdf2/start
1953126
This partition starts at 1,953,126 bytes from the beginning of the disk. Because this number is not divisible by
4,096, the partition would not be attaining optimal performance if it were on SSD.
4.2 Filesystems
The last link between the kernel and user space for disks is typically the file-system; this is what you’re
accustomed to interacting with when you run commands such as ls and cd. As previously mentioned, the
filesystem is a form of database; it supplies the structure to transform a simple block device into the
sophisticated hierarchy of files and subdirectories that users can understand.
At one time, filesystems resided on disks and other physical media used exclusively for data storage. However,
the tree-like directory structure and I/O interface of filesystems are quite versatile, so filesystems now perform
a variety of tasks, such as the system interfaces that you see in /sys and /proc. Filesystems are also traditionally
implemented in the kernel, but the innovation of 9P from Plan 9 (http://plan9.bell-labs.com/sys/doc/9.html)
has inspired the development of user-space filesystems. The File System in User Space (FUSE) feature allows
user-space filesystems in Linux.
The Virtual File System (VFS) abstraction layer completes the filesystem implementation. Much as the SCSI
subsystem standardizes communication between different device types and kernel control commands, VFS
ensures that all filesystem implementations support a standard interface so that user-space applications access
files and directories in the same manner. VFS support has enabled Linux to support an extraordinarily large
number of filesystems.
4.2.1 Filesystem Types
Linux filesystem support includes native designs optimized for Linux, foreign types such as the Windows FAT
family, universal filesystems like ISO 9660, and many others. The following list includes the most common
types of filesystems for data storage. The type names as recognized by Linux are in parentheses next to the
filesystem names.
o The Fourth Extended filesystem (ext4) is the current iteration of a line of filesystems native to Linux. The
Second Extended filesystem (ext2) was a longtime default for Linux systems inspired by traditional Unix
filesystems such as the Unix File System (UFS) and the Fast File System (FFS). The Third Extended
filesystem (ext3) added a journal feature (a small cache outside the normal filesystem data structure) to
enhance data integrity and hasten booting. The ext4 filesystem is an incremental improvement with support
for larger files than ext2 or ext3 support and a greater number of subdirectories.
There is a certain amount of backward compatibility in the extended filesystem series. For example, you can
mount ext2 and ext3 filesystems as each other, and you can mount ext2 and ext3 filesystems as ext4, but you
cannot mount ext4 as ext2 or ext3.
o ISO 9660 (iso9660) is a CD-ROM standard. Most CD-ROMs use some variety of the ISO 9660 standard.
o FAT filesystems (msdos, vfat, umsdos) pertain to Microsoft systems. The simple msdos type supports the
very primitive monocase variety in MS-DOS systems. For most modern Windows filesystems, you should
www.EBooksWorld.ir
use the vfat filesystem in order to get full access from Linux. The rarely used umsdos filesystem is peculiar
to Linux. It supports Unix features such as symbolic links on top of an MS-DOS filesystem.
o HFS+ (hfsplus) is an Apple standard used on most Macintosh systems.
Although the Extended filesystem series has been perfectly acceptable to most casual users, many advances
have been made in filesystem technology that even ext4 cannot utilize due to the backward compatibility
requirement. The advances are primarily in scalability enhancements pertaining to very large numbers of files,
large files, and similar scenarios. New Linux filesystems, such as Btrfs, are under development and may be
poised to replace the Extended series.
4.2.2 Creating a Filesystem
Once you’re done with the partitioning process described in 4.1 Partitioning Disk Devices, you’re ready to
create filesystems. As with partitioning, you’ll do this in user space because a user-space process can directly
access and manipulate a block device. The mkfs utility can create many kinds of filesystems. For example,
you can create an ext4 partition on /dev/sdf2 with this command:
# mkfs -t ext4 /dev/sdf2
The mkfs program automatically determines the number of blocks in a device and sets some reasonable
defaults. Unless you really know what you’re doing and feel like reading the documentation in detail, don’t
change these.
When you create a filesystem, mkfs prints diagnostic output as it works, including output pertaining to the
superblock. The superblock is a key component at the top level of the filesystem database, and it’s so important
that mkfs creates a number of backups in case the original is destroyed. Consider recording a few of the
superblock backup numbers when mkfs runs, in case you need to recover the superblock in the event of a
disk failure (see 4.2.11 Checking and Repairing Filesystems).
WARNING
Filesystem creation is a task that you should only need to perform after adding a new disk or
repartitioning an old one. You should create a filesystem just once for each new partition that has
no preexisting data (or that has data that you want to remove). Creating a new filesystem on top of
an existing filesystem will effectively destroy the old data.
It turns out that mkfs is only a frontend for a series of filesystem creation programs, mkfs.fs, where fs is
a filesystem type. So when you run mkfs -t ext4, mkfs in turn runs mkfs.ext4.
And there’s even more indirection. Inspect the mkfs.* files behind the commands and you’ll see the following:
$ ls -l /sbin/mkfs.*
-rwxr-xr-x 1 root root 17896 Mar 29 21:49 /sbin/mkfs.bfs
-rwxr-xr-x 1 root root 30280 Mar 29 21:49 /sbin/mkfs.cramfs
lrwxrwxrwx 1 root root 6 Mar 30 13:25 /sbin/mkfs.ext2 -> mke2fs
lrwxrwxrwx 1 root root 6 Mar 30 13:25 /sbin/mkfs.ext3 -> mke2fs
lrwxrwxrwx 1 root root 6 Mar 30 13:25 /sbin/mkfs.ext4 -> mke2fs
lrwxrwxrwx 1 root root 6 Mar 30 13:25 /sbin/mkfs.ext4dev -> mke2fs
-rwxr-xr-x 1 root root 26200 Mar 29 21:49 /sbin/mkfs.minix
lrwxrwxrwx 1 root root 7 Dec 19 2011 /sbin/mkfs.msdos -> mkdosfs
lrwxrwxrwx 1 root root 6 Mar 5 2012 /sbin/mkfs.ntfs -> mkntfs
www.EBooksWorld.ir
lrwxrwxrwx 1 root root 7 Dec 19 2011 /sbin/mkfs.vfat -> mkdosfs
As you can see, mkfs.ext4 is just a symbolic link to mke2fs. This is important to remember if you run across a
system without a specific mkfs command or when you’re looking up the documentation for a particular
filesystem. Each filesystem’s creation utility has its own manual page, like mke2fs(8). This shouldn’t be a
problem on most systems, because accessing the mkfs.ext4(8) manual page should redirect you to the
mke2fs(8) manual page, but keep it in mind.
4.2.3 Mounting a Filesystem
On Unix, the process of attaching a filesystem is called mounting. When the system boots, the kernel reads
some configuration data and mounts root (/) based on the configuration data.
In order to mount a filesystem, you must know the following:
o The filesystem’s device (such as a disk partition; where the actual file-system data resides).
o The filesystem type.
o The mount point—that is, the place in the current system’s directory hierarchy where the filesystem will be
attached. The mount point is always a normal directory. For instance, you could use /cdrom as a mount
point for CD-ROM devices. The mount point need not be directly below /; it may be anywhere on the
system.
When mounting a filesystem, the common terminology is “mount a device on a mount point.” To learn the
current filesystem status of your system, run mount. The output should look like this:
$ mount
/dev/sda1 on / type ext4 (rw,errors=remount-ro)
proc on /proc type proc (rw,noexec,nosuid,nodev)
sysfs on /sys type sysfs (rw,noexec,nosuid,nodev)
none on /sys/fs/fuse/connections type fusectl (rw)
none on /sys/kernel/debug type debugfs (rw)
none on /sys/kernel/security type securityfs (rw)
udev on /dev type devtmpfs (rw,mode=0755)
devpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)
tmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)
--snip--
Each line corresponds to one currently mounted filesystem, with items in this order:
o The device, such as /dev/sda3. Notice that some of these aren’t real devices (proc, for example) but are
stand-ins for real device names because these special-purpose filesystems do not need devices.
o The word on.
o The mount point.
o The word type.
o The filesystem type, usually in the form of a short identifier.
o Mount options (in parentheses). (See 4.2.6 Filesystem Mount Options for more details.)
www.EBooksWorld.ir
To mount a filesystem, use the mount command as follows with the file-system type, device, and desired
mount point:
# mount -t type device mountpoint
For example, to mount the Fourth Extended filesystem /dev/sdf2 on /home/extra, use this command:
# mount -t ext4 /dev/sdf2 /home/extra
You normally don’t need to supply the -t type option because mount can usually figure it out for you.
However, sometimes it’s necessary to distinguish between two similar types, such as the various FAT-style
filesystems.
See 4.2.6 Filesystem Mount Options for a few more long options to mount. To unmount (detach) a filesystem,
use the umount command:
# umount mountpoint
You can also unmount a filesystem with its device instead of its mount point.
4.2.4 Filesystem UUID
The method of mounting filesystems discussed in the preceding section depends on device names. However,
device names can change because they depend on the order in which the kernel finds the devices. To solve
this problem, you can identify and mount filesystems by their Universally Unique Identifier (UUID), a
software standard. The UUID is a type of serial number, and each one should be different. Filesystem creation
programs like mke2fs generate a UUID identifier when initializing the filesystem data structure.
To view a list of devices and the corresponding filesystems and UUIDs on your system, use the blkid (block
ID) program:
# blkid
/dev/sdf2: UUID="a9011c2b-1c03-4288-b3fe-8ba961ab0898" TYPE="ext4"
/dev/sda1: UUID="70ccd6e7-6ae6-44f6-812c-51aab8036d29" TYPE="ext4"
/dev/sda5: UUID="592dcfd1-58da-4769-9ea8-5f412a896980" TYPE="swap"
/dev/sde1: SEC_TYPE="msdos" UUID="3762-6138" TYPE="vfat"
In this example, blkid found four partitions with data: two with ext4 filesystems, one with a swap space
signature (see 4.3 swap space), and one with a FAT-based filesystem. The Linux native partitions all have
standard UUIDs, but the FAT partition doesn’t have one. You can reference the FAT partition with its FAT
volume serial number (in this case, 3762-6138).
To mount a filesystem by its UUID, use the UUID= syntax. For example, to mount the first filesystem from
the preceding list on /home/extra, enter:
# mount UUID=a9011c2b-1c03-4288-b3fe-8ba961ab0898 /home/extra
You will typically not manually mount filesystems by UUID as above, because you’ll probably know the
device, and it’s much easier to mount a device by its name than by its crazy UUID number. Still, it’s important
to understand UUIDs. For one thing, they’re the preferred way to automatically mount filesystems in /etc/fstab
at boot time (see 4.2.8 The /etc/fstab Filesystem Table). In addition, many distributions use the UUID as a
mount point when you insert removable media. In the preceding example, the FAT filesystem is on a flash
media card. An Ubuntu system with someone logged in will mount this partition at /media/3762-6138 upon
insertion. The udevd daemon described in Chapter 3 handles the initial event for the device insertion.
You can change the UUID of a filesystem if necessary (for example, if you copied the complete filesystem
www.EBooksWorld.ir
from somewhere else and now need to distinguish it from the original). See the tune2fs(8) manual page for
how to do this on an ext2/ext3/ext4 filesystem.
4.2.5 Disk Buffering, Caching, and Filesystems
Linux, like other versions of Unix, buffers writes to the disk. This means that the kernel usually doesn’t
immediately write changes to filesystems when processes request changes. Instead it stores the changes in
RAM until the kernel can conveniently make the actual change to the disk. This buffering system is transparent
to the user and improves performance.
When you unmount a filesystem with umount, the kernel automatically synchronizes with the disk. At any
other time, you can force the kernel to write the changes in its buffer to the disk by running the sync command.
If for some reason you can’t unmount a filesystem before you turn off the system, be sure to run sync first.
In addition, the kernel has a series of mechanisms that use RAM to automatically cache blocks read from a
disk. Therefore, if one or more processes repeatedly access a file, the kernel doesn’t have to go to the disk
again and again—it can simply read from the cache and save time and resources.
4.2.6 Filesystem Mount Options
There are many ways to change the mount command behavior, as is often necessary with removable media
or when performing system maintenance. In fact, the total number of mount options is staggering. The
extensive mount(8) manual page is a good reference, but it’s hard to know where to start and what you can
safely ignore. You’ll see the most useful options in this section.
Options fall into two rough categories: general and filesystem-specific ones. General options include -t for
specifying the filesystem type (as mentioned earlier). In contrast, a filesystem-specific option pertains only to
certain filesystem types.
To activate a filesystem option, use the -o switch followed by the option. For example, -o norock turns
off Rock Ridge extensions on an ISO 9660 file-system, but it has no meaning for any other kind of filesystem.
Short Options
The most important general options are these:
o -r The -r option mounts the filesystem in read-only mode. This has a number of uses, from write
protection to bootstrapping. You don’t need to specify this option when accessing a read-only device such
as a CD-ROM; the system will do it for you (and will also tell you about the read-only status).
o -n The -n option ensures that mount does not try to update the system runtime mount database, /etc/mtab.
The mount operation fails when it cannot write to this file, which is important at boot time because the
root partition (and, therefore, the system mount database) is read-only at first. You’ll also find this option
handy when trying to fix a system problem in single-user mode, because the system mount database may
not be available at the time.
o -t The -t type option specifies the filesystem type.
Long Options
Short options like -r are too limited for the ever-increasing number of mount options; there are too few
letters in the alphabet to accommodate all possible options. Short options are also troublesome because it is
difficult to determine an option’s meaning based on a single letter. Many general options and all filesystem-
specific options use a longer, more flexible option format.
To use long options with mount on the command line, start with -o and supply some keywords. Here’s a
complete example, with the long options following -o:
www.EBooksWorld.ir
# mount -t vfat /dev/hda1 /dos -o ro,conv=auto
The two long options here are ro and conv=auto. The ro option specifies read-only mode and is the same
as the -r short option. The conv=auto option tells the kernel to automatically convert certain text files from
the DOS newline format to the Unix style (you’ll see more shortly).
The most useful long options are these:
o exec, noexec Enables or disables execution of programs on the filesystem.
o suid, nosuid Enables or disables setuid programs.
o ro Mounts the filesystem in read-only mode (as does the -r short option).
o rw Mounts the filesystem in read-write mode.
o conv=rule (FAT-based filesystems) Converts the newline characters in files based on rule, which can
be binary, text, or auto. The default is binary, which disables any character translation. To treat all
files as text, use text. The auto setting converts files based on their extension. For example, a .jpg file
gets no special treatment, but a .txt file does. Be careful with this option because it can damage files.
Consider using it in read-only mode.
4.2.7 Remounting a Filesystem
There will be times when you may need to reattach a currently mounted filesystem at the same mount point
when you need to change mount options. The most common such situation is when you need to make a read-
only file-system writable during crash recovery.
The following command remounts the root in read-write mode (you need the -n option because the mount
command can’t write to the system mount database when the root is read-only):
# mount -n -o remount /
This command assumes that the correct device listing for / is in /etc/fstab (as discussed in the next section). If
it is not, you must specify the device.
4.2.8 The /etc/fstab Filesystem Table
To mount filesystems at boot time and take the drudgery out of the mount command, Linux systems keep a
permanent list of filesystems and options in /etc/fstab. This is a plaintext file in a very simple format, as Listing
4-1 shows.
Example 4-1. List of filesystems and options in /etc/fstab
proc /proc proc nodev,noexec,nosuid 0 0
UUID=70ccd6e7-6ae6-44f6-812c-51aab8036d29 / ext4 errors=remount-ro 0 1
UUID=592dcfd1-58da-4769-9ea8-5f412a896980 none swap sw 0 0
/dev/sr0 /cdrom iso9660 ro,user,nosuid,noauto 0 0
Each line corresponds to one filesystem, each of which is broken into six fields. These fields are as follows,
in order from left to right:
o The device or UUID. Most current Linux systems no longer use the device in /etc/fstab, preferring the
UUID. (Notice that the /proc entry has a stand-in device named proc.)
o The mount point. Indicates where to attach the filesystem.
o The filesystem type. You may not recognize swap in this list; this is a swap partition (see 4.3 swap space).
o Options. Use long options separated by commas.
o Backup information for use by the dump command. You should always use a 0 in this field.
www.EBooksWorld.ir
o The filesystem integrity test order. To ensure that fsck always runs on the root first, always set this to 1
for the root filesystem and 2 for any other filesystems on a hard disk. Use 0 to disable the bootup check for
everything else, including CD-ROM drives, swap, and the /proc file-system (see the fsck command in
4.2.11 Checking and Repairing Filesystems).
When using mount, you can take some shortcuts if the filesystem you want to work with is in /etc/fstab. For
example, if you were using Listing 4-1 and mounting a CD-ROM, you would simply run mount /cdrom.
You can also try to mount all entries at once in /etc/fstab that do not contain the noauto option with this
command:
# mount -a
Listing 4-1 contains some new options, namely errors, noauto, and user, because they don’t apply
outside the /etc/fstab file. In addition, you’ll often see the defaults option here. The meanings of these
options are as follows:
o defaults This uses the mount defaults: read-write mode, enable device files, executables, the setuid bit,
and so on. Use this when you don’t want to give the filesystem any special options but you do want to fill
all fields in /etc/fstab.
o errors This ext2-specific parameter sets the kernel behavior when the system has trouble mounting a
filesystem. The default is normally errors=continue, meaning that the kernel should return an error
code and keep running. To have the kernel try the mount again in read-only mode, use
errors=remount-ro. The errors=panic setting tells the kernel (and your system) to halt when
there is a problem with the mount.
o noauto This option tells a mount -a command to ignore the entry. Use this to prevent a boot-time
mount of a removable-media device, such as a CD-ROM or floppy drive.
o user This option allows unprivileged users to run mount on a particular entry, which can be handy for
allowing access to CD-ROM drives. Because users can put a setuid-root file on removable media with
another system, this option also sets nosuid, noexec, and nodev (to bar special device files).
4.2.9 Alternatives to /etc/fstab
Although the /etc/fstab file has been the traditional way to represent filesystems and their mount points, two
new alternatives have appeared. The first is an /etc/fstab.d directory that contains individual filesystem
configuration files (one file for each filesystem). The idea is very similar to many other configuration
directories that you’ll see throughout this book.
A second alternative is to configure systemd units for the filesystems. You’ll learn more about systemd and its
units in Chapter 6. However, the systemd unit configuration is often generated from (or based on) the /etc/
fstab file, so you may find some overlap on your system.
4.2.10 Filesystem Capacity
To view the size and utilization of your currently mounted filesystems, use the df command. The output
should look like this:
$ df
Filesystem 1024-blocks Used Available Capacity Mounted on
/dev/sda1 1011928 71400 889124 7% /
/dev/sda3 17710044 9485296 7325108 56% /usr
Here’s a brief description of the fields in the df output:
www.EBooksWorld.ir
o Filesystem. The filesystem device
o 1024-blocks. The total capacity of the filesystem in blocks of 1024 bytes
o Used. The number of occupied blocks
o Available. The number of free blocks
o Capacity. The percentage of blocks in use
o Mounted on. The mount point
It should be easy to see that the two filesystems here are roughly 1GB and 17.5GB in size. However, the
capacity numbers may look a little strange because 71,400 plus 889,124 does not equal 1,011,928, and
9,485,296 does not constitute 56 percent of 17,710,044. In both cases, 5 percent of the total capacity is
unaccounted for. In fact, the space is there, but it is hidden in reserved blocks. Therefore, only the superuser
can use the full filesystem space if the rest of the partition fills up. This feature keeps system servers from
immediately failing when they run out of disk space.
If your disk fills up and you need to know where all of those space-hogging media files are, use the du
command. With no arguments, du prints the disk usage of every directory in the directory hierarchy, starting
at the current working directory. (That’s kind of a mouthful, so just run cd /; du to get the idea. Press
CTRL-C when you get bored.) The du -s command turns on summary mode to print only the grand total. To
evaluate a particular directory, change to that directory and run du -s *.
NOTE
The POSIX standard defines a block size of 512 bytes. However, this size is harder to read, so by
default, the df and du output in most Linux distributions is in 1024-byte blocks. If you insist on
displaying the numbers in 512-byte blocks, set the POSIXLY_CORRECT environment variable. To
explicitly specify 1024-byte blocks, use the -k option (both utilities support this). The df program
also has a -m option to list capacities in 1MB blocks and a -h option to take a best guess at what
a person can read.
4.2.11 Checking and Repairing Filesystems
The optimizations that Unix filesystems offer are made possible by a sophisticated database mechanism. For
filesystems to work seamlessly, the kernel has to trust that there are no errors in a mounted filesystem. If errors
exist, data loss and system crashes may result.
Filesystem errors are usually due to a user shutting down the system in a rude way (for example, by pulling
out the power cord). In such cases, the filesystem cache in memory may not match the data on the disk, and
the system also may be in the process of altering the filesystem when you happen to give the computer a kick.
Although a new generation of filesystems supports journals to make filesystem corruption far less common,
you should always shut the system down properly. And regardless of the filesystem in use, filesystem checks
are still necessary every now and to maintain sanity.
The tool to check a filesystem is fsck. As with the mkfs program, there is a different version of fsck for
each filesystem type that Linux supports. For example, when you run fsck on an Extended filesystem series
(ext2/ ext3/ext4), fsck recognizes the filesystem type and starts the e2fsck utility. Therefore, you generally
don’t need to type e2fsck, unless fsck can’t figure out the filesystem type or you’re looking for the
e2fsck manual page.
The information presented in this section is specific to the Extended filesystem series and e2fsck.
To run fsck in interactive manual mode, give the device or the mount point (as listed in /etc/fstab) as the
argument. For example:
# fsck /dev/sdb1
www.EBooksWorld.ir
WARNING
You should never use fsck on a mounted filesystem because the kernel may alter the disk data
as you run the check, causing runtime mismatches that can crash your system and corrupt files.
There is only one exception: If you mount the root partition read-only in single-user mode, you may
use fsck on it.
In manual mode, fsck prints verbose status reports on its passes, which should look something like this when
there are no problems:
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information /dev/sdb1: 11/1976 files (0.0%
non-contiguous), 265/7891 blocks
If fsck finds a problem in manual mode, it stops and asks you a question relevant to fixing the problem.
These questions deal with the internal structure of the filesystem, such as reconnecting loose inodes and
clearing blocks (an inode is a building block of the filesystem; you’ll see how inodes work in 4.5 Inside a
Traditional Filesystem). When fsck asks you about reconnecting an inode, it has found a file that doesn’t
appear to have a name. When reconnecting such a file, fsck places the file in the lost+found directory in the
filesystem, with a number as the filename. If this happens, you need to guess the name based on the content
of the file; the original name is probably gone.
In general, it’s pointless to sit through the fsck repair process if you’ve just uncleanly shut down the system,
because fsck may have a lot of minor errors to fix. Fortunately, e2fsck has a -p option that automatically
fixes ordinary problems without asking and aborts when there’s a serious error. In fact, Linux distributions run
some variant of fsck -p at boot time. (You may also see fsck -a, which just does the same thing.)
If you suspect a major disaster on your system, such as a hardware failure or device misconfiguration, you
need to decide on a course of action because fsck can really mess up a filesystem that has larger problems.
(One telltale sign that your system has a serious problem is that fsck asks a lot of questions in manual mode.)
If you think that something really bad has happened, try running fsck -n to check the filesystem without
modifying anything. If there’s a problem with the device configuration that you think you can fix (such as an
incorrect number of blocks in the partition table or loose cables), fix it before running fsck for real, or you’re
likely to lose a lot of data.
If you suspect that only the superblock is corrupt (for example, because someone wrote to the beginning of
the disk partition), you might be able to recover the filesystem with one of the superblock backups that mkfs
creates. Use fsck -b num to replace the corrupted superblock with an alternate at block num and hope for
the best.
If you don’t know where to find a backup superblock, you may be able to run mkfs -n on the device to view
a list of superblock backup numbers without destroying your data. (Again, make sure that you’re using -n, or
you’ll really tear up the filesystem.)
Checking ext3 and ext4 Filesystems
You normally do not need to check ext3 and ext4 filesystems manually because the journal ensures data
integrity. However, you may wish to mount a broken ext3 or ext4 filesystem in ext2 mode because the kernel
will not mount an ext3 or ext4 filesystem with a nonempty journal. (If you don’t shut your system down
www.EBooksWorld.ir
cleanly, you can expect the journal to contain some data.) To flush the journal in an ext3 or ext4 filesystem to
the regular filesystem database, run e2fsck as follows:
# e2fsck –fy /dev/disk_device
The Worst Case
Disk problems that are worse in severity leave you with few choices:
o You can try to extract the entire filesystem image from the disk with dd and transfer it to a partition on
another disk of the same size.
o You can try to patch the filesystem as much as possible, mount it in read-only mode, and salvage what you
can.
o You can try debugfs.
In the first two cases, you still need to repair the filesystem before you mount it, unless you feel like picking
through the raw data by hand. If you like, you can choose to answer y to all of the fsck questions by entering
fsck -y, but do this as a last resort because issues may come up during the repair process that you would
rather handle manually.
The debugfs tool allows you to look through the files on a filesystem and copy them elsewhere. By default,
it opens filesystems in read-only mode. If you’re recovering data, it’s probably a good idea to keep your files
intact to avoid messing things up further.
Now, if you’re really desperate, say with a catastrophic disk failure on your hands and no backups, there isn’t
a lot you can do other than hope a professional service can “scrape the platters.”
4.2.12 Special-Purpose Filesystems
Not all filesystems represent storage on physical media. Specifically, most versions of Unix have filesystems
that serve as system interfaces. That is, rather than serving only as a means to store data on a device, a
filesystem can represent system information such as process IDs and kernel diagnostics. This idea goes back
to the /dev mechanism, which is an early model of using files for I/O interfaces. The /proc idea came from the
eighth edition of research Unix, implemented by Tom J. Killian and accelerated when Bell Labs (including
many of the original Unix designers) created Plan 9—a research operating system that took filesystem
abstraction to a whole new level (http://plan9.bell-labs.com/sys/doc/9.html).
The special filesystem types in common use on Linux include the following:
o proc. Mounted on /proc. The name proc is actually an abbreviation for process. Each numbered directory
inside /proc is actually the process ID of a current process on the system; the files in those directories
represent various aspects of the processes. The file /proc/self represents the current process. The Linux
proc filesystem includes a great deal of additional kernel and hardware information in files like
/proc/cpuinfo. (There has been a push to move information unrelated to processes out of /proc and into
/sys.)
o sysfs. Mounted on /sys. (You saw this in Chapter 3.)
o tmpfs. Mounted on /run and other locations. With tmpfs, you can use your physical memory and swap
space as temporary storage. For example, you can mount tmpfs where you like, using the size and
nr_blocks long options to control the maximum size. However, be careful not to constantly pour things
into a tmpfs because your system will eventually run out of memory and programs will start to crash. (For
years, Sun Microsystems used a version of tmpfs for /tmp that caused problems on long-running systems.)
www.EBooksWorld.ir
4.3 swap space
Not every partition on a disk contains a filesystem. It’s also possible to augment the RAM on a machine with
disk space. If you run out of real memory, the Linux virtual memory system can automatically move pieces of
memory to and from a disk storage. This is called swapping because pieces of idle programs are swapped to
the disk in exchange for active pieces residing on the disk. The disk area used to store memory pages is called
swap space (or just swap for short).
The free command’s output includes the current swap usage in kilobytes as follows:
$ free
total used free
--snip--
Swap: 514072 189804 324268
4.3.1 Using a Disk Partition as Swap Space
To use an entire disk partition as swap, follow these steps:
1. Make sure the partition is empty.
2. Run mkswap dev, where dev is the partition’s device. This command puts a swap signature on the
partition.
3. Execute swapon dev to register the space with the kernel.
After creating a swap partition, you can put a new swap entry in your /etc/fstab file to make the system use
the swap space as soon as the machine boots. Here is a sample entry that uses /dev/sda5 as a swap partition:
/dev/sda5 none swap sw 0 0
Keep in mind that many systems now use UUIDs instead of raw device names.
4.3.2 Using a File as Swap Space
You can use a regular file as swap space if you’re in a situation where you would be forced to repartition a
disk in order to create a swap partition. You shouldn’t notice any problems when doing this.
Use these commands to create an empty file, initialize it as swap, and add it to the swap pool:
# dd if=/dev/zero of=swap_file bs=1024k count=num_mb
# mkswap swap_file
# swapon swap_file
Here, swap_file is the name of the new swap file, and num_mb is the desired size, in megabytes.
To remove a swap partition or file from the kernel’s active pool, use the swapoff command.
4.3.3 How Much Swap Do You Need?
At one time, Unix conventional wisdom said you should always reserve at least twice as much swap as you
have real memory. Today, not only do the enormous disk and memory capacities available cloud the issue, but
so do the ways we use the system. On one hand, disk space is so plentiful that it’s tempting to allocate more
than double the memory size. On the other hand, you may never even dip into your swap space because you
have so much real memory.
The “double the real memory” rule dated from a time when multiple users would be logged into one machine
www.EBooksWorld.ir
at a time. Not all of them would be active, though, so it was convenient to be able to swap out the memory of
the inactive users when an active user needed more memory.
The same may still hold true for a single-user machine. If you’re running many processes, it’s generally fine
to swap out parts of inactive processes or even inactive pieces of active processes. However, if you’re
constantly using the swap space because many active processes want to use the memory at once, you will
suffer serious performance problems because disk I/O is just too slow to keep up with the rest of the system.
The only solutions are to buy more memory, terminate some processes, or complain.
Sometimes, the Linux kernel may choose to swap out a process in favor of a little more disk cache. To prevent
this behavior, some administrators configure certain systems with no swap space at all. For example, high-
performance network servers should never dip into swap space and should avoid disk access if at all possible.
NOTE
It’s dangerous to do this on a general-purpose machine. If a machine completely runs out of both
real memory and swap space, the Linux kernel invokes the out-of-memory (OOM) killer to kill a
process in order to free up some memory. You obviously don’t want this to happen to your desktop
applications. On the other hand, high-performance servers include sophisticated monitoring and
load-balancing systems to ensure that they never reach the danger zone.
You’ll learn much more about how the memory system works in Chapter 8.
4.4 Looking Forward: Disks and User Space
In disk-related components on a Unix system, the boundaries between user space and the kernel can be difficult
to characterize. As you’ve seen, the kernel handles raw block I/O from the devices, and user-space tools can
use the block I/O through device files. However, user space typically uses the block I/O only for initializing
operations such as partitioning, file-system creation, and swap space creation. In normal use, user space uses
only the filesystem support that the kernel provides on top of the block I/O. Similarly, the kernel also handles
most of the tedious details when dealing with swap space in the virtual memory system.
The remainder of this chapter briefly looks at the innards of a Linux filesystem. This is more advanced material,
and you certainly don’t need to know it to proceed with the book. If this is your first time through, skip to the
next chapter and start learning about how Linux boots.
4.5 Inside a Traditional Filesystem
A traditional Unix filesystem has two primary components: a pool of data blocks where you can store data
and a database system that manages the data pool. The database is centered around the inode data structure.
An inode is a set of data that describes a particular file, including its type, permissions, and—perhaps most
importantly—where in the data pool the file data resides. Inodes are identified by numbers listed in an inode
table.
Filenames and directories are also implemented as inodes. A directory inode contains a list of filenames and
corresponding links to other inodes.
To provide a real-life example, I created a new filesystem, mounted it, and changed the directory to the mount
point. Then, I added some files and directories with these commands (feel free to do this yourself with a flash
drive):
$ mkdir dir_1
$ mkdir dir_2
$ echo a > dir_1/file_1
www.EBooksWorld.ir
$ echo b > dir_1/file_2
$ echo c > dir_1/file_3
$ echo d > dir_2/file_4
$ ln dir_1/file_3 dir_2/file_5
Note that I created dir_2/file_5 as a hard link to dir_1/file_3, meaning that these two filenames actually
represent the same file. (More on this shortly.)
If you were to explore the directories in this filesystem, its contents would appear to the user as shown in
Figure 4-4. The actual layout of the filesystem, as shown in Figure 4-5, doesn’t look nearly as clean as the
user-level representation.
www.EBooksWorld.ir
Figure 4-4. User-level representation of a filesystem
Figure 4-5. Inode structure of the filesystem shown in Figure 4-4
How do we make sense of this? For any ext2/3/4 filesystem, you start at inode number 2—the root inode.
From the inode table in Figure 4-5, you can see that this is a directory inode (dir), so you can follow the arrow
over to the data pool, where you see the contents of the root directory: two entries named dir_1 and dir_2
corresponding to inodes 12 and 7633, respectively. To explore those entries, go back to the inode table and
look at either of those inodes.
To examine dir_1/file_2 in this filesystem, the kernel does the following:
1. Determines the path’s components: a directory named dir_1, followed by a component named file_2.
2. Follows the root inode to its directory data.
3. Finds the name dir_1 in inode 2’s directory data, which points to inode number 12.
4. Looks up inode 12 in the inode table and verifies that it is a directory inode.
5. Follows inode 12’s data link to its directory information (the second box down in the data pool).
6. Locates the second component of the path (file_2) in inode 12’s directory data. This entry points to inode
number 14.
7. Looks up inode 14 in the directory table. This is a file inode.
At this point, the kernel knows the properties of the file and can open it by following inode 14’s data link.
www.EBooksWorld.ir
This system, of inodes pointing to directory data structures and directory data structures pointing to inodes,
allows you to create the filesystem hierarchy that you’re used to. In addition, notice that the directory inodes
contain entries for . (the current directory) and .. (the parent directory, except for the root directory). This
makes it easy to get a point of reference and to navigate back down the directory structure.
4.5.1 Viewing Inode Details
To view the inode numbers for any directory, use the ls -i command. Here’s what you’d get at the root of
this example. (For more detailed inode information, use the stat command.)
$ ls -i
12 dir_1 7633 dir_2
Now you’re probably wondering about the link count. You’ve already seen the link count in the output of the
common ls -l command, but you likely ignored it. How does the link count relate to the files in Figure 4-
5, in particular the “hard-linked” file_5? The link count field is the number of total directory entries (across
all directories) that point to an inode. Most of the files have a link count of 1 because they occur only once in
the directory entries. This is expected: Most of the time when you create a file, you create a new directory
entry and a new inode to go with it. However, inode 15 occurs twice: First it’s created as dir_1/file_3, and then
it’s linked to as dir_2/file_5. A hard link is just a manually created entry in a directory to an inode that already
exists. The ln command (without the -s option) allows you to manually create new links.
This is also why removing a file is sometimes called unlinking. If you run rm dir_1/file_2, the kernel
searches for an entry named file_2 in inode 12’s directory entries. Upon finding that file_2 corresponds to
inode 14, the kernel removes the directory entry and then subtracts 1 from inode 14’s link count. As a result,
inode 14’s link count will be 0, and the kernel will know that there are no longer any names linking to the
inode. Therefore, it can now delete the inode and any data associated with it.
However, if you run rm dir_1/file_3, the end result is that the link count of inode 15 goes from 2 to 1
(because dir_2/file_5 still points there), and the kernel knows not to remove the inode.
Link counts work much the same for directories. Observe that inode 12’s link count is 2, because there are
two inode links there: one for dir_1 in the directory entries for inode 2 and the second a self-reference (.) in
its own directory entries. If you create a new directory dir_1/dir_3, the link count for inode 12 would go to 3
because the new directory would include a parent (..) entry that links back to inode 12, much as inode 12’s
parent link points to inode 2.
There is one small exception. The root inode 2 has a link count of 4. However, Figure 4-5 shows only three
directory entry links. The “fourth” link is in the filesystem’s superblock because the superblock tells you where
to find the root inode.
Don’t be afraid to experiment on your system. Creating a directory structure and then using ls -i or stat
to walk through the pieces is harmless. You don’t need to be root (unless you mount and create a new
filesystem).
But there’s still one piece missing: When allocating data pool blocks for a new file, how does the filesystem
know which blocks are in use and which are available? One of the most basic ways is with an additional
management data structure called a block bitmap. In this scheme, the filesystem reserves a series of bytes,
with each bit corresponding to one block in the data pool. A value of 0 means that the block is free, and a 1
means that it’s in use. Thus, allocating and deallocating blocks is a matter of flipping bits.
Problems in a filesystem arise when the inode table data doesn’t match the block allocation data or when the
link counts are incorrect; this can happen when you don’t cleanly shut down a system. Therefore, when you
check a filesystem, as described in 4.2.11 Checking and Repairing Filesystems, the fsck program walks
through the inode table and directory structure to generate new link counts and a new block allocation map
www.EBooksWorld.ir
(such as the block bitmap), and then it compares the newly generated data with the filesystem on the disk. If
there are mismatches, fsck must fix the link counts and determine what to do with any inodes and/or data
that didn’t come up when it traversed the directory structure. Most fsck programs make these “orphans” new
files in the filesystem’s lost+found directory.
4.5.2 Working with Filesystems in User Space
When working with files and directories in user space, you shouldn’t have to worry much about the
implementation going on below them. You’re expected to access the contents of files and directories of a
mounted file-system through kernel system calls. Curiously, though, you do have access to certain filesystem
information that doesn’t seem to fit in user space—in particular, the stat() system call returns inode
numbers and link counts.
When not maintaining a filesystem, do you have to worry about inode numbers and link counts? Generally,
no. This stuff is accessible to user mode programs primarily for backward compatibility. Furthermore, not all
filesystems available in Linux have these filesystem internals. The Virtual File System (VFS) interface layer
ensures that system calls always return inode numbers and link counts, but those numbers may not necessarily
mean anything.
You may not be able to perform traditional Unix filesystem operations on nontraditional filesystems. For
example, you can’t use ln to create a hard link on a mounted VFAT filesystem because the directory entry
structure is entirely different.
Fortunately, the system calls available to user space on Unix/Linux systems provide enough abstraction for
painless file access—you don’t need to know anything about the underlying implementation in order to access
files. In addition, filenames are flexible in format and mixed-case names are supported, making it easy to
support other hierarchical-style filesystems.
Remember, specific filesystem support does not necessarily need to be in the kernel. In user-space filesystems,
the kernel only needs to act as a conduit for system calls.
4.5.3 The Evolution of Filesystems
As you can see, even the simple filesystem just described has many different components to maintain. At the
same time, the demands placed on filesystems continuously increase with new tasks, technology, and storage
capacity. Today’s performance, data integrity, and security requirements are beyond the offerings of older
filesystem implementations, so filesystem technology is constantly changing. We’ve already mentioned Btrfs
as an example of a next-generation filesystem (see 4.2.1 Filesystem Types).
One example of how filesystems are changing is that new filesystems use separate data structures to represent
directories and filenames, rather than the directory inodes described here. They reference data blocks
differently. Also, filesystems that optimize for SSDs are still evolving. Continuous change in the development
of filesystems is the norm, but keep in mind that the evolution of filesystems doesn’t change their purpose.
www.EBooksWorld.ir
Chapter 5. How the Linux Kernel Boots
You now know the physical and logical structure of a Linux system, what the kernel is, and how to work with
processes. This chapter will teach you how the kernel starts— or boots. In other words, you’ll learn how the
kernel moves into memory up to the point where the first user process starts.
A simplified view of the boot process looks like this:
1. The machine’s BIOS or boot firmware loads and runs a boot loader.
2. The boot loader finds the kernel image on disk, loads it into memory, and starts it.
3. The kernel initializes the devices and its drivers.
4. The kernel mounts the root filesystem.
5. The kernel starts a program called init with a process ID of 1. This point is the user space start.
6. init sets the rest of the system processes in motion.
7. At some point, init starts a process allowing you to log in, usually at the end or near the end of the boot.
This chapter covers the first four stages, focusing on the kernel and boot loaders. Chapter 6 continues with the
user space start.
Your ability to identify each stage of the boot process will prove invaluable in fixing boot problems and
understanding the system as a whole. However, the default behavior in many Linux distributions often makes
it difficult, if not impossible, to identify the first few boot stages as they proceed, so you’ll probably be able
to get a good look only after they’ve completed and you log in.
5.1 Startup Messages
Traditional Unix systems produce many diagnostic messages upon boot that tell you about the boot process.
The messages come first from the kernel and then from processes and initialization procedures that init starts.
However, these messages aren’t pretty or consistent, and in some cases they aren’t even very informative.
Most current Linux distributions do their best to hide them with splash screens, filler, and boot options. In
addition, hardware improvements have caused the kernel to start much faster than before; the messages flash
by so quickly, it can be difficult to see what is happening.
There are two ways to view the kernel’s boot and runtime diagnostic messages. You can:
o Look at the kernel system log file. You’ll often find this in /var/log/ kern.log, but depending on how your
system is configured, it might also be lumped together with a lot of other system logs in /var/log/messages
or elsewhere.
o Use the dmesg command, but be sure to pipe the output to less because there will be much more than a
screen’s worth. The dmesg command uses the kernel ring buffer, which is of limited size, but most newer
kernels have a large enough buffer to hold boot messages for a long time.
www.EBooksWorld.ir
Here’s a sample of what you can expect to see from the dmesg command:
$ dmesg
[ 0.000000] Initializing cgroup subsys cpu
[ 0.000000] Linux version 3.2.0-67-generic-pae (buildd@toyol) (gcc
version 4.
6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) ) #101-Ubuntu SMP Tue Jul 15 18:04:54
UTC 2014
(Ubuntu 3.2.0-67.101-generic-pae 3.2.60)
[ 0.000000] KERNEL supported cpus:
--snip--
[ 2.986148] sr0: scsi3-mmc drive: 24x/8x writer dvd-ram cd/rw xa/form2
cdda tray
[ 2.986153] cdrom: Uniform CD-ROM driver Revision: 3.20
[ 2.986316] sr 1:0:0:0: Attached scsi CD-ROM sr0
[ 2.986416] sr 1:0:0:0: Attached scsi generic sg1 type 5
[ 3.007862] sda: sda1 sda2 < sda5 >
[ 3.008658] sd 0:0:0:0: [sda] Attached SCSI disk
--snip--
After the kernel has started, the user-space startup procedure often generates messages. These messages will
likely be more difficult to view and review because on most systems you won’t find them in a single log file.
Startup scripts usually print the messages to the console and they’re erased after the boot process finishes.
However, this usually isn’t a problem because each script typically writes its own log. Some versions of init,
such as Upstart and systemd, can capture diagnostic messages from startup and runtime that would normally
go to the console.
5.2 Kernel Initialization and Boot Options
Upon startup, the Linux kernel initializes in this general order:
1. CPU inspection
2. Memory inspection
3. Device bus discovery
4. Device discovery
5. Auxiliary kernel subsystem setup (networking, and so on)
6. Root filesystem mount
7. User space start
The first steps aren’t too remarkable, but when the kernel gets to devices, a question of dependencies arises.
For example, the disk device drivers may depend on bus support and SCSI subsystem support.
Later in the initialization process, the kernel must mount a root file-system before starting init. In general, you
www.EBooksWorld.ir
won’t have to worry about any of this, except that some necessary components may be loadable kernel
modules rather than part of the main kernel. On some machines, you may need to load these kernel modules
before the true root filesystem is mounted. We’ll cover this problem and its initial RAM filesystem workaround
solutions in 6.8 The Initial RAM Filesystem.
As of this writing, the kernel does not emit specific messages when it’s about to start its first user process.
However, the following memory management messages are a good indication that the user-space handoff is
about to happen because this is where the kernel protects its own memory from user-space processes:
Freeing unused kernel memory: 740k freed
Write protecting the kernel text: 5820k
Write protecting the kernel read-only data: 2376k
NX-protecting the kernel data: 4420k
You may also see a message about the root filesystem being mounted at this point.
NOTE
Feel free to skip ahead to Chapter 6 to learn the specifics of user space start and the init program
that the kernel runs as its first process. The remainder of this chapter details how the kernel starts.
5.3 Kernel Parameters
When running the Linux kernel, the boot loader passes in a set of text-based kernel parameters that tell the
kernel how it should start. The parameters specify many different types of behavior, such as the amount of
diagnostic output the kernel should produce and device driver–specific options.
You can view the kernel parameters from your system’s boot by looking at the /proc/cmdline file:
$ cat /proc/cmdline
BOOT_IMAGE=/boot/vmlinuz-3.2.0-67-generic-pae root=UUID=70ccd6e7-6ae6-
44f6-
812c-51aab8036d29 ro quiet splash vt.handoff=7
The parameters are either simple one-word flags, such as ro and quiet, or key=value pairs, such as
vt.handoff=7. Many of the parameters are unimportant, such as the splash flag for displaying a splash
screen, but one that is critical is the root parameter. This is the location of the root filesystem; without it, the
kernel cannot find init and therefore cannot perform the user space start.
The root filesystem can be specified as a device file, such as in this example:
root=/dev/sda1
However, on most modern desktop systems, a UUID is more common (see 4.2.4 Filesystem UUID):
root=UUID=70ccd6e7-6ae6-44f6-812c-51aab8036d29
The ro parameter is normal; it instructs the kernel to mount the root filesystem in read-only mode upon user
space start. (Read-only mode ensures that fsck can check the root filesystem safely; after the check, the
bootup process remounts the root filesystem in read-write mode.)
Upon encountering a parameter that it does not understand, the Linux kernel saves the parameter. The kernel
later passes the parameter to init when performing the user space start. For example, if you add -s to the
kernel parameters, the kernel passes the -s to the init program to indicate that it should start in single-user
mode.
www.EBooksWorld.ir
Now let’s look at the mechanics of how boot loaders start the kernel.
5.4 Boot Loaders
At the start of the boot process, before the kernel and init start, a boot loader starts the kernel. The task of a
boot loader sounds simple: It loads the kernel into memory, and then starts the kernel with a set of kernel
parameters. But consider the questions that the boot loader must answer:
o Where is the kernel?
o What kernel parameters should be passed to the kernel when it starts?
The answers are (typically) that the kernel and its parameters are usually somewhere on the root filesystem. It
sounds like the kernel parameters should be easy to find, except that the kernel is not yet running, so it can’t
traverse a filesystem to find the necessary files. Worse, the kernel device drivers normally used to access the
disk are also unavailable. Think of this as a kind of “chicken or egg” problem.
Let’s start with the driver concern. On PCs, boot loaders use the Basic Input/Output System (BIOS) or Unified
Extensible Firmware Interface (UEFI) to access disks. Nearly all disk hardware has firmware that allows the
BIOS to access attached storage hardware with Linear Block Addressing (LBA). Although it exhibits poor
performance, this mode of access does allow universal access to disks. Boot loaders are often the only
programs to use the BIOS for disk access; the kernel uses its own high-performance drivers.
The filesystem question is trickier. Most modern boot loaders can read partition tables and have built-in
support for read-only access to filesystems. Thus, they can find and read files. This capability makes it far
easier to dynamically configure and enhance the boot loader. Linux boot loaders have not always had this
capability; without it, configuring the boot loader was more difficult.
5.4.1 Boot Loader Tasks
A Linux boot loader’s core functionality includes the ability to do the following:
o Select among multiple kernels.
o Switch between sets of kernel parameters.
o Allow the user to manually override and edit kernel image names and parameters (for example, to enter
single-user mode).
o Provide support for booting other operating systems.
Boot loaders have become considerably more advanced since the inception of the Linux kernel, with features
such as history and menu systems, but the basic need has always been flexibility in kernel image and parameter
selection. One interesting phenomenon is that certain needs have diminished. For example, because you can
now perform an emergency or recovery boot partially or entirely from a USB storage device, you probably
won’t have to worry about manually entering kernel parameters or going into single-user mode. But modern
boot loaders offer more power than ever, which can be particularly handy if you’re building custom kernels
or just want to tweak parameters.
5.4.2 Boot Loader Overview
Here are the main boot loaders that you may encounter, in order of popularity:
o GRUB. A near-universal standard on Linux systems
o LILO. One of the first Linux boot loaders. ELILO is a UEFI version
o SYSLINUX. Can be configured to run from many different kinds of filesystems
www.EBooksWorld.ir
o LOADLIN. Boots a kernel from MS-DOS
o efilinux. A UEFI boot loader intended to serve as a model and reference for other UEFI boot loaders
o coreboot (formerly LinuxBIOS). A high-performance replacement for the PC BIOS that can include a
kernel
o Linux Kernel EFISTUB. A kernel plugin for loading the kernel directly from the EFI/UEFI System
Partition (ESP) found on recent systems
This book deals exclusively with GRUB. The rationale behind using other boot loaders is either that they are
simpler to configure than GRUB or that they are faster.
To enter a kernel name and parameters, you first need to know how to get to a boot prompt. Unfortunately,
this can sometimes be difficult to figure out because Linux distributions customize boot loader behavior and
appearance to their hearts’ content.
The next sections tell you how to get to a boot prompt in order to enter a kernel name and parameters. Once
you’re comfortable with that, you’ll see how to configure and install a boot loader.
5.5 GRUB Introduction
GRUB stands for Grand Unified Boot Loader. We’ll cover GRUB 2; there is also an older version now called
GRUB Legacy that is slowing falling out of use.
One of GRUB’s most important capabilities is filesystem navigation that allows for much easier kernel image
and configuration selection. One of the best ways to see this in action and to learn about GRUB in general is
to look at its menu. The interface is easy to navigate, but there’s a good chance that you’ve never seen it. Linux
distributions often do their best to hide the boot loader from you.
To access the GRUB menu, press and hold SHIFT when your BIOS or firmware startup screen first appears.
Otherwise, the boot loader configuration may not pause before loading the kernel. Figure 5-1 shows the GRUB
menu. Press ESC to temporarily disable the automatic boot timeout after the GRUB menu appears.
www.EBooksWorld.ir
Figure 5-1. GRUB menu
Try the following to explore the boot loader:
1. Reboot or power on your Linux system.
2. Hold down SHIFT during the BIOS/Firmware self-test and/or splash screen to get the GRUB menu.
3. Press e to view the boot loader configuration commands for the default boot option. You should see
something like Figure 5-2.
Figure 5-2. GRUB configuration editor
This screen tells us that for this configuration, the root is set with a UUID, the kernel image is /boot/vmlinuz-
3.2.0-31-generic-pae, and the kernel parameters include ro, quiet, and splash. The initial RAM
filesystem is /boot/initrd.img-3.2.0-31-generic-pae. But if you’ve never seen this sort of configuration before,
you may find it somewhat confusing. Why are there multiple references to root, and why are they different?
Why is insmod here? Isn’t that a Linux kernel feature normally run by udevd?
The double-takes are warranted, because GRUB doesn’t really use the Linux kernel—it starts it. The
configuration you see consists wholly of GRUB internal commands. GRUB really is an entirely separate world.
The confusion stems from the fact that GRUB borrows terminology from many sources. GRUB has its own
“kernel” and its own insmod command to dynamically load GRUB modules, completely independent of the
Linux kernel. Many GRUB commands are similar to Unix shell commands; there’s even an ls command to
list files.
But the most confusion comes from the use of the word root. To clear it up, there is one simple rule to follow
when you’re looking for your system’s root filesystem: Only the root kernel parameter will be the root
filesystem when you boot your system.
In the GRUB configuration, that kernel parameter is somewhere after the image name of the linux command.
Every other reference to root in the configuration is to the GRUB root, which exists only inside of GRUB.
The GRUB “root” is the filesystem where GRUB searches for kernel and RAM filesystem image files.
www.EBooksWorld.ir
In Figure 5-2, the GRUB root is first set to a GRUB-specific device (hd0,msdos1). Then in the following
command, GRUB searches for a particular UUID on a partition. If it finds that UUID, it sets the GRUB root
to that partition.
To wrap things up, the linux command’s first argument (/boot/vmlinuz-...) is the location of the
Linux kernel image file. GRUB loads this file from the GRUB root. The initrd command is similar,
specifying the file for the initial RAM filesystem.
You can edit this configuration inside GRUB; doing so is usually the easiest way to temporarily fix an
erroneous boot. To permanently fix a boot problem, you’ll need to change the configuration (see 5.5.2 GRUB
Configuration), but for now, let’s go one step deeper and examine some GRUB internals with the command-
line interface.
5.5.1 Exploring Devices and Partitions with the GRUB Command Line
As you can see in Figure 5-2, GRUB has its own device-addressing scheme. For example, the first hard disk
found is hd0, followed by hd1, and so on. But device assignments are subject to change. Fortunately, GRUB
can search all partitions for a UUID in order to find the one where the kernel resides, as you just saw with the
search command.
Listing Devices
To get a feel for how GRUB refers to the devices on your system, access the GRUB command line by pressing
C at the boot menu or configuration editor. You should get the GRUB prompt:
grub>
You can enter any command here that you see in a configuration, but to get started, try a diagnostic command
instead: ls. With no arguments, the output is a list of devices known to GRUB:
grub> ls
(hd0) (hd0,msdos1) (hd0,msdos5)
In this case, there is one main disk device denoted by (hd0) and the partitions (hd0,msdos1) and (hd0,msdos5).
The msdos prefix on the partitions tells you that the disk contains an MBR partition table; it would begin with
gpt for GPT. (You will find even deeper combinations with a third identifier, where a BSD disklabel map
resides inside a partition, but you won’t normally have to worry about this unless you’re running multiple
operating systems on one machine.)
To get more detailed information, use ls -l. This command can be particularly useful because it displays
any UUIDs of the partitions on the disk. For example:
grub> ls -l
Device hd0: Not a known filesystem - Total size 426743808 sectors
Partition hd0,msdos1: Filesystem type ext2 – Last modification
time
2015-09-18 20:45:00 Friday, UUID 4898e145-b064-45bd-b7b4-
7326b00273b7 -
Partition start at 2048 - Total size 424644608 sectors
Partition hd0,msdos5: Not a known filesystem - Partition start at
424648704 - Total size 2093056 sectors
This particular disk has a Linux ext2/3/4 filesystem on the first MBR partition and a Linux swap signature on
www.EBooksWorld.ir
partition 5, which is a fairly common configuration. (You can’t tell that (hd0,msdos5) is a swap partition from
this output, though.)
File Navigation
Now let’s look at GRUB’s filesystem navigation capabilities. Determine the GRUB root with the echo
command (recall that this is where GRUB expects to find the kernel):
grub> echo $root
hd0,msdos1
To use GRUB’s ls command to list the files and directories in that root, you can append a forward slash to
the end of the partition:
grub> ls (hd0,msdos1)/
But it’s a pain to remember and type the actual root partition, so use the root variable to save yourself some
time:
grub> ls ($root)/
The output is a short list of file and directory names on that partition’s filesystem, such as etc/, bin/, and dev/.
You should realize that this is now a completely different function of the GRUB ls: Before, you were listing
devices, partition tables, and perhaps some filesystem header information. Now you’re actually looking at the
contents of filesystems.
You can take a deeper look into the files and directories on a partition in a similar manner. For example, to
inspect the /boot directory, start with the following:
grub> ls ($root)/boot
NOTE
Use the up and down arrow keys to flip through GRUB command history and the left and right
arrows to edit the current command line. The standard readline keys (CTRL-N, CTRL-P, and so
on) also work.
You can also view all currently set GRUB variables with the set command:
grub> set
?=0
color_highlight=black/white
color_normal=white/black
--snip--
prefix=(hd0,msdos1)/boot/grub
root=hd0,msdos1
One of the most important of these variables is $prefix, the filesystem and directory where GRUB expects
to find its configuration and auxiliary support. We’ll explore this in the next section.
Once you’ve finished with the GRUB command-line interface, enter the boot command to boot your current
configuration or just press ESC to return to the GRUB menu. In any case, boot your system; we’re going to
explore the GRUB configuration, and that’s best done when you have your full system available.
www.EBooksWorld.ir
5.5.2 GRUB Configuration
The GRUB configuration directory contains the central configuration file (grub.cfg) and numerous loadable
modules with a .mod suffix. (As GRUB versions progress, these modules will move into subdirectories such
as i386-pc.) The directory is usually /boot/grub or /boot/grub2. We won’t modify grub.cfg directly; instead,
we’ll use the grub-mkconfig command (or grub2-mkconfig on Fedora).
Reviewing Grub.cfg
First, take a quick look at grub.cfg to see how GRUB initializes its menu and kernel options. You’ll see that
the grub.cfg file consists of GRUB commands, which usually begin with a number of initialization steps
followed by a series of menu entries for different kernel and boot configurations. The initialization isn’t
complicated; it’s a bunch of function definitions and video setup commands like this:
if loadfont /usr/share/grub/unicode.pf2 ; then
set gfxmode=auto
load_video
insmod gfxterm
--snip--
Later in this file you should see the available boot configurations, each beginning with the menuentry
command. You should be able to read and understand this example based on what you learned in the preceding
section:
menuentry 'Ubuntu, with Linux 3.2.0-34-generic-pae' --class ubuntu --
class gnu-linux --class gnu
--class os {
recordfail
gfxmode $linux_gfx_mode
insmod gzio
insmod part_msdos
insmod ext2
set root='(hd0,msdos1)'
search --no-floppy --fs-uuid --set=root 70ccd6e7-6ae6-44f6-812c-
51aab8036d29
linux /boot/vmlinuz-3.2.0-34-generic-pae root=UUID=70ccd6e7-
6ae6-44f6-812c-51aab8036d29
ro quiet splash $vt_handoff
initrd /boot/initrd.img-3.2.0-34-generic-pae
}
Watch for submenu commands. If your grub.cfg file contains numerous menuentry commands, most of
them are probably wrapped up inside a submenu command for older versions of the kernel so that they don’t
crowd the GRUB menu.
www.EBooksWorld.ir
Generating a New Configuration File
If you want to make changes to your GRUB configuration, you won’t edit your grub.cfg file directly because
it’s automatically generated and the system occasionally overwrites it. You’ll add your new configuration
elsewhere, then run grub-mkconfig to generate the new configuration.
To see how the configuration generation works, look at the very beginning of grub.cfg. There should be
comment lines such as this:
### BEGIN /etc/grub.d/00_header ###
Upon further inspection, you’ll find that every file in /etc/grub.d is a shell script that produces a piece of the
grub.cfg file. The grub-mkconfig command itself is a shell script that runs everything in /etc/grub.d.
Try it yourself as root. (Don’t worry about overwriting your current configuration. This command by itself
simply prints the configuration to the standard output.)
# grub-mkconfig
What if you want to add menu entries and other commands to the GRUB configuration? The short answer is
that you should put your customizations into a new custom.cfg file in your GRUB configuration directory,
such as /boot/grub/custom.cfg.
The long answer is a little more complicated. The /etc/grub.d configuration directory gives you two options:
40_custom and 41_custom. The first, 40_custom, is a script that you can edit yourself, but it’s probably the
least stable; a package upgrade is likely to destroy any changes you make. The 41_custom script is simpler;
it’s just a series of commands that load custom.cfg when GRUB starts. (Keep in mind that if you choose this
second option, your changes won’t appear when you generate your configuration file.)
The two options for custom configuration files aren’t particularly extensive. You’ll see additions in your
particular distribution’s /etc/grub.d directory. For example, Ubuntu adds memory tester boot options
(memtest86+) to the configuration.
To write and install a newly generated GRUB configuration file, you can write the configuration to your
GRUB directory with the -o option to grub-mkconfig, like this:
# grub-mkconfig -o /boot/grub/grub.cfg
Or if you’re an Ubuntu user, just run install-grub. In any case, back up your old configuration, make
sure that you’re installing to the correct directory, and so on.
Now we’re going to get into some of the more technical details of GRUB and boot loaders. If you’re tired of
hearing about boot loaders and the kernel, feel free to skip to Chapter 6.
5.5.3 GRUB Installation
Installing GRUB is more involved than configuring it. Fortunately, you won’t normally have to worry about
installation because your distribution should handle it for you. However, if you’re trying to duplicate or restore
a bootable disk, or preparing your own boot sequence, you might need to install it on your own.
Before proceeding, read 5.8.3 How GRUB Works to get an idea of how PCs boot and determine whether
you’re using MBR or EFI boot. Next, build the GRUB software set and determine where your GRUB directory
will be; the default is /boot/grub. You may not need to build GRUB if your distribution does it for you, but if
you do, see Chapter 16 for how to build software from source code. Make sure that you build the correct target:
It’s different for MBR or UEFI boot (and there are even differences between 32-bit and 64-bit EFI).
Installing GRUB on Your System
Installing the boot loader requires that you or an installer determine the following:
www.EBooksWorld.ir
o The target GRUB directory as seen by your currently running system. That’s usually /boot/grub, but it
might be different if you’re installing GRUB on another disk for use on another system.
o The current device of the GRUB target disk.
o For UEFI booting, the current mount point of the UEFI boot partition.
Remember that GRUB is a modular system, but in order to load modules, it must read the filesystem that
contains the GRUB directory. Your task is to construct a version of GRUB capable of reading that filesystem
so that it can load the rest of its configuration (grub.cfg) and any required modules. On Linux, this usually
means building a version of GRUB with its ext2.mod module preloaded. Once you have this version, all you
need to do is place it on the bootable part of the disk and place the rest of the required files into /boot/grub.
Fortunately, GRUB comes with a utility called grub-install (not to be confused with Ubuntu’s
install-grub), which performs most of the work of installing the GRUB files and configuration for you.
For example, if your current disk is at /dev/sda and you want to install GRUB on that disk with your current
/boot/grub directory, use this command to install GRUB on the MBR:
# grub-install /dev/sda
WARNING
Incorrectly installing GRUB may break the bootup sequence on your system, so don’t take this
command lightly. If you’re concerned, read up on how to back up your MBR with dd, back up any
other currently installed GRUB directory, and make sure that you have an emergency bootup plan.
Installing GRUB on an External Storage Device
To install GRUB on a storage device outside the current system, you must manually specify the GRUB
directory on that device as your current system now sees it. For example, say that you have a target device of
/dev/sdc and that device’s root/boot filesystem (for example, /dev/sdc1) is mounted on /mnt of your current
system. This implies that when you install GRUB, your current system will see the GRUB files in
/mnt/boot/grub. When running grub-install, tell it where those files should go as follows:
# grub-install --boot-directory=/mnt/boot /dev/sdc
Installing GRUB with UEFI
UEFI installation is supposed to be easier, because you all you need to do is copy the boot loader into place.
But you also need to “announce” the boot loader to the firmware with the efibootmgr command. The
grub-install command runs this if it’s available, so in theory all you need to do to install on an UEFI
partition is the following:
# grub-install --efi-directory=efi_dir –-bootloader-id=name
Here, efi_dir is where the UEFI directory appears on your current system (usually /boot/efi/efi, because
the UEFI partition is often mounted at /boot/efi) and name is an identifier for the boot loader, as described in
5.8.2 UEFI Boot.
Unfortunately, many problems can crop up when installing a UEFI boot loader. For example, if you’re
installing to a disk that will eventually end up in another system, you have to figure out how to announce that
boot loader to the new system’s firmware. And there are differences in the install procedure for removable
media.
But one of the biggest problems is UEFI secure boot.
www.EBooksWorld.ir
5.6 UEFI Secure Boot Problems
One of the newest problems affecting Linux installations is the secure boot feature found on recent PCs. When
active, this mechanism in UEFI requires boot loaders to be digitally signed by a trusted authority in order to
run. Microsoft has required vendors shipping Windows 8 to use secure boot. The result is that if you try to
install an unsigned boot loader (which is most current Linux distributions), it will not load.
The easiest way around this for anyone with no interest in Windows is to disable secure boot in the EFI settings.
However, this won’t work cleanly for dual-boot systems and may not be an option for all users. Therefore,
Linux distributions are offering signed boot loaders. Some solutions are just front-ends to GRUB, some offer
a fully signed loading sequence (from the boot loader to the kernel), and others are entirely new boot loaders
(some based on efilinux).
5.7 Chainloading Other Operating Systems
UEFI makes it relatively easy to support loading other operating systems because you can install multiple boot
loaders in the EFI partition. However, the older MBR style doesn’t support it, and even if you do have UEFI,
you may still have an individual partition with an MBR-style boot loader that you want to use. You can get
GRUB to load and run a different boot loader on a specific partition on your disk by chainloading.
To chainload, create a new menu entry in your GRUB configuration (using one of the methods in Reviewing
Grub.cfg). Here’s an example for a Windows installation on the third partition of a disk:
menuentry "Windows" {
insmod chain
insmod ntfs
set root=(hd0,3)
chainloader +1
}
The +1 option to chainloader tells it to load whatever is at the first sector of a partition. You can also get
it to directly load a file by using a line like this to load the io.sys MS-DOS loader:
menuentry "DOS" {
insmod chain
insmod fat
set root=(hd0,3)
chainloader /io.sys
}
5.8 Boot Loader Details
Now we’ll look quickly at some boot loader internals. Feel free to skip to the next chapter if this material
doesn’t interest you.
To understand how boot loaders like GRUB work, let’s first survey how a PC boots when you turn it on. Due
to the repeated inadequacies of traditional PC boot mechanisms, there are several variations, but there are two
main schemes: MBR and UEFI.
www.EBooksWorld.ir
5.8.1 MBR Boot
In addition to the partition information described in 4.1 Partitioning Disk Devices, the Master Boot Record
(MBR) includes a small area (441 bytes) that the PC BIOS loads and executes after its Power-On Self-Test
(POST). Unfortunately, this is too little storage to house almost any boot loader, so additional space is
necessary, resulting in what is sometimes called a multi-stage boot loader. In this case the initial piece of code
in the MBR does nothing other than load the rest of the boot loader code. The remaining pieces of the boot
loader are usually stuffed into the space between the MBR and the first partition on the disk.
Of course, this isn’t terribly secure because anything can overwrite the code there, but most boot loaders do
it, including most GRUB installations. In addition, this scheme won’t work with a GPT-partitioned disk using
the BIOS to boot because the GPT table information resides in the area after the MBR. (GPT leaves the
traditional MBR alone for backward compatibility.)
The workaround for GPT is to create a small partition called a BIOS boot partition with a special UUID to
give the full boot loader code a place to reside. But GPT is normally used with UEFI, not the traditional BIOS,
which leads us to the UEFI boot scheme.
5.8.2 UEFI Boot
PC manufacturers and software companies realized that the traditional PC BIOS is severely limited, so they
decided to develop a replacement called Extensible Firmware Interface (EFI). EFI took a while to catch on
for most PCs, but now it’s fairly common. The current standard is Unified EFI (UEFI), which includes features
such as a built-in shell and the ability to read partition tables and navigate filesystems. The GPT partitioning
scheme is part of the UEFI standard.
Booting is radically different on UEFI systems and, for the most part, much easier to understand. Rather than
executable boot code residing outside of a filesystem, there is always a special filesystem called the EFI System
Partition (ESP), which contains a directory named efi. Each boot loader has its own identifier and a
corresponding subdirectory, such as efi/microsoft, efi/apple, or efi/grub. A boot loader file has an .efi extension
and resides in one of these subdirectories, along with other supporting files.
NOTE
The ESP differs from the BIOS boot partition described in 5.8.1 MBR Boot and has a different
UUID.
There’s a wrinkle, though: You can’t just put old boot loader code into the ESP because that code was written
for the BIOS interface. Instead, you must provide a boot loader written for UEFI. For example, when using
GRUB, you have to install the UEFI version of GRUB rather than the BIOS version. In addition, you must
“announce” new boot loaders to the firmware.
And, as mentioned in 5.6 UEFI Secure Boot Problems, we have the “secure boot” issue.
5.8.3 How GRUB Works
Let’s wrap up our discussion of GRUB by looking at how it does its work:
1. The PC BIOS or firmware initializes the hardware and searches its boot-order storage devices for boot
code.
2. Upon finding the boot code, the BIOS/firmware loads and executes it. This is where GRUB begins.
3. The GRUB core loads.
4. The core initializes. At this point, GRUB can now access disks and filesystems.
5. GRUB identifies its boot partition and loads a configuration there.
6. GRUB gives the user a chance to change the configuration.
www.EBooksWorld.ir
7. After a timeout or user action, GRUB executes the configuration (the sequence of commands outlined in
5.5.2 GRUB Configuration).
8. In the course of executing the configuration, GRUB may load additional code (modules) in the boot
partition.
9. GRUB executes a boot command to load and execute the kernel as specified by the configuration’s
linux command.
Steps 3 and 4 of the preceding sequence, where the GRUB core loads, can be complicated due to the repeated
inadequacies of traditional PC boot mechanisms. The biggest question is “Where is the GRUB core?” There
are three basic possibilities:
o Partially stuffed between the MBR and the beginning of the first partition
o In a regular partition
o In a special boot partition: a GPT boot partition, EFI System Partition (ESP), or elsewhere
In all cases except where you have an ESP, the PC BIOS loads 512 bytes from the MBR, and that is where
GRUB starts. This little piece (derived from boot.img in the GRUB directory) isn’t yet the core, but it contains
the start location of the core and loads the core from this point.
However, if you have an ESP, the GRUB core goes there as a file. The firmware can navigate the ESP and
directly execute the GRUB core or any other operating system loader located there.
Still, on most systems, this is not the complete picture. The boot loader might also need to load an initial RAM
filesystem image into memory before loading and executing the kernel. That’s what the initrd configuration
parameter in 6.8 The Initial RAM Filesystem specifies. But before you learn about the initial RAM filesystem,
you should learn about the user space start—that’s where the next chapter begins.
www.EBooksWorld.ir
Chapter 6. How User Space Starts
The point where the kernel starts its first user-space process, init, is significant—not just because that’s where
the memory and CPU are finally ready for normal system operation, but because that’s where you can see how
the rest of the system builds up as a whole. Prior to this point, the kernel executes a well-controlled path of
execution defined by a relatively small number of software developers. User space is far more modular. It’s
much easier to see what goes into the user space startup and operation. For the adventurous, it’s also relatively
easy to change the user space startup because doing so requires no low-level programming.
User space starts in roughly this order:
1. init
2. Essential low-level services such as udevd and syslogd
3. Network configuration
4. Mid- and high-level services (cron, printing, and so on)
5. Login prompts, GUIs, and other high-level applications
6.1 Introduction to init
The init program is a user-space program like any other program on the Linux system, and you’ll find it in
/sbin along with many of the other system binaries. Its main purpose is to start and stop the essential service
processes on the system, but newer versions have more responsibilities.
There are three major implementations of init in Linux distributions:
o System V init. A traditional sequenced init (Sys V, usually pronounced “sys-five”). Red Hat Enterprise
Linux and several other distributions use this version.
o systemd. The emerging standard for init. Many distributions have moved to systemd, and most that have
not yet done so are planning to move to it.
o Upstart. The init on Ubuntu installations. However, as of this writing, Ubuntu has also planned to migrate
to systemd.
There are various other versions of init as well, especially on embedded platforms. For example, Android has
its own init. The BSDs also have their version of init, but you are unlikely to see them on a modern Linux
machine. (Some distributions have also modified the System V init configuration to resemble the BSD style.)
There are many different implementations of init because System V init and other older versions relied on a
sequence that performed only one startup task at a time. Under this scheme, it is relatively easy to resolve
dependencies. However, performance isn’t terribly good, because two parts of the boot sequence cannot
normally run at once. Another limitation is that you can only start a fixed set of services as defined by the boot
sequence: When you plug in new hardware or need a service that isn’t already running, there is no standardized
www.EBooksWorld.ir
way to coordinate the new components with init. systemd and Upstart attempt to remedy the performance
issue by allowing many services to start in parallel thereby speeding up the boot process. Their
implementations are quite different, though:
o systemd is goal oriented. You define a target that you want to achieve, along with its dependencies, and
when you want to reach the target. systemd satisfies the dependencies and resolves the target. systemd can
also defer the start of a service until it is absolutely needed.
o Upstart is reactionary. It receives events and, based on those events, runs jobs that can in turn produce more
events, causing Upstart to run more jobs, and so on.
The systemd and Upstart init systems also offer a more advanced way to start and track services. In traditional
init systems, service daemons are expected to start themselves from scripts. A script runs a daemon program,
which detaches itself from the script and runs autonomously. To find the PID of a service daemon, you need
to use ps or some other mechanism specific to the service. In contrast, Upstart and systemd can manage
individual service daemons from the beginning, giving the user more power and insight into exactly what is
running on the system.
Because the new init systems are not script-centric, configuring services for them also tends to be easier. In
particular, System V init scripts tend to contain many similar commands designed to start, stop, and restart
services. You don’t need all of this redundancy with systemd and Upstart, which allow you to concentrate on
the services themselves, rather than their scripts.
Finally, systemd and Upstart both offer some level of on-demand services. Rather than trying to start all the
services that may be necessary at boot time (as the System V init would do), they start some services only
when needed. This idea is not really new; this was done with the traditional inetd daemon, but the new
implementations are more sophisticated.
Both systemd and Upstart offer some System V backward compatibility. For example, both support the
concept of runlevels.
6.2 System V Runlevels
At any given time on a Linux system, a certain base set of processes (such as crond and udevd) is running.
In System V init, this state of the machine is called its runlevel, which is denoted by a number from 0 through
6. A system spends most of its time in a single runlevel, but when you shut the machine down, init switches
to a different runlevel in order to terminate the system services in an orderly fashion and to tell the kernel to
stop.
You can check your system’s runlevel with the who -r command. A system running Upstart responds with
something like this:
$ who -r
run-level 2 2015-09-06 08:37
This output tells us that the current runlevel is 2, as well as the date and time that the runlevel was established.
Runlevels serve various purposes, but the most common one is to distinguish between system startup,
shutdown, single-user mode, and console mode states. For example, Fedora-based systems traditionally used
runlevels 2 through 4 for the text console; a runlevel of 5 means that the system will start a GUI login.
But runlevels are becoming a thing of the past. Even though all three init versions in this book support them,
systemd and Upstart consider runlevels obsolete as end states for the system. To systemd and Upstart, runlevels
exist primarily to start services that support only the System V init scripts, and the implementations are so
different that even if you’re familiar with one type of init, you won’t necessarily know what to do with another.
www.EBooksWorld.ir
6.3 Identifying Your init
Before proceeding, you need to determine your system’s version of init. If you’re not sure, check your system
as follows:
o If your system has /usr/lib/systemd and /etc/systemd directories, you have systemd. Go to 6.4 systemd.
o If you have an /etc/init directory that contains several .conf files, you’re probably running Upstart (unless
you’re running Debian 7, in which case you probably have System V init). Go to 6.5 Upstart.
o If neither of the above is true, but you have an /etc/inittab file, you’re probably running System V init. Go
to 6.6 System V init.
If your system has manual pages installed, viewing the init(8) manual page should help identify your version.
6.4 systemd
The systemd init is one of the newest init implementations on Linux. In addition to handling the regular boot
process, systemd aims to incorporate a number of standard Unix services such as cron and inetd. As such,
it takes some inspiration from Apple’s launchd. One of its most significant features is its ability to defer the
start of services and operating system features until they are necessary.
There are so many systemd features that it can be very difficult to know where to start learning the basics.
Let’s outline what happens when systemd runs at boot time:
1. systemd loads its configuration.
2. systemd determines its boot goal, which is usually named default.target.
3. systemd determines all of the dependencies of the default boot goal, dependencies of these dependencies,
and so on.
4. systemd activates the dependencies and the boot goal.
5. After boot, systemd can react to system events (such as uevents) and activate additional components.
When starting services, systemd does not follow a rigid sequence. As with other modern init systems, there is
a considerable amount of flexibility in the systemd bootup process. Most systemd configurations deliberately
try to avoid any kind of startup sequence, preferring to use other methods to resolve strict dependencies.
6.4.1 Units and Unit Types
One of the most interesting things about systemd is that it does not just operate processes and services; it can
also mount filesystems, monitor network sockets, run timers, and more. Each type of capability is called a unit
type, and each specific capability is called a unit. When you turn on a unit, you activate it.
Rather than describe all of the unit types (you’ll find them in the systemd(1) manual page), here’s a look at a
few of the unit types that perform the boot-time tasks required in any Unix system:
o Service units. Control the traditional service daemons on a Unix system.
o Mount units. Control the attachment of filesystems to the system.
o Target units. Control other units, usually by grouping them.
The default boot goal is usually a target unit that groups together a number of service and mount units as
dependencies. As a result, it’s easy to get a partial picture of what’s going to happen when you boot, and you
can even create a dependency tree diagram with the systemctl dot command. You’ll find the tree to be
quite large on a typical system, because many units don’t run by default.
Figure 6-1 shows a part of the dependency tree for the default.target unit found on a Fedora system. When
www.EBooksWorld.ir
you activate that unit, all of the units below it on the tree also activate.
Figure 6-1. Unit dependency tree
6.4.2 systemd Dependencies
Boot-time and operational dependencies are more complicated than they may seem at first because strict
dependencies are too inflexible. For example, imagine a scenario in which you want to display a login prompt
after starting a database server, so you define a dependency from the login prompt to the database server.
However, if the database server fails, the login prompt will also fail due to that dependency, and you won’t
even be able to log in to your machine to fix it.
Unix boot-time tasks are fairly fault tolerant and can often fail without causing serious problems for standard
services. For example, if a data disk for a system was removed but its /etc/fstab entry remained, the initial file-
system mount would fail. However, that failure typically wouldn’t seriously affect standard operating system
operation.
To accommodate the need for flexibility and fault tolerance, systemd offers a myriad of dependency types and
styles. We’ll label them by their keyword syntax, and but we won’t go into details about configuration syntax
until 6.4.3 systemd Configuration. Let’s first look at the basic types:
o Requires Strict dependencies. When activating a unit with a Requires dependency unit, systemd attempts to
activate the dependency unit. If the dependency unit fails, systemd deactivates the dependent unit.
o Wants. Dependencies for activation only. Upon activating a unit, systemd activates the unit’s Wants
dependencies, but it doesn’t care if those dependencies fail.
o Requisite. Units that must already be active. Before activating a unit with a Requisite dependency, systemd
first checks the status of the dependency. If the dependency has not been activated, systemd fails on
activation of the unit with the dependency.
o Conflicts. Negative dependencies. When activating a unit with a Conflict dependency, systemd
automatically deactivates the dependency if it is active. Simultaneous activation of two conflicting units
fails.
www.EBooksWorld.ir
NOTE
The Wants dependency type is especially significant because it does not propagate failures to
other units. The systemd documentation states that this is the way you should specify
dependencies if possible, and it’s easy to see why. This behavior produces a much more robust
system, similar to that of a traditional init.
You can also attach dependencies “in reverse.” For example, in order to add Unit A as a Wants dependency to
Unit B, you don’t have to add the Wants in Unit B’s configuration. Instead, you can install it as a WantedBy
in Unit A’s configuration. The same is true of the RequiredBy dependency. The configuration for (and result
of) a “By” dependency is slightly more involved than just editing a configuration file; see Enabling Units and
the [Install] Section
You can view a unit’s dependencies with the systemctl command, as long as you specify a type of
dependency, such as Wants or Requires:
# systemctl show -p type unit
Ordering
None of the dependency syntax that you’ve seen so far explicitly specifies order. By default, activating a unit
with a Requires or Wants causes systemd to activate all of these dependencies at the same time as the first unit.
This is optimal, because you want to start as many services as possible as quickly as possible to reduce boot
time. However, there are situations when one unit must start after another. For instance, in the system that
Figure 6-1 is based on, the default.target unit is set to start after multi-user.service (this order distinction is not
shown in the figure).
To activate units in a particular order, you can use the following dependency modifiers:
o Before. The current unit will activate before the listed unit(s). For example, if Before=bar.target appears in
foo.target, systemd activates foo.target before bar.target.
o After. The current unit activates after the listed unit(s).
Conditional Dependencies
Several dependency condition keywords operate on various operation system states rather than systemd units.
For example:
o ConditionPathExists=p: True if the (file) path p exists in the system.
o ConditionPathIsDirectory=p: True if p is a directory.
o ConditionFileNotEmpty=p: True if p is a file and it’s not zero-length.
If a conditional dependency in a unit is false when systemd tries to activate the unit, the unit does not activate,
though this applies only to the unit in which it appears. Therefore, if you activate a unit that has a condition
dependency as well as some other unit dependencies, systemd attempts to activate the unit dependencies
regardless of whether the condition is true or false.
Other dependencies are primarily variations on the preceding. For example, the RequiresOverridable
dependency is just like Requires when running normally, but it acts like a Wants dependency if a unit is
manually activated. (For a full list, see the systemd.unit(5) manual page.)
Now that you’ve seen some of the a few pieces of the systemd configuration, let’s look at some actual unit
files and how to work with them.
6.4.3 systemd Configuration
The systemd configuration files are spread among many directories across the system, so you typically won’t
www.EBooksWorld.ir
find the files for all of the units on a system in one place. That said, there are two main directories for systemd
configuration: the system unit directory (globally configured, usually /usr/lib/systemd/system) and a system
configuration directory (local definitions, usually /etc/systemd/system).
To prevent confusion, stick to this rule: Avoid making changes to the system unit directory because your
distribution will maintain it for you. Make your local changes to the system configuration directory. So when
given the choice between modifying something in /usr and /etc, always change /etc.
NOTE
You can check the current systemd configuration search path (including precedence) with this
command:
# systemctl -p UnitPath show
However, this particular setting comes from a third source: pkg-config settings. To see the system unit and
configuration directories on your system, use the following commands:
$ pkg-config systemd –-variable=systemdsystemunitdir
$ pkg-config systemd --variable=systemdsystemconfdir
Unit Files
Unit files are derived from the XDG Desktop Entry Specification (for .desktop files, which are very similar
to .ini files on Microsoft systems), with section names in brackets ([]) and variable and value assignments
(options) in each section.
Consider the example unit file media.mount in /usr/lib/systemd/system, which is standard on Fedora
installations. This file represents the /media tmpfs filesystem, which is a container directory for mounting
removable media.
[Unit]
Description=Media Directory
Before=local-fs.target
[Mount]
What=tmpfs
Where=/media
Type=tmpfs
Options=mode=755,nosuid,nodev,noexec
There are two sections here. The [Unit] section gives some details about the unit and contains description
and dependency information. In particular, this unit is set to activate before the local-fs.target unit.
The [Mount] section details the unit as being a mount unit, and it gives the details on the mount point, the
type of filesystem, and the mount options as described in 4.2.6 Filesystem Mount Options. The What=
variable identifies the device or UUID of the device to mount. Here, it’s set to tmpfs because this filesystem
does not have a device. (For a full list of mount unit options, see the systemd.mount(5) manual page.)
Many other unit configuration files are similarly straightforward. For example, the service unit file
sshd.service enables secure shell logins:
[Unit]
www.EBooksWorld.ir
Description=OpenSSH server daemon
After=syslog.target network.target auditd.service
[Service]
EnvironmentFile=/etc/sysconfig/sshd
ExecStartPre=/usr/sbin/sshd-keygen
ExecStart=/usr/sbin/sshd -D $OPTIONS
ExecReload=/bin/kill -HUP $MAINPID
[Install]
WantedBy=multi-user.target
Because this is a service target, you’ll find the details about the service in the [Service] section, including
how to prepare, start, and reload the service. You’ll find a complete listing in the systemd.service(5) manual
page (and in systemd.exec(5)), as well as in the discussion of process tracking in 6.4.6 systemd Process
Tracking and Synchronization.
Enabling Units and the [Install] Section
The [Install] section in the sshd.service unit file is important because it helps us to understand how to
use systemd’s WantedBy and RequiredBy dependency options. It’s actually a mechanism for enabling units
without modifying any configuration files. During normal operation, systemd ignores the [Install]
section. However, consider the case when sshd.service is disabled on your system and you would like to turn
it on. When you enable a unit, systemd reads the [Install] section; in this case, enabling the sshd.service
unit causes systemd to see the WantedBy dependency for multi-user.target. In response, systemd creates a
symbolic link to sshd.service in the system configuration directory as follows:
ln -s '/usr/lib/systemd/system/sshd.service'
'/etc/systemd/system/multi-user.
target.wants/sshd.service'
Notice that the symbolic link is placed into a subdirectory corresponding to the dependent unit (multi-
user.target in this case).
The [Install] section is usually responsible for the the .wants and .requires directories in the system
configuration directory (/etc/systemd/system). However, there are also .wants directories in the unit
configuration directory (/usr/lib/systemd/system), and you may also add links that don’t correspond to
[Install] sections in the unit files. These manual additions are a simple way to add a dependency without
modifying a unit file that may be overwritten in the future (by a software upgrade, for instance).
NOTE
Enabling a unit is different from activating a unit. When you enable a unit, you are installing it into
systemd’s configuration, making semipermanent changes that will survive a reboot. But you don’t
always need to explicitly enable a unit. If the unit file has an [Install] section, you must enable
it with systemctl enable; otherwise, the existence of the file is enough to enable it. When you
activate a unit with systemctl start, you’re just turning it on in the current runtime environment.
In addition, enabling a unit does not activate it.
www.EBooksWorld.ir
Variables and Specifiers
The sshd.service unit file also shows use of variables—specifically, the $OPTIONS and $MAINPID
environment variables that are passed in by systemd. $OPTIONS are options that you can pass to sshd when
you activate the unit with systemctl, and $MAINPID is the tracked process of the service (see 6.4.6
systemd Process Tracking and Synchronization).
A specifier is another variable-like feature often found in unit files. Specifiers start with a percent (%). For
example, the %n specifier is the current unit name, and the %H specifier is the current hostname.
NOTE
The unit name can contain some interesting specifiers. You can parameterize a single unit file in
order to spawn multiple copies of a service, such as getty processes running on tty1, tty2, and
so on. To use these specifiers, add the @ symbol to the end of the unit name. For getty, create a
unit file named getty@.service, which allows you to refer to units such as getty@tty1 and
getty@tty2. Anything after the @ is called the instance, and when processing the unit file, systemd
expands the %I specifier to the instance. You can see this in action with the getty@.service unit
files that come with most distributions running systemd.
6.4.4 systemd Operation
You’ll interact with systemd primarily through the systemctl command, which allows you to activate and
deactivate services, list status, reload the configuration, and much more.
The most essential basic commands deal with obtaining unit information. For example, to view a list of active
units on your system, issue a list-units command. (This is actually the default command for
systemctl, so you don’t really need the list-units part.):
$ systemctl list-units
The output format is typical of a Unix information-listing command. For example, the header and the line for
media.mount would look like this:
UNIT LOAD ACTIVE SUB JOB DESCRIPTION
media.mount loaded active mounted Media Directory
This command produces a lot of output, because a typical system has numerous active units, but it will still be
abridged because systemctl truncates any really large unit names. To see the full names of the units, use
the --full option, and to see all units (not just active), use the --all option.
A particularly useful systemctl operation is getting the status of a unit. For example, here is a typical status
command and its output:
$ systemctl status media.mount
media.mount - Media Directory
Loaded: loaded (/usr/lib/systemd/system/media.mount; static)
Active: active (mounted) since Wed, 13 May 2015 11:14:55 -0800;
37min ago
Where: /media
What: tmpfs
Process: 331 ExecMount=/bin/mount tmpfs /media -t tmpfs -o
www.EBooksWorld.ir
mode=755,nosuid,nodev,noexec (code=exited, status=0/SUCCESS)
CGroup: name=systemd:/system/media.mount
Notice that there is much more information output here than you would see on any traditional init system. You
get not only the state of the unit but also the exact command used to perform the mount, its PID, and its exit
status.
One of the most interesting pieces of the output is the control group name. In the preceding example, the
control group doesn’t include any information other than the name systemd:/system/media.mount
because the unit’s processes have already terminated. However, if you get the status of a service unit such as
NetworkManager.service, you’ll also see the process tree of the control group. You can view control groups
without the rest of the unit status with the systemd-cgls command. You’ll learn more about control groups
in 6.4.6 systemd Process Tracking and Synchronization.
The status command also displays recent information from the unit’s journal (a log that records diagnostic
information for each unit). You can view a unit’s entire journal with this command:
$ journalctl _SYSTEMD_UNIT=unit
(This syntax is a bit odd because journalctl can access the logs of more than just a systemd unit.)
To activate, deactivate, and restart units, use the systemd start, stop, and restart commands.
However, if you’ve changed a unit configuration file, you can tell systemd to reload the file in one of two
ways:
systemctl reload unit Reloads just the configuration for unit.
systemctl daemon-reload Reloads all unit configurations.
Requests to activate, reactivate, and restart units are known as jobs in systemd, and they are essentially unit
state changes. You can check the current jobs on a system with
$ systemctl list-jobs
If a system has been running for some time, you can reasonably expect there to be no active jobs on it because
all of the activations should be complete. However, at boot time, you can sometimes log in fast enough to see
some units start so slowly that they are not yet fully active. For example:
JOB UNIT TYPE STATE
1 graphical.target start waiting
2 multi-user.target start waiting
71 systemd-...nlevel.service start waiting
75 sm-client.service start waiting
76 sendmail.service start running
120 systemd-...ead-done.timer start waiting
In this case, job 76, the sendmail.service unit startup, is taking a really long time. The other listed jobs are in
a waiting state, most likely because they’re all waiting for job 76. When sendmail.service finishes starting and
becomes fully active, job 76 will complete, the rest of the jobs will also complete, and the job list will be
empty.
www.EBooksWorld.ir
NOTE
The term job can be confusing, especially because Upstart, another init system described in this
chapter, uses the word job to (roughly) refer to what systemd calls a unit. It’s important to
remember that although a systemd job associated with a unit will terminate, the unit itself can be
active and running afterwards, especially in the case of service units.
See 6.7 Shutting Down Your System for how to shut down and reboot the system.
6.4.5 Adding Units to systemd
Adding units to systemd is primarily a matter of creating, then activating and possibly enabling, unit files. You
should normally put your own unit files in the system configuration directory /etc/systemd/system so that you
won’t confuse them with anything that came with your distribution and so that the distribution won’t overwrite
them when you upgrade.
Because it’s easy to create target units that don’t do anything and don’t interfere with anything, you should try
it. Here’s how to create two targets, one with a dependency on the other:
1. Create a unit file named test1.target:
2. [Unit]
Description=test 1
3. Create a test2.target file with a dependency on test1.target:
4. [Unit]
5. Description=test 2
Wants=test1.target
6. Activate the test2.target unit (remember that the dependency in test2.target causes systemd to activate
test1.target when you do this):
# systemctl start test2.target
7. Verify that both units are active:
8. # systemctl status test1.target test2.target
9. test1.target - test 1
10. Loaded: loaded (/etc/systemd/system/test1.target; static)
11. Active: active since Thu, 12 Nov 2015 15:42:34 -0800; 10s
ago
12.
13. test2.target - test 2
14. Loaded: loaded (/etc/systemd/system/test2.target; static)
Active: active since Thu, 12 Nov 2015 15:42:34 -0800; 10s ago
NOTE
If your unit file has an [Install] section, “enable” the unit before activating it:
# systemctl enable unit
www.EBooksWorld.ir
Try this with the preceding example. Remove the dependency from test2.target and add an [Install]
section to test1.target containing WantedBy=test2.target.
Removing Units
To remove a unit, follow these steps:
1. Deactivate the unit if necessary:
# systemctl stop unit
2. If the unit has an [Install] section, disable the unit to remove any dependent symbolic links:
# systemctl disable unit
3. Remove the unit file, if you like.
6.4.6 systemd Process Tracking and Synchronization
systemd wants a reasonable amount of information and control over every process that it starts. The main
problem that it faces is that a service can start in different ways; it may fork new instances of itself or even
daemonize and detach itself from the original process.
To minimize the work that a package developer or administrator needs to do in order to create a working unit
file, systemd uses control groups (cgroups), an optional Linux kernel feature that allows for finer tracking of
a process hierarchy. If you’ve worked with Upstart before, you know that you have to do a little extra work to
figure out what the main process is for a service. In systemd, you don’t have to worry about how many times
a process forks—just whether it forks. Use the Type option in your service unit file to indicate its startup
behavior. There are two basic startup styles:
o Type=simple The service process doesn’t fork.
o Type=forking The service forks, and systemd expects the original service process to terminate. Upon
termination, systemd assumes that the service is ready.
The Type=simple option doesn’t account for the fact that a service may take some time to set up, and
systemd doesn’t know when to start any dependencies that absolutely require such a service to be ready. One
way to deal with this is to use delayed startup (see 6.4.7 systemd On-Demand and Resource-Parallelized
Startup). However, some Type startup styles can indicate that the service itself will notify systemd when it is
ready:
o Type=notify The service sends a notification specific to systemd (with the sd_notify() function
call) when it’s ready.
o Type=dbus The service registers itself on the D-bus (Desktop Bus) when it’s ready.
Another service startup style is specified with Type=oneshot; here the service process actually terminates
completely when it’s finished. With such a service, you will almost certainly need to add a
RemainAfterExit=yes option so that systemd will still regard the service as active even after its
processes terminate.
Finally, there’s one last style: Type=idle. This simply instructs systemd not to start the service until there
are no active jobs. The idea here is just to delay a service start until other services have started to keep the
system load down, or to keep services from stepping on one another’s output. (Remember, once a service has
started, the systemd job that started the service terminates.)
6.4.7 systemd On-Demand and Resource-Parallelized Startup
One of systemd’s most significant features is its ability to delay a unit startup until it is absolutely needed. The
www.EBooksWorld.ir
setup typically works like this:
1. You create a systemd unit (call it Unit A) for the system service that you’d like to provide, as normal.
2. You identify a system resource such as a network port/socket, file, or device that Unit A uses to offer its
services.
3. You create another systemd unit, Unit R, to represent that resource. These units have special types such
as socket units, path units, and device units.
Operationally, it goes like this:
1. Upon activation of Unit R, systemd monitors the resource.
2. When anything tries to access the resource, systemd blocks the resource, and the input to the resource is
buffered.
3. systemd activates Unit A.
4. When the service from Unit A is ready, it takes control of the resource, reads the buffered input, and runs
normally.
There are a few concerns:
o You must make sure that your resource unit covers every resource that the service provides. This normally
isn’t a problem, as most services have just one point of access.
o You need to make sure your resource unit is tied to the service unit that it represents. This can be implicit or
explicit, and in some cases, many options represent different ways for systemd to perform the handoff to the
service unit.
o Not all servers know how to interface with the units that systemd can provide.
If you already know what utilities like inetd, xinetd, and automount do, you’ll see that there are a lot
of similarities. Indeed, the concept is nothing new (and in fact, systemd includes support for automount units).
We’ll go over an example of a socket unit in An Example Socket Unit and Service. But let’s first take a look
at how these resource units help you at boot time.
Boot Optimization with Auxiliary Units
A common style of unit activation in systemd attempts to simplify dependency order and speed up boot time.
It’s similar to on-demand startup in that a service unit and an auxiliary unit represent the service unit’s offered
resource, except that in this case systemd starts the service unit as soon as it activates the auxiliary unit.
The reasoning behind this scheme is that essential boot-time service units such as syslog and dbus take some
time to start, and many other units depend on them. However, systemd can offer a unit’s essential resource
(such as a socket unit) very quickly, and then it can immediately activate not only the essential unit but also
any units that depend on the essential resource. Once the essential unit is ready, it takes control of the resource.
Figure 6-2 shows how this might work in a traditional system. In this boot timeline, Service E provides an
essential Resource R. Services A, B, and C depend on this resource and must wait until Service E has started.
When booting, the system takes quite a long time to get around to starting Service C.
www.EBooksWorld.ir
Figure 6-2. Sequential boot timeline with a resource dependency
Figure 6-3 shows an equivalent systemd boot configuration. The services are represented by Units A, B, C,
and E, and a new Unit R represents the resource that Unit E provides. Because systemd can provide an interface
for Unit R while Unit E starts, Units A, B, C, and E can all be started at the same time. Unit E takes over for
Unit R when ready. (An interesting point here is that Units A, B, and C may not need to explicitly access Unit
R before they finish their startup, as Unit B in the figure demonstrates.)
Figure 6-3. systemd boot timeline with a resource unit
NOTE
When parallelizing startup like this, there is a chance that your system may slow down temporarily
due to a large number of units starting at once.
The takeaway is that, although you’re not creating an on-demand unit startup in this case, you’re using the
same features that make on-demand startup possible. For common real-life examples, see the syslog and D-
Bus configuration units on a machine running systemd; they’re very likely to be parallelized in this way.
www.EBooksWorld.ir
An Example Socket Unit and Service
We’ll now look at an example, a simple network echo service that uses a socket unit. This is somewhat
advanced material, and you may not really understand it until you’ve read the discussion of TCP, ports, and
listening in Chapter 9 and sockets in Chapter 10, so feel free to skip this and come back later.
The idea behind this service is that when a network client connects to the service, the service repeats anything
that the client sends back to the client. The unit will listen on TCP port 22222. We’ll call it the echo service
and start with a socket unit, represented by the following echo.socket unit file:
[Unit]
Description=echo socket
[Socket]
ListenStream=22222
Accept=yes
Note that there’s no mention of the service unit that this socket supports inside the unit file. So what is the
corresponding service unit file?
Its name is echo@.service. The link is done by naming convention; if a service unit file has the same prefix
as a .socket file (in this case, echo), systemd knows to activate that service unit when there’s activity on the
socket unit. In this case, systemd creates an instance of echo@.service when there’s activity on echo.socket.
Here is the echo@.service unit file:
[Unit]
Description=echo service
[Service]
ExecStart=-/bin/cat
StandardInput=socket
NOTE
If you don’t like the implicit activation of units based on the prefixes, or you need to create an
activation mechanism between two units with different prefixes, you can use an explicit option in
the unit defining your resource. For example, use Socket=bar.socket inside foo.service to
have bar.socket hand its socket to foo.service.
To get this example service unit running, you need to start the echo.socket unit behind it, like this:
# systemctl start echo.socket
Now you can test the service by connecting to your local port 22222. When the following telnet command
connects, type anything and press ENTER. The service repeats what you typed back to you:
$ telnet localhost 22222
Trying 127.0.0.1...
Connected to localhost.
www.EBooksWorld.ir
Escape character is '^]'.
Hi there.
Hi there.
When you’re bored with this, press CTRL-] on a line by itself, and then CTRL-D. To stop the service, stop the
socket unit:
# systemctl stop echo.socket
Instances and Handoff
Because the echo@.service unit supports multiple simultaneous instances, there’s an @ in the name (recall
from Note that @ signifies parameterization). Why would you want multiple instances? The reason is that you
may have more than one network client connecting to the service at the same time, and each connection should
have its own instance.
In this case, the service unit must support multiple instances because of the Accept option in echo.socket.
That option instructs systemd not only to listen on the port, but also to accept incoming connections and pass
the incoming connections on to the service unit, with each connection a separate instance. Each instance reads
data from the connection as standard input, but it doesn’t necessarily need to know that the data is coming
from a network connection.
NOTE
Most network connections require more flexibility than just a simple gateway to standard input and
output, so don’t expect to be able to create network services with a service unit file like the
echo@.service unit file shown here.
Although the service unit could do all of the work of accepting the connection, it wouldn’t have the @ in its
name if it did. In that case, it would take complete control of the socket, and systemd wouldn’t attempt to
listen on the network port again until the service unit has finished.
The many different resources and options for handoff to service units make it difficult to provide a categorical
summary. Also, the documentation for the options is spread out over several manual pages. The ones to check
for the resource-oriented units are systemd.socket(5), systemd.path(5), and systemd.device(5). One document
that’s often overlooked for service units is systemd.exec(5), which contains information about how the service
unit can expect to receive a resource upon activation.
6.4.8 systemd System V Compatibility
One feature that sets systemd apart from other newer-generation init systems is that it tries to do a more
complete job of tracking services started by System V–compatible init scripts. It works like this:
1. First, systemd activates runlevel<N>.target, where N is the runlevel.
2. For each symbolic link in /etc/rc<N>.d, systemd identifies the script in /etc/init.d.
3. systemd associates the script name with a service unit (for example, /etc/init.d/foo would be foo.service).
4. systemd activates the service unit and runs the script with either a start or stop argument, based on
its name in rc<N>.d.
5. systemd attempts to associate any processes from the script with the service unit.
Because systemd makes the association with a service unit name, you can use systemctl to restart the
service or view its status. But don’t expect any miracles from System V compatibility mode; it still must run
the init scripts serially, for example.
www.EBooksWorld.ir
6.4.9 systemd Auxiliary Programs
When starting out with systemd, you may notice the exceptionally large number of programs in /lib/systemd.
These are primarily support programs for units. For example, udevd is part of systemd, and you’ll find it
there as systemd-udevd. Another, the systemd-fsck program, works as a middleman between systemd
and fsck.
Many of these programs exist because they contain notification mechanisms that the standard system utilities
lack. Often, they simply run the standard system utilities and notify systemd of the results. (After all, it would
be silly to try to reimplement all of fsck inside systemd.)
NOTE
One other interesting aspect of these programs is that they are written in C, because one goal of
systemd is to reduce the number of shell scripts on a system. There is some debate as to whether
it’s a good idea to do so (after all, many of these programs could probably be written as shell
scripts), but as long as everything works and does so reliably, securely, and reasonably quickly,
there’s little reason to bother taking sides.
When you see a program in /lib/systemd that you can’t identify, see the manual page. There’s a good chance
that the manual page will not only describe the utility but also describe the type of unit that it’s meant to
augment.
If you’re not running (or interested in) Upstart, skip ahead to 6.6 System V init for an overview of the System
V init process.
6.5 Upstart
The Upstart version of init revolves around jobs and events. Jobs are startup and runtime actions for Upstart
to perform (such as system services and configuration), and events are messages that Upstart receives from
itself or other processes (such as udevd). Upstart works by starting jobs in response to events.
To get an idea of how this works, consider the udev job for starting the udevd daemon. Its configuration file
is typically /etc/init/udev.conf, which includes the following:
start on virtual-filesystems
stop on runlevel [06]
These lines mean that Upstart starts the udev job upon receiving the virtual-filesystems event, and
it stops the job upon receiving a runlevel event with an argument of 0 or 6.
There are many variations on events and their arguments. For example, Upstart can react to events emitted in
response to job status, such as the started udev event emitted by the udev job above. But before
explaining jobs in detail, here’s a high-level overview of how Upstart works.
6.5.1 Upstart Initialization Procedure
Upon startup, Upstart does the following:
1. Loads its configuration and the job configuration files in /etc/init.
2. Emits the startup event.
3. Runs jobs configured to start upon receiving the startup event.
4. These initial jobs emit their own events, triggering more jobs and events.
Upon finishing all jobs associated with a normal startup, Upstart continues to monitor and react to events
during the entire system uptime.
www.EBooksWorld.ir
Most Upstart installations run like this:
1. The most significant job that Upstart runs in response to the startup event is mountall. This job
attaches all necessary local and virtual filesystems to the currently running system so that everything else
can run.
2. The mountall job emits a number of events, including filesystem, virtual-filesystems,
local-filesystems, remote-filesystems, and all-swaps, among others. These events
indicate that the important filesystems on the system are now attached and ready.
3. In response to these events, Upstart starts a number of essential service jobs. For example, udev starts in
response to the virtual-filesystems event, and dbus starts in response to the local-
filesystems event.
4. Among the essential service jobs, Upstart starts the network-interfaces job, usually in response to the
local-filesystems event and udevd being ready.
5. The network-interfaces job emits the static-network-up event.
6. Upstart runs the rc-sysinit job in response to the filesystem and static-network-up events.
This job is responsible for maintaining the system’s current runlevel, and when started for the first time
without a runlevel, it switches the system to the default runlevel by emitting a runlevel event.
7. Upstart runs most of the other startup jobs on the system in response to the runlevel event and the
new runlevel.
The process can become complicated because it’s not always clear where events originate. Upstart emits only
a few events, and the rest come from jobs. Job configuration files usually declare the events that they will emit,
but the details of how the job emits the events are usually not in the Upstart job configuration files.
To get to the bottom of things, you’ll often have to dig. For example, consider the static-network-up
event. The network-interface.conf job configuration file says that it emits this event, but it doesn’t say where.
It turns out that the event stems from the ifup command, which this job runs when initializing a network
interface in the /etc/network/if-up.d/upstart script.
NOTE
Though all of this is documented (the ifup.d directory is in the interfaces(5) manual page
referenced by the ifup(8) manual page), it can be challenging to find out how this all works just by
reading the documentation. It’s usually faster to grep the event name in a lot of configuration files
to see what comes up, then to try to piece everything back together from there.
One issue with Upstart is that there’s currently no clear way to view events. You can turn its log priority to
debug, which will cause it to log everything that comes in (typically to /var/log/syslog), but the copious amount
of extraneous information in this file makes it difficult to determine an event’s context.
6.5.2 Upstart Jobs
Each file in the Upstart /etc/init configuration directory corresponds to a job, and the main configuration file
for each job has a .conf extension. For example, /etc/init/mountall.conf defines the mountall job.
There are two primary kinds of Upstart jobs:
o Task jobs. These are jobs with a clear end. For example, mountall is a task job because it terminates when
finished mounting filesystems.
o Service jobs. These jobs have no defined stop. Servers (daemons) such as udevd, database servers, and
web servers are all service jobs.
A third kind of job is an abstract job. Think of this as a kind of virtual service job. Abstract jobs exist only in
www.EBooksWorld.ir
Upstart and start nothing by themselves, but they are sometimes used as management tools for other jobs
because other jobs can start and stop based on the events coming from an abstract job.
Viewing Jobs
You can view Upstart jobs and job status with the initctl command. To get an overview of what’s
happening on your system, run:
$ initctl list
You’ll get a lot of output, so let’s just look at two sample jobs that might appear in a typical listing. Here’s a
simple example of a task job status:
mountall stop/waiting
This indicates that the mountall task job has a status of stop/waiting, meaning that it’s not running.
(Unfortunately, as of this writing, you can’t use the status to determine whether a job already ran or not because
stop/waiting also applies to jobs that have never run.)
Service jobs that have associated processes appear in the status listing as follows:
tty1 start/running, process 1634
This line shows that the tty1 job is running and that process ID 1634 is performing the job. (Not all service
jobs have associated processes.)
NOTE
If you know a job’s name, you can view its status directly with initctl status job.
The status portion of the initctl output (e.g., stop/waiting) can be confusing. The left-hand side
(before the /) is the goal, or what the job is supposed to be working toward, such as start or stop. The right-
hand side is the current job state, or what the job is doing right now, such as waiting or running. For example,
in the preceding listing, the tty1 job has the status start/running, meaning that its goal is to start. The state of
running indicates that it has started successfully. (For service jobs, the running state is nominal.)
The mountall case is a bit different because task jobs don’t remain running. The stop/waiting status usually
indicates that the job started and completed its task. Upon completing its task, it moved from a start to a stop
goal, and it is now waiting for further commands from Upstart.
Unfortunately, as mentioned earlier, because jobs that have never started also have an Upstart stop/waiting
status, you can’t really tell whether a job has run or never started unless you enable debugging and look at the
logs, as described in 6.5.5 Upstart Logs.
NOTE
You won’t see jobs running on your system that were started with Upstart’s System V compatibility
feature.
Job State Transitions
There are many job states, but there’s a set way to move between them. For example, here’s how a typical job
starts:
1. All jobs begin in the stop/waiting status.
2. When a user or a system event starts a job, the job’s goal changes from stop to start.
3. Upstart changes the job’s state from waiting to starting, so the status is now start/starting.
4. Upstart emits a starting job event.
5. The job performs whatever it needs to do for the starting state.
www.EBooksWorld.ir
6. Upstart changes the job’s state from starting to pre-start and emits the pre-start job event.
7. The job works its way through several more states until it hits the running state.
8. Upstart emits a started job event.
Task termination involves a similar set of state changes and events. (See the upstart-events(7) manual page
for details on all of the states and transitions in both goals.)
6.5.3 Upstart Configuration
Let’s examine the two configuration files: one for the task job mountall and the other for the service job tty1.
Like all Upstart configuration files, the configuration files are in /etc/init, and they are named mountall.conf
and tty1.conf. The configuration files are organized into smaller pieces called stanzas. Each stanza starts with
a leading keyword, such as description or start.
To get started, open the mountall.conf file on your system. Look for a line like this in the first stanza:
description "Mount filesystems on boot"
This stanza gives a short text description of the job.
Next you’ll see a few stanzas describing how the mountall job starts:
start on startup
stop on starting rcS
Here, the first line tells Upstart to start the job upon receiving the startup event (the initial event that Upstart
emits). The second line tells Upstart to terminate the job upon receiving the rcS event, when the system goes
into single-user mode.
The next two lines tell Upstart how the mountall job behaves:
expect daemon
task
The task stanza tells Upstart that this is a task job, so the job should complete at some point. The expect
stanza is tricky. It means that the mountall job will spawn a daemon that will operate independently of the
original job script. Upstart needs to know this because it must know when the daemon terminates in order to
correctly signal that the mountall job has terminated. (We’ll discuss this in more detail in Process Tracking
and the Upstart expect Stanza.)
The mountall.conf file continues with several emits stanzas, indicating events that the jobs produce:
emits virtual-filesystems
emits local-filesystems
emits remote-filesystems
emits all-swaps
emits filesystem
emits mounting
emits mounted
NOTE
As mentioned in 6.5.1 Upstart Initialization Procedure, even though these lines are present, this is
www.EBooksWorld.ir
not the actual source of the events. You’ll need to hunt through the job script to find them.
You may also see a console stanza stating where Upstart should send the output:
console output
With the output parameter, Upstart sends the mountall job’s output to the system’s console.
Now you’ll see the details of the job itself—in this case, with a script stanza:
script
. /etc/default/rcS
[ -f /forcefsck ] && force_fsck="--force-fsck"
[ "$FSCKFIX" = "yes" ] && fsck_fix="-fsck-fix"
# set $LANG so that messages appearing in plymouth are translated
if [ -r /etc/default/locale ]; then
. /etc/default/locale
export LANG LANGUAGE LC_MESSAGES LC_ALL
fi
exec mountall --daemon $force_fsck $fsck_fix
end script
This is a shell script (see Chapter 11), most of which is preparatory— setting locale and determining whether
an fsck is necessary. The exec mountall command near the bottom of this script is where the real action
happens. This command mounts the filesystems and emits the job’s events when finished.
A Service Job: tty1
The service job tty1 is much simpler; it controls a virtual console login prompt. Its entire configuration file,
tty1.conf, looks like this:
start on stopped rc RUNLEVEL=[2345] and (
not-container or
container CONTAINER=lxc or
container CONTAINER=lxc-libvirt)
stop on runlevel [!2345]
respawn
exec /sbin/getty -8 38400 tty1
The most complicated part of this job is actually when it starts, but for now, ignore the container lines and
concentrate on this portion:
www.EBooksWorld.ir
start on stopped rc RUNLEVEL=[2345]
This part tells Upstart to activate the job upon receiving a stopped rc event from Upstart when the rc task
job has run and terminated. To make the condition true, the rc job must also set the RUNLEVEL environment
variable to a value from 2 through 5 (see 6.5.6 Upstart Runlevels and System V Compatibility).
NOTE
Other jobs that start on runlevels aren’t so picky. For example, you might see this instead:
start on runlevel [2345]
The only real difference between these last two start stanzas is timing; this example activates the
job as soon as the runlevel is set, while the prior one waits until the System V stuff finishes.
The container configuration is there because Upstart not only runs directly on top of the Linux kernel on real
hardware, but it can also run in virtual environments or containers. Some of these environments do not have
virtual consoles, and you don’t want to run getty on a console that doesn’t exist.
Stopping the tty1 job is straightforward:
stop on runlevel [!2345]
This stop stanza tells Upstart to terminate the job whenever the run-level is not 2 through 5 (for example,
during system shutdown).
The exec stanza at the bottom is the command to run:
exec /sbin/getty -8 38400 tty1
This stanza is much like the script stanza that you saw for the mountall job, except that the tty1 job has no
complicated setup to perform—it’s easy to start with a single line. In this case, we’re running the login prompt
program getty on /dev/tty1, which is the first virtual console (the one you get when you press CTRL-ALT-F1
in graphics mode).
The respawn stanza instructs Upstart to restart the tty1 job if the job terminates. In this case, Upstart runs a
new getty for a new login prompt when you log out of the virtual console.
Those are the basics of Upstart configuration. You’ll find much more detail in the init(5) manual page and
online resources, but one stanza requires special attention. The expect stanza is discussed next.
Process Tracking and the Upstart expect Stanza
Because Upstart tracks processes in jobs once they’ve started (so that it can terminate and restart them
efficiently), it wants to know which processes are relevant to each job. This can be a difficult task, because in
the traditional Unix startup scheme, processes fork from others during startup to become daemons, and the
main process for a job may start after one or two forks. Without proper process tracking, Upstart won’t be able
to finalize its job startup, or it may track the incorrect PID for the job.
You tell Upstart how a job behaves with the expect stanza. There are four basic possibilities:
o No expect stanza The main job process does not fork. Track the main process.
o expect fork The process forks once. Track the forked process.
o expect daemon The process forks twice. Track the second fork.
o expect stop The job’s main process will raise a SIGSTOP signal to indicate that it is ready. (This is
rare.)
For Upstart and other modern versions of init, such as systemd, the ideal case is the first one (no expect
stanza), because the main job process doesn’t have to include any of its own startup and shutdown mechanics.
www.EBooksWorld.ir
In other words, it doesn’t need to bother with forking or detaching itself from a current terminal—nuisances
that Unix systems developers have had to deal with for years.
Many traditional service daemons already include debugging-style options that tell the main process to not
fork. Examples include the Secure Shell daemon, sshd, and its -D option. A look at the /etc/init/ssh.conf
startup stanzas reveals a simple configuration to start sshd, prevent rapid respawning, and eliminate spurious
output to stderr:
respawn
respawn limit 10 5
umask 022
# 'sshd -D' leaks stderr and confuses things in conjunction with 'console
log'
console none
--snip--
exec /usr/sbin/sshd -D
Among jobs that require an expect stanza, expect fork is the most common. For example, here’s the
startup portion of the /etc/init/cron.conf file:
expect fork
respawn
exec cron
A simple job startup like this usually indicates a well-behaved, stable daemon.
NOTE
It’s worth reading more about the expect stanza on the upstart.ubuntu.com site because it relates
directly to process life span. For example, you can trace the life of a process and its system calls,
including fork(), with the strace command.
6.5.4 Upstart Operation
In addition to the list and status commands described in 6.5.2 Upstart Jobs, you can also use the
initctl utility to control Upstart and its jobs. You should read the initctl(8) manual page at some point, but
for now let’s look at the essentials.
To start an Upstart job, use initctl start:
# initctl start job
To stop a job, use initctl stop:
# initctl stop job
To restart a job:
# initctl restart job
www.EBooksWorld.ir
If you need to emit an event to Upstart, you can do it manually with:
# initctl emit event
You can also add environment variables to the emitted event by adding key=value parameters after event.
NOTE
You can’t start and stop individual services that started via Upstart’s System V compatibility
feature. See 6.6.1 System V init: Startup Command Sequence for more on how to do this in a
System V init script.
There are many ways to disable an Upstart job so that it will not start at boot time, but the most maintainable
one is to determine the name of the job’s configuration file (usually /etc/init/<job>.conf ) and then create a
new file called /etc/init/<job>.override containing only the line:
manual
Now the only way that the job will start is by running initctl start job.
The primary advantage to this method is that it’s easily reversible. To reenable the job at boot, remove
the .override file.
6.5.5 Upstart Logs
There are two basic kinds of logs in Upstart: service job logs, and diagnostic messages that Upstart itself
produces. Service job logs record the standard output and standard error of the scripts and daemons that run
the services. These messages, recorded in /var/log/upstart, are in addition to the standard syslog messages that
a service may produce. (You’ll learn more about syslog in Chapter 7.) It’s hard to categorize what goes into
these logs because there are no standards, but the most common contents are startup and shutdown messages,
as well as emergency error messages. Many services produce no messages at all because they send everything
to syslog or their own logging facility.
Upstart’s own diagnostic log can contain information about when it starts and reloads, as well as certain
information about jobs and events. This diagnostic log goes to the kernel syslog utility. On Ubuntu, you’ll
usually find this log in the /var/log/kern.log file and the catchall /var/log/syslog file.
That said, by default, Upstart logs little to nothing, so to see anything at all in the logs, you must change the
Upstart log priority. The name of the default priority is message. To log events and job changes on a running
system, change the log priority to info:
# initctl log-priority info
Keep in mind that this won’t be permanent and the priority will reset after a reboot. To have Upstart log
everything when it starts, add a --verbose parameter as a boot parameter, as described in 5.5 GRUB
Introduction.
6.5.6 Upstart Runlevels and System V Compatibility
So far, we’ve touched upon a few places where Upstart supports the idea of System V runlevels and mentioned
that it has the ability to run System V startup scripts as a job. Here’s a more detailed overview of how it works
on Ubuntu systems:
1. The rc-sysinit job runs, usually after getting the filesystem and static-network-up events.
Before it runs, there is no runlevel.
2. The rc-sysinit job determines which runlevel to enter. Usually, the run-level is the default, but it can also
parse an older /etc/inittab file or take the runlevel from a kernel parameter (in /proc/cmdline).
www.EBooksWorld.ir
3. The rc-sysinit job runs telinit to switch the runlevel. The command emits a runlevel event,
specifying the runlevel in the RUNLEVEL environment variable.
4. Upstart receives the runlevel event. A number of jobs are configured to start on the runlevel event
paired with a certain runlevel, and Upstart sets these in motion.
5. One of the runlevel-activated task jobs, rc, is responsible for running the System V start. In order to do
so, the rc job runs /etc/init.d/rc, just as System V init would (see 6.6 System V init).
6. Once the rc job terminates, Upstart can start a number of other jobs upon receiving the stopped rc
event (such as the tty1 job in A Service Job: tty1).
Notice that although Upstart treats the runlevel no differently than any other event, many of the job
configuration files on most Upstart systems refer to the runlevel.
In any case, there is a critical point during boot when the filesystems are mounted and when most of the
important system initialization is done. At this point, the system is ready to start higher-level system services
such as graphical display managers and database servers. A runlevel event is handy for marking this point.
You could configure Upstart to use any event as a trigger, though. One challenge comes when trying to
determine which services start as Upstart jobs and which ones start in System V compatibility mode. The
easiest way to find out is to look in your runlevel’s System V link farm (see 6.6.2 The System V init Link
Farm). For example, if your runlevel is 2, look in /etc/rc2.d; anything there is likely running in System V
compatibility mode.
NOTE
One stumbling block may be the presence of dummy scripts in /etc/init.d. For any Upstart service
job, there may also be a System V–style script for that service in /etc/init.d, but that script won’t do
anything other than tell you that the service has been converted to an Upstart job. There also
won’t be a link to the script in the System V link directory. If you run into a dummy script, find out
the Upstart job name, and use initctl to control the job.
6.6 System V init
The System V init implementation on Linux dates to the early days of Linux; its core idea is to support an
orderly bootup to different runlevels with a carefully sequenced process startup. Though System V is now
uncommon on most desktop installations, you may encounter System V init in Red Hat Enterprise Linux, as
well as in embedded Linux environments such as routers and phones.
There are two major components to a typical System V init installation: a central configuration file and a large
set of boot scripts augmented by a symbolic link farm. The configuration file /etc/inittab is where it all starts.
If you have System V init, look for a line like the following in your inittab file:
id:5:initdefault:
This indicates that the default runlevel is 5.
All lines in inittab take the following form, with four fields separated by colons in this order:
o A unique identifier (a short string, such as id in the previous example)
o The applicable runlevel number(s)
o The action that init should take (default runlevel to 5 in the previous example)
o A command to execute (optional)
To see how commands work in an inittab file, consider this line:
www.EBooksWorld.ir
l5:5:wait:/etc/rc.d/rc 5
This particular line is important because it triggers most of the system configuration and services. Here, the
wait action determines when and how System V init runs the command: Run /etc/rc.d/rc 5 once
when entering runlevel 5, then wait for this command to finish before doing anything else. To make a long
story short, the rc 5 command executes anything in /etc/rc5.d that starts with a number (in the order of the
numbers).
The following are some of the most common inittab actions in addition to initdefault and wait.
respawn
The respawn action tells init to run the command that follows and, if the command finishes executing, to
run it again. You’re likely to see something like this in an inittab file:
1:2345:respawn:/sbin/mingetty tty1
The getty programs provide login prompts. The line above is used for the first virtual console (/dev/tty1),
which is the one you see when you press ALT-F1 or CTRL-ALT-F1 (see 3.4.4 Terminals: /dev/tty*, /dev/pts/*,
and /dev/tty). The respawn action brings the login prompt back after you log out.
ctrlaltdel
The ctrlaltdel action controls what the system does when you press CTRLALT-DEL on a virtual console.
On most systems, this is some sort of reboot command, using the shutdown command (discussed in 6.7
Shutting Down Your System).
sysinit
The sysinit action is the first thing that init should run when starting, before entering any runlevels.
NOTE
For more available actions, see the inittab(5) manual page.
6.6.1 System V init: Startup Command Sequence
You are now ready to learn how System V init starts system services, just before it lets you log in. Recall this
inittab line from earlier:
l5:5:wait:/etc/rc.d/rc 5
This small line triggers many other programs. In fact, rc stands for run commands, which many people refer
to as scripts, programs, or services. But where are these commands?
The 5 in this line tells us that we’re talking about runlevel 5. The commands are probably either in
/etc/rc.d/rc5.d or /etc/rc5.d. (Runlevel 1 uses rc1.d, runlevel 2 uses rc2.d, and so on.) For example, you might
find the following items in the rc5.d directory:
S10sysklogd S20ppp S99gpm
S12kerneld S25netstd_nfs S99httpd
S15netstd_init S30netstd_misc S99rmnologin
S18netbase S45pcmcia S99sshd
S20acct S89atd
S20logoutd S89cron
www.EBooksWorld.ir
The rc 5 command starts programs in the rc5.d directory by executing the following commands in this
sequence:
S10sysklogd start
S12kerneld start
S15netstd_init start
S18netbase start
--snip--
S99sshd start
Notice the start argument in each command. The capital S in a command name means that the command
should run in start mode, and the number (00 through 99) determines where in the sequence rc starts the
command. The rc*.d commands are usually shell scripts that start programs in /sbin or /usr/sbin.
Normally, you can figure out what a particular command does by viewing the script with less or another
pager program.
NOTE
Some rc*.d directories contain commands that start with K (for “kill,” or stop mode). In this case,
rc runs the command with the stop argument instead of start. You will most likely encounter K
commands in runlevels that shut down the system.
You can run these commands by hand. However, you normally want to do so through the init.d directory
instead of the rc*.d directories, which we’ll now describe.
6.6.2 The System V init Link Farm
The contents of the rc*.d directories are actually symbolic links to files in yet another directory, init.d. If your
goal is to interact with, add, delete, or modify services in the rc*.d directories, you need to understand these
symbolic links. A long listing of a directory such as rc5.d reveals a structure like this:
lrwxrwxrwx . . . S10sysklogd -> ../init.d/sysklogd
lrwxrwxrwx . . . S12kerneld -> ../init.d/kerneld
lrwxrwxrwx . . . S15netstd_init -> ../init.d/netstd_init
lrwxrwxrwx . . . S18netbase -> ../init.d/netbase
--snip--
lrwxrwxrwx . . . S99httpd -> ../init.d/httpd
--snip--
A large number of symbolic links across several subdirectories such as this is called a link farm. Linux
distributions contain these links so that they can use the same startup scripts for all runlevels. This convention
is not a requirement, but it simplifies organization.
Starting and Stopping Services
To start and stop services by hand, use the script in the init.d directory. For example, one way to start the
httpd web server program manually is to run init.d/httpd start. Similarly, to kill a running service,
you can use the stop argument (httpd stop, for instance).
www.EBooksWorld.ir
Modifying the Boot Sequence
Changing the boot sequence in System V init is normally done by modifying the link farm. The most common
change is to prevent one of the commands in the init.d directory from running in a particular runlevel. You
have to be careful about how you do this. For example, you might consider removing the symbolic link in the
appropriate rc*.d directory. But beware: If you ever need to put the link back, you might have trouble
remembering the exact name of the link. One of the best ways to do it is to add an underscore (_) at the
beginning of the link name, like this:
# mv S99httpd _S99httpd
This change causes rc to ignore _S99httpd because the filename no longer starts with S or K, but the original
name is still obvious.
To add a service, create a script like those in the init.d directory and then create a symbolic link in the correct
rc*.d directory. The easiest way is to copy and modify one of the scripts already in init.d that you understand
(see Chapter 11 for more information on shell scripts).
When adding a service, choose an appropriate place in the boot sequence to start it. If the service starts too
soon, it may not work, due to a dependency on some other service. For nonessential services, most systems
administrators prefer numbers in the 90s, which puts the services after most of the services that came with the
system.
6.6.3 run-parts
The mechanism that System V init uses to run the init.d scripts has found its way into many Linux systems,
regardless of whether they use System V init. It’s a utility called run-parts, and the only thing it does is
run a bunch of executable programs in a given directory, in some kind of predictable order. You can think of
it as almost like a person who runs the ls command in some directory and then just runs whatever programs
they see in the output.
The default behavior is to run all programs in a directory, but you often have the option to select certain
programs and ignore others. In some distributions, you don’t need much control over the programs that run.
For example, Fedora ships with a very simple run-parts utility.
Other distributions, such as Debian and Ubuntu, have a more complicated run-parts program. Their
features include the ability to run programs based on a regular expression (for example, using the S[0-9]{2}
expression for running all “start” scripts in an /etc/init.d runlevel directory) and to pass arguments to the
programs. These capabilities allow you to start and stop System V runlevels with a single command.
You don’t really need to understand the details of how to use run-parts; in fact, most people don’t know
that run-parts even exists. The main things to remember are that it shows up in scripts from time to time
and that it exists solely to run the programs in a given directory.
6.6.4 Controlling System V init
Occasionally, you’ll need to give init a little kick to tell it to switch runlevels, to reread its configuration, or to
shut down the system. To control System V init, use telinit. For example, to switch to runlevel 3, enter:
# telinit 3
When switching runlevels, init tries to kill off any processes not in the inittab file for the new runlevel, so be
careful when changing runlevels.
When you need to add or remove jobs, or make any other change to the inittab file, you must tell init about
the change and cause it to reload the file. The telinit command for this is:
# telinit q
www.EBooksWorld.ir
You can also use telinit s to switch to single-user mode (see 6.9 Emergency Booting and Single-User
Mode).
6.7 Shutting Down Your System
init controls how the system shuts down and reboots. The commands to shut down the system are the same
regardless of which version of init you run. The proper way to shut down a Linux machine is to use the
shutdown command.
There are two basic ways to use shutdown. If you halt the system, it shuts the machine down and keeps it
down. To make the machine halt immediately, run this:
# shutdown -h now
On most machines and versions of Linux, a halt cuts the power to the machine. You can also reboot the
machine. For a reboot, use -r instead of -h.
The shutdown process takes several seconds. You should never reset or power off a machine during this stage.
In the preceding example, now is the time to shut down. This argument is mandatory, but there are many ways
to specify the time. For example, if you want the machine to shut down sometime in the future, you can use
+n, where n is the number of minutes shutdown should wait before doing its work. (For other options, see
the shutdown(8) manual page.)
To make the system reboot in 10 minutes, enter:
# shutdown -r +10
On Linux, shutdown notifies anyone logged on that the machine is going down, but it does little real work.
If you specify a time other than now, the shutdown command creates a file called /etc/nologin. When this
file is present, the system prohibits logins by anyone except the superuser.
When system shutdown time finally arrives, shutdown tells init to begin the shutdown process. On systemd,
it means activating the shutdown units; on Upstart, it means emitting the shutdown events; and on System V
init, it means changing the runlevel to 0 or 6. Regardless of the init implementation or configuration, the
procedure generally goes like this:
1. init asks every process to shut down cleanly.
2. If a process doesn’t respond after a while, init kills it, first trying a TERM signal.
3. If the TERM signal doesn’t work, init uses the KILL signal on any stragglers.
4. The system locks system files into place and makes other preparations for shutdown.
5. The system unmounts all filesystems other than the root.
6. The system remounts the root filesystem read-only.
7. The system writes all buffered data out to the filesystem with the sync program.
8. The final step is to tell the kernel to reboot or stop with the reboot(2) system call. This can be done by init
or an auxiliary program such as reboot, halt, or poweroff.
The reboot and halt programs behave differently depending on how they’re called, which may cause
confusion. By default, these programs call shutdown with the -r or -h options. However, if the system is
already at a halt or reboot runlevel, the programs tell the kernel to shut itself off immediately. If you really
want to shut your machine down in a hurry, regardless of any potential damage from a disorderly shutdown,
use the -f (force) option.
www.EBooksWorld.ir
6.8 The Initial RAM Filesystem
The Linux boot process is, for the most part, fairly straightforward. However, one component has always been
somewhat confounding: initramfs, or the intitial RAM filesystem. Think of this as a little user-space wedge
that goes in front of the normal user mode start. But first, let’s talk about why it exists.
The problem stems from the availability of many different kinds of storage hardware. Remember, the Linux
kernel does not talk to the PC BIOS or EFI interfaces to get data from disks, so in order to mount its root file-
system, it needs driver support for the underlying storage mechanism. For example, if the root is on a RAID
array connected to a third-party controller, the kernel needs the driver for that controller first. Unfortunately,
there are so many storage controller drivers that distributions can’t include all of them in their kernels, so
many drivers are shipped as loadable modules. But loadable modules are files, and if your kernel doesn’t have
a filesystem mounted in the first place, it can’t load the driver modules that it needs.
The workaround is to gather a small collection of kernel driver modules along with a few other utilities into
an archive. The boot loader loads this archive into memory before running the kernel. Upon start, the kernel
reads the contents of the archive into a temporary RAM filesystem (the initramfs), mounts it at /, and performs
the user-mode handoff to the init on the initramfs. Then, the utilities included in the initramfs allow the kernel
to load the necessary driver modules for the real root filesystem. Finally, the utilities mount the real root
filesystem and start true init.
Implementations vary and are ever evolving. On some distributions, the init on the initramfs is a fairly simple
shell script that starts a udevd to load drivers, then mounts the real root and executes the init there. On
distributions that use systemd, you’ll typically see an entire systemd installation there with no unit
configuration files and just a few udevd configuration files.
One basic characteristic of the initial RAM filesystem that has (so far) remained unchanged since its inception
is the ability to bypass it if you don’t need it. That is, if your kernel has all the drivers it needs to mount your
root filesystem, you can omit the initial RAM filesystem in your boot loader configuration. When successful,
eliminating the initial RAM file-system shortens boot time, usually by a couple of seconds. Try it yourself at
boot time by using the GRUB menu editor to remove the initrd line. (It’s best not to experiment by
changing the GRUB configuration file, as you can make a mistake that will be difficult to repair.) Recently, it
has been a little more difficult to bypass the initial RAM filesystem because features such as mount-by-UUID
may not be available with generic distribution kernels.
It’s easy to see the contents of your initial RAM filesystem because, on most modern systems, they are simple
gzip-compressed cpio archives (see the cpio(1) manual page). First, find the archive file by looking at your
boot loader configuration (for example, grep for initrd lines in your grub.cfg configuration file). Then
use cpio to dump the contents of the archive into a temporary directory somewhere and peruse the results.
For example:
$ mkdir /tmp/myinitrd
$ cd /tmp/myinitrd
$ zcat /boot/initrd.img-3.2.0-34 | cpio -i --no-absolute-filenames
--snip--
One particular piece of interest is the “pivot” near the very end of the init process on the initial RAM filesystem.
This part is responsible for removing the contents of the temporary filesystem (to save memory) and
permanently switch to the real root.
You won’t typically create your own initial RAM filesystem, as this is a painstaking process. There are a
number of utilities for creating initial RAM filesystem images, and your distribution likely comes with one.
www.EBooksWorld.ir
Two of the most common are dracut and mkinitramfs.
NOTE
The term initial RAM filesystem (initramfs) refers to the implementation that uses the cpio archive
as the source of the temporary filesystem. There is an older version called the initial RAM disk, or
initrd, that uses a disk image as the basis of the temporary filesystem. This has fallen into disuse
because it’s much easier to maintain a cpio archive. However, you’ll often see the term initrd
used to refer to a cpio-based initial RAM filesystem. Often, as in the preceding example, the
filenames and configuration files will still contain initrd.
6.9 Emergency Booting and Single-User Mode
When something goes wrong with the system, the first recourse is usually to boot the system with a
distribution’s “live” image (most distributions’ installation images double as live images) or with a dedicated
rescue image such as SystemRescueCd that you can put on removable media. Common tasks for fixing a
system include the following:
o Checking filesystems after a system crash
o Resetting a forgotten root password
o Fixing problems in critical files, such as /etc/fstab and /etc/passwd
o Restoring from backups after a system crash
Another option for booting quickly to a usable state is single-user mode. The idea is that the system quickly
boots to a root shell instead of going through the whole mess of services. In the System V init, single-user
mode is usually runlevel 1, and you can also enter the mode with an -s parameter to the boot loader. You may
need to type the root password to enter single-user mode.
The biggest problem with single-user mode is that it doesn’t offer many amenities. The network almost
certainly won’t be available (and if it is, it will be hard to use), you won’t have a GUI, and your terminal may
not even work correctly. For this reason, live images are nearly always considered preferable.
www.EBooksWorld.ir
Chapter 7. System Configuration: Logging, System Time, Batch Jobs, and Users
When you first look in the /etc directory, you might feel a bit overwhelmed. Although most of the files that
you see affect a system’s operations to some extent, a few are fundamental.
The subject material in this chapter covers the parts of the system that make the infrastructure discussed in
Chapter 4 available to the user-level tools covered in Chapter 2. In particular, we’re going to look at the
following:
o Configuration files that the system libraries access to get server and user information
o Server programs (sometimes called daemons) that run when the system boots
o Configuration utilities that can be used to tweak the server programs and configuration files
o Administration utilities
As in previous chapters, there is virtually no networking material here because the network is a separate
building block of the system. In Chapter 9, you’ll see where the network fits in.
7.1 The Structure of /etc
Most system configuration files on a Linux system are found in /etc. Historically, each program had one or
more configuration files there, and because there are so many packages on a Unix system, /etc would
accumulate files quickly.
There were two problems with this approach: It was hard to find particular configuration files on a running
system, and it was difficult to maintain a system configured this way. For example, if you wanted to change
the system logger configuration, you’d have to edit /etc/syslog.conf. But after your change, an upgrade to your
distribution could wipe out your customizations.
The trend for many years now has been to place system configuration files into subdirectories under /etc, as
you’ve already seen for the boot directories (/etc/init for Upstart and /etc/systemd for systemd). There are still
a few individual configuration files in /etc, but for the most part, if you run ls -F /etc, you’ll see that
most of the items there are now subdirectories.
To solve the problem of overwriting configuration files, you can now place customizations in separate files in
the configuration subdirectories, such as the ones in /etc/grub.d.
What kind of configuration files are found in /etc? The basic guideline is that customizable configurations for
a single machine, such as user information (/etc/passwd) and network details (/etc/network), go into /etc.
However, general application details, such as a distribution’s defaults for a user interface, don’t belong in /etc.
And you’ll often find that noncustomizable system configuration files may be found elsewhere, as with the
prepackaged systemd unit files in /usr/lib/systemd.
You’ve already seen some of the configuration files that pertain to booting. Now we’ll look at a typical system
service and how to view and specify its configuration.
www.EBooksWorld.ir
7.2 System Logging
Most system programs write their diagnostic output to the syslog service. The traditional syslogd daemon
waits for messages and, depending on the type of message received, funnels the output to a file, the screen,
users, or some combination of these, or just ignores it.
7.2.1 The System Logger
The system logger is one of the most important parts of the system. When something goes wrong and you
don’t know where to start, check the system log files first. Here is a sample log file message:
Aug 19 17:59:48 duplex sshd[484]: Server listening on 0.0.0.0 port 22.
Most Linux distributions run a new version of syslogd called rsyslogd that does much more than simply
write log messages to files. For example, you can use it to load a module to send log messages to a database.
But when starting out with system logs, it’s easiest to start with the log files normally stored in /var/log. Check
out some log files—once you know what they look like, you’ll be ready to find out how they got there.
Many of the files in /var/log aren’t maintained by the system logger. The only way to know for sure which
ones belong to rsyslogd is to look at its configuration file.
7.2.2 Configuration Files
The base rsyslogd configuration file is /etc/rsyslog.conf, but you’ll find certain configurations in other
directories, such as /etc/rsyslog.d. The configuration format is a blend of traditional rules and rsyslog-
specific extensions. One rule of thumb is that anything beginning with a dollar sign ($) is an extension.
A traditional rule has a selector and an action to show how to catch logs and where to send them, respectively.
For example:
Example 7-1. syslog rules
kern.* /dev/console
*.info;authpriv.none➊ /var/log/messages
authpriv.* /var/log/secure,root
mail.* /var/log/maillog
cron.* /var/log/cron
*.emerg *➋
local7.* /var/log/boot.log
The selector is on the left. It’s the type of information to be logged. The list on the right is the action: where
to send the log. Most actions in Example 7-1 are normal files, with some exceptions. For example,
/dev/console refers to a special device for the system console, root means send a message to the
superuser if that user is logged in, and * means message all users currently on the system. You can also send
messages to another network host with @host.
Facility and Priority
The selector is a pattern that matches the facility and priority of log messages. The facility is a general category
of message. (See rsyslog.conf(5) for a list of all facilities.)
The function of most facilities will be fairly obvious from their name. For example, the configuration file in
Example 7-1 catches messages carrying the kern, authpriv, mail, cron, and local7 facilities. In this
same listing, the asterisk at ➋ is a wildcard that catches output related to all facilities.
www.EBooksWorld.ir
The priority follows the dot (.) after the facility. The order of priorities from lowest to highest is debug,
info, notice, warning, err, crit, alert, or emerg.
NOTE
To exclude log messages from a facility in rsyslog.conf, specify a priority of none, as shown at ➊
in Example 7-1.
When you put a specific priority in a selector, rsyslogd sends messages with that priority and all higher
priorities to the destination on that line. Therefore, in Example 7-1, the *.info for the line at ➊ actually
catches most log messages and puts them into /var/log/messages because info is a relatively low priority.
Extended Syntax
As previously mentioned, the syntax of rsyslogd extends the traditional syslogd syntax. The
configuration extensions are called directives and usually begin with a $. One of the most common extensions
allows you to load additional configuration files. Check your rsyslog.conf file for a directive like this, which
causes rsyslogd to load all .conf files in /etc/rsyslog.d into the configuration:
$IncludeConfig /etc/rsyslog.d/*.conf
Most of the other extended directives are fairly self-explanatory. For example, these directives deal with users
and permissions:
$FileOwner syslog
$FileGroup adm
$FileCreateMode 0640
$DirCreateMode 0755
$Umask 0022
NOTE
Additional rsyslogd configuration file extensions define output templates and channels. If you
need to use them, the rsyslogd(5) manual page is fairly comprehensive, but the web-based
documentation is more complete.
Troubleshooting
One of the easiest ways to test the system logger is to send a log message manually with the logger command,
as shown here:
$ logger -p daemon.info something bad just happened
Very little can go wrong with rsyslogd. The most common problems occur when a configuration doesn’t
catch a certain facility or priority or when log files fill their disk partitions. Most distributions automatically
trim the files in /var/log with automatic invocations of logrotate or a similar utility, but if too many
messages arrive in a brief period, you can still fill the disk or end up with a high system load.
NOTE
The logs caught by rsyslogd are not the only ones recorded by various pieces of the system.
We discussed the startup log messages captured by systemd and Upstart in Chapter 6, but you’ll
find many other sources, such as the Apache Web server, which normally records its own access
and error logs. To find those logs, see the server configuration.
www.EBooksWorld.ir
Logging: Past and Future
The syslog service has evolved over time. For example, there was once a daemon called klogd that trapped
kernel diagnostic messages for syslogd. (These messages are the ones you see with the dmesg command.)
This capability has been folded into rsyslogd.
It’s a near certainty that Linux system logging will change in the future. Unix system logging has never had a
true standard, but efforts are underway to change that.
7.3 User Management Files
Unix systems allow for multiple independent users. At the kernel level, users are simply numbers (user IDs),
but because it’s much easier to remember a name than a number, you’ll normally work with usernames (or
login names) instead of user IDs when managing Linux. Usernames exist only in user space, so any program
that works with a username generally needs to be able to map the username to a user ID if it wants to refer to
a user when talking to the kernel.
7.3.1 The /etc/passwd File
The plaintext file /etc/passwd maps usernames to user IDs. It looks something like this:
Example 7-2. A list of users in /etc/passwd
root:x:0:0:Superuser:/root:/bin/sh
daemon:*:1:1:daemon:/usr/sbin:/bin/sh
bin:*:2:2:bin:/bin:/bin/sh
sys:*:3:3:sys:/dev:/bin/sh
nobody:*:65534:65534:nobody:/home:/bin/false
juser:x:3119:1000:J. Random User:/home/juser:/bin/bash
beazley:x:143:1000:David Beazley:/home/beazley:/bin/bash
Each line represents one user and has seven fields separated by colons. The fields are as follows:
o The username.
o The user’s encrypted password. On most Linux systems, the password is not actually stored in the passwd
file, but rather, in the shadow file (see 7.3.3 The /etc/shadow File). The shadow file format is similar to that
of passwd, but normal users do not have read permission for shadow. The second field in passwd or shadow
is the encrypted password, and it looks like a bunch of unreadable garbage, such as d1CVEWiB/oppc.
(Unix passwords are never stored as clear text.)
An x in the second passwd file field indicates that the encrypted password is stored in the shadow file. A star
(*) indicates that the user cannot log in, and if the field is blank (that is, you see two colons in a row, like ::),
no password is required to log in. (Beware of blank passwords. You should never have a user without a
password.)
o The user ID (UID), which is the user’s representation in the kernel. You can have two entries with the same
user ID, but doing this will confuse you, and your software may mix them up as well. Keep the user ID
unique.
o The group ID (GID). This should be one of the numbered entries in the /etc/group file. Groups determine
file permissions and little else. This group is also called the user’s primary group.
o The user’s real name (often called the GECOS field). You’ll sometimes find commas in this field, denoting
room and telephone numbers.
o The user’s home directory.
www.EBooksWorld.ir
o The user’s shell (the program that runs when the user runs a terminal session).
Figure 7-1 identifies the various fields in one of the entries in Example 7-2.
Figure 7-1. An entry in the password file
The /etc/passwd file syntax is fairly strict, allowing for no comments or blank lines.
NOTE
A user in /etc/passwd and a corresponding home directory are collectively known as an account.
7.3.2 Special Users
You will find a few special users in /etc/passwd. The superuser (root) always has UID 0 and GID 0, as in
Example 7-2. Some users, such as daemon, have no login privileges. The nobody user is an underprivileged
user. Some processes run as nobody because the nobody user cannot write to anything on the system.
The users that cannot log in are called pseudo-users. Although they can’t log in, the system can start processes
with their user IDs. Pseudo-users such as nobody are usually created for security reasons.
7.3.3 The /etc/shadow File
The shadow password file (/etc/shadow) on a Linux system normally contains user authentication information,
including the encrypted passwords and password expiration information that correspond to the users in
/etc/passwd.
The shadow file was introduced to provide a more flexible (and more secure) way of storing passwords. It
included a suite of libraries and utilities, many of which were soon replaced by pieces of PAM (see 7.10 PAM).
Rather than introduce an entirely new set of files for Linux, PAM uses /etc/shadow, but not certain
corresponding configuration files such as /etc/login.defs.
7.3.4 Manipulating Users and Passwords
Regular users interact with /etc/passwd using the passwd command. By default, passwd changes the user’s
password, but you can also use -f to change the user’s real name or -s to change the user’s shell to one listed
in /etc/shells. (You can also use the commands chfn and chsh to change the real name and shell.) The
passwd command is an suid-root program, because only the superuser can change the /etc/passwd file.
Changing /etc/passwd as the Superuser
Because /etc/passwd is plaintext, the superuser may use any text editor to make changes. To add a user, simply
add an appropriate line and create a home directory for the user; to delete, do the opposite. However, to edit
the file, you’ll most likely want to use the vipw program, which backs up and locks /etc/passwd while you’re
editing it as an added precaution. To edit /etc/shadow instead of /etc/passwd, use vipw -s. (You’ll likely
never need to do this, though.)
Most organizations frown on editing passwd directly because it’s too easy to make a mistake. It’s much easier
(and safer) to make changes to users using separate commands available from the terminal or through the GUI.
www.EBooksWorld.ir
For example, to set a user’s password, run passwd user as the superuser. Use adduser and userdel to
add and remove users.
7.3.5 Working with Groups
Groups in Unix offer a way to share files with certain users but deny access to all others. The idea is that you
can set read or write permission bits for a particular group, excluding everyone else. This feature was once
important because many users shared one machine, but it’s become less significant in recent years as
workstations are shared less often.
The /etc/group file defines the group IDs (such as the ones found in the /etc/passwd file). Example 7-3 is an
example.
Example 7-3. A sample /etc/group file
root:*:0:juser
daemon:*:1:
bin:*:2:
sys:*:3:
adm:*:4:
disk:*:6:juser,beazley
nogroup:*:65534:
user:*:1000:
Like the /etc/passwd file, each line in /etc/group is a set of fields separated by colons. The fields in each entry
are as follows, from left to right:
o The group name. This appears when you run a command like ls -l.
o The group password. This is hardly ever used, nor should you use it (use sudo instead). Use * or any
other default value.
o The group ID (a number). The GID must be unique within the group file. This number goes into a user’s
group field in that user’s /etc/passwd entry.
o An optional list of users that belong to the group. In addition to the users listed here, users with the
corresponding group ID in their passwd file entries also belong to the group.
Figure 7-2 identifies the fields in a group file entry.
Figure 7-2. An entry in the group file
To see the groups you belong to, run groups.
NOTE
Linux distributions often create a new group for each new user added, with the same name as the
user.
7.4 getty and login
getty is a program that attaches to terminals and displays a login prompt. On most Linux systems, getty
www.EBooksWorld.ir
is uncomplicated because the system only uses it for logins on virtual terminals. In a process listing, it usually
looks something like this (for example, when running on /dev/tty1):
$ ps ao args | grep getty
/sbin/getty 38400 tty1
In this example, 38400 is the baud rate. Some getty programs don’t need the baud rate setting. (Virtual
terminals ignore the baud rate; it’s only there for backward compatibility with software that connects to real
serial lines.)
After you enter your login name, getty replaces itself with the login program, which asks for your
password. If you enter the correct password, login replaces itself (using exec()) with your shell. Otherwise,
you get a “Login incorrect” message.
You now know what getty and login do, but you’ll probably never need to configure or change them. In
fact, you’ll rarely even use them, because most users now log in either through a graphical interface such as
gdm or remotely with SSH, neither of which uses getty or login. Much of the login program’s real
authentication work is handled by PAM (see 7.10 PAM).
7.5 Setting the Time
Unix machines depend on accurate timekeeping. The kernel maintains the system clock, which is the clock
that is consulted when you run commands like date. You can also set the system clock using the date
command, but it’s usually a bad idea to do so because you’ll never get the time exactly right. Your system
clock should be as close to the correct time as possible.
PC hardware has a battery-backed real-time clock (RTC). The RTC isn’t the best clock in the world, but it’s
better than nothing. The kernel usually sets its time based on the RTC at boot time, and you can reset the
system clock to the current hardware time with hwclock. Keep your hardware clock in Universal
Coordinated Time (UTC) in order to avoid any trouble with time zone or daylight savings time corrections.
You can set the RTC to your kernel’s UTC clock using this command:
# hwclock --hctosys --utc
Unfortunately, the kernel is even worse at keeping time than the RTC, and because Unix machines often stay
up for months or years on a single boot, they tend to develop time drift. Time drift is the current difference
between the kernel time and the true time (as defined by an atomic clock or another very accurate clock).
You should not try to fix the drift with hwclock because time-based system events can get lost or mangled.
You could run a utility like adjtimex to smoothly update the clock, but usually it’s best to keep your system
time correct with a network time daemon (see 7.5.2 Network Time).
7.5.1 Kernel Time Representation and Time Zones
The kernel’s system clock represents the current time as the number of seconds since 12:00 midnight on
January 1, 1970, UTC. To see this number at the moment, run:
$ date +%s
To convert this number into something that humans can read, user-space programs change it to local time and
compensate for daylight savings time and any other strange circumstances (such as living in Indiana). The
local time zone is controlled by the file /etc/localtime. (Don’t bother trying to look at it; it’s a binary file.)
The time zone files on your system are in /usr/share/zoneinfo. You’ll find that this directory contains a lot of
time zones and a lot of aliases for time zones. To set your system’s time zone manually, either copy one of the
files in /usr/share/zoneinfo to /etc/localtime (or make a symbolic link) or change it with your distribution’s
www.EBooksWorld.ir
time zone tool. (The command-line program tzselect may help you identify a time zone file.)
To use a time zone other than the system default for just one shell session, set the TZ environment variable to
the name of a file in /usr/share/ zoneinfo and test the change, like this:
$ export TZ=US/Central
$ date
As with other environment variables, you can also set the time zone for the duration of a single command like
this:
$ TZ=US/Central date
7.5.2 Network Time
If your machine is permanently connected to the Internet, you can run a Network Time Protocol (NTP) daemon
to maintain the time using a remote server. Many distributions have built-in support for an NTP daemon, but
it may not be enabled by default. You might need to install an ntpd package to get it to work.
If you need to do the configuration by hand, you’ll find help on the main NTP web page at http://www.ntp.org/,
but if you’d rather not read through the mounds of documentation there, do this:
1. Find the closest NTP time server from your ISP or from the ntp.org web page.
2. Put that time server in /etc/ntpd.conf.
3. Run ntpdate server at boot time.
4. Run ntpd at boot time, after the ntpdate command.
If your machine doesn’t have a permanent Internet connection, you can use a daemon like chronyd to
maintain the time during disconnections.
You can also set your hardware clock based on the network time in order to help your system maintain time
coherency when it reboots. (Many distributions do this automatically.) To do so, set your system time from
the network with ntpdate (or ntpd), then run the command you saw back in Note:
# hwclock --systohc –-utc
7.6 Scheduling Recurring Tasks with cron
The Unix cron service runs programs repeatedly on a fixed schedule. Most experienced administrators
consider cron to be vital to the system because it can perform automatic system maintenance. For example,
cron runs log file rotation utilities to ensure that your hard drive doesn’t fill up with old log files. You should
know how to use cron because it’s just plain useful.
You can run any program with cron at whatever times suit you. The program running through cron is called a
cron job. To install a cron job, you’ll create an entry line in your crontab file, usually by running the crontab
command. For example, the crontab entry schedules the /home/juser/bin/spmake command daily at
9:15 AM:
15 09 * * * /home/juser/bin/spmake
The five fields at the beginning of this line, delimited by whitespace, specify the scheduled time (see also
Figure 7-3). The fields are as follows, in order:
o Minute (0 through 59). The cron job above is set for minute 15.
o Hour (0 through 23). The job above is set for the ninth hour.
www.EBooksWorld.ir
o Day of month (1 through 31).
o Month (1 through 12).
o Day of week (0 through 7). The numbers 0 and 7 are Sunday.
Figure 7-3. An entry in the crontab file
A star (*) in any field means to match every value. The preceding example runs spmake daily because the
day of month, month, and day of week fields are all filled with stars, which cron reads as “run this job every
day, of every month, of every week.”
To run spmake only on the 14th day of each month, you would use this crontab line:
15 09 14 * * /home/juser/bin/spmake
You can select more than one time for each field. For example, to run the program on the 5th and the 14th day
of each month, you could enter 5,14 in the third field:
15 09 5,14 * * /home/juser/bin/spmake
NOTE
If the cron job generates standard output or an error or exits abnormally, cron should mail this
information to you. Redirect the output to /dev/null or some other log file if you find the email
annoying.
The crontab(5) manual page provides complete information on the crontab format.
7.6.1 Installing Crontab Files
Each user can have his or her own crontab file, which means that every system may have multiple crontabs,
usually found in /var/spool/cron/crontabs. Normal users can’t write to this directory; the crontab command
installs, lists, edits, and removes a user’s crontab.
The easiest way to install a crontab is to put your crontab entries into a file and then use crontab file to
install file as your current crontab. The crontab command checks the file format to make sure that you
haven’t made any mistakes. To list your cron jobs, run crontab -l. To remove the crontab, use crontab
-r.
However, after you’ve created your initial crontab, it can be a bit messy to use temporary files to make further
edits. Instead, you can edit and install your crontab in one step with the crontab -e command. If you make
a mistake, crontab should tell you where the mistake is and ask if you want to try editing again.
7.6.2 System Crontab Files
Rather than use the superuser’s crontab to schedule recurring system tasks, Linux distributions normally have
an /etc/crontab file. Don’t use crontab to edit this file, because this version has an additional field inserted
before the command to run—the user that should run the job. For example, this cron job defined in /etc/crontab
runs at 6:42 AM as the superuser (root, shown at ➊):
www.EBooksWorld.ir
42 6 * * * root➊ /usr/local/bin/cleansystem > /dev/null 2>&1
NOTE
Some distributions store system crontab files in the /etc/cron.d directory. These files may have any
name, but they have the same format as /etc/crontab.
7.6.3 The Future of cron
The cron utility is one of the oldest components of a Linux system; it’s been around for decades (predating
Linux itself), and its configuration format hasn’t changed much for many years. When something gets to be
this old, it becomes fodder for replacement, and there are efforts underway to do exactly that.
The proposed replacements are actually just parts of the newer versions of init: For systemd, there are timer
units, and for Upstart, the idea is to be able to create recurring events to trigger jobs. After all, both versions
of init can run tasks as any user, and they offer certain advantages, such as custom logging.
However, the reality is that neither systemd nor Upstart currently has all of the capabilities of cron.
Furthermore, when they do become capable, backward compatibility will be necessary to support everything
that relies on cron. For these reasons, it’s unlikely that the cron format will go away anytime soon.
7.7 Scheduling One-Time Tasks with at
To run a job once in the future without using cron, use the at service. For example, to run myjob at 10:30
PM, enter this command:
$ at 22:30
at> myjob
End the input with CTRL-D. (The at utility reads the commands from the standard input.)
To check that the job has been scheduled, use atq. To remove it, use atrm. You can also schedule jobs days
into the future by adding the date in DD.MM.YY format, for example, at 22:30 30.09.15.
There isn’t much else to the at command. Though at isn’t used that often, it can be handy for that odd time
when you need to tell the system to shut down in the future.
7.8 Understanding User IDs and User Switching
We’ve discussed how setuid programs such as sudo and su allow you to change users, and we’ve mentioned
system components like login that control user access. Perhaps you’re wondering how these pieces work
and what role the kernel plays in user switching.
There are two ways to change a user ID, and the kernel handles both. The first is with a setuid executable,
which is covered in 2.17 File Modes and Permissions. The second is through the setuid() family of system
calls. There are a few different versions of this system call to accommodate the various user IDs associated
with a process, as you’ll learn in 7.8.1 Process Ownership, Effective UID, Real UID, and Saved UID.
The kernel has basic rules about what a process can or can’t do, but here are the three basics:
o A process running as root (userid 0) can use setuid() to become any other user.
o A process not running as root has severe restrictions on how it may use setuid(); in most cases, it
cannot.
o Any process can execute a setuid program as long as it has adequate file permissions.
www.EBooksWorld.ir
NOTE
User switching has nothing to do with passwords or usernames. Those are strictly user-space
concepts, as you first saw in the /etc/passwd file in 7.3.1 The /etc/passwd File. You’ll learn more
details about how this works in 7.9.1 Using Libraries for User Information.
7.8.1 Process Ownership, Effective UID, Real UID, and Saved UID
Our discussion of user IDs so far has been simplified. In reality, every process has more than one user ID.
We’ve described the effective user ID (euid), which defines the access rights for a process. A second user ID,
the real user ID (ruid), indicates who initiated a process. When you run a setuid program, Linux sets the
effective user ID to the program’s owner during execution, but it keeps your original user ID in the real user
ID.
On modern systems, the difference between the effective and real user IDs is confusing, so much so that a lot
of documentation regarding process ownership is incorrect.
Think of the effective user ID as the actor and the real user ID as the owner. The real user ID defines the user
that can interact with the running process—most significantly, which user can kill and send signals to a process.
For example, if user A starts a new process that runs as user B (based on setuid permissions), user A still owns
the process and can kill it.
On normal Linux systems, most processes have the same effective user ID and real user ID. By default, ps
and other system diagnostic programs show the effective user ID. To view both the effective and real user IDs
on your system, try this, but don’t be surprised if you find that the two user ID columns are identical for all
processes on your system:
$ ps -eo pid,euser,ruser,comm
To create an exception just so that you can see different values in the columns, try experimenting by creating
a setuid copy of the sleep command, running the copy for a few seconds, and then running the preceding
ps command in another window before the copy terminates.
To add to the confusion, in addition to the real and effective user IDs, there is also a saved user ID (which is
usually not abbreviated). A process can switch its effective user ID to the real or saved user ID during
execution. (To make things even more complicated, Linux has yet another user ID: the file system user ID
[fsuid], which defines the user accessing the filesystem but is rarely used.)
Typical Setuid Program Behavior
The idea of the real user ID might contradict your previous experience. Why don’t you have to deal with the
other user IDs very frequently? For example, after starting a process with sudo, if you want to kill it, you still
use sudo; you can’t kill it as your own regular user. Shouldn’t your regular user be the real user ID in this
case, giving you the correct permissions?
The cause of this behavior is that sudo and many other setuid programs explicitly change the effective and
real user IDs with one of the setuid() system calls. These programs do so because there are often
unintended side effects and access problems when all of the user IDs do not match.
NOTE
If you’re interested in the details and rules regarding user ID switching, read the setuid(2) manual
page and check the other manual pages listed in the SEE ALSO section. There are many different
system calls for diverse situations.
Some programs don’t like to have a real user ID of root. To prevent sudo from changing the real user ID, add
this line to your /etc/sudoers file (and beware of side effects on other programs you want to run as root!):
www.EBooksWorld.ir
Defaults stay_setuid
Security Implications
Because the Linux kernel handles all user switches (and as a result, file access permissions) through setuid
programs and subsequent system calls, systems developers and administrators must be extremely careful with
two things:
o The programs that have setuid permissions
o What those programs do
If you make a copy of the bash shell that is setuid root, any local user can execute it and have complete run
of the system. It’s really that simple. Furthermore, even a special-purpose program that is setuid root can pose
a danger if it has bugs. Exploiting weaknesses in programs running as root is a primary method of systems
intrusion, and there are too many such exploits to count.
Because there are so many ways to break into a system, preventing intrusion is a multifaceted affair. One of
the most essential ways to keep unwanted activity off your system is to enforce user authentication with
usernames and passwords.
7.9 User Identification and Authentication
A multiuser system must provide basic support for user security in terms of identification and authentication.
The identification portion of security answers the question of who users are. The authentication piece asks
users to prove that they are who they say they are. Finally, authorization is used to define and limit what users
are allowed to do.
When it comes to user identification, the Linux kernel knows only the numeric user IDs for process and file
ownership. The kernel knows authorization rules for how to run setuid executables and how user IDs may run
the setuid() family of system calls to change from one user to another. However, the kernel does not know
anything about authentication: usernames, passwords, and so on. Practically everything related to
authentication happens in user space.
We discussed the mapping between user IDs and passwords in 7.3.1 The /etc/passwd File; now we’ll explain
how user processes access this mapping. We’ll begin with an oversimplified case, in which a user process
wants to know its username (the name corresponding to the effective user ID). On a traditional Unix system,
a process could do something like this to get its username:
1. The process asks the kernel for its effective user ID with the geteuid() system call.
2. The process opens the /etc/passwd file and starts reading at the beginning.
3. The process reads a line of the /etc/passwd file. If there’s nothing left to read, the process has failed to
find the username.
4. The process parses the line into fields (breaking out everything between the colons). The third field is the
user ID for the current line.
5. The process compares the ID from Step 4 to the ID from Step 1. If they’re identical, the first field in Step
4 is the desired username, and the process can stop searching and use this name.
6. The process moves on to the next line in /etc/passwd and goes back to Step 3.
This is a long procedure that’s usually much more complicated in reality.
7.9.1 Using Libraries for User Information
If every developer who needed to know the current username had to write all of the code you’ve just seen, the
www.EBooksWorld.ir
system would be a horrifyingly disjointed, buggy, bloated, and unmaintainable mess. Fortunately, we can use
standard libraries to perform repetitive tasks, so all you’d normally need to do to get a username is call a
function like getpwuid() in the standard library after you have the answer from geteuid(). (See the
manual pages for these calls for more on how they work.)
When the standard library is shared, you can make significant changes to the implementation without changing
any other program. For example, you can move away from using /etc/passwd for your users and use a network
service such as LDAP instead.
This approach has worked well for identifying usernames associated with user IDs, but passwords have proven
more troublesome. 7.3.1 The /etc/passwd File describes how, traditionally, the encrypted password was part
of /etc/passwd, so if you wanted to verify a password that a user entered, you’d encrypt whatever the user
typed and compare it to the contents of the /etc/passwd file.
This traditional implementation has the following limitations:
o It doesn’t set a system-wide standard for the encryption protocol.
o It assumes that you have access to the encrypted password.
o It assumes that you want to prompt the user for a password every time the user wants to access something
that requires authentication (which gets annoying).
o It assumes that you want to use passwords. If you want to use one-time tokens, smart cards, biometrics, or
some other form of user authentication, you have to add that support yourself.
Some of these limitations contributed to the development of the shadow password package discussed in 7.3.3
The /etc/shadow File, which took the first step in allowing system-wide password configuration. But the
solution to the bulk of the problems came with the design and implementation of PAM.
7.10 PAM
To accommodate flexibility in user authentication, in 1995 Sun Microsystems proposed a new standard called
Pluggable Authentication Modules (PAM), a system of shared libraries for authentication (Open Source
Software Foundation RFC 86.0, October 1995). To authenticate a user, an application hands the user to PAM
to determine whether the user can successfully identify itself. This way, it’s relatively easy to add support for
additional authentication techniques, such as two-factor and physical keys. In addition to authentication
mechanism support, PAM also provides a limited amount of authorization control for services (for example,
if you’d like to deny a service like cron to certain users).
Because there are many kinds of authentication scenarios, PAM employs a number of dynamically loadable
authentication modules. Each module performs a specific task; for example, the pam_unix.so module can
check a user’s password.
This is tricky business, to say the least. The programming interface isn’t easy, and it’s not clear that PAM
actually solves all of the existing problems. Nevertheless, PAM support is in nearly every program that
requires authentication on a Linux system, and most distributions use PAM. And because it works on top of
the existing Unix authentication API, integrating support into a client requires little, if any, extra work.
7.10.1 PAM Configuration
We’ll explore the basics of how PAM works by examining its configuration. You’ll normally find PAM’s
application configuration files in the /etc/pam.d directory (older systems may use a single /etc/pam.conf file).
Most installations include many files, so you may not know where to start. Some filenames should correspond
to parts of the system that you know already, such as cron and passwd.
Because the specific configuration in these files varies significantly between distributions, it can be difficult
www.EBooksWorld.ir
to find a common example. We’ll look at an example configuration line that you might find for chsh (the
change shell program):
auth requisite pam_shells.so
This line says that the user’s shell must be in /etc/shells in order for the user to successfully authenticate with
the chsh program. Let’s see how. Each configuration line has three fields: a function type, control argument,
and module, in that order. Here’s what they mean for this example:
o Function type. The function that a user application asks PAM to perform. Here, it’s auth, the task of
authenticating the user.
o Control argument. This setting controls what PAM does after success or failure of its action for the current
line (requisite in this example). We’ll get to this shortly.
o Module. The authentication module that runs for this line, determining what the line actually does. Here,
the pam_shells.so module checks to see whether the user’s current shell is listed in /etc/shells.
PAM configuration is detailed on the pam.conf(5) manual page. Let’s look at a few of the essentials.
Function Types
A user application can ask PAM to perform one of the following four functions:
o auth Authenticate a user (see if the user is who they say they are).
o account Check user account status (whether the user is authorized to do something, for example).
o session Perform something only for the user’s current session (such as displaying a message of the day).
o password Change a user’s password or other credentials.
For any configuration line, the module and function together determine PAM’s action. A module can have
more than one function type, so when determining the purpose of a configuration line, always remember to
consider the function and module as a pair. For example, the pam_unix.so module checks a password when
performing the auth function, but it sets a password when performing the password function.
Control Arguments and Stacked Rules
One important feature of PAM is that the rules specified by its configuration lines stack, meaning that you can
apply many rules when performing a function. This is why the control argument is important: The success or
failure of an action in one line can impact following lines or cause the entire function to succeed or fail.
There are two kinds of control arguments: the simple syntax and a more advanced syntax. Here are the three
major simple syntax control arguments that you’ll find in a rule:
o sufficient If this rule succeeds, the authentication is successful, and PAM does not need to look at any
more rules. If the rule fails, PAM proceeds to additional rules.
o requisite If this rule succeeds, PAM proceeds to additional rules. If the rule fails, the authentication is
unsuccessful, and PAM does not need to look at any more rules.
o required If this rule succeeds, PAM proceeds to additional rules. If the rule fails, PAM proceeds to
additional rules but will always return an unsuccessful authentication regardless of the end result of the
additional rules.
Continuing with the preceding example, here is an example stack for the chsh authentication function:
auth sufficient pam_rootok.so
auth requisite pam_shells.so
www.EBooksWorld.ir
auth sufficient pam_unix.so
auth required pam_deny.so
With this configuration, when the chsh command asks PAM to perform the authentication function, PAM
does the following (see Figure 7-4 for a flowchart):
1. The pam_rootok.so module checks to see if the root user is the one trying to authenticate. If so, it
immediately succeeds and attempts no further authentication. This works because the control argument is
set to sufficient, meaning that success from this action is good enough for PAM to immediately
report success back to chsh. Otherwise, it proceeds to Step 2.
2. The pam_shells.so module checks to see if the user’s shell is in /etc/shells. If the shell is not there, the
module returns failure, and the requisite control argument indicates that PAM must immediately
report this failure back to chsh and attempt no further authentication. Otherwise, the shell is in
/etc/shells, so the module returns success and fulfills the control flag of required; proceed to Step 3.
3. The pam_unix.so module asks the user for the user’s password and checks it. The control argument is set
to sufficient, so success from this module (a correct password) is enough for PAM to report success
to chsh. If the password is incorrect, PAM continues to Step 4.
4. The pam_deny.so module always fails, and because the required control argument is present, PAM
reports failure back to chsh. This is a default for when there’s nothing left to try. (Note that a
required control argument does not cause PAM to fail its function immediately—it will run any lines
left on its stack—but the report back to the application will always be of failure.)
www.EBooksWorld.ir
Figure 7-4. PAM rule execution flow
NOTE
Don’t confuse the terms function and action when working with PAM. The function is the high-level
goal: what the user application wants PAM to do (authenticate a user, for example). An action is a
specific step that PAM takes in order to reach that goal. Just remember that the user application
invokes the function first and that PAM takes care of the particulars with actions.
The advanced control argument syntax, denoted inside square brackets ([]), allows you to manually control
a reaction based on the specific return value of the module (not just success or failure). For details, see the
pam.conf(5) manual page; when you understand the simple syntax, you’ll have no trouble with the advanced
syntax.
Module Arguments
PAM modules can take arguments after the module name. You’ll often encounter this example with the
www.EBooksWorld.ir
pam_unix.so module:
auth sufficient pam_unix.so nullok
The nullok argument here says that the user can have no password (the default would be fail if the user has
no password).
7.10.2 Notes on PAM
Due to its control flow capability and module argument syntax, the PAM configuration syntax has many
features of a programming language and a certain degree of power. We’ve only scratched the surface so far,
but here are a few more tips on PAM:
o To find out which PAM modules are present on your system, try man -k pam_ (note the underscore). It
can be difficult to track down the location of modules. Try the locate unix_pam.so command and see
where that leads you.
o The manual pages contain the functions and arguments for each module.
o Many distributions automatically generate certain PAM configuration files, so it may not be wise to change
them directly in /etc/pam.d. Read the comments in your /etc/pam.d files before editing them; if they’re
generated files, the comments will tell you where they came from.
o The /etc/pam.d/other configuration file defines the default configuration for any application that lacks its
own configuration file. The default is often to deny everything.
o There are different ways to include additional configuration files in a PAM configuration file. The
@include syntax loads an entire configuration file, but you can also use a control argument to load only
the configuration for a particular function. The usage varies among distributions.
o PAM configuration doesn’t end with module arguments. Some modules can access additional files in
/etc/security, usually to configure per-user restrictions.
7.10.3 PAM and Passwords
Due to the evolution of Linux password verification over the years, a number of password configuration
artifacts remain that can cause confusion at times. The first to be aware of is the file /etc/login.defs. This is the
configuration file for the original shadow password suite. It contains information about the encryption
algorithm used for the shadow password file, but it’s rarely used on a modern system with PAM installed,
because the PAM configuration contains this information. This said, the encryption algorithm in /etc/login.defs
should match the PAM configuration in the rare case that you run into an application that doesn’t support PAM.
Where does PAM get its information about the password encryption scheme? Recall that there are two ways
for PAM to interact with passwords: the auth function (for verifying a password) and the password
function (for setting a password). It’s easiest to track down the password-setting parameter. The best way is
probably just to grep it:
$ grep password.*unix /etc/pam.d/*
The matching lines should contain pam_unix.so and look something like this:
password sufficient pam_unix.so obscure sha512
The arguments obscure and sha512 tell PAM what to do when setting a password. First, PAM checks to
see if the password is “obscure” enough (that is, the password isn’t too similar to the old password, among
other things), and then PAM uses the SHA512 algorithm to encrypt the new password.
But this happens only when a user sets a password, not when PAM is verifying a password. So how does PAM
know which algorithm to use when authenticating? Unfortunately, the configuration won’t tell you anything;
www.EBooksWorld.ir
there are no encryption arguments for pam_unix.so for the auth function. The manual pages also tell you
nothing.
It turns out that (as of this writing) pam_unix.so simply tries to guess the algorithm, usually by asking the
libcrypt library to do the dirty work of trying a whole bunch of things until something works or there’s nothing
left to try. Therefore, you normally don’t have to worry about the verification encryption algorithm.
7.11 Looking Forward
We’re now at about the midpoint in our progression through this book, having covered many of the vital
building blocks of a Linux system. The discussion of logging and users on a Linux system has introduced you
to what makes it possible to divide services and tasks into small, independent chunks that still know how to
interact to a certain extent.
This chapter dealt almost exclusively with user space, and we now need to refine our view of user-space
processes and the resources they consume. To do so, we’ll go back into the kernel in Chapter 8.
www.EBooksWorld.ir
Chapter 8. A Closer Look at Processes and Resource Utilization
This chapter takes you deeper into the relationships between processes, the kernel, and system resources.
There are three basic kinds of hardware resources: CPU, memory, and I/O. Processes vie for these resources,
and the kernel’s job is to allocate resources fairly. The kernel itself is also a resource—a software resource
that processes use to perform tasks such as creating new processes and communicating with other processes.
Many of the tools that you see in this chapter are often thought of as performance-monitoring tools. They’re
particularly helpful if your system is slowing to a crawl and you’re trying to figure out why. However, you
shouldn’t get too distracted by performance; trying to optimize a system that’s already working correctly is
often a waste of time. Instead, concentrate on understanding what the tools actually measure, and you’ll gain
great insight into how the kernel works.
8.1 Tracking Processes
You learned how to use ps in 2.16 Listing and Manipulating Processes to list processes running on your
system at a particular time. The ps command lists current processes, but it does little to tell you how processes
change over time. Therefore, it won’t really help you to determine which process is using too much CPU time
or memory.
The top program is often more useful than ps because it displays the current system status as well as many
of the fields in a ps listing, and it updates the display every second. Perhaps most important is that top shows
the most active processes (that is, those currently taking up the most CPU time) at the top of its display.
You can send commands to top with keystrokes. These are some of the most important commands:
Spacebar Updates the display immediately.
M Sorts by current resident memory usage.
T Sorts by total (cumulative) CPU usage.
P Sorts by current CPU usage (the default).
u Displays only one user’s processes.
f Selects different statistics to display.
? Displays a usage summary for all top commands.
Two other utilities for Linux, similar to top, offer an enhanced set of views and features: atop and htop.
Most of the extra features are available from other utilities. For example, htop has many of abilities of the
www.EBooksWorld.ir
lsof command described in the next section.
8.2 Finding Open Files with lsof
The lsof command lists open files and the processes using them. Because Unix places a lot of emphasis on
files, lsof is among the most useful tools for finding trouble spots. But lsof doesn’t stop at regular files—
it can list network resources, dynamic libraries, pipes, and more.
8.2.1 Reading the lsof Output
Running lsof on the command line usually produces a tremendous amount of output. Below is a fragment
of what you might see. This output includes open files from the init process as well as a running vi process:
$ lsof
COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME
init 1 root cwd DIR 8,1 4096 2 /
init 1 root rtd DIR 8,1 4096 2 /
init 1 root mem REG 8, 47040 9705817 /lib/i386-linux-
gnu/libnss_files-2.15.so
init 1 root mem REG 8,1 42652 9705821 /lib/i386-linux-
gnu/libnss_nis-2.15.so
init 1 root mem REG 8,1 92016 9705833 /lib/i386-linux-
gnu/libnsl-2.15.so
--snip--
vi 22728 juser cwd DIR 8,1 4096 14945078 /home/juser/w/c
vi 22728 juser 4u REG 8,1 1288 1056519 /home/juser/w/c/f
--snip--
The output shows the following fields (listed in the top row):
o COMMAND. The command name for the process that holds the file descriptor.
o PID. The process ID.
o USER. The user running the process.
o FD. This field can contain two kinds of elements. In the output above, the FD column shows the purpose of
the file. The FD field can also list the file descriptor of the open file—a number that a process uses together
with the system libraries and kernel to identify and manipulate a file.
o TYPE. The file type (regular file, directory, socket, and so on).
o DEVICE. The major and minor number of the device that holds the file.
o SIZE. The file’s size.
o NODE. The file’s inode number.
o NAME. The filename.
The lsof(1) manual page contains a full list of what you might see for each field, but you should be able to
figure out what you’re looking at just by looking at the output. For example, look at the entries with cwd in
www.EBooksWorld.ir
the FD field as highlighted in bold. These lines indicate the current working directories of the processes.
Another example is the very last line, which shows a file that the user is currently editing with vi.
8.2.2 Using lsof
There are two basic approaches to running lsof:
o List everything and pipe the output to a command like less, and then search for what you’re looking for.
This can take a while due to the amount of output generated.
o Narrow down the list that lsof provides with command-line options.
You can use command-line options to provide a filename as an argument and have lsof list only the entries
that match the argument. For example, the following command displays entries for open files in /usr:
$ lsof /usr
To list the open files for a particular process ID, run:
$ lsof -p pid
For a brief summary of lsof’s many options, run lsof -h. Most options pertain to the output format. (See
Chapter 10 for a discussion of the lsof network features.)
NOTE
lsof is highly dependent on kernel information. If you upgrade your kernel and you’re not
routinely updating everything, you might need to upgrade lsof. In addition, if you perform a
distribution update to both the kernel and lsof, the updated lsof might not work until you reboot
with the new kernel.
8.3 Tracing Program Execution and System Calls
The tools we’ve seen so far examine active processes. However, if you have no idea why a program dies
almost immediately after starting up, even lsof won’t help you. In fact, you’d have a difficult time even
running lsof concurrently with a failed command.
The strace (system call trace) and ltrace (library trace) commands can help you discover what a program
attempts to do. These tools produce extraordinarily large amounts of output, but once you know what to look
for, you’ll have more tools at your disposal for tracking down problems.
8.3.1 strace
Recall that a system call is a privileged operation that a user-space process asks the kernel to perform, such as
opening and reading data from a file. The strace utility prints all the system calls that a process makes. To
see it in action, run this command:
$ strace cat /dev/null
In Chapter 1, you learned that when one process wants to start another process, it invokes the fork() system
call to spawn a copy of itself, and then the copy uses a member of the exec() family of system calls to start
running a new program. The strace command begins working on the new process (the copy of the original
process) just after the fork() call. Therefore, the first lines of the output from this command should show
execve() in action, followed by a memory initialization call, brk(), as follows:
execve("/bin/cat", ["cat", "/dev/null"], [/* 58 vars */]) = 0
brk(0) = 0x9b65000
www.EBooksWorld.ir
The next part of the output deals primarily with loading shared libraries. You can ignore this unless you really
want to know what the shared library system does.
access("/etc/ld.so.nohwcap", F_OK) = -1 ENOENT (No such file or
directory)
mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1,
0) = 0xb77b5000
access("/etc/ld.so.preload", R_OK) = -1 ENOENT (No such file or
directory)
open("/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
--snip--
open("/lib/libc.so.6", O_RDONLY) = 3
read(3, "\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0\3\0\1\0\0\0\200^\1"...,
1024)= 1024
In addition, skip past the mmap output until you get to the lines that look like this:
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 6), ...}) = 0
open("/dev/null", O_RDONLY|O_LARGEFILE) = 3
fstat64(3, {st_mode=S_IFCHR|0666, st_rdev=makedev(1, 3), ...}) = 0
fadvise64_64(3, 0, 0, POSIX_FADV_SEQUENTIAL)= 0
read(3,"", 32768) = 0
close(3) = 0
close(1) = 0
close(2) = 0
exit_group(0) = ?
This part of the output shows the command at work. First, look at the open() call, which opens a file. The
3 is a result that means success (3 is the file descriptor that the kernel returns after opening the file). Below
that, you see where cat reads from /dev/null (the read() call, which also has 3 as the file descriptor). Then
there’s nothing more to read, so the program closes the file descriptor and exits with exit_group().
What happens when there’s a problem? Try strace cat not_a_file instead and examine the open()
call in the resulting output:
open("not_a_file", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or
directory)
Because open() couldn’t open the file, it returned -1 to signal an error. You can see that strace reports
the exact error and gives you a small description of the error.
Missing files are the most common problems with Unix programs, so if the system log and other log
information aren’t very helpful and you have nowhere else to turn, strace can be of great use. You can even
use it on daemons that detach themselves. For example:
$ strace -o crummyd_strace -ff crummyd
In this example, the -o option to strace logs the action of any child process that crummyd spawns into
www.EBooksWorld.ir
crummyd_strace.pid, where pid is the process ID of the child process.
8.3.2 ltrace
The ltrace command tracks shared library calls. The output is similar to that of strace, which is why
we’re mentioning it here, but it doesn’t track anything at the kernel level. Be warned that there are many more
shared library calls than system calls. You’ll definitely need to filter the output, and ltrace itself has many
built-in options to assist you.
NOTE
See 15.1.4 Shared Libraries for more on shared libraries. The ltrace command doesn’t work on
statically linked binaries.
8.4 Threads
In Linux, some processes are divided into pieces called threads. A thread is very similar to a process—it has
an identifier (TID, or thread ID), and the kernel schedules and runs threads just like processes. However,
unlike separate processes, which usually do not share system resources such as memory and I/O connections
with other processes, all threads inside a single process share their system resources and some memory.
8.4.1 Single-Threaded and Multithreaded Processes
Many processes have only one thread. A process with one thread is single-threaded, and a process with more
than one thread is multithreaded. All processes start out single-threaded. This starting thread is usually called
the main thread. The main thread may then start new threads in order for the process to become multithreaded,
similar to the way a process can call fork() to start a new process.
NOTE
It’s rare to refer to threads at all when a process is single-threaded. This book will not mention
threads unless multithreaded processes make a difference in what you see or experience.
The primary advantage of a multithreaded process is that when the process has a lot to do, threads can run
simultaneously on multiple processors, potentially speeding up computation. Although you can also achieve
simultaneous computation with multiple processes, threads start faster than processes, and it is often easier
and/or more efficient for threads to intercommunicate using their shared memory than it is for processes to
communicate over a channel such as a network connection or a pipe.
Some programs use threads to overcome problems managing multiple I/O resources. Traditionally, a process
would sometimes use fork() to start a new subprocess in order to deal with a new input or output stream.
Threads offer a similar mechanism without the overhead of starting a new process.
8.4.2 Viewing Threads
By default, the output from the ps and top commands shows only processes. To display the thread
information in ps, add the m option. Here is some sample output:
Example 8-1. Viewing threads with ps m
$ ps m
PID TTY STAT TIME COMMAND
3587 pts/3 - 0:00 bash➊
- - Ss 0:00 -
3592 pts/4 - 0:00 bash➋
www.EBooksWorld.ir
- - Ss 0:00 -
12287 pts/8 - 0:54 /usr/bin/python /usr/bin/gm-notify➌
- - SL1 0:48 -
- - SL1 0:00 -
- - SL1 0:06 -
- - SL1 0:00 -
Example 8-1 shows processes along with threads. Each line with a number in the PID column (at ➊, ➋, and
➌) represents a process, as in the normal ps output. The lines with the dashes in the PID column represent
the threads associated with the process. In this output, the processes at ➊ and ➋ have only one thread each,
but process 12287 at ➌ is multithreaded with four threads.
If you would like to view the thread IDs with ps, you can use a custom output format. This example shows
only the process IDs, thread IDs, and command:
Example 8-2. Showing process IDs and thread IDs with ps m
$ ps m -o pid,tid,command
PID TID COMMAND
3587 - bash
- 3587 -
3592 - bash
- 3592 -
12287 - /usr/bin/python /usr/bin/gm-notify
- 12287 -
- 12288 -
- 12289 -
- 12295 -
The sample output in Example 8-2 corresponds to the threads shown in Example 8-1. Notice that the thread
IDs of the single-threaded processes are identical to the process IDs; this is the main thread. For the
multithreaded process 12287, thread 12287 is also the main thread.
NOTE
Normally, you won’t interact with individual threads as you would processes. You need to know a
lot about how a multithreaded program was written in order to act on one thread at a time, and
even then, doing so might not be a good idea.
Threads can confuse things when it comes to resource monitoring because individual threads in a
multithreaded process can consume resources simultaneously. For example, top doesn’t show threads by
default; you’ll need to press H to turn it on. For most of the resource monitoring tools that you’re about to see,
you’ll have to do a little extra work to turn on the thread display.
8.5 Introduction to Resource Monitoring
Now we’ll discuss some topics in resource monitoring, including processor (CPU) time, memory, and disk
I/O. We’ll examine utilization on a systemwide scale, as well as on a per-process basis.
Many people touch the inner workings of the Linux kernel in the interest of improving performance. However,
most Linux systems perform well under a distribution’s default settings, and you can spend days trying to tune
your machine’s performance without meaningful results, especially if you don’t know what to look for. So
rather than think about performance as you experiment with the tools in this chapter, think about seeing the
www.EBooksWorld.ir
kernel in action as it divides resources among processes.
8.6 Measuring CPU Time
To monitor one or more specific processes over time, use the -p option to top, with this syntax:
$ top -p pid1 [-p pid2 ...]
To find out how much CPU time a command uses during its lifetime, use time. Most shells have a built-in
time command that doesn’t provide extensive statistics, so you’ll probably need to run /usr/bin/time.
For example, to measure the CPU time used by ls, run
$ /usr/bin/time ls
After ls terminates, time should print output like that below. The key fields are in boldface:
0.05user 0.09system 0:00.44elapsed 31%CPU (0avgtext+0avgdata
0maxresident)k
0inputs+0outputs (125major+51minor)pagefaults 0swaps
o User time. The number of seconds that the CPU has spent running the program’s own code. On modern
processors, some commands run so quickly, and therefore the CPU time is so low, that time rounds down
to zero.
o System time. How much time the kernel spends doing the process’s work (for example, reading files and
directories).
o Elapsed time. The total time it took to run the process from start to finish, including the time that the CPU
spent doing other tasks. This number is normally not very useful for performance measurement, but
subtracting the user and system time from elapsed time can give you a general idea of how long a process
spends waiting for system resources.
The remainder of the output primarily details memory and I/O usage. You’ll learn more about the page fault
output in 8.9 Memory.
8.7 Adjusting Process Priorities
You can change the way the kernel schedules a process in order to give the process more or less CPU time
than other processes. The kernel runs each process according to its scheduling priority, which is a number
between –20 and 20, with –20 being the foremost priority. (Yes, this can be confusing.)
The ps -l command lists the current priority of a process, but it’s a little easier to see the priorities in action
with the top command, as shown here:
$ top
Tasks: 244 total, 2 running, 242 sleeping, 0 stopped, 0 zombie
Cpu(s): 31.7%us, 2.8%sy, 0.0%ni, 65.4%id, 0.2%wa, 0.0%hi, 0.0%si,
0.0%st
Mem: 6137216k total, 5583560k used, 553656k free, 72008k buffers
Swap: 4135932k total, 694192k used, 3441740k free, 767640k cached
PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND
28883 bri 20 0 1280m 763m 32m S 58 12.7 213:00.65 chromium-
www.EBooksWorld.ir
browse
1175 root 20 0 210m 43m 28m R 44 0.7 14292:35 Xorg
4022 bri 20 0 413m 201m 28m S 29 3.4 3640:13 chromium-
browse
4029 bri 20 0 378m 206m 19m S 2 3.5 32:50.86 chromium-
browse
3971 bri 20 0 881m 359m 32m S 2 6.0 563:06.88 chromium-
browse
5378 bri 20 0 152m 10m 7064 S 1 0.2 24:30.21 compiz
3821 bri 20 0 312m 37m 14m S 0 0.6 29:25.57 soffice.bin
4117 bri 20 0 321m 105m 18m S 0 1.8 34:55.01 chromium-
browse
4138 bri 20 0 331m 99m 21m S 0 1.7 121:44.19 chromium-
browse
4274 bri 20 0 232m 60m 13m S 0 1.0 37:33.78 chromium-
browse
4267 bri 20 0 1102m 844m 11m S 0 14.1 29:59.27 chromium-
browse
2327 bri 20 0 301m 43m 16m S 0 0.7 109:55.65 unity-2d-shell
In the top output above, the PR (priority) column lists the kernel’s current schedule priority for the process.
The higher the number, the less likely the kernel is to schedule the process if others need CPU time. The
schedule priority alone does not determine the kernel’s decision to give CPU time to a process, and it changes
frequently during program execution according to the amount of CPU time that the process consumes.
Next to the priority column is the nice value (NI) column, which gives a hint to the kernel’s scheduler. This is
what you care about when trying to influence the kernel’s decision. The kernel adds the nice value to the
current priority to determine the next time slot for the process.
By default, the nice value is 0. Now, say you’re running a big computation in the background that you don’t
want to bog down your interactive session. To have that process take a backseat to other processes and run
only when the other tasks have nothing to do, you could change the nice value to 20 with the renice
command (where pid is the process ID of the process that you want to change):
$ renice 20 pid
If you’re the superuser, you can set the nice value to a negative number, but doing so is almost always a bad
idea because system processes may not get enough CPU time. In fact, you probably won’t need to alter nice
values much because many Linux systems have only a single user, and that user does not perform much real
computation. (The nice value was much more important back when there were many users on a single
machine.)
8.8 Load Averages
CPU performance is one of the easier metrics to measure. The load average is the average number of processes
currently ready to run. That is, it is an estimate of the number of processes that are capable of using the CPU
at any given time. When thinking about a load average, keep in mind that most processes on your system are
www.EBooksWorld.ir
usually waiting for input (from the keyboard, mouse, or network, for example), meaning that most processes
are not ready to run and should contribute nothing to the load average. Only processes that are actually doing
something affect the load average.
8.8.1 Using uptime
The uptime command tells you three load averages in addition to how long the kernel has been running:
$ uptime
... up 91 days, ... load average: 0.08, 0.03, 0.01
The three bolded numbers are the load averages for the past 1 minute, 5 minutes, and 15 minutes, respectively.
As you can see, this system isn’t very busy: An average of only 0.01 processes have been running across all
processors for the past 15 minutes. In other words, if you had just one processor, it was only running user-
space applications for 1 percent of the last 15 minutes. (Traditionally, most desktop systems would exhibit a
load average of about 0 when you were doing anything except compiling a program or playing a game. A load
average of 0 is usually a good sign, because it means that your processor isn’t being challenged and you’re
saving power.)
NOTE
User interface components on current desktop systems tend to occupy more of the CPU than
those in the past. For example, on Linux systems, a web browser’s Flash plugin can be a
particularly notorious resource hog, and Flash applications can easily occupy much of a system’s
CPU and memory due to poor all-around implementation.
If a load average goes up to around 1, a single process is probably using the CPU nearly all of the time. To
identify that process, use the top command; the process will usually rise to the the top of the display.
Most modern systems have more than one processor core or CPU, so multiple processes can easily run
simultaneously. If you have two cores, a load average of 1 means that only one of the cores is likely active at
any given time, and a load average of 2 means that both cores have just enough to do all of the time.
8.8.2 High Loads
A high load average does not necessarily mean that your system is having trouble. A system with enough
memory and I/O resources can easily handle many running processes. If your load average is high and your
system still responds well, don’t panic: The system just has a lot of processes sharing the CPU. The processes
have to compete with each other for processor time, and as a result they’ll take longer to perform their
computations than they would if they were each allowed to use the CPU all of the time. Another case where
you might see a high load average as normal is a web server, where processes can start and terminate so
quickly that the load average measurement mechanism can’t function effectively.
However, if you sense that the system is slow and the load average is high, you might be running into memory
performance problems. When the system is low on memory, the kernel can start to thrash, or rapidly swap
memory for processes to and from the disk. When this happens, many processes will become ready to run, but
their memory might not be available, so they will remain in the ready-to-run state (and contribute to the load
average) for much longer than they normally would.
We’ll now look at memory in much more detail.
8.9 Memory
One of the simplest ways to check your system’s memory status as a whole is to run the free command or
view /proc/meminfo to see how much real memory is being used for caches and buffers. As we’ve just
www.EBooksWorld.ir
mentioned, performance problems can arise from memory shortages. If there isn’t much cache/buffer memory
being used (and the rest of the real memory is taken), you may need more memory. However, it’s too easy to
blame a shortage of memory for every performance problem on your machine.
8.9.1 How Memory Works
Recall from Chapter 1 that the CPU has a memory management unit (MMU) that translates the virtual memory
addresses used by processes into real ones. The kernel assists the MMU by breaking the memory used by
processes into smaller chunks called pages. The kernel maintains a data structure, called a page table, that
contains a mapping of a processes’ virtual page addresses to real page addresses in memory. As a process
accesses memory, the MMU translates the virtual addresses used by the process into real addresses based on
the kernel’s page table.
A user process does not actually need all of its pages to be immediately available in order to run. The kernel
generally loads and allocates pages as a process needs them; this system is known as on-demand paging or
just demand paging. To see how this works, consider how a program starts and runs as a new process:
1. The kernel loads the beginning of the program’s instruction code into memory pages.
2. The kernel may allocate some working-memory pages to the new process.
3. As the process runs, it might reach a point where the next instruction in its code isn’t in any of the pages
that the kernel initially loaded. At this point, the kernel takes over, loads the necessary pages into
memory, and then lets the program resume execution.
4. Similarly, if the program requires more working memory than was initially allocated, the kernel handles
it by finding free pages (or by making room) and assigning them to the process.
8.9.2 Page Faults
If a memory page is not ready when a process wants to use it, the process triggers a page fault. In the event of
a page fault, the kernel takes control of the CPU from the process in order to get the page ready. There are two
kinds of page faults: minor and major.
Minor Page Faults
A minor page fault occurs when the desired page is actually in main memory but the MMU doesn’t know
where it is. This can happen when the process requests more memory or when the MMU doesn’t have enough
space to store all of the page locations for a process. In this case, the kernel tells the MMU about the page and
permits the process to continue. Minor page faults aren’t such a big deal, and many occur as a process runs.
Unless you need maximum performance from some memory-intensive program, you probably shouldn’t
worry about them.
Major Page Faults
A major page fault occurs when the desired memory page isn’t in main memory at all, which means that the
kernel must load it from the disk or some other slow storage mechanism. A lot of major page faults will bog
the system down because the kernel must do a substantial amount of work to provide the pages, robbing
normal processes of their chance to run.
Some major page faults are unavoidable, such as those that occur when you load the code from disk when
running a program for the first time. The biggest problems happen when you start running out of memory and
the kernel starts to swap pages of working memory out to the disk in order to make room for new pages.
Watching Page Faults
You can drill down to the page faults for individual processes with the ps, top, and time commands. The
following command shows a simple example of how the time command displays page faults. (The output of
www.EBooksWorld.ir
the cal command doesn’t matter, so we’re discarding it by redirecting that to /dev/null.)
$ /usr/bin/time cal > /dev/null
0.00user 0.00system 0:00.06elapsed 0%CPU (0avgtext+0avgdata
3328maxresident)k
648inputs+0outputs (2major+254minor)pagefaults 0swaps
As you can see from the bolded text, when this program ran, there were 2 major page faults and 254 minor
ones. The major page faults occurred when the kernel needed to load the program from the disk for the first
time. If you ran the command again, you probably wouldn’t get any major page faults because the kernel
would have cached the pages from the disk.
If you’d rather see the page faults of processes as they’re running, use top or ps. When running top, use f
to change the displayed fields and u to display the number of major page faults. (The results will show up in
a new, nFLT column. You won’t see the minor page faults.)
When using ps, you can use a custom output format to view the page faults for a particular process. Here’s
an example for process ID 20365:
$ ps -o pid,min_flt,maj_flt 20365
PID MINFL MAJFL
20365 834182 23
The MINFL and MAJFL columns show the numbers of minor and major page faults. Of course, you can
combine this with any other process selection options, as described in the ps(1) manual page.
Viewing page faults by process can help you zero in on certain problematic components. However, if you’re
interested in your system performance as a whole, you need a tool to summarize CPU and memory action
across all processes.
8.10 Monitoring CPU and Memory Performance with vmstat
Among the many tools available to monitor system performance, the vmstat command is one of the oldest,
with minimal overhead. You’ll find it handy for getting a high-level view of how often the kernel is swapping
pages in and out, how busy the CPU is, and IO utilization.
The trick to unlocking the power of vmstat is to understand its output. For example, here’s some output
from vmstat 2, which reports statistics every 2 seconds:
$ vmstat 2
procs -----------memory---------- ---swap-- -----io---- -system-- ----
cpu----
r b swpd free buff cache si so bi bo in cs us sy id wa
2 0 320416 3027696 198636 1072568 0 0 1 1 2 0 15 2 83 0
2 0 320416 3027288 198636 1072564 0 0 0 1182 407 636 1 0 99 0
1 0 320416 3026792 198640 1072572 0 0 0 58 281 537 1 0 99 0
0 0 320416 3024932 198648 1074924 0 0 0 308 318 541 0 0 99 1
0 0 320416 3024932 198648 1074968 0 0 0 0 208 416 0 0 99 0
www.EBooksWorld.ir
0 0 320416 3026800 198648 1072616 0 0 0 0 207 389 0 0 100 0
The output falls into categories: procs for processes, memory for memory usage, swap for the pages pulled
in and out of swap, io for disk usage, system for the number of times the kernel switches into kernel code,
and cpu for the time used by different parts of the system.
The preceding output is typical for a system that isn’t doing much. You’ll usually start looking at the second
line of output—the first one is an average for the entire uptime of the system. For example, here the system
has 320416KB of memory swapped out to the disk (swpd) and around 3025000KB (3 GB) of real memory
free. Even though some swap space is in use, the zero-valued si (swap-in) and so (swap-out) columns
report that the kernel is not currently swapping anything in or out from the disk. The buff column indicates
the amount of memory that the kernel is using for disk buffers (see 4.2.5 Disk Buffering, Caching, and
Filesystems).
On the far right, under the CPU heading, you see the distribution of CPU time in the us, sy, id, and wa
columns. These list (in order) the percentage of time that the CPU is spending on user tasks, system (kernel)
tasks, idle time, and waiting for I/O. In the preceding example, there aren’t too many user processes running
(they’re using a maximum of 1 percent of the CPU); the kernel is doing practically nothing, while the CPU is
sitting around doing nothing 99 percent of the time.
Now, watch what happens when a big program starts up sometime later (the first two lines occur right before
the program runs):
Example 8-3. Memory activity
procs -----------memory---------- ---swap-- -----io---- -system-- ----
cpu----
r b swpd free buff cache si so bi bo in cs us sy id wa
1 0 320412 2861252 198920 1106804 0 0 0 0 2477 4481 25 2 72
0➊
1 0 320412 2861748 198924 1105624 0 0 0 40 2206 3966 26 2 72 0
1 0 320412 2860508 199320 1106504 0 0 210 18 2201 3904 26 2 71 1
1 1 320412 2817860 199332 1146052 0 0 19912 0 2446 4223 26 3 63 8
2 2 320284 2791608 200612 1157752 202 0 4960 854 3371 5714 27 3 51
18➋
1 1 320252 2772076 201076 1166656 10 0 2142 1190 4188 7537 30 3 53
14
0 3 320244 2727632 202104 1175420 20 0 1890 216 4631 8706 36 4 46
14
As you can see at ➊ in Example 8-3, the CPU starts to see some usage for an extended period, especially from
user processes. Because there is enough free memory, the amount of cache and buffer space used starts to
increase as the kernel starts to use the disk more.
Later on, we see something interesting: Notice at ➋ that the kernel pulls some pages into memory that were
once swapped out (the si column). This means that the program that just ran probably accessed some pages
shared by another process. This is common; many processes use the code in certain shared libraries only when
starting up.
Also notice from the b column that a few processes are blocked (prevented from running) while waiting for
memory pages. Overall, the amount of free memory is decreasing, but it’s nowhere near being depleted.
There’s also a fair amount of disk activity, as seen by the increasing numbers in the bi (blocks in) and bo
www.EBooksWorld.ir
(blocks out) columns.
The output is quite different when you run out of memory. As the free space depletes, both the buffer and
cache sizes decrease because the kernel increasingly needs the space for user processes. Once there is nothing
left, you’ll start to see activity in the so (swapped out) column as the kernel starts moving pages onto the disk,
at which point nearly all of the other output columns change to reflect the amount of work that the kernel is
doing. You see more system time, more data going in and out of the disk, and more processes blocked because
the memory they want to use is not available (it has been swapped out).
We haven’t explained all of the vmstat output columns. You can dig deeper into them in the vmstat(8)
manual page, but you might have to learn more about kernel memory management first from a class or a book
like Operating System Concepts, 9th edition (Wiley, 2012) in order to understand them.
8.11 I/O Monitoring
By default, vmstat shows you some general I/O statistics. Although you can get very detailed per-partition
resource usage with vmstat -d, you’ll get a lot of output from this option, which might be overwhelming.
Instead, try starting out with a tool just for I/O called iostat.
8.11.1 Using iostat
Like vmstat, when run without any options, iostat shows the statistics for your machine’s current uptime:
$ iostat
[kernel information]
avg-cpu: %user %nice %system %iowait %steal %idle
4.46 0.01 0.67 0.31 0.00 94.55
Device: tp s kB_read/s kB_wrtn/s kB_read kB_wrtn
sda 4.6 7 7.2 8 49.86 9493727 65011716
sde 0.0 0 0.0 0 0.00 1230 0
The avg-cpu part at the top reports the same CPU utilization information as other utilities that you’ve seen
in this chapter, so skip down to the bottom, which shows you the following for each device:
tps Average number of data transfers per second
kB_read/s Average number of kilobytes read per second
kB_wrtn/s Average number of kilobytes written per second
kB_read Total number of kilobytes read
kB_wrtn Total number of kilobytes written
Another similarity to vmstat is that you can give an interval argument, such as iostat 2, to give an update
every 2 seconds. When using an interval, you might want to display only the device report by using the -d
option (such as iostat -d 2).
By default, the iostat output omits partition information. To show all of the partition information, use the
www.EBooksWorld.ir
-p ALL option. Because there are many partitions on a typical system, you’ll get a lot of output. Here’s part
of what you might see:
$ iostat -p ALL
--snip
--Device: tps kB_read/s kB_wrtn/s kB_read
kB_wrtn
--snip-
sda 4.67 7.27 49.83 9496139
65051472
sda1 4.38 7.16 49.51 9352969
64635440
sda2 0.00 0.00 0.00 6
0
sda5 0.01 0.11 0.32 141884
416032
scd0 0.00 0.00 0.00 0
0
--snip--
sde 0.00 0.00 0.00 1230
0
In this example, sda1, sda2, and sda5 are all partitions of the sda disk, so there will be some overlap
between the read and written columns. However, the sum of the partition columns won’t necessarily add up
to the disk column. Although a read from sda1 also counts as a read from sda, keep in mind that you can
read from sda directly, such as when reading the partition table.
8.11.2 Per-Process I/O Utilization and Monitoring: iotop
If you need to dig even deeper to see I/O resources used by individual processes, the iotop tool can help.
Using iotop is similar to using top. There is a continuously updating display that shows the processes using
the most I/O, with a general summary at the top:
# iotop
Total DISK READ: 4.76 K/s | Total DISK WRITE: 333.31 K/s
TID PRIO USER DISK READ DISK WRITE SWAPIN IO> COMMAND
260 be/3 root 0.00 B/s 38.09 K/s 0.00 % 6.98 % [jbd2/sda1-
8]
2611 be/4 juser 4.76 K/s 10.32 K/s 0.00 % 0.21 % zeitgeist-
daemon
2636 be/4 juser 0.00 B/s 84.12 K/s 0.00 % 0.20 % zeitgeist-
fts
1329 be/4 juser 0.00 B/s 65.87 K/s 0.00 % 0.03 % soffice.b~ash-
pipe=6
www.EBooksWorld.ir
6845 be/4 juser 0.00 B/s 812.63 B/s 0.00 % 0.00 % chromium-browser
19069 be/4 juser 0.00 B/s 812.63 B/s 0.00 % 0.00 % rhythmbox
Along with the user, command, and read/write columns, notice that there is a TID column (thread ID) instead
of a process ID. The iotop tool is one of the few utilities that displays threads instead of processes.
The PRIO (priority) column indicates the I/O priority. It’s similar to the CPU priority that you’ve already seen,
but it affects how quickly the kernel schedules I/O reads and writes for the process. In a priority such as be/4,
the be part is the scheduling class, and the number is the priority level. As with CPU priorities, lower numbers
are more important; for example, the kernel allows more time for I/O for a process with be/3 than one with
be/4.
The kernel uses the scheduling class to add more control for I/O scheduling. You’ll see three scheduling classes
from iotop:
o be Best-effort. The kernel does its best to fairly schedule I/O for this class. Most processes run under this
I/O scheduling class.
o rt Real-time. The kernel schedules any real-time I/O before any other class of I/O, no matter what.
o idle Idle. The kernel performs I/O for this class only when there is no other I/O to be done. There is no
priority level for the idle scheduling class.
You can check and change the I/O priority for a process with the ionice utility; see the ionice(1) manual
page for details. You probably will never need to worry about the I/O priority, though.
8.12 Per-Process Monitoring with pidstat
You’ve seen how you can monitor specific processes with utilities such as top and iotop. However, this
display refreshes over time, and each update erases the previous output. The pidstat utility allows you to
see the resource consumption of a process over time in the style of vmstat. Here’s a simple example for
monitoring process 1329, updating every second:
$ pidstat -p 1329 1
Linux 3.2.0-44-generic-pae (duplex) 07/01/2015 _i686_ (4 CPU)
09:26:55 PM PID %usr %system %guest %CPU CPU Command
09:27:03 PM 1329 8.00 0.00 0.00 8.00 1 myprocess
09:27:04 PM 1329 0.00 0.00 0.00 0.00 3 myprocess
09:27:05 PM 1329 3.00 0.00 0.00 3.00 1 myprocess
09:27:06 PM 1329 8.00 0.00 0.00 8.00 3 myprocess
09:27:07 PM 1329 2.00 0.00 0.00 2.00 3 myprocess
09:27:08 PM 1329 6.00 0.00 0.00 6.00 2 myprocess
The default output shows the percentages of user and system time and the overall percentage of CPU time,
and it even tells you which CPU the process was running on. (The %guest column here is somewhat odd—
it’s the percentage of time that the process spent running something inside a virtual machine. Unless you’re
running a virtual machine, don’t worry about this.)
Although pidstat shows CPU utilization by default, it can do much more. For example, you can use the -
r option to monitor memory and -d to turn on disk monitoring. Try them out, and then look at the pidstat(1)
manual page to see even more options for threads, context switching, or just about anything else that we’ve
www.EBooksWorld.ir
talked about in this chapter.
8.13 Further Topics
One reason there are so many tools to measure resource utilization is that a wide array of resource types are
consumed in many different ways. In this chapter, you’ve seen CPU, memory, and I/O as system resources
being consumed by processes, threads inside processes, and the kernel.
The other reason that the tools exist is that the resources are limited and, for a system to perform well, its
components must strive to consume fewer resources. In the past, many users shared a machine, so it was
necessary to make sure that each user had a fair share of resources. Now, although a modern desktop computer
may not have multiple users, it still has many processes competing for resources. Likewise, high-performance
network servers require intense system resource monitoring.
Further topics in resource monitoring and performance analysis include the following:
o sar (System Activity Reporter) The sar package has many of the continuous monitoring capabilities of
vmstat, but it also records resource utilization over time. With sar, you can look back at a particular
time to see what your system was doing. This is handy when you have a past system event that you want to
analyze.
o acct (Process accounting) The acct package can record the processes and their resource utilization.
o Quotas. You can limit many system resources on a per-process or peruser basis. See
/etc/security/limits.conf for some of the CPU and memory options; there’s also a limits.conf(5)
manual page. This is a PAM feature, so processes are subject to this only if they’ve been started from
something that uses PAM (such as a login shell). You can also limit the amount of disk space that a user can
use with the quota system.
If you’re interested in systems tuning and performance in particular, Systems Performance: Enterprise and
the Cloud by Brendan Gregg (Prentice Hall, 2013) goes into much more detail.
We also haven’t yet touched on the many, many tools that can be used to monitor network resource utilization.
To use those, you first have to understand how the network works. That’s where we’re headed next.
www.EBooksWorld.ir
Chapter 9. Understanding your Network and its Configuration
Networking is the practice of connecting computers and sending data between them. That sounds simple
enough, but to understand how it works, you need to ask two fundamental questions:
o How does the computer sending the data know where to send its data?
o When the destination computer receives the data, how does it know what it just received?
A computer answers these questions by using a series of components, with each one responsible for a certain
aspect of sending, receiving, and identifying data. The components are arranged in groups that form network
layers, which stack on top of each other in order to form a complete system. The Linux kernel handles
networking in a similar way to the SCSI subsystem described in Chapter 3.
Because each layer tends to be independent, it’s possible to build networks with many different combinations
of components. This is where network configuration can become very complicated. For this reason, we’ll
begin this chapter by looking at the layers in very simple networks. You’ll learn how to view your own network
settings, and when you understand the basic workings of each layer, you’ll be ready to learn how to configure
those layers by yourself. Finally, you’ll move on to more advanced topics like building your own networks
and configuring firewalls. (Skip over that material if your eyes start to glaze over; you can always come back.)
9.1 Network Basics
Before getting into the theory of network layers, take a look at the simple network shown in Figure 9-1.
Figure 9-1. A typical local area network with a router that provides Internet access
This type of network is ubiquitous; most home and small office networks are configured this way. Each
machine connected to the network is called a host. The hosts are connected to a router, which is a host that
can move data from one network to another. These machines (here, Hosts A, B, and C) and the router form a
local area network (LAN). The connections on the LAN can be wired or wireless.
www.EBooksWorld.ir
The router is also connected to the Internet—the cloud in the figure. Because the router is connected to both
the LAN and the Internet, all machines on the LAN also have access to the Internet through the router. One of
the goals of this chapter is to see how the router provides this access.
Your initial point of view will be from a Linux-based machine such as Host A on the LAN in Figure 9-1.
9.1.1 Packets
A computer transmits data over a network in small chunks called packets, which consist of two parts: a header
and a payload. The header contains identifying information such as the origin/destination hosts and basic
protocol. The payload, on the other hand, is the actual application data that the computer wants to send (for
example, HTML or image data).
Packets allow a host to communicate with others “simultaneously,” because hosts can send, receive, and
process packets in any order, regardless of where they came from or where they’re going. Breaking messages
into smaller units also makes it easier to detect and compensate for errors in transmission.
For the most part, you don’t have to worry about translating between packets and the data that your application
uses, because the operating system has facilities that do this for you. However, it is helpful to know the role
of packets in the network layers that you’re about to see.
9.2 Network Layers
A fully functioning network includes a full set of network layers called a network stack. Any functional
network has a stack. The typical Internet stack, from the top to bottom layer, looks like this:
o Application layer. Contains the “language” that applications and servers use to communicate; usually a
high-level protocol of some sort. Common application layer protocols include Hypertext Transfer Protocol
(HTTP, used for the Web), Secure Socket Layer (SSL), and File Transfer Protocol (FTP). Application layer
protocols can often be combined. For example, SSL is commonly used in conjunction with HTTP.
o Transport layer. Defines the data transmission characteristics of the application layer. This layer includes
data integrity checking, source and destination ports, and specifications for breaking application data into
packets (if the application layer has not already done so). Transmission Control Protocol (TCP) and User
Datagram Protocol (UDP) are the most common transport layer protocols. The transport layer is also
sometimes called the protocol layer.
o Network or Internet layer. Defines how to move packets from a source host to a destination host. The
particular packet transit rule set for the Internet is known as Internet Protocol (IP). Because we’ll only talk
about Internet networks in this book, we’ll really only be talking about the Internet layer. However, because
network layers are meant to be hardware independent, you can simultaneously configure several
independent network layers (such as IP, IPv6, IPX, and AppleTalk) on a single host.
o Physical layer. Defines how to send raw data across a physical medium, such as Ethernet or a modem. This
is sometimes called the link layer or host-to-network layer.
It’s important to understand the structure of a network stack because your data must travel through these layers
at least twice before it reaches a program at its destination. For example, if you’re sending data from Host A
to Host B, as shown in Figure 9-1, your bytes leave the application layer on Host A and travel through the
transport and network layers on Host A; then they go down to the physical medium, across the medium, and
up again through the various lower levels to the application layer on Host B in much the same way. If you’re
sending something to a host on the Internet through the router, it will go through some (but usually not all) of
the layers on the router and anything else in between.
The layers sometimes bleed into each other in strange ways because it can be inefficient to process all of them
www.EBooksWorld.ir
in order. For example, devices that historically dealt with only the physical layer now sometimes look at the
transport and Internet layer data to filter and route data quickly. (Don’t worry about this when you’re learning
the basics.)
We’ll begin by looking at how your Linux machine connects to the network in order to answer the where
question at the beginning of the chapter. This is the lower part of the stack—the physical and network layers.
Later, we’ll look at the upper two layers that answer the what question.
NOTE
You might have heard of another set of layers known as the Open Systems Interconnection (OSI)
Reference Model. This is a seven-layer network model often used in teaching and designing
networks, but we won’t cover the OSI model because you’ll be working directly with the four layers
described here. To learn a lot more about layers (and networks in general), see Andrew S.
Tanenbaum and David J. Wetherall’s Computer Networks, 5th edition (Prentice Hall, 2010).
9.3 The Internet Layer
Rather than start at the very bottom of the network stack with the physical layer, we’ll start at the network
layer because it can be easier to understand. The Internet as we currently know it is based on the Internet
Protocol, version 4 (IPv4), though version 6 (IPv6) is gaining adoption. One of the most important aspects of
the Internet layer is that it’s meant to be a software network that places no particular requirements on hardware
or operating systems. The idea is that you can send and receive Internet packets over any kind of hardware,
using any operating system.
The Internet’s topology is decentralized; it’s made up of smaller networks called subnets. The idea is that all
subnets are interconnected in some way. For example, in Figure 9-1, the LAN is normally a single subnet.
A host can be attached to more than one subnet. As you saw in 9.1 Network Basics, that kind of host is called
a router if it can transmit data from one subnet to another (another term for router is gateway). Figure 9-2
refines Figure 9-1 by identifying the LAN as a subnet, as well as Internet addresses for each host and the router.
The router in the figure has two addresses, the local subnet 10.23.2.1 and the link to the Internet (but this
Internet link’s address is not important right now so it’s just marked “Uplink Address”). We’ll look first at the
addresses and then the subnet notation.
Each Internet host has at least one numeric IP address in the form of a.b.c.d, such as 10.23.2.37. An address
in this notation is called a dotted-quad sequence. If a host is connected to multiple subnets, it has at least one
IP address per subnet. Each host’s IP address should be unique across the entire Internet, but as you’ll see later,
private networks and NAT can make this a little confusing.
www.EBooksWorld.ir
Figure 9-2. Network with IP addresses
NOTE
Technically, an IP address consists of 4 bytes (or 32 bits), abcd. Bytes a and d are numbers from 1
to 254, and b and c are numbers from 0 to 255. A computer processes IP addresses as raw bytes.
However, it’s much easier for a human to read and write a dotted-quad address, such as
10.23.2.37, instead of something ugly like the hexadecimal 0x0A170225.
IP addresses are like postal addresses in some ways. To communicate with another host, your machine must
know that other host’s IP address.
Let’s take a look at the address on your machine.
9.3.1 Viewing Your Computer’s IP Addresses
One host can have many IP addresses. To see the addresses that are active on your Linux machine, run
$ ifconfig
There will probably be a lot of output, but it should include something like this:
eth0 Link encap:Ethernet HWaddr 10:78:d2:eb:76:97
inet addr:10.23.2.4 Bcast:10.23.2.255 Mask:255.255.255.0
inet6 addr: fe80::1278:d2ff:feeb:7697/64 Scope:Link
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
RX packets:85076006 errors:0 dropped:0 overruns:0 frame:0
TX packets:68347795 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:1000
RX bytes:86427623613 (86.4 GB) TX bytes:23437688605 (23.4 GB)
Interrupt:20 Memory:fe500000-fe520000
The ifconfig command’s output includes many details from both the Internet layer and the physical layer.
(Sometimes it doesn’t even include an Internet address at all!) We’ll discuss the output in more detail later,
but for now, concentrate on the second line, which reports that the host is configured to have an IPv4 address
(inet addr) of 10.23.2.4. On the same line, a Mask is reported as being 255.255.255.0. This is a subnet
mask, which defines the subnet that an IP address belongs to. Let’s see how that works.
NOTE
The ifconfig command, as well some of the others you’ll see later in this chapter (such as
route and arp), has been technically supplanted with the newer ip command. The ip command
can do more than the old commands, and it is preferable when writing scripts. However, most
people still use the old commands when manually working with the network, and these commands
can also be used on other versions of Unix. For this reason, we’ll use the old-style commands.
9.3.2 Subnets
A subnet is a connected group of hosts with IP addresses in some sort of order. Usually, the hosts are on the
same physical network, as shown in Figure 9-2. For example, the hosts between 10.23.2.1 and 10.23.2.254
could comprise a subnet, as could all hosts between 10.23.1.1 and 10.23.255.254.
You define a subnet with two pieces: a network prefix and a subnet mask (such as the one in the output of
ifconfig in the previous section). Let’s say you want to create a subnet containing the IP addresses between
www.EBooksWorld.ir
10.23.2.1 and 10.23.2.254. The network prefix is the part that is common to all addresses in the subnet; in this
example, it’s 10.23.2.0, and the subnet mask is 255.255.255.0. Let’s see why those are the right numbers.
It’s not immediately clear how the prefix and mask work together to give you all possible IP addresses on a
subnet. Looking at the numbers in binary form helps clear it up. The mask marks the bit locations in an IP
address that are common to the subnet. For example, here are the binary forms of 10.23.2.0 and 255.255.255.0:
10.23.2.0: 00001010 00010111 00000010 00000000
255.255.255.0: 11111111 11111111 11111111 00000000
Now, let’s use boldface to mark the bit locations in 10.23.2.0 that are 1s in 255.255.255.0:
10.23.2.0: 00001010 00010111 00000010 00000000
Look at the bits that are not in bold. You can set any number of these bits to 1 to get a valid IP address in this
subnet, with the exception of all 0s or all 1s.
Putting it all together, you can see how a host with an IP address of 10.23.2.1 and a subnet mask of
255.255.255.0 is on the same subnet as any other computers that have IP addresses beginning with 10.23.2.
You can denote this entire subnet as 10.23.2.0/255.255.255.0.
9.3.3 Common Subnet Masks and CIDR Notation
If you’re lucky, you’ll only deal with easy subnet masks like 255.255.255.0 or 255.255.0.0, but you may be
unfortunate and encounter stuff like 255.255.255.192, where it isn’t quite so simple to determine the set of
addresses that belong to the subnet. Furthermore, it’s likely that you’ll also encounter a different form of
subnet representation called Classless Inter-Domain Routing (CIDR) notation, where a subnet such as
10.23.2.0/255.255.255.0 is written as 10.23.2.0/24.
To understand what this means, look at the mask in binary form (as in the example you saw in the preceding
section). You’ll find that nearly all subnet masks are just a bunch of 1s followed by a bunch of 0s. For example,
you just saw that 255.255.255.0 in binary form is 24 1-bits followed by 8 0-bits. The CIDR notation identifies
the subnet mask by the number of leading 1s in the subnet mask. Therefore, a combination such as
10.23.2.0/24 includes both the subnet prefix and its subnet mask.
Table 9-1 shows several example subnet masks and their CIDR forms.
Table 9-1. Subnet Masks
Long Form CIDR Form
255.0.0.0 8
255.255.0.0 16
255.240.0.0 12
255.255.255.0 24
255.255.255.192 26
NOTE
If you aren’t familiar with conversion between decimal, binary, and hexadecimal formats, you can
use a calculator utility such as bc or dc to convert between different radix representations. For
www.EBooksWorld.ir
example, in bc, you can run the command obase=2; 240 to print the number 240 in binary
(base 2) form.
Identifying subnets and their hosts is the first building block to understanding how the Internet works.
However, you still need to connect the subnets.
9.4 Routes and the Kernel Routing Table
Connecting Internet subnets is mostly a process of identifying the hosts connected to more than one subnet.
Returning to Figure 9-2, think about Host A at IP address 10.23.2.4. This host is connected to a local network
of 10.23.2.0/24 and can directly reach hosts on that network. To reach hosts on the rest of the Internet, it must
communicate through the router at 10.23.2.1.
How does the Linux kernel distinguish between these two different kinds of destinations? It uses a destination
configuration called a routing table to determine its routing behavior. To show the routing table, use the
route -n command. Here’s what you might see for a simple host such as 10.23.2.4:
$ route -n
Kernel IP routing table
Destination Gateway Genmask Flags Metric Ref Use Iface
0.0.0.0 10.23.2.1 0.0.0.0 UG 0 0 0 eth0
10.23.2.0 0.0.0.0 255.255.255.0 U 1 0 0 eth0
The last two lines here contain the routing information. The Destination column tells you a network prefix,
and the Genmask column is the netmask corresponding to that network. There are two networks defined in
this output: 0.0.0.0/0 (which matches every address on the Internet) and 10.23.2.0/24. Each network has a U
under its Flags column, indicating that the route is active (“up”).
Where the destinations differ is in the combination of their Gateway and Flags columns. For 0.0.0.0/0,
there is a G in the Flags column, meaning that communication for this network must be sent through the
gateway in the Gateway column (10.23.2.1, in this case). However, for 10.23.2.0/24, there is no G in Flags,
indicating that the network is directly connected in some way. Here, 0.0.0.0 is used as a stand-in under
Gateway. Ignore the other columns of output for now.
There’s one tricky detail: Say the host wants to send something to 10.23.2.132, which matches both rules in
the routing table, 0.0.0.0/0 and 10.23.2.0/24. How does the kernel know to use the second one? It chooses the
longest destination prefix that matches. This is where CIDR network form comes in particularly handy:
10.23.2.0/24 matches, and its prefix is 24 bits long; 0.0.0.0/0 also matches, but its prefix is 0 bits long (that is,
it has no prefix), so the rule for 10.23.2.0/24 takes priority.
NOTE
The -n option tells route to show IP addresses instead of showing hosts and networks by name.
This is an important option to remember because you’ll be able to use it in other network-related
commands such as netstat.
9.4.1 The Default Gateway
An entry for 0.0.0.0/0 in the routing table has special significance because it matches any address on the
Internet. This is the default route, and the address configured under the Gateway column (in the route -
n output) in the default route is the default gateway. When no other rules match, the default route always does,
and the default gateway is where you send messages when there is no other choice. You can configure a host
without a default gateway, but it won’t be able to reach hosts outside the destinations in the routing table.
www.EBooksWorld.ir
NOTE
On most networks with a netmask of 255.255.255.0, the router is usually at address 1 of the
subnet (for example, 10.23.2.1 in 10.23.2.0/24). Because this is simply a convention, there can be
exceptions.
9.5 Basic ICMP and DNS Tools
Now it’s time to look at some basic practical utilities to help you interact with hosts. These tools use two
protocols of particular interest: Internet Control Message Protocol (ICMP), which can help you root out
problems with connectivity and routing, and the Domain Name Service (DNS) system, which maps names to
IP addresses so that you don’t have to remember a bunch of numbers.
9.5.1 ping
ping (see http://ftp.arl.mil/~mike/ping.html) is one of the most basic network debugging tools. It sends ICMP
echo request packets to a host that ask a recipient host to return the packet to the sender. If the recipient host
gets the packet and is configured to reply, it sends an ICMP echo response packet in return.
For example, say that you run ping 10.23.2.1 and get this output:
$ ping 10.23.2.1
PING 10.23.2.1 (10.23.2.1) 56(84) bytes of data.
64 bytes from 10.23.2.1: icmp_req=1 ttl=64 time=1.76 ms
64 bytes from 10.23.2.1: icmp_req=2 ttl=64 time=2.35 ms
64 bytes from 10.23.2.1: icmp_req=4 ttl=64 time=1.69 ms
64 bytes from 10.23.2.1: icmp_req=5 ttl=64 time=1.61 ms
The first line says that you’re sending 56-byte packets (84 bytes, if you include the headers) to 10.23.2.1 (by
default, one packet per second), and the remaining lines indicate responses from 10.23.2.1. The most important
parts of the output are the sequence number (icmp_req) and the round-trip time (time). The number of
bytes returned is the size of the packet sent plus 8. (The content of the packets isn’t important to you.)
A gap in the sequence numbers, such as the one between 2 and 4, usually means there’s some kind of
connectivity problem. It’s possible for packets to arrive out of order, and if they do, there’s some kind of
problem because ping sends only one packet a second. If a response takes more than a second (1000ms) to
arrive, the connection is extremely slow.
The round-trip time is the total elapsed time between the moment that the request packet leaves and moment
that the response packet arrives. If there’s no way to reach the destination, the final router to see the packet
returns an ICMP “host unreachable” packet to ping.
On a wired LAN, you should expect absolutely no packet loss and very low numbers for the round-trip time.
(The preceding example output is from a wireless network.) You should also expect no packet loss from your
network to and from your ISP and reasonably steady round-trip times.
NOTE
For security reasons, not all hosts on the Internet respond to ICMP echo request packets, so you
might find that you can connect to a website on a host but not get a ping response.
9.5.2 traceroute
The ICMP-based program traceroute will come in handy when you reach the material on routing later in
www.EBooksWorld.ir
this chapter. Use traceroute host to see the path your packets take to a remote host. (traceroute -n
host will disable hostname lookups.)
One of the best things about traceroute is that it reports return trip times at each step in the route, as
demonstrated in this output fragment:
4 206.220.243.106 1.163 ms 0.997 ms 1.182 ms
5 4.24.203.65 1.312 ms 1.12 ms 1.463 ms
6 64.159.1.225 1.421 ms 1.37 ms 1.347 ms
7 64.159.1.38 55.642 ms 55.625 ms 55.663 ms
8 209.247.10.230 55.89 ms 55.617 ms 55.964 ms
9 209.244.14.226 55.851 ms 55.726 ms 55.832 ms
10 209.246.29.174 56.419 ms 56.44 ms 56.423 ms
Because this output shows a big latency jump between hops 6 and 7, that part of the route is probably some
sort of long-distance link.
The output from traceroute can be inconsistent. For example, the replies may time out at a certain step,
only to “reappear” in later steps. The reason is usually that the router at that step refused to return the
debugging output that traceroute wants but routers in later steps were happy to return the output. In
addition, a router might choose to assign a lower priority to the debugging traffic than it does to normal traffic.
9.5.3 DNS and host
IP addresses are difficult to remember and subject to change, which is why we normally use names such as
www.example.com instead. The DNS library on your system normally handles this translation automatically,
but sometimes you’ll want to manually translate between a name and an IP address. To find the IP address
behind a domain name, use the host command:
$ host www.example.com
www.example.com has address 93.184.216.119
www.example.com has IPv6 address 2606:2800:220:6d:26bf:1447:1097:aa7
Notice how this example has both the IPv4 address 93.184.216.119 and the much larger IPv6 address. This
means that this host also has an address on the next-generation version of the Internet.
You can also use host in reverse: Enter an IP address instead of a hostname to try to discover the hostname
behind the IP address. But don’t expect this to work reliably. Many hostnames can represent a single IP address,
and DNS doesn’t know how to determine which hostname should correspond to an IP address. The domain
administrator must manually set up this reverse lookup, and often the administrator does not. (There is a lot
more to DNS than the host command. We’ll cover basic client configuration later in 9.12 Resolving
Hostnames.)
9.6 The Physical Layer and Ethernet
One of the key things to understand about the Internet is that it’s a software network. Nothing we’ve discussed
so far is hardware specific, and indeed, one reason for the Internet’s success is that it works on almost any
kind of computer, operating system, and physical network. However, you still have to put a network layer on
top of some kind of hardware, and that interface is called the physical layer.
In this book, we’ll look at the most common kind of physical layer: an Ethernet network. The IEEE 802 family
www.EBooksWorld.ir
of standards documents defines many different kinds of Ethernet networks, from wired to wireless, but they
all have a few things in common, in particular, the following:
o All devices on an Ethernet network have a Media Access Control (MAC) address, sometimes called a
hardware address. This address is independent of a host’s IP address, and it is unique to the host’s Ethernet
network (but not necessarily a larger software network such as the Internet). A sample MAC address is
10:78:d2:eb:76:97.
o Devices on an Ethernet network send messages in frames, which are wrappers around the data sent. A frame
contains the origin and destination MAC addresses.
Ethernet doesn’t really attempt to go beyond hardware on a single network. For example, if you have two
different Ethernet networks with one host attached to both networks (and two different network interface
devices), you can’t directly transmit a frame from one Ethernet network to the other unless you set up a special
Ethernet bridge. And this is where higher network layers (such as the Internet layer) come in. By convention,
each Ethernet network is also usually an Internet subnet. Even though a frame can’t leave one physical network,
a router can take the data out of a frame, repackage it, and send it to a host on a different physical network,
which is exactly what happens on the Internet.
9.7 Understanding Kernel Network Interfaces
The physical and the Internet layers must be connected in a way that allows the Internet layer to retain its
hardware-independent flexibility. The Linux kernel maintains its own division between the two layers and
provides communication standards for linking them called a (kernel) network interface. When you configure
a network interface, you link the IP address settings from the Internet side with the hardware identification on
the physical device side. Network interfaces have names that usually indicate the kind of hardware underneath,
such as eth0 (the first Ethernet card in the computer) and wlan0 (a wireless interface).
In 9.3.1 Viewing Your Computer’s IP Addresses, you learned the most important command for viewing or
manually configuring the network interface settings: ifconfig. Recall this output:
eth0 Link encap:Ethernet HWaddr 10:78:d2:eb:76:97
inet addr:10.23.2.4 Bcast:10.23.2.255 Mask:255.255.255.0
inet6 addr: fe80::1278:d2ff:feeb:7697/64 Scope:Link
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
RX packets:85076006 errors:0 dropped:0 overruns:0 frame:0
TX packets:68347795 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:1000
RX bytes:86427623613 (86.4 GB) TX bytes:23437688605 (23.4 GB)
Interrupt:20 Memory:fe500000-fe520000
For each network interface, the left side of the output shows the interface name, and the right side contains
settings and statistics for the interface. In addition to the Internet layer pieces that we’ve already covered, you
also see the MAC address on the physical layer (HWaddr). The lines containing UP and RUNNING tell you
that the interface is working.
Although ifconfig shows some hardware information (in this case, even some low-level device settings
such as the interrupt and memory used), it’s designed primarily for viewing and configuring the software
layers attached to the interfaces. To dig deeper into the hardware and physical layer behind a network interface,
www.EBooksWorld.ir
use something like the ethtool command to display or change the settings on Ethernet cards. (We’ll look
briefly at wireless networks in 9.23 Wireless Ethernet.)
9.8 Introduction to Network Interface Configuration
You’ve now seen all of the basic elements that go into the lower levels of a network stack: the physical layer,
the network (Internet) layer, and the Linux kernel’s network interfaces. In order to combine these pieces to
connect a Linux machine to the Internet, you or a piece of software must do the following:
1. Connect the network hardware and ensure that the kernel has a driver for it. If the driver is present,
ifconfig -a displays a kernel network interface corresponding to the hardware.
2. Perform any additional physical layer setup, such as choosing a network name or password.
3. Bind an IP address and netmask to the kernel network interface so that the kernel’s device drivers
(physical layer) and Internet subsystems (Internet layer) can talk to each other.
4. Add any additional necessary routes, including the default gateway.
When all machines were big stationary boxes wired together, this was relatively straightforward: The kernel
did step 1, you didn’t need step 2, and you’d do step 3 with the ifconfig command and step 4 with the
route command.
To manually set the IP address and netmask for a kernel network interface, you’d do this:
# ifconfig interface address netmask mask
Here, interface is the name of the interface, such as eth0. When the interface was up, you’d be ready to
add routes, which was typically just a matter of setting the default gateway, like this:
# route add default gw gw-address
The gw-address parameter is the IP address of your default gateway; it must be an address in a locally
connected subnet defined by the address and mask settings of one of your network interfaces.
9.8.1 Manually Adding and Deleting Routes
To remove a default gateway, run
# route del -net default
You can easily override the default gateway with other routes. For example, say your machine is on subnet
10.23.2.0/24, you want to reach a subnet at 192.168.45.0/24, and you know that 10.23.2.44 can act as a router
for that subnet. Run this command to send traffic bound for 192.168.45.0 to that router:
# route add -net 192.168.45.0/24 gw 10.23.2.44
You don’t need to specify the router in order to delete a route:
# route del -net 192.168.45.0/24
Now, before you go crazy with routes, you should know that messing with routes is often more complicated
than it appears. For this particular example, you also have to make sure that the routing for all hosts on
192.163.45.0/24 can lead back to 10.23.2.0/24, or the first route you add is basically useless.
Normally, you should keep things as simple as possible for your clients, setting up networks so that their hosts
need only a default route. If you need multiple subnets and the ability to route between them, it’s usually best
to configure the routers acting as the default gateways to do all of the work of routing between different local
subnets. (You’ll see an example in 9.17 Configuring Linux as a Router.)
www.EBooksWorld.ir
9.9 Boot-Activated Network Configuration
We’ve discussed ways to manually configure a network, and the traditional way to ensure the correctness of a
machine’s network configuration was to have init run a script to run the manual configuration at boot time.
This boils down to running tools like ifconfig and route somewhere in the chain of boot events. Many
servers still do it this way.
There have been many attempts in Linux to standardize configuration files for boot-time networking. The
tools ifup and ifdown do so—for example, a boot script can (in theory) run ifup eth0 to run the correct
ifconfig and route commands for the eth0 interface. Unfortunately, different distributions have
completely different implementations of ifup and ifdown, and as a result, their configuration files are also
completely different. Ubuntu, for example, uses the ifupdown suite with configuration files in /etc/network,
and Fedora uses its own set of scripts with configuration in /etc/sysconfig/network-scripts.
You don’t need to know the details of these configuration files, and if you insist on doing it all by hand and
bypass your distribution’s configuration tools, you can just look up the formats in manual pages such as ifup(8)
and interfaces(5). But it is important to know that this type of boot-activated configuration is often not even
used. You’ll most often see it for the local-host (or lo; see 9.13 Localhost) network interface but nothing else
because it’s too inflexible to meet the needs of modern systems.
9.10 Problems with Manual and Boot-Activated Network Configuration
Although most systems used to configure the network in their boot mechanisms—and many servers still do—
the dynamic nature of modern networks means that most machines don’t have static (unchanging) IP addresses.
Rather than storing the IP address and other network information on your machine, your machine gets this
information from somewhere on the local physical network when it first attaches to that network. Most normal
network client applications don’t particularly care what IP address your machine uses, as long as it works.
Dynamic Host Configuration Protocol (DHCP, described in 9.16 Understanding DHCP) tools do the basic
network layer configuration on typical clients.
There’s more to the story, though. For example, wireless networks add additional dimensions to interface
configuration, such as network names, authentication, and encryption techniques. When you step back to look
at the bigger picture, you see that your system needs a way to answer the following questions:
o If the machine has multiple physical network interfaces (such as a notebook with wired and wireless
Ethernet), how do you choose which one(s) to use?
o How should the machine set up the physical interface? For wireless networks, this includes scanning for
network names, choosing a name, and negotiating authentication.
o Once the physical network interface is connected, how should the machine set up the software network
layers, such as the Internet layer?
o How can you let a user choose connectivity options? For example, how do you let a user choose a wireless
network?
o What should the machine do if it loses connectivity on a network interface?
Answering these questions is usually more than simple boot scripts can handle, and it’s a real hassle to do it
all by hand. The answer is to use a system service that can monitor physical networks and choose (and
automatically configure) the kernel network interfaces based on a set of rules that makes sense to the user. The
service should also be able to respond to requests from users, who should be able to change the wireless
network they’re on without having to become root just to fiddle around with network settings every time
something changes.
www.EBooksWorld.ir
9.11 Network Configuration Managers
There are several ways to automatically configure networks in Linux-based systems. The most widely used
option on desktops and notebooks is NetworkManager. Other network configuration management systems are
mainly targeted for smaller embedded systems, such as OpenWRT’s netifd, Android’s
ConnectivityManager service, ConnMan, and Wicd. We’ll briefly discuss NetworkManager because it’s the
one you’re most likely to encounter. We won’t go into a tremendous amount of detail, though, because after
you see the big picture, NetworkManager and other configuration systems will be more transparent.
9.11.1 NetworkManager Operation
NetworkManager is a daemon that the system starts upon boot. Like all daemons, it does not depend on a
running desktop component. Its job is to listen to events from the system and users and to change the network
configuration based on a bunch of rules.
When running, NetworkManager maintains two basic levels of configuration. The first is a collection of
information about available hardware devices, which it normally collects from the kernel and maintains by
monitoring udev over the Desktop Bus (D-Bus). The second configuration level is a more specific list of
connections: hardware devices and additional physical and network layer configuration parameters. For
example, a wireless network can be represented as a connection.
To activate a connection, NetworkManager often delegates the tasks to other specialized network tools and
daemons such as dhclient to get Internet layer configuration from a locally attached physical network.
Because network configuration tools and schemes vary among distributions, NetworkManager uses plugins
to interface with them, rather than imposing its own standard. There are plugins for the both the Debian/
Ubuntu and Red Hat–style interface configuration, for example.
Upon startup, NetworkManager gathers all available network device information, searches its list of
connections, and then decides to try to activate one. Here’s how it makes that decision for Ethernet interfaces:
1. If a wired connection is available, try to connect using it. Otherwise, try the wireless connections.
2. Scan the list of available wireless networks. If a network is available that you’ve previously connected to,
NetworkManager will try it again.
3. If more than one previously connected wireless networks are available, select the most recently
connected.
After establishing a connection, NetworkManager maintains it until the connection is lost, a better network
becomes available (for example, you plug in a network cable while connected over wireless), or the user forces
a change.
9.11.2 Interacting with NetworkManager
Most users interact with NetworkManager through an applet on the desktop—it’s usually an icon in the upper
or lower right that indicates the connection status (wired, wireless, or not connected). When you click on the
icon, you get a number of connectivity options, such as a choice of wireless networks and an option to
disconnect from your current network. Each desktop environment has its own version of this applet, so it looks
a little different on each one.
In addition to the applet, there are a few tools that you can use to query and control NetworkManager from
your shell. For a very quick summary of your current connection status, use the nm-tool command with no
arguments. You’ll get a list of interfaces and configuration parameters. In some ways, this is like ifconfig
except that there’s more detail, especially when viewing wireless connections.
To control NetworkManager from the command line, use the nmcli command. This is a somewhat extensive
www.EBooksWorld.ir
command. See the nmcli(1) manual page for more information.
Finally, the utility nm-online will tell you whether the network is up or down. If the network is up, the
command returns zero as its exit code; it’s nonzero otherwise. (For more on how to use an exit code in a shell
script, see Chapter 11.)
9.11.3 NetworkManager Configuration
The general configuration directory for NetworkManager is usually /etc/NetworkManager, and there are
several different kinds of configuration. The general configuration file is NetworkManager.conf. The format
is similar to the XDG-style .desktop and Microsoft .ini files, with key-value parameters falling into different
sections. You’ll find that nearly every configuration file has a [main] section that defines the plugins to use.
Here’s a simple example that activates the ifupdown plugin used by Ubuntu and Debian:
[main]
plugins=ifupdown,keyfile
Other distribution-specific plugins are ifcfg-rh (for Red Hat–style distributions) and ifcfg-suse (for SuSE).
The keyfile plugin that you also see here supports NetworkManager’s native configuration file support. When
using the plugin, you can see the system’s known connections in /etc/NetworkManager/system-connections.
For the most part, you won’t need to change NetworkManager.conf because the more specific configuration
options are found in other files.
Unmanaged Interfaces
Although you may want NetworkManager to manage most of your network interfaces, there will be times
when you want it to ignore interfaces. For example, there’s no reason why most users would need any kind of
dynamic configuration on the localhost (lo) interface because the configuration never changes. You also want
to configure this interface early in the boot process because basic system services often depend on it. Most
distributions keep NetworkManager away from localhost.
You can tell NetworkManager to disregard an interface by using plugins. If you’re using the ifupdown plugin
(for example, in Ubuntu and Debian), add the interface configuration to your /etc/network/interfaces file and
then set the value of managed to false in the ifupdown section of the NetworkManager.conf file:
[ifupdown]
managed=false
For the ifcfg-rh plugin that Fedora and Red Hat use, look for a line like this in the /etc/sysconfig/network-
scripts directory that contains the ifcfg-* configuration files:
NM_CONTROLLED=yes
If this line is not present or the value is set to no, NetworkManager ignores the interface. For example, you’ll
find it deactivated in the ifcfg-lo file. You can also specify a hardware address to ignore, like this:
HWADDR=10:78:d2:eb:76:97
If you don’t use either of these network configuration schemes, you can still use the keyfile plugin to specify
the unmanaged device directly inside your NetworkManager.conf file using the MAC address. Here’s how that
might look:
[keyfile]
unmanaged-devices=mac:10:78:d2:eb:76:97;mac:1c:65:9d:cc:ff:b9
www.EBooksWorld.ir
Dispatching
One final detail of NetworkManager configuration relates to specifiying additional system actions for when a
network interface goes up or down. For example, some network daemons need to know when to start or stop
listening on an interface in order to work correctly (such as the secure shell daemon discussed in the next
chapter).
When the network interface status on a system changes, NetworkManager runs everything in
/etc/NetworkManager/dispatcher.d with an argument such as up or down. This is relatively straightforward,
but many distributions have their own network control scripts so they don’t place the individual dispatcher
scripts in this directory. Ubuntu, for example, has just one script named 01ifupdown that runs everything
in an appropriate subdirectory of /etc/network, such as /etc/network/if-up.d.
As with the rest of the NetworkManager configuration, the details of these scripts are relatively unimportant;
all you need to know is how to track down the appropriate location if you need to make an addition or change.
As ever, don’t be shy about looking at scripts on your system.
9.12 Resolving Hostnames
One of the final basic tasks in any network configuration is hostname resolution with DNS. You’ve already
seen the host resolution tool that translates a name such as www.example.com to an IP address such as
10.23.2.132.
DNS differs from the network elements we’ve looked at so far because it’s in the application layer, entirely in
user space. Technically, it is slightly out of place in this chapter alongside the Internet and physical layer
discussion, but without proper DNS configuration, your Internet connection is practically worthless. No one
in their right mind advertises IP addresses for websites and email addresses because a host’s IP address is
subject to change and it’s not easy to remember a bunch of numbers. Automatic network configuration services
such as DHCP nearly always include DNS configuration.
Nearly all network applications on a Linux system perform DNS lookups. The resolution process typically
unfolds like this:
1. The application calls a function to look up the IP address behind a hostname. This function is in the
system’s shared library, so the application doesn’t need to know the details of how it works or whether
the implementation will change.
2. When the function in the shared library runs, it acts according to a set of rules (found in
/etc/nsswitch.conf) to determine a plan of action on lookups. For example, the rules usually say that even
before going to DNS, check for a manual override in the /etc/hosts file.
3. When the function decides to use DNS for the name lookup, it consults an additional configuration file to
find a DNS name server. The name server is given as an IP address.
4. The function sends a DNS lookup request (over the network) to the name server.
5. The name server replies with the IP address for the hostname, and the function returns this IP address to
the application.
This is the simplified version. In a typical modern system, there are more actors attempting to speed up the
transaction and/or add flexibility. Let’s ignore that for now and take a closer look at the basic pieces.
9.12.1 /etc/hosts
On most systems, you can override hostname lookups with the /etc/hosts file. It usually looks like this:
127.0.0.1 localhost
www.EBooksWorld.ir
10.23.2.3 atlantic.aem7.net atlantic
10.23.2.4 pacific.aem7.net pacific
You’ll nearly always see the entry for localhost here (see 9.13 Localhost).
NOTE
In the bad old days, there was one central hosts file that everyone copied to their own machine in
order to stay up-to-date (see RFCs 606, 608, 623, and 625), but as the ARPANET/Internet grew,
this quickly got out of hand.
9.12.2 resolv.conf
The traditional configuration file for DNS servers is /etc/resolv.conf. When things were simpler, a typical
example might have looked like this, where the ISP’s name server addresses are 10.32.45.23 and 10.3.2.3:
search mydomain.example.com example.com
nameserver 10.32.45.23
nameserver 10.3.2.3
The search line defines rules for incomplete hostnames (just the first part of the hostname; for example,
myserver instead of myserver.example.com). Here, the resolver library would try to look up
host.mydomain.example.com and host.example.com. But things are usually no longer this
straightforward. Many enhancements and modifications have been made to the DNS configuration.
9.12.3 Caching and Zero-Configuration DNS
There are two main problems with the traditional DNS configuration. First, the local machine does not cache
name server replies, so frequent repeated network access may be unnecessarily slow due to name server
requests. To solve this problem, many machines (and routers, if acting as name servers) run an intermediate
daemon to intercept name server requests and return a cached answer to name service requests if possible;
otherwise, requests go to a real name server. Two of the most common such daemons for Linux are dnsmasq
and nscd. You can also set up BIND (the standard Unix name server daemon) as a cache. You can often tell
if you’re running a name server caching daemon when you see 127.0.0.1 (localhost) in your /etc/resolv.conf
file or when you see 127.0.0.1 show up as the server if you run nslookup -debug host.
It can be a tricky to track down your configuration if you’re running a name server–caching daemon. By
default, dnsmasq has the configuration file /etc/dnsmasq.conf, but your distribution may override that. For
example, in Ubuntu, if you’ve manually set up an interface that’s set up by NetworkManager, you’ll find it in
the appropriate file in /etc/NetworkManager/system-connections because when NetworkManager activates a
connection, it also starts dnsmasq with that configuration. (You can override all of this by uncommenting
the dnsmasq part of your NetworkManager.conf.)
The other problem with the traditional name server setup is that it can be particularly inflexible if you want to
be able to look up names on your local network without messing around with a lot of network configuration.
For example, if you set up a network appliance on your network, you’ll want to be able to call it by name
immediately. This is part of the idea behind zero-configuration name service systems such as Multicast DNS
(mDNS) and Simple Service Discovery Protocol (SSDP). If you want to find a host by name on the local
network, you just broadcast a request over the network; if the host is there, it replies with its address. These
protocols go beyond hostname resolution by also providing information about available services.
The most widely used Linux implementation of mDNS is called Avahi. You’ll often see mdns as a resolver
option in /etc/nsswitch.conf, which we’ll now look at in more detail.
www.EBooksWorld.ir
9.12.4 /etc/nsswitch.conf
The /etc/nsswitch.conf file controls several name-related precedence settings on your system, such as user and
password information, but we’ll only talk about the DNS settings in this chapter. The file on your system
should have a line like this:
hosts: files dns
Putting files ahead of dns here ensures that your system checks the /etc/hosts file for the hostname of your
requested IP address before asking the DNS server. This is usually a good idea (especially for looking up
localhost, as discussed below), but your /etc/hosts file should be as short as possible. Don’t put anything in
there to boost performance; doing so will burn you later. You can put all the hosts within a small private LAN
in /etc/hosts, but the general rule of thumb is that if a particular host has a DNS entry, it has no place in
/etc/hosts. (The /etc/hosts file is also useful for resolving hostnames in the early stages of booting, when the
network may not be available.)
NOTE
DNS is a broad topic. If you have any responsibility for domain names, read DNS and BIND, 5th
edition, by Cricket Liu and Paul Albitz (O’Reilly, 2006).
9.13 Localhost
When running ifconfig, you’ll notice the lo interface:
lo Link encap:Local Loopback
inet addr:127.0.0.1 Mask:255.0.0.0
inet6 addr: ::1/128 Scope:Host
UP LOOPBACK RUNNING MTU:16436 Metric:1
The lo interface is a virtual network interface called the loopback because it “loops back” to itself. The effect
is that connecting to 127.0.0.1 is connecting to the machine that you’re currently using. When outgoing data
to local-host reaches the kernel network interface for lo, the kernel just repackages it as incoming data and
sends it back through lo.
The lo loopback interface is often the only place you’ll see static network configuration in boot-time scripts.
For example, Ubuntu’s ifup command reads /etc/network/interfaces and Fedora uses /etc/sysconfig/network-
interfaces/ ifcfg-lo. You can often find the loopback device configuration by digging around in /etc with grep.
9.14 The Transport Layer: TCP, UDP, and Services
So far, we’ve only seen how packets move from host to host on the Internet— in other words, the where
question from the beginning of the chapter. Now let’s start to answer the what question. It’s important to know
how your computer presents the packet data it receives from other hosts to its running processes. It’s difficult
and inconvenient for user-space programs to deal with a bunch of raw packets the way that the kernel can.
Flexibility is especially important: More than one application should be able to talk to the network at the same
time (for example, you might have email and several web clients running).
Transport layer protocols bridge the gap between the raw packets of the Internet layer and the refined needs
of applications. The two most popular transport protocols are the Transmission Control Protocol (TCP) and
the User Datagram Protocol (UDP). We’ll concentrate on TCP because it’s by far the most common protocol
in use, but we’ll also take a quick look at UDP.
www.EBooksWorld.ir
9.14.1 TCP Ports and Connections
TCP provides for multiple network applications on one machine by means of network ports. A port is just a
number. If an IP address is like the postal address of an apartment building, a port is like a mailbox number—
it’s a further subdivision.
When using TCP, an application opens a connection (not to be confused with NetworkManager connections)
between one port on its own machine and a port on a remote host. For example, an application such as a web
browser could open a connection between port 36406 on its own machine and port 80 on a remote host. From
the application’s point of view, port 36406 is the local port and port 80 is the remote port.
You can identify a connection by using the pair of IP addresses and port numbers. To view the connections
currently open on your machine, use netstat. Here’s an example that shows TCP connections: The -n
option disables hostname (DNS) resolution, and -t limits the output to TCP.
$ netstat -nt
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address Foreign Address State
tcp 0 0 10.23.2.4:47626 10.194.79.125:5222
ESTABLISHED
tcp 0 0 10.23.2.4:41475 172.19.52.144:6667
ESTABLISHED
tcp 0 0 10.23.2.4:57132 192.168.231.135:22
ESTABLISHED
The Local Address and Foreign Address fields show connections from your machine’s point of view, so the
machine here has an interface configured at 10.23.2.4, and ports 47626, 41475, and 57132 on the local side
are all connected. The first connection here shows port 47626 connected to port 5222 of 10.194.79.125.
9.14.2 Establishing TCP Connections
To establish a transport layer connection, a process on one host initiates the connection from one of its local
ports to a port on a second host with a special series of packets. In order to recognize the incoming connection
and respond, the second host must have a process listening on the correct port. Usually, the connecting process
is called the client, and the listener is the called the server (more about this in Chapter 10).
The important thing to know about the ports is that the client picks a port on its side that isn’t currently in use,
but it nearly always connects to some well-known port on the server side. Recall this output from the
netstat command in the preceding section:
Proto Recv-Q Send-Q Local Address Foreign Address State
tcp 0 0 10.23.2.4:47626 10.194.79.125:5222 ESTABLISHED
With a little help, you can see that this connection was probably initiated by a local client to a remote server
because the port on the local side (47626) looks like a dynamically assigned number, whereas the remote port
(5222) is a well-known service (the Jabber or XMPP messaging service, to be specific).
NOTE
A dynamically assigned port is called an ephemeral port.
However, if the local port in the output is well-known, a remote host probably initiated the connection. In this
example, remote host 172.24.54.234 has connected to port 80 (the default web port) on the local host.
www.EBooksWorld.ir
Proto Recv-Q Send-Q Local Address Foreign Address State
tcp 0 0 10.23.2.4:80 172.24.54.234:43035 ESTABLISHED
A remote host connecting to your machine on a well-known port implies that a server on your local machine
is listening on this port. To confirm this, list all TCP ports that your machine is listening on with netstat:
$ netstat -ntl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address Foreign Address State
tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN
tcp 0 0 127.0.0.1:53 0.0.0.0:* LISTEN
--snip--
The line with 0.0.0.0:80 as the local address shows that the local machine is listening on port 80 for
connections from any remote machine. (A server can restrict the access to certain interfaces, as shown in the
last line, where something is listening for connections only on the localhost interface.) To learn even more,
use lsof to identify the specific process that’s listening (as discussed in 10.5.1 lsof).
9.14.3 Port Numbers and /etc/services
How do you know if a port is a well-known port? There’s no single way to tell, but one good place to start is
to look in /etc/services, which translates well-known port numbers into names. This is a plaintext file. You
should see entries like this:
ssh 22/tcp # SSH Remote Login Protocol
smtp 25/tcp
domain 53/udp
The first column is a name and the second column indicates the port number and the specific transport layer
protocol (which can be other than TCP).
NOTE
In addition to /etc/services, an online registry for ports at http://www.iana.org/ is governed by the
RFC6335 network standards document.
On Linux, only processes running as the superuser can use ports 1 through 1023. All user processes may listen
on and create connections from ports 1024 and up.
9.14.4 Characteristics of TCP
TCP is popular as a transport layer protocol because it requires relatively little from the application side. An
application process only needs to know how to open (or listen for), read from, write to, and close a connection.
To the application, it seems as if there are incoming and outgoing streams of data; the process is nearly as
simple as working with a file.
However, there’s a lot of work to do behind the scenes. For one, the TCP implementation needs to know how
to break an outgoing data stream from a process into packets. However, the hard part is knowing how to
convert a series of incoming packets into an input data stream for processes to read, especially when incoming
packets don’t necessarily arrive in the correct order. In addition, a host using TCP must check for errors:
Packets can get lost or mangled when sent across the Internet, and a TCP implementation must detect and
correct these situations. Figure 9-3 shows a simplification of how a host might use TCP to send a message.
www.EBooksWorld.ir
Luckily, you need to know next to nothing about this mess other than that the Linux TCP implementation is
primarily in the kernel and that utilities that work with the transport layer tend to manipulate kernel data
structures. One example is the IP Tables packet-filtering system discussed in 9.21 Firewalls.
9.14.5 UDP
UDP is a far simpler transport layer than TCP. It defines a transport only for single messages; there is no data
stream. At the same time, unlike TCP, UDP won’t correct for lost or out-of-order packets. In fact, although
UDP has ports, it doesn’t even have connections! One host simply sends a message from one of its ports to a
port on a server, and the server sends something back if it wants to. However, UDP does have error detection
for data inside a packet; a host can detect if a packet gets mangled, but it doesn’t have to do anything about it.
Where TCP is like having a telephone conversation, UDP is like sending a letter, telegram, or instant message
(except that instant messages are more reliable). Applications that use UDP are often concerned with speed—
sending a message as quickly as possible. They don’t want the overhead of TCP because they assume the
network between two hosts is generally reliable. They don’t need TCP’s error correction because they either
have their own error detection systems or simply don’t care about errors.
One example of an application that uses UDP is the Network Time Protocol (NTP). A client sends a short and
simple request to a server to get the current time, and the response from the server is equally brief. Because
the client wants the response as quickly as possible, UDP suits the application; if the response from the server
gets lost somewhere in the network, the client can just resend a request or give up. Another example is video
chat—in this case, pictures are sent with UDP—and if some pieces get lost along the way, the client on the
receiving end compensates the best it can.
www.EBooksWorld.ir
Figure 9-3. Sending a message with TCP
NOTE
The rest of this chapter deals with more advanced networking topics, such as network filtering and
routers, as they relate to the lower network layers that we’ve already seen: physical, network, and
transport. If you like, feel free to skip ahead to the next chapter to see the application layer where
everything comes together in user space. You’ll see processes that actually use the network rather
www.EBooksWorld.ir
than just throwing around a bunch of addresses and packets.
9.15 Revisiting a Simple Local Network
We’re now going to look at additional components of the simple network introduced in 9.3 The Internet Layer.
Recall that this network consists of one local area network as one subnet and a router that connects the subnet
to the rest of the Internet. You’ll learn the following:
o How a host on the subnet automatically gets its network configuration
o How to set up routing
o What a router really is
o How to know which IP addresses to use for the subnet
o How to set up firewalls to filter out unwanted traffic from the Internet
Let’s start by learning how a host on the subnet automatically gets its network configuration.
9.16 Understanding DHCP
When you set a network host to get its configuration automatically from the network, you’re telling it to use
the Dynamic Host Configuration Protocol (DHCP) to get an IP address, subnet mask, default gateway, and
DNS servers. Aside from not having to enter these parameters by hand, DHCP has other advantages for a
network administrator, such as preventing IP address clashes and minimizing the impact of network changes.
It’s very rare to see a modern network that doesn’t use DHCP.
For a host to get its configuration with DHCP, it must be able to send messages to a DHCP server on its
connected network. Therefore, each physical network should have its own DHCP server, and on a simple
network (such as the one in 9.3 The Internet Layer), the router usually acts as the DHCP server.
NOTE
When making an initial DHCP request, a host doesn’t even know the address of a DHCP server,
so it broadcasts the request to all hosts (usually all hosts on its physical network).
When a machine asks a DHCP server for an IP address, it’s really asking for a lease on an address for a certain
amount of time. When the lease is up, a client can ask to renew the lease.
9.16.1 The Linux DHCP Client
Although there are many different kinds of network manager systems, nearly all use the Internet Software
Consortium (ISC) dhclient program to do the actual work. You can test dhclient by hand on the
command line, but before doing so you must remove any default gateway route. To run the test, simply specify
the network interface name (here, it’s eth0):
# dhclient eth0
Upon startup, dhclient stores its process ID in /var/run/dhclient.pid and its lease information in
/var/state/dhclient.leases.
9.16.2 Linux DHCP Servers
You can task a Linux machine with running a DHCP server, which provides a good amount of control over
the addresses that it gives out. However, unless you’re administering a large network with many subnets,
you’re probably better off using specialized router hardware that includes built-in DHCP servers.
Probably the most important thing to know about DHCP servers is that you want only one running on the same
www.EBooksWorld.ir
subnet in order to avoid problems with clashing IP addresses or incorrect configurations.
9.17 Configuring Linux as a Router
Routers are essentially just computers with more than one physical network interface. You can easily configure
a Linux machine as a router.
For example, say you have two LAN subnets, 10.23.2.0/24 and 192.168.45.0/24. To connect them, you have
a Linux router machine with three network interfaces: two for the LAN subnets and one for an Internet uplink,
as shown in Figure 9-4. As you can see, this doesn’t look very different from the simple network example that
we’ve used in the rest of this chapter.
Figure 9-4. Two subnets joined with a router
The router’s IP addresses for the LAN subnets are 10.23.2.1 and 192.168.45.1. When those addresses are
configured, the routing table looks something like this (the interface names might vary in practice; ignore the
Internet uplink for now):
Destination Gateway Genmask Flags Metric Ref Use
Iface
10.23.2.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0
192.168.45.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1
Now let’s say that the hosts on each subnet have the router as their default gateway (10.23.2.1 for 10.23.2.0/24
and 192.168.45.1 for 192.168.45.0/24). If 10.23.2.4 wants to send a packet to anything outside of 10.23.2.0/24,
it passes the packet to 10.23.2.1. For example, to send a packet from 10.23.2.4 (Host A) to 192.168.45.61
www.EBooksWorld.ir
(Host E), the packet goes to 10.23.2.1 (the router) via its eth0 interface, then back out through the router’s
eth1 interface.
However, by default, the Linux kernel does not automatically move packets from one subnet to another. To
enable this basic routing function, you need to enable IP forwarding in the router’s kernel with this command:
# sysctl -w net.ipv4.ip_forward
As soon as you enter this command, the machine should start routing packets between the two subnets,
assuming that the hosts on those subnets know to send their packets to the router you just created.
To make this change permanent upon reboot, you can add it to your /etc/sysctl.conf file. Depending on your
distribution, you may have the option to put it into a file in /etc/sysctl.d so that distribution updates won’t
overwrite your changes.
9.17.1 Internet Uplinks
When the router also has the third network interface with an Internet uplink, this same setup allows Internet
access for all hosts on both subnets because they’re configured to use the router as the default gateway. But
that’s where things get more complicated. The problem is that certain IP addresses such as 10.23.2.4 are not
actually visible to the whole Internet; they’re on so-called private networks. To provide for Internet
connectivity, you must set up a feature called Network Address Translation (NAT) on the router. The software
on nearly all specialized routers does this, so there’s nothing out of the ordinary here, but let’s examine the
problem of private networks in a bit more detail.
9.18 Private Networks
Say you decide to build your own network. You have your machines, router, and network hardware ready.
Given what you know about a simple network so far, your next question is “What IP subnet should I use?”
If you want a block of Internet addresses that every host on the Internet can see, you can buy one from your
ISP. However, because the range of IPv4 addresses is very limited, this costs a a lot and isn’t useful for much
more than running a server that the rest of the Internet can see. Most people don’t really need this kind of
service because they access the Internet as a client.
The conventional, inexpensive alternative is to pick a private subnet from the addresses in the RFC 1918/6761
Internet standards documents, shown in Table 9-2.
Table 9-2. Private Networks Defined by RFC 1918 and 6761
Network Subnet Mask CIDR Form
10.0.0.0 255.0.0.0 10.0.0.0/8
192.168.0.0 255.255.0.0 192.168.0.0/16
172.16.0.0 255.240.0.0 172.16.0.0/12
You can carve up private subnets as you wish. Unless you plan to have more than 254 hosts on a single network,
pick a small subnet like 10.23.2.0/24, as we’ve been using throughout this chapter. (Networks with this
netmask are sometimes called class C subnets. Although the term is technically somewhat obsolete, it’s still
useful.)
What’s the catch? Hosts on the real Internet know nothing about private subnets and will not send packets to
them, so without some help, hosts on private subnets cannot talk to the outside world. A router connected to
www.EBooksWorld.ir
the Internet (with a true, nonprivate address) needs to have some way to fill in the gap between that connection
and the hosts on a private network.
9.19 Network Address Translation (IP Masquerading)
NAT is the most commonly used way to share a single IP address with a private network, and it’s nearly
universal in home and small office networks. In Linux, the variant of NAT that most people use is known as
IP masquerading.
The basic idea behind NAT is that the router doesn’t just move packets from one subnet to another; it
transforms them as it moves them. Hosts on the Internet know how to connect to the router, but they know
nothing about the private network behind it. The hosts on the private network need no special configuration;
the router is their default gateway.
The system works roughly like this:
1. A host on the internal private network wants to make a connection to the outside world, so it sends its
connection request packets through the router.
2. The router intercepts the connection request packet rather than passing it out to the Internet (where it
would get lost because the public Internet knows nothing about private networks).
3. The router determines the destination of the connection request packet and opens its own connection to
the destination.
4. When the router obtains the connection, it fakes a “connection established” message back to the original
internal host.
5. The router is now the middleman between the internal host and the destination. The destination knows
nothing about the internal host; the connection on the remote host looks like it came from the router.
This isn’t quite as simple as it sounds. Normal IP routing knows only source and destination IP addresses in
the Internet layer. However, if the router dealt only with the Internet layer, each host on the internal network
could establish only one connection to a single destination at one time (among other limitations), because
there is no information in the Internet layer part of a packet to distinguish multiple requests from the same
host to the same destination. Therefore, NAT must go beyond the Internet layer and dissect packets to pull out
more identifying information, particularly the UDP and TCP port numbers from the transport layers. UDP is
fairly easy because there are ports but no connections, but the TCP transport layer is complex.
In order to set up a Linux machine to perform as a NAT router, you must activate all of the following inside
the kernel configuration: network packet filtering (“firewall support”), connection tracking, IP tables support,
full NAT, and MASQUERADE target support. Most distribution kernels come with this support.
Next you need to run some complex-looking iptables commands to make the router perform NAT for its
private subnet. Here’s an example that applies to an internal Ethernet network on eth1 sharing an external
connection at eth0 (you’ll learn more about the iptables syntax in 9.21 Firewalls):
# sysctl -w net.ipv4.ip_forward
# iptables -P FORWARD DROP
# iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
# iptables -A FORWARD -i eth0 -o eth1 -m state --state
ESTABLISHED,RELATED -j ACCEPT
# iptables -A FORWARD -i eth1 -o eth0 -j ACCEPT
www.EBooksWorld.ir
NOTE
Although NAT works well in practice, remember that it’s essentially a hack used to extend the
lifetime of the IPv4 address space. In a perfect world, we would all be using IPv6 (the next-
generation Internet) and using its larger and more sophisticated address space without any pain.
You likely won’t ever need to use the commands above unless you’re developing your own software,
especially with so much special-purpose router hardware available. But the role of Linux in a network doesn’t
end here.
9.20 Routers and Linux
In the early days of broadband, users with less demanding needs simply connected their machine directly to
the Internet. But it didn’t take long for many users to want to share a single broadband connection with their
own networks, and Linux users in particular would often set up an extra machine to use as a router running
NAT.
Manufacturers responded to this new market by offering specialized router hardware consisting of an efficient
processor, some flash memory, and several network ports—with enough power to manage a typical simple
network, run important software such as a DHCP server, and use NAT. When it came to software, many
manufacturers turned to Linux to power their routers. They added the necessary kernel features, stripped down
the user-space software, and created GUI-based administration interfaces.
Almost as soon as the first of these routers appeared, many people became interested in digging deeper into
the hardware. One manufacturer, Linksys, was required to release the source code for its software under the
terms of the license of one its components, and soon specialized Linux distributions such as OpenWRT
appeared for routers. (The “WRT” in these names came from the Linksys model number.)
Aside from the hobbyist aspect, there are good reasons to use these distributions: They’re often more stable
than the manufacturer firmware, especially on older router hardware, and they typically offer additional
features. For example, to bridge a network with a wireless connection, many manufacturers require you to buy
matching hardware, but with OpenWRT installed, the manufacturer and age of the hardware don’t really matter.
This is because you’re using a truly open operating system on the router that doesn’t care what hardware you
use as long as your hardware is supported.
You can use much of the knowledge in this book to examine the internals of custom Linux firmware, though
you’ll encounter differences, especially when logging in. As with many embedded systems, open firmware
tends to use BusyBox to provide many shell features. BusyBox is a single executable program that offers
limited functionality for many Unix commands such as the shell, ls, grep, cat, and more. (This saves a
significant amount of memory.) In addition, the boot-time init tends to be very simple on embedded systems.
However, you typically won’t find these limitations to be a problem, because custom Linux firmware often
includes a web administration interface similar to what you’d see from a manufacturer.
9.21 Firewalls
Routers in particular should always include some kind of firewall to keep undesirable traffic out of your
network. A firewall is a software and/or hardware configuration that usually sits on a router between the
Internet and a smaller network, attempting to ensure that nothing “bad” from the Internet harms the smaller
network. You can also set up firewall features for each machine where the machine screens all of its incoming
and outgoing data at the packet level (as opposed to the application layer, where server programs usually try
to perform some access control of their own). Firewalling on individual machines is sometimes called IP
filtering.
A system can filter packets when it
www.EBooksWorld.ir
o receives a packet,
o sends a packet, or
o forwards (routes) a packet to another host or gateway.
With no firewalling in place, a system just processes packets and sends them on their way. Firewalls put
checkpoints for packets at the points of data transfer identified above. The checkpoints drop, reject, or accept
packets, usually based on some of these criteria:
o The source or destination IP address or subnet
o The source or destination port (in the transport layer information)
o The firewall’s network interface
Firewalls provide an opportunity to work with the subsystem of the Linux kernel that processes IP packets.
Let’s look at that now.
9.21.1 Linux Firewall Basics
In Linux, you create firewall rules in a series known as a chain. A set of chains makes up a table. As a packet
moves through the various parts of the Linux networking subsystem, the kernel applies the rules in certain
chains to the packets. For example, after receiving a new packet from the physical layer, the kernel activates
rules in chains corresponding to input.
All of these data structures are maintained by the kernel. The whole system is called iptables, with an
iptables user-space command to create and manipulate the rules.
NOTE
There is a newer system called nftables that has a goal of replacing iptables, but as of this writing,
iptables is the dominant system for firewalls.
Because there can be many tables—each with their own sets of chains, each of which can contain many rules—
packet flow can become quite complicated. However, you’ll normally work primarily with a single table
named filter that controls basic packet flow. There are three basic chains in the filter table: INPUT for incoming
packets, OUTPUT for outgoing packets, and FORWARD for routed packets.
Figure 9-5 and Figure 9-6 show simplified flowcharts for where rules are applied to packets in the filter table.
There are two figures because packets can either come into the system from a network interface (Figure 9-5)
or be generated by a local process (Figure 9-6). As you can see, an incoming packet from the network can be
consumed by a user process and may not reach the FORWARD chain or the OUTPUT chain. Packets generated
by user processes won’t reach the INPUT or FORWARD chains.
www.EBooksWorld.ir
Figure 9-5. Chain-processing sequence for incoming packets from a network
Figure 9-6. Chain-processing sequence for incoming packets from a local process
This gets more complicated because there are many steps along the way other than just these three chains. For
example, packets are subject to PREROUTING and POSTROUTING chains, and chain processing can also
occur at any of the three lower network levels. For a big diagram for everything that’s going on, search the
Internet for “Linux netfilter packet flow,” but remember that these diagrams try to include every possible
scenario for packet input and flow. It often helps to break the diagrams down by packet source, as in Figure 9-
5 and Figure 9-6.
9.21.2 Setting Firewall Rules
Let’s look at how the IP tables system works in practice. Start by viewing the current configuration with this
command:
# iptables -L
The output is usually an empty set of chains, as follows:
Chain INPUT (policy ACCEPT)
target prot opt source destination
Chain FORWARD (policy ACCEPT)
target prot opt source destination
Chain OUTPUT (policy ACCEPT)
target prot opt source destination
www.EBooksWorld.ir
Each firewall chain has a default policy that specifies what to do with a packet if no rule matches the packet.
The policy for all three chains in this example is ACCEPT, meaning that the kernel allows the packet to pass
through the packet-filtering system. The DROP policy tells the kernel to discard the packet. To set the policy
on a chain, use iptables -P like this:
# iptables -P FORWARD DROP
WARNING
Don’t do anything rash with the policies on your machine until you’ve read through the rest of this
section.
Say that someone at 192.168.34.63 is annoying you. To prevent them from talking to your machine, run this
command:
# iptables -A INPUT -s 192.168.34.63 -j DROP
The -A INPUT parameter appends a rule to the INPUT chain. The -s 192.168.34.63 part specifies the
source IP address in the rule, and -j DROP tells the kernel to discard any packet matching the rule. Therefore,
your machine will throw out any packet coming from 192.168.34.63.
To see the rule in place, run iptables -L:
Chain INPUT (policy ACCEPT)
target prot opt source destination
DROP all -- 192.168.34.63 anywhere
Unfortunately, your friend at 192.168.34.63 has told everyone on his subnet to open connections to your SMTP
port (TCP port 25). To get rid of that traffic as well, run
# iptables -A INPUT -s 192.168.34.0/24 -p tcp --destination-port 25 -j
DROP
This example adds a netmask qualifier to the source address as well as -p tcp to specify TCP packets only.
A further restriction, --destination-port 25, says that the rule should only apply to traffic to port 25.
The IP table list for INPUT now looks like this:
Chain INPUT (policy ACCEPT)
target prot opt source destination
DROP all -- 192.168.34.63 anywhere
DROP tcp -- 192.168.34.0/24 anywhere tcp dpt:smtp
All is well until you hear from someone you know at 192.168.34.37 saying that they can’t send you email
because you blocked their machine. Thinking that this is a quick fix, you run this command:
# iptables -A INPUT -s 192.168.34.37 -j ACCEPT
However, it doesn’t work. To see why, look at the new chain:
Chain INPUT (policy ACCEPT)
target prot opt source destination
DROP all -- 192.168.34.63 anywhere
DROP tcp -- 192.168.34.0/24 anywhere tcp dpt:smtp
www.EBooksWorld.ir
ACCEPT all -- 192.168.34.37 anywhere
The kernel reads the chain from top to bottom, using the first rule that matches.
The first rule does not match 192.168.34.37, but the second does, because it applies to all hosts from
192.168.34.1 to 192.168.34.254 and this second rule says to drop packets. When a rule matches, the kernel
carries out the action and looks no further down in the chain. (You might notice that 192.168.34.37 can send
packets to any port on your machine except port 25 because the second rule only applies to port 25.)
The solution is to move the third rule to the top. First, delete the third rule with this command:
# iptables -D INPUT 3
Then insert that rule at the top of the chain with iptables -I:
# iptables -I INPUT -s 192.168.34.37 -j ACCEPT
To insert a rule elsewhere in a chain, put the rule number after the chain name (for example, iptables -I
INPUT 4 ...).
9.21.3 Firewall Strategies
Although the tutorial above showed you how to insert rules and how the kernel processes IP chains, we haven’t
seen firewall strategies that actually work. Let’s talk about that now.
There are two basic kinds of firewall scenarios: one for protecting individual machines (where you set rules
in each machine’s INPUT chain) and one for protecting a network of machines (where you set rules in the
router’s FORWARD chain). In both cases, you can’t have serious security if you use a default policy of
ACCEPT and continuously insert rules to drop packets from sources that start to send bad stuff. You must
allow only the packets that you trust and deny everything else.
For example, say your machine has an SSH server on TCP port 22. There’s no reason for any random host to
initiate a connection to any other port on your machine, and you shouldn’t give any such host a chance. To set
that up, first set the INPUT chain policy to DROP:
# iptables -P INPUT DROP
To enable ICMP traffic (for ping and other utilities), use this line:
# iptables -A INPUT -p icmp -j ACCEPT
Make sure that you can receive packets you send to both your own network IP address and 127.0.0.1
(localhost). Assuming your host’s IP address is my_addr, do this:
# iptables -A INPUT -s 127.0.0.1 -j ACCEPT
# iptables -A INPUT -s my_addr -j ACCEPT
If you control your entire subnet (and trust everything on it), you can replace my_addr with your subnet
address and subnet mask, for example, 10.23.2.0/24.
Now, although you still want to deny incoming TCP connections, you still need to make sure that your host
can make TCP connections to the outside world. Because all TCP connections start with a SYN (connection
request) packet, if you let all TCP packets through that aren’t SYN packets, you’re still okay:
# iptables -A INPUT -p tcp '!' --syn -j ACCEPT
Next, if you’re using remote UDP-based DNS, you must accept traffic from your name server so that your
machine can look up names with DNS. Do this for all DNS servers in /etc/resolv.conf. Use this command
(where the name server’s address is ns_addr):
www.EBooksWorld.ir
# iptables -A INPUT -p udp --source-port 53 -s ns_addr -j ACCEPT
And finally, allow SSH connections from anywhere:
# iptables -A INPUT -p tcp --destination-port 22 -j ACCEPT
The preceding iptables settings work for many situations, including any direct connection (especially
broadband) where an intruder is much more likely to port-scan your machine. You could also adapt these
settings for a firewalling router by using the FORWARD chain instead of INPUT and using source and
destination subnets where appropriate. For more advanced configurations, you may find a configuration tool
such as Shorewall to be helpful.
This discussion has only touched on security policy. Remember that the key idea is to permit only the things
that you find acceptable, not to try to find and execute the bad stuff. Furthermore, IP firewalling is only one
piece of the security picture. (You’ll see more in the next chapter.)
9.22 Ethernet, IP, and ARP
There is one interesting basic detail in the implementation of IP over Ethernet that we have yet to cover. Recall
that a host must place an IP packet inside an Ethernet frame in order to transmit the packet across the physical
layer to another host. Recall, too, that frames themselves do not include IP address information; they use MAC
(hardware) addresses. The question is this: When constructing the Ethernet frame for an IP packet, how does
the host know which MAC address corresponds to the destination IP address?
We don’t normally think about this question much because networking software includes an automatic system
of looking up MAC addresses called Address Resolution Protocol (ARP). A host using Ethernet as its physical
layer and IP as the network layer maintains a small table called an ARP cache that maps IP addresses to MAC
addresses. In Linux, the ARP cache is in the kernel. To view your machine’s ARP cache, use the arp command.
(As with many other network commands, the -n option here disables reverse DNS lookups.)
$ arp -n
Address Hwtype Hwaddr Flags Mask Iface
10.1.2.141 ether 00:11:32:0d:ca:82 C eth0
10.1.2.1 ether 00:24:a5:b5:a0:11 C eth0
10.1.2.50 ether 00:0c:41:f6:1c:99 C eth0
When a machine boots, its ARP cache is empty. So how do these MAC addresses get in the cache? It all starts
when the machine wants to send a packet to another host. If a target IP address is not in an ARP cache, the
following steps occur:
1. The origin host creates a special Ethernet frame containing an ARP request packet for the MAC address
that corresponds to the target IP address.
2. The origin host broadcasts this frame to the entire physical network for the target’s subnet.
3. If one of the other hosts on the subnet knows the correct MAC address, it creates a reply packet and
frame containing the address and sends it back to the origin. Often, the host that replies is the target host
and is simply replying with its own MAC address.
4. The origin host adds the IP-MAC address pair to the ARP cache and can proceed.
NOTE
Remember that ARP only applies to machines on local subnets (refer to 9.4 Routes and the Kernel
Routing Table to see your local subnets). To reach destinations outside your subnet, your host
www.EBooksWorld.ir
sends the packet to the router, and it’s someone else’s problem after that. Of course, your host still
needs to know the MAC address for the router, and it can use ARP to find it.
The only real problem you can have with ARP is that your system’s cache can get out-of-date if you’re moving
an IP address from one network interface card to another because the cards have different MAC addresses (for
example, when testing a machine). Unix systems invalidate ARP cache entries if there’s no activity after a
while, so there shouldn’t be any trouble other than a small delay for invalidated data, but you can delete an
ARP cache entry immediately with this command:
# arp -d host
You can also view the ARP cache for a single network interface with
$ arp -i interface
The arp(8) manual page explains how to manually set ARP cache entries, but you shouldn’t need to do this.
NOTE
Don’t confuse ARP with Reverse Address Resolution Protocol (RARP). RARP transforms a MAC
address back to a hostname or IP address. Before DHCP became popular, some diskless
workstations and other devices used RARP to get their configuration, but RARP is rare today.
9.23 Wireless Ethernet
In principle, wireless Ethernet (“WiFi”) networks aren’t much different from wired networks. Much like any
wired hardware, they have MAC addresses and use Ethernet frames to transmit and receive data, and as a
result the Linux kernel can talk to a wireless network interface much as it would a wired network interface.
Everything at the network layer and above is the same; the main differences are additional components in the
physical layer such as frequencies, network IDs, security, and so on.
Unlike wired network hardware, which is very good at automatically adjusting to nuances in the physical setup
without much fuss, wireless network configuration is much more open-ended. To get a wireless interface
working properly, Linux needs additional configuration tools.
Let’s take a quick look at the additional components of wireless networks.
o Transmission details. These are physical characteristics, such as the radio frequency.
o Network identification. Because more than one wireless network can share the same basic medium, you
have to be able to distinguish between them. The SSID (Service Set Identifier, also known as the “network
name”) is the wireless network identifier.
o Management. Although it’s possible to configure wireless networking to have hosts talk directly to each
other, most wireless networks are managed by one or more access points that all traffic goes through.
Access points often bridge a wireless network with a wired network, making both appear as one single
network.
o Authentication. You may want to restrict access to a wireless network. To do so, you can configure access
points to require a password or other authentication key before they’ll even talk to a client.
o Encryption. In addition to restricting the initial access to a wireless network, you normally want to encrypt
all traffic that goes out across radio waves.
The Linux configuration and utilities that handle these components are spread out over a number of areas.
Some are in the kernel: Linux features a set of wireless extensions that standardize user-space access to
hardware. As far as user space goes, wireless configuration can get complicated, so most people prefer to use
GUI frontends, such as the desktop applet for NetworkManager, to get things working. Still, it’s worth looking
www.EBooksWorld.ir
at a few of the things happening behind the scenes.
9.23.1 iw
You can view and change kernel space device and network configuration with a utility called iw. To use iw,
you normally need to know the network interface name for the device, such as wlan0. Here’s an example that
dumps a scan of available wireless networks. (Expect a lot of output if you’re in an urban area.)
# iw dev wlan0 scan
NOTE
The network interface must be up for this command to work (if it’s not, run ifconfig wlan0
up), but you don’t need to configure any network layer parameters, such as an IP address.
If the network interface has joined a wireless network, you can view the network details like this:
# iw dev wlan0 link
The MAC address in the output of this command is from the access point that you’re currently talking to.
NOTE
The iw command distinguishes between physical device names such as phy0 and network
interface names such as wlan0 and allows you to change various settings for each. You can even
create more than one network interface for a single physical device. However, in nearly all basic
cases, you’ll just use the network interface name.
Use iw to connect a network interface to an unsecured wireless network as follows:
# iw wlan0 connect network_name
Connecting to secured networks is a different story. For the rather insecure Wired Equivalent Privacy (WEP)
system, you can use the keys parameter with the iw connect command. However, you shouldn’t use WEP
if you’re serious about security.
9.23.2 Wireless Security
For most wireless security setups, Linux relies on a daemon called wpa_supplicant to manage both
authentication and encryption for a wireless network interface. This daemon can handle both WPA (WiFi
Protected Access) and WPA2 schemes of authentication, as well as nearly any kind of encryption technique
used on wireless networks. When the daemon first starts, it reads a configuration file (by default,
/etc/wpa_supplicant.conf) and attempts to identify itself to an access point and establish communication based
on a given network name. The system is well documented; in particular, the wpa_supplicant(1) and
wpa_supplicant.conf(5) manual pages are very detailed.
Running the daemon by hand every time you want to establish a connection is a lot of work. In fact, just
creating the configuration file is tedious due to the number of possible options. To make matters worse, all of
the work of running iw and wpa_supplicant simply allows your system to join a wireless physical
network; it doesn’t even set up the network layer. And that’s where automatic network configuration managers
such as NetworkManager take a lot of pain out of the process. Although they don’t do any of the work on their
own, they know the correct sequence and required configuration for each step toward getting a wireless
network operational.
9.24 Summary
You can now see that understanding the positions and roles of the various network layers is critical to
understanding how Linux networking operates and how to perform network configuration. Although we’ve
www.EBooksWorld.ir
covered only the basics, more advanced topics in the physical, network, and transport layers bear similarities
to what you’ve seen. Layers themselves are often subdivided, as you just saw with the various pieces of the
physical layer in a wireless network.
A substantial amount of action that you’ve seen in this chapter happens in the kernel, with some basic user-
space control utilities to manipulate the kernel’s internal data structures (such as routing tables). This is the
traditional way of working with the network. However, as with many of the topics discussed in this book,
some tasks aren’t suitable for the kernel due to their complexity and need for flexibility, and that’s where user-
space utilities take over. In particular, NetworkManager monitors and queries the kernel and then manipulates
the kernel configuration. Another example is support for dynamic routing protocols such as Border Gateway
Protocol (BGP), which is used in large Internet routers.
But you’re probably a little bit bored with network configuration by now. Let’s turn to using the network—
the application layer.
www.EBooksWorld.ir
Chapter 10. Network Applications and Services
This chapter explores basic network applications—the clients and servers running in user space that reside at
the application layer. Because this layer is at the top of the stack, close to end users, you may find this material
more accessible than the material in Chapter 9. Indeed, you interact with network client applications such as
web browsers and email readers every day.
To do their work, network clients connect to corresponding network servers. Unix network servers come in
many forms. A server program can listen to a port on its own or through a secondary server. In addition, servers
have no common configuration database and a wide variety of features. Most servers have a configuration file
to control their behavior (though with no common format), and most use the operating system’s syslog service
for message logging. We’ll look at some common servers as well as some tools that will help you understand
and debug server operation.
Network clients use the operating system’s transport layer protocols and interfaces, so understanding the basics
of the TCP and UDP transport layers is important. Let’s start looking at network applications by experimenting
with a network client that uses TCP.
10.1 The Basics of Services
TCP services are among the easiest to understand because they are built upon simple, uninterrupted two-way
data streams. Perhaps the best way to see how they work is to talk directly to a web server on TCP port 80 to
get an idea of how data moves across the connection. For example, run the following command to connect to
a web server:
$ telnet www.wikipedia.org 80
You should get a response like this:
Trying some address...
Connected to www.wikipedia.org.
Escape character is '^]'.
Now enter
GET / HTTP/1.0
Press ENTER twice. The server should send a bunch of HTML text as a response and then terminate the
connection.
This exercise tells us that
o the remote host has a web server process listening on TCP port 80; and
o telnet was the client that initiated the connection.
www.EBooksWorld.ir
NOTE
telnet is a program originally meant to enable logins to remote hosts. Although the non-
Kerberos telnet remote login server is completely insecure (as you will learn later), the telnet
client can be useful for debugging remote services. telnet does not work with UDP or any
transport layer other than TCP. If you’re looking for a general-purpose network client, consider
netcat, described in 10.5.3 netcat.
10.1.1 A Closer Look
In the example above, you manually interacted with a web server on the network with telnet, using the
Hypertext Transfer Protocol (HTTP) application layer protocol. Although you’d normally use a web browser
to make this sort of connection, let’s take just one step up from telnet and use a command-line program
that knows how to speak to the HTTP application layer. We’ll use the curl utility with a special option to
record details about its communication:
$ curl --trace-ascii trace_file http://www.wikipedia.org/
NOTE
Your distribution may not have the curl package preinstalled, but you should have no trouble
installing it if necessary.
You’ll get a lot of HTML output. Ignore it (or redirect it to /dev/null) and instead look at the newly created file
trace_file. Assuming that the connection was successful, the first part of the file should look something like
the following, at the point where curl attempts to establish the TCP connection to the server:
== Info: About to connect() to www.wikipedia.org port 80 (#0)
== Info: Trying 10.80.154.224... == Info: connected
Everything you’ve seen so far happens in the transport layer or below. However, if this connection succeeds,
curl tries to send the request (the “header”); this is where the application layer starts:
=> Send header, 167 bytes (0xa7)
0000: GET / HTTP/1.1
0010: User-Agent: curl/7.22.0 (i686-pc-linux-gnu) libcurl/7.22.0 OpenS
0050: SL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
007f: Host: www.wikipedia.org
0098: Accept: */*
00a5:
The first line here is curl debugging output telling you what it will do next. The remaining lines show what
curl sends to the server. The text in bold is what goes to the server; the hexadecimal numbers at the beginning
are just debugging offsets from curl to help you keep track of how much data was sent or received.
You can see that curl starts by issuing a GET command to the server (as you did with telnet), followed
by some extra information for the server and an empty line. Next, the server sends a reply, first with its own
header, shown here in bold:
<= Recv header, 17 bytes (0x11)
0000: HTTP/1.1 200 OK
<= Recv header, 16 bytes (0x10)
www.EBooksWorld.ir
0000: Server: Apache
<= Recv header, 42 bytes (0x2a)
0000: X-Powered-By: PHP/5.3.10-1ubuntu3.9+wmf1
--snip--
Much like the previous output, the <= lines are debugging output, and 0000: precedes the lines of output to
tell you offsets.
The header in the server’s reply can be fairly long, but at some point the server transitions from transmitting
headers to sending the actual requested document, like this:
<= Recv header, 55 bytes (0x37)
0000: X-Cache: cp1055 hit (16), cp1054 frontend hit (22384)
<= Recv header, 2 bytes (0x2)
0000:
<= Recv data, 877 bytes (0x36d)
0000: 008000
0008: <!DOCTYPE html>.<html lang="mul" dir="ltr">.<head>.<!-- Sysops:
--snip--
This output also illustrates an important property of the application layer. Even though the debugging output
says Recv header and Recv data, implying that those are two different kinds of messages from the
server, there’s no difference in the way that curl talked to the operating system to retrieve the two kinds of
messages, nor any difference in how the operating system handled them, nor any difference in the way that
the network handled the packets underneath. The difference is entirely within the user-space curl application
itself. curl knew that until this point it had been getting headers, but when it received a blank line (the 2-
byte chunk in the middle) signifying the end of headers in HTTP, it knew to interpret anything that followed
as the requested document.
The same is true of the server sending this data. When sending the reply, the server didn’t differentiate between
header and document data sent to the operating system; the distinctions happen inside the user-space server
program.
10.2 Network Servers
Most network servers are like other server daemons on your system such as cron, except that they interact
with network ports. In fact, recall syslogd discussed in Chapter 7; it accepts UDP packets on port 514 when
started with the -r option.
These are some other common network servers that you might find running on your system:
o httpd, apache, apache2 Web servers
o sshd Secure shell daemon (see 10.3 Secure Shell (SSH))
o postfix, qmail, sendmail Mail servers
o cupsd Print server
o nfsd, mountd Network filesystem (file-sharing) daemons
www.EBooksWorld.ir
o smbd, nmbd Windows file-sharing daemons (see Chapter 12)
o rpcbind Remote procedure call (RPC) portmap service daemon
One feature common to most network servers is that they usually operate as multiple processes. At least one
process listens on a network port, and when a new incoming connection is received, the listening process uses
fork() to create a new child process, which is then responsible for the new connection. The child, often
called a worker process, terminates when the connection is closed. Meanwhile, the original listening process
continues to listen on the network port. This process allows a server to easily handle many connections without
much trouble.
There are some exceptions to this model, however. Calling fork() adds a significant amount of system
overhead. In comparison, high-performance TCP servers such as the Apache web server can create a number
of worker processes upon startup so that they are already there to handle connections as needed. Servers that
accept UDP packets simply receive data and react to it; they don’t have connections to listen for.
10.3 Secure Shell (SSH)
Every server works a bit differently. Let’s take a close look at one—the standalone SSH server. One of the
most common network service applications is the secure shell (SSH), the de facto standard for remote access
to a Unix machine. When configured, SSH allows secure shell logins, remote program execution, simple file
sharing, and more—replacing the old, insecure telnet and rlogin remote-access systems with public-key
cryptography for authentication and simpler ciphers for session data. Most ISPs and cloud providers require
SSH for shell access to their services, and many Linux-based network appliances (such as NAS devices) allow
access via SSH as well. OpenSSH (http://www.openssh.com/) is a popular free SSH implementation for Unix,
and nearly all Linux distributions come with it preinstalled. The OpenSSH client is ssh, and the server is
sshd. There are two main SSH protocol versions: 1 and 2. OpenSSH supports both, but version 1 is rarely
used.
Among its many useful capabilities and features, SSH does the following:
o Encrypts your password and all other session data, protecting you from snoopers.
o Tunnels other network connections, including those from X Window System clients. You’ll learn more
about X in Chapter 14.
o Offers clients for nearly any operating system.
o Uses keys for host authentication.
NOTE
Tunneling is the process of packaging and transporting one network connection using another
one. The advantages of using SSH to tunnel X Window System connections are that SSH sets up
the display environment for you and encrypts the X data inside the tunnel.
SSH does have its disadvantages. For one, in order to set up an SSH connection, you need the remote host’s
public key, and you don’t necessarily get it in a secure way (though you can check it manually to make sure
you’re not being spoofed). For an overview of how several methods of cryptography work, get your hands on
the book Applied Cryptography: Protocols, Algorithms, and Source Code in C, 2nd edition, by Bruce Schneier
(Wiley, 1996). Two in-depth books on SSH are SSH Mastery: OpenSSH, PuTTY, Tunnels and Keys by Michael
W. Lucas (Tilted Windmill Press, 2012) and SSH, The Secure Shell, 2nd edition, by Daniel J. Barrett, Richard
E. Silverman, and Robert G. Byrnes(O’Reilly, 2005).
10.3.1 The SSHD Server
Running sshd requires a configuration file and host keys. Most distributions keep configurations in the
www.EBooksWorld.ir
/etc/ssh configuration directory and try to configure everything properly for you if you install their sshd
package. (The configuration filename sshd_config is easy to confuse with the client’s ssh_config setup file, so
be careful.)
You shouldn’t need to change anything in sshd_config, but it never hurts to check. The file consists of
keyword-value pairs, as shown in this fragment:
Port 22
#Protocol 2,1
#ListenAddress 0.0.0.0
#ListenAddress ::
HostKey /etc/ssh/ssh_host_key
HostKey /etc/ssh/ssh_host_rsa_key
HostKey /etc/ssh/ssh_host_dsa_key
Lines beginning with # are comments, and many comments in your sshd_config might indicate default values.
The sshd_config(5) manual page contains descriptions of all possible values, but these are the most important
ones:
o HostKey file Uses file as a host key. (Host keys are described shortly.)
o LogLevel level Logs messages with syslog level level.
o PermitRootLogin value Permits the superuser to log in with SSH if value is set to yes. Set
value to no to prevent this.
o SyslogFacility name Logs messages with syslog facility name.
o X11Forwarding value Enables X Window System client tunneling if value is set to yes.
o XAuthLocation path Provides a path for xauth. X11 tunneling will not work without this path. If
xauth isn’t in /usr/bin, set path to the full pathname for xauth.
Host Keys
OpenSSH has three host key sets: one for protocol version 1 and two for protocol 2. Each set has a public key
(with a .pub file extension) and a private key (with no extension). Do not let anyone see your private key, even
on your own system, because if someone obtains it, you’re at risk from intruders.
SSH version 1 has RSA keys only, and SSH version 2 has RSA and DSA keys. RSA and DSA are public key
cryptography algorithms. The key filenames are given in Table 10-1.
Table 10-1. OpenSSH Key Files
Filename Key Type
ssh_host_rsa_key Private RSA key (version 2)
ssh_host_rsa_key.pub Public RSA key (version 2)
ssh_host_dsa_key Private DSA key (version 2)
ssh_host_dsa_key.pub Public DSA key (version 2)
www.EBooksWorld.ir
Filename Key Type
ssh_host_key Private RSA key (version 1)
ssh_host_key.pub Public RSA key (version 1)
Normally you won’t need to build the keys because the OpenSSH installation program or your distribution’s
installation script will do it for you, but you do need to know how to create keys if you plan to use programs
like ssh-agent. To create SSH protocol version 2 keys, use the ssh-keygen program that comes with
OpenSSH:
# ssh-keygen -t rsa -N '' -f /etc/ssh/ssh_host_rsa_key
# ssh-keygen -t dsa -N '' -f /etc/ssh/ssh_host_dsa_key
For the version 1 keys, use
# ssh-keygen -t rsa1 -N '' -f /etc/ssh/ssh_host_key
The SSH server and clients also use a key file called ssh_known_hosts, which contains public keys from other
hosts. If you intend to use host-based authentication, the server’s ssh_known_hosts file must contain the public
host keys of all trusted clients. Knowing about the key files is handy if you’re replacing a machine. When
installing a new machine from scratch, you can import the key files from the old machine to ensure that users
don’t get key mismatches when connecting to the new one.
Starting the SSH Server
Although most distributions ship with SSH, they usually don’t start the sshd server by default. On Ubuntu
and Debian, installing the SSH server package creates the keys, starts the server, and adds the startup to the
bootup configuration. On Fedora, sshd is installed by default but turned off. To start sshd at boot, use
chkconfig like this (this won’t start the server immediately; use service sshd start for that):
# chkconfig sshd on
Fedora normally creates any missing host key files upon the first sshd startup.
If you don’t have any init support installed yet, running sshd as root starts the server, and upon startup, sshd
writes its PID to /var/run/sshd.pid.
You can also start sshd as a socket unit in systemd or with inetd, but it’s usually not a good idea to do so
because the server occasionally needs to generate key files, a process that can take a long time.
10.3.2 The SSH Client
To log in to a remote host, run
$ ssh remote_username@host
You may omit remote_username@ if your local username is the same as on host. You can also run
pipelines to and from an ssh command as shown in the following example, which copies a directory dir to
another host:
$ tar zcvf - dir | ssh remote_host tar zxvf -
The global SSH client configuration file ssh_config should be in /etc/ssh with your sshd_config file. As with
the server configuration file, the client configuration file has key-value pairs, but you shouldn’t need to change
them.
www.EBooksWorld.ir
The most frequent problem with using SSH clients occurs when an SSH public key in your local
ssh_known_hosts or .ssh/known_hosts file does not match the key on the remote host. Bad keys cause errors
or warnings like this:
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle
attack)!
It is also possible that the RSA host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
38:c2:f6:0d:0d:49:d4:05:55:68:54:2a:2f:83:06:11.
Please contact your system administrator.
Add correct host key in /home/user/.ssh/known_hosts to get rid of this
message.
Offending key in /home/user/.ssh/known_hosts:12➊
RSA host key for host has changed and you have requested
strict checking.
Host key verification failed.
This usually just means that the remote host’s administrator changed the keys (this often happens when
replacing hardware), but it never hurts to check with the administrator if you’re not sure. In any case, the
preceding message tells you that the bad key is in line 12 of a user’s known_hosts file, as shown at ➊.
If you don’t suspect foul play, just remove the offending line or replace it with the correct public key.
SSH File Transfer Clients
OpenSSH includes the file transfer programs scp and sftp, which are intended as replacements for the older,
insecure programs rcp and ftp.
You can use scp to transfer files to or from a remote machine to your machine or from one host to another. It
works like the cp command. Here are a few examples:
$ scp user@host:file .
$ scp file user@host:dir
$ scp user1@host1:file user2@host2:dir
The sftp program works like the command-line ftp client, using get and put commands. The remote
host must have an sftp-server program installed, which you can expect if the remote host also uses
OpenSSH.
NOTE
If you need more features and flexibility than the offerings of scp and sftp (for example, if you’re
www.EBooksWorld.ir
transferring large numbers of files often), have a look at rsync, described in Chapter 12.
SSH Clients for Non-Unix Platforms
There are SSH clients for all popular operating systems, as listed on the OpenSSH web page
(http://www.openssh.com/). Which one should you choose? PuTTY is a good, basic Windows client that
includes a secure file-copy program. MacSSH works well for Mac OS 9.x and lower. Mac OS X is based on
Unix and includes OpenSSH.
10.4 The inetd and xinetd Daemons
Implementing standalone servers for every service can be somewhat inefficient. Each server must be
separately configured to handle port listening, access control, and port configuration. These actions are
performed in the same way for most services; only when a server accepts a connection is there any difference
in the way communication is handled.
One traditional way to simplify the use of servers is with the inetd daemon, a kind of superserver designed
to standardize network port access and interfaces between server programs and network ports. After you start
inetd, it reads its configuration file and then listens on the network ports defined in that file. As new network
connections come in, inetd attaches a newly started process to the connection.
A newer version of inetd called xinetd offers easier configuration and better access control, but xinetd
itself is being phased out in favor of systemd, which can provide the same functionality through socket units,
as described in 6.4.7 systemd On-Demand and Resource-Parallelized Startup.
Although inetd is no longer commonly used, its configuration shows everything necessary to set up a service.
As it turns out, sshd can also be invoked by inetd rather than as a standalone server, as shown in this /etc/
inetd.conf configuration file:
ident stream tcp nowait root /usr/sbin/sshd sshd -i
The seven fields here are, from left to right:
o Service name. The service name from /etc/services (see 9.14.3 Port Numbers and /etc/services).
o Socket type. This is usually stream for TCP and dgram for UDP.
o Protocol. The transport protocol, usually tcp or udp.
o Datagram server behavior. For UDP, this is wait or nowait. Services using any other transport
protocol should use nowait.
o User. The username to run the service. Add .group to set a group.
o Executable. The program that inetd should connect to the service.
o Arguments. The arguments for the executable. The first argument should be the name of the program.
10.4.1 TCP Wrappers: tcpd, /etc/hosts.allow, and /etc/hosts.deny
Before lower-level firewalls became popular, many administrators used the TCP wrapper library and daemon
for host control over network services. In these implementations, inetd runs the tcpd program, which first
looks at the incoming connection as well as the access control lists in the /etc/hosts.allow and /etc/hosts.deny
files. The tcpd program logs the connection, and if it decides that the incoming connection is okay, it hands
it to the final service program. (Although you may find a system that still uses the TCP wrapper system, we
won’t cover it in detail because it has largely fallen into disuse.)
www.EBooksWorld.ir
10.5 Diagnostic Tools
Let’s look at a few diagnostic tools that are useful for poking around the application layer. Some dig into the
transport and network layers, because everything in the application layer eventually maps down to something
in those lower layers.
As discussed in Chapter 9, netstat is a basic network service debugging tool that can display a number of
transport and network layer statistics. Table 10-2 reviews a few useful options for viewing connections.
Table 10-2. Useful Connection-Reporting Options for netstat
Option Description
-t Prints TCP port information
-u Prints UDP port information
-l Prints listening ports
-a Prints every active port
-n Disables name lookups (speeds things up; also useful if DNS isn’t working)
10.5.1 lsof
In Chapter 8, you learned that lsof can track open files, but it can also list the programs currently using or
listening to ports. For a complete list of programs using or listening to ports, run
# lsof -i
When run as a regular user, this command only shows that user’s processes. When run as root, the output
should look something like this, displaying a variety of processes and users:
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
rpcbind 700 root 6u IPv4 10492 0t0 UDP *:sunrpc
rpcbind 700 root 8u IPv4 10508 0t0 TCP *:sunrpc
(LISTEN)
avahi-dae 872 avahi 13u IPv4 21736375 0t0 UDP *:mdns
cupsd 1010 root 9u IPv6 42321174 0t0 TCP ip6-
localhost:ipp (LISTEN)
ssh 14366 juser 3u IPv4 38995911 0t0 TCP
thishost.local:55457->
somehost.example.com:ssh (ESTABLISHED)
chromium- 26534 juser 8r IPv4 42525253 0t0 TCP
thishost.local:41551->
anotherhost.example.com:https (ESTABLISHED)
This example output shows users and process IDs for server and client programs, from the old-style RPC
services at the top, to the multicast DNS service provided by avahi, and even an IPv6-ready printer service
www.EBooksWorld.ir
(cupsd). The last two entries show client connections: an SSH connection and a secure web connection from
the Chromium web browser. Because the output can be extensive, it’s usually best to apply a filter (as discussed
in the following section).
The lsof program is like netstat in that it tries to reverse-resolve every IP address that it finds into a
hostname, which slows down the output. Use the -n option to disable name resolution:
# lsof -n -i
You can also specify -P to disable /etc/services port name lookups.
Filtering by Protocol and Port
If you’re looking for a particular port (say, you know that a process is using a particular port and you want to
know what that process is), use this command:
# lsof -i:port
The full syntax is as follows:
# lsof -iprotocol@host:port
The protocol, @host, and :port parameters are all optional and will filter the lsof output accordingly.
As with most network utilities, host and port can be either names or numbers. For example, if you only
want to see connections on TCP port 80 (the HTTP port), use
# lsof -iTCP:80
Filtering by Connection Status
One particularly handy lsof filter is connection status. For example, to show only the processes listening on
TCP ports, enter
# lsof -iTCP -sTCP:LISTEN
This command gives you a good overview of the network server processes currently running on your system.
However, because UDP servers don’t listen and don’t have connections, you’ll have to use -iUDP to view
running clients as well as servers. This usually isn’t a problem, because you probably won’t have many UDP
servers on your system.
10.5.2 tcpdump
If you need to see exactly what’s crossing your network, tcpdump puts your network interface card into
promiscuous mode and reports on every packet that crosses the wire. Entering tcpdump with no arguments
produces output like the following, which includes an ARP request and web connection:
# tcpdump
tcpdump: listening on eth0
20:36:25.771304 arp who-has mikado.example.com tell duplex.example.com
20:36:25.774729 arp reply mikado.example.com is-at 0:2:2d:b:ee:4e
20:36:25.774796 duplex.example.com.48455 > mikado.example.com.www: S
3200063165:3200063165(0) win 5840 <mss 1460,sackOK,timestamp
38815804[|tcp]>
(DF)
20:36:25.779283 mikado.example.com.www > duplex.example.com.48455: S
www.EBooksWorld.ir
3494716463:3494716463(0) ack 3200063166 win 5792 <mss
1460,sackOK,timestamp
4620[|tcp]> (DF)
20:36:25.779409 duplex.example.com.48455 > mikado.example.com.www: .
ack 1 win
5840 <nop,nop,timestamp 38815805 4620> (DF)
20:36:25.779787 duplex.example.com.48455 > mikado.example.com.www: P
1:427(426)
ack 1 win 5840 <nop,nop,timestamp 38815805 4620> (DF)
20:36:25.784012 mikado.example.com.www > duplex.example.com.48455: .
ack 427
win 6432 <nop,nop,timestamp 4620 38815805> (DF)
20:36:25.845645 mikado.example.com.www > duplex.example.com.48455: P
1:773(772)
ack 427 win 6432 <nop,nop,timestamp 4626 38815805> (DF)
20:36:25.845732 duplex.example.com.48455 > mikado.example.com.www: .
ack 773
win 6948 <nop,nop,timestamp 38815812 4626> (DF)
9 packets received by filter
0 packets dropped by kernel
You can tell tcpdump to be more specific by adding filters. You can filter based on source and destination
hosts, networks, Ethernet addresses, protocols at many different layers in the network model, and much more.
Among the many packet protocols that tcpdump recognizes are ARP, RARP, ICMP, TCP, UDP, IP, IPv6,
AppleTalk, and IPX packets. For example, to tell tcpdump to output only TCP packets, run
# tcpdump tcp
To see web packets and UDP packets, enter
# tcpdump udp or port 80
NOTE
If you need to do a lot of packet sniffing, consider using a GUI alternative to tcpdump such as
Wireshark.
Primitives
In the preceding examples, tcp, udp, and port 80 are called primitives. The most important primitives are
in Table 10-3:
Table 10-3. tcpdump Primitives
www.EBooksWorld.ir
Primitive Packet Specification
tcp TCP packets
udp UDP packets
port port TCP and/or UDP packets to/from port port
host host Packets to or from host
net network Packets to or from network
Operators
The or used in the previous example is an operator. tcpdump can use multiple operators (such as and
and !), and you can group operators in parentheses. If you plan to do any serious work with tcpdump, make
sure to read the manual page, especially the section that describes the primitives.
When Not to Use tcpdump
Be very careful when using tcpdump. The tcpdump output shown earlier in this section includes only
packet TCP (transport layer) and IP (Internet layer) header information, but you can also make tcpdump
print the entire packet contents. Even though many network operators make it far too easy to look at their
network packets, you shouldn’t snoop around on networks unless you own them.
10.5.3 netcat
If you need more flexibility in connecting to a remote host than a command like telnet host port allows,
use netcat (or nc). netcat can connect to remote TCP/UDP ports, specify a local port, listen on ports,
scan ports, redirect standard I/O to and from network connections, and more. To open a TCP connection to a
port with netcat, run
$ netcat host port
netcat only terminates when the other side of the connection ends the connection, which can confuse things
if you redirect standard input to netcat. You can end the connection at any time by pressing CTRL-C. (If
you’d like the program and network connection to terminate based on the standard input stream, try the sock
program instead.)
To listen on a particular port, run
$ netcat -l -p port_number
10.5.4 Port Scanning
Sometimes you don’t even know what services the machines on your networks are offering or even which IP
addresses are in use. The Network Mapper (Nmap) program scans all ports on a machine or network of
machines looking for open ports, and it lists the ports it finds. Most distributions have an Nmap package, or
you can get it at http://www.insecure.org/. (See the Nmap manual page and online resources for all that Nmap
can do.)
When listing ports on your own machine, it often helps to run the Nmap scan from at least two points: from
your own machine and from another one (possibly outside your local network). Doing so will give you an
overview of what your firewall is blocking.
www.EBooksWorld.ir
WARNING
If someone else controls the network that you want to scan with Nmap, ask for permission.
Network administrators watch for port scans and usually disable access to machines that run
them.
Run nmap host to run a generic scan on a host. For example:
$ nmap 10.1.2.2
Starting Nmap 5.21 ( http://nmap.org ) at 2015-09-21 16:51 PST
Nmap scan report for 10.1.2.2
Host is up (0.00027s latency).
Not shown: 993 closed ports
PORT STATE SERVICE
22/tcp open ssh
25/tcp open smtp
80/tcp open http
111/tcp open rpcbind
8800/tcp open unknown
9000/tcp open cslistener
9090/tcp open zeus-admin
Nmap done: 1 IP address (1 host up) scanned in 0.12 seconds
As you can see, a number of services are open here, many of which are not enabled by default on most
distributions. In fact, the only one here that’s usually on by default is port 111, the rpcbind port.
10.6 Remote Procedure Call (RPC)
What about the rpcbind service that you just saw in the scan in the preceding section? RPC stands for
remote procedure call, a system residing in the lower parts of the application layer. It’s designed to make it
easier for programmers to access network applications by leveraging the fact that programs call functions on
remote programs (identified by program numbers) and the remote programs return a result code or message.
RPC implementations use transport protocols such as TCP and UDP, and they require a special intermediary
service to map program numbers to TCP and UDP ports. The server is called rpcbind, and it must be running
on any machine that wants to use RPC services.
To see what RPC services your computer has, run
$ rpcinfo -p localhost
RPC is one of those protocols that just doesn’t want to die. The Network File System (NFS) and Network
Information Service (NIS) systems use RPC, but they are completely unnecessary on standalone machines.
But whenever you think that you’ve eliminated all need for rpcbind, something else comes up, such as File
Access Monitor (FAM) support in GNOME.
www.EBooksWorld.ir
10.7 Network Security
Because Linux is a very popular Unix flavor on the PC platform, and especially because it is widely used for
web servers, it attracts many unpleasant characters who try to break into computer systems. 9.21 Firewalls
discussed firewalls, but that’s not really the whole story on security.
Network security attracts extremists—those who really like to break into systems (whether for fun or money)
and those who come up with elaborate protection schemes who really like to swat away people trying to break
into their systems. (This, too, can be very profitable.) Fortunately, you don’t need to know very much to keep
your system safe. Here are a few basic rules of thumb:
o Run as few services as possible. Intruders can’t break into services that don’t exist on your system. If you
know what a service is and you’re not using it, don’t turn it on for the sole reason that you might want to
use it “at some later point.”
o Block as much as possible with a firewall. Unix systems have a number of internal services that you may
not know about (such as TCP port 111 for the RPC port-mapping server), and no other system in the world
should know about them. It can be very difficult to track and regulate the services on your system because
many different kinds of programs listen on various ports. To keep intruders from discovering internal
services on your system, use effective firewall rules, and install a firewall at your router.
o Track the services that you offer to the Internet. If you run an SSH server, Postfix, or similar services,
keep your software up-to-date and get appropriate security alerts. (See 10.7.2 Security Resources for some
online resources.)
o Use “long-term support” distribution releases for servers. Security teams normally concentrate their
work on stable, supported distribution releases. Development and testing releases such Debian Unstable and
Fedora Rawhide receive much less attention.
o Don’t give an account on your system to anyone who doesn’t need one. It’s much easier to gain
superuser access from a local account than it is to break in remotely. In fact, given the huge base of
software (and the resulting bugs and design flaws) available on most systems, it can be easy to gain
superuser access to a system after you get to a shell prompt. Don’t assume that your friends know how to
protect their passwords (or choose good passwords in the first place).
o Avoid installing dubious binary packages. They can contain Trojan horses.
That’s the practical end of protecting yourself. But why is it important to do so? There are three basic kinds
of network attacks:
o Full compromise. This means getting superuser access (full control) of a machine. An intruder can
accomplish this by trying a service attack, such as a buffer overflow exploit, or by taking over a poorly
protected user account and then trying to exploit a poorly written setuid program.
o Denial-of-service (DoS) attack. This prevents a machine from carrying out its network services or forces a
computer to malfunction in some other way without the use of any special access. These attacks are harder
to prevent, but they are easier to respond to.
o Malware. Linux users are mostly immune to malware such as email worms and viruses, simply because
their email clients aren’t stupid enough to actually run programs that they get in message attachments. But
Linux malware does exist. Avoid downloading and installing binary software from places that you’ve never
heard of.
10.7.1 Typical Vulnerabilities
There are two important kinds of vulnerabilities to worry about: direct attacks and clear-text password sniffing.
Direct attacks try to take over a machine without being terribly subtle. The most common is a buffer overflow
www.EBooksWorld.ir
exploit, where a careless programmer doesn’t check the bounds of a buffer array. The attacker fabricates a
stack frame inside a huge chunk of data, dumps it to the remote server, and then hopes that the server
overwrites its program data and eventually executes the new stack frame. Although a somewhat complicated
attack, it’s easy to replicate.
A second attack to worry about is one that captures passwords sent across the wire as clear text. As soon as an
attacker gets your password, it’s game over. From there, the assailant will inevitably try to gain superuser
access locally (which is much easier than making a remote attack), try to use the machine as an intermediary
for attacking other hosts, or both.
NOTE
If you have a service that offers no native support for encryption, try Stunnel
( http://www.stunnel.org/), an encryption wrapper package much like TCP wrappers. Like tcpd,
Stunnel is especially good at wrapping inetd services.
Some services are chronic attack targets due to poor implementation and design. You should always deactivate
the following services (they’re rarely activated by default on most systems):
o ftpd For whatever reason, all FTP servers seem plagued with vulnerabilities. In addition, most FTP
servers use clear-text passwords. If you have to move files from one machine to another, consider an SSH-
based solution or an rsync server.
o telnetd, rlogind, rexecd All of these pass remote session data (including passwords) in clear-text
form. Avoid them unless you happen to have a Kerberos-enabled version.
o fingerd Intruders can get user lists and other information with the finger service.
10.7.2 Security Resources
Here are three good security sites:
o http://www.sans.org/ Offers training, services, a free weekly newsletter listing the top current
vulnerabilities, sample security policies, and more.
o http://www.cert.org/ A place to look for the most severe problems.
o http://www.insecure.org/ This is the place to go for Nmap and pointers to all sorts of network exploit-
testing tools. It’s much more open and specific about exploits than are many other sites.
If you’re interested in network security, you should learn all about Transport Layer Security (TLS) and its
predecessor, Secure Socket Layer (SSL). These user-space network levels are typically added to networking
clients and servers to support network transactions through the use of public-key encryption and certificates.
A good guide is Davies’s Implementing SSL/TLS Using Cryptography and PKI (Wiley, 2011).
10.8 Looking Forward
If you’re interested in getting your hands dirty with some complicated network servers, two very common
ones are the Apache web server and the Postfix email server. In particular, Apache is easy to install and most
distributions supply a package. If your machine is behind a firewall or NAT-enabled router, you can experiment
with the configuration as much as you’d like without worrying about security.
Throughout the last few chapters, we’ve been gradually moving from kernel space into user space. Only a few
utilities discussed in this chapter, such as tcpdump, interact with the kernel. The remainder of this chapter
describes how sockets bridge the gap between the kernel’s transport layer and the user-space application layer.
It’s more advanced material, of particular interest to programmers, so feel free to skip to the next chapter if
you like.
www.EBooksWorld.ir
10.9 Sockets: How Processes Communicate with the Network
We’re now going to shift gears a little and look at how processes do the work of reading data from and writing
data to the network. It’s easy enough for processes to read from and write to network connections that are
already set up: All you need are some system calls, which you can read about in the recv(2) and send(2)
manual pages. From the point of view of a process, perhaps the most important thing to know is how to refer
to the network when using these system calls. On Unix systems, a process uses a socket to identify when and
how it’s talking to the network. Sockets are the interface that processes use to access the network through the
kernel; they represent the boundary between user space and kernel space. They’re often also used for
interprocess communication (IPC).
There are different types of sockets because processes need to access the network in different ways. For
example, TCP connections are represented by stream sockets (SOCK_STREAM, from a programmer’s point
of view), and UDP connections are represented by datagram sockets (SOCK_DGRAM).
Setting up a network socket can be somewhat complicated because you need to account for socket type, IP
addresses, ports, and transport protocol at particular times. However, after all of the initial details are sorted
out, servers use certain standard methods to deal with incoming traffic from the network.
The flowchart in Figure 10-1 shows how many servers handle connections for incoming stream sockets.
Notice that this type of server involves two kinds of sockets: a listening socket and a socket for reading and
writing. The master process uses the listening socket to look for connections from the network. When a new
connection comes in, the master process uses the accept() system call to accept the connection, which
creates the read/write socket dedicated to that one connection. Next, the master process uses fork() to create
a new child process to deal with the connection. Finally, the original socket remains the listener and continues
to look for more connections on behalf of the master process.
After a process has set up a socket of a particular type, it can interact with it in a way that fits the socket type.
This is what makes sockets flexible: If you need to change the underlying transport layer, you don’t have to
rewrite all of the parts that send and receive data; you mostly need to modify the initialization code.
Figure 10-1. One method for accepting and processing incoming connections
If you’re a programmer and you’d like to learn how to use the socket interface, Unix Network Programming,
Volume 1, 3rd edition, by W. Richard Stephens, Bill Fenner, and Andrew M. Rudoff (Addison-Wesley
Professional, 2003) is the classic guide. Volume 2 also covers interprocess communication.
www.EBooksWorld.ir
10.10 Unix Domain Sockets
Applications that use network facilities don’t have to involve two separate hosts. Many applications are built
as client-server or peer-to-peer mechanisms, where processes running the same machine use interprocess
communication (IPC) to negotiate what work needs to be done and who does it. For example, recall that
daemons such as systemd and NetworkManager use D-Bus to monitor and react to system events.
Processes can use regular IP networking over localhost (127.0.0.1) to communicate, but instead, typically use
a special kind of socket, which we briefly touched upon in Chapter 3, called a Unix domain socket. When a
process connects to a Unix domain socket, it behaves almost exactly like a network socket: It can listen for
and accept connections on the socket, and you can even choose between different kinds of socket types to
make it behave like TCP or UDP.
NOTE
It’s important to remember that a Unix domain socket is not a network socket, and there’s no
network behind one. You don’t even need networking to be configured to use one. And Unix
domain sockets don’t have to be bound to socket files. A process can create an unnamed Unix
domain socket and share the address with another process.
10.10.1 Advantages for Developers
Developers like Unix domain sockets for IPC for two reasons. First, they allow developers the option to use
special socket files in the filesystem to control access, so any process that doesn’t have access to a socket file
can’t use it. And because there’s no interaction with the network, it’s simpler and less prone to conventional
network intrusion. For example, you’ll usually find the socket file for D-Bus in /var/run/dbus:
$ ls -l /var/run/dbus/system_bus_socket
srwxrwxrwx 1 root root 0 Nov 9 08:52 /var/run/dbus/system_bus_socket
Second, because the Linux kernel does not have to go through the many layers of its networking subsystem
when working with Unix domain sockets, performance tends to be much better.
Writing code for Unix domain sockets is not much different from supporting normal network sockets. Because
the benefits can be significant, some network servers offer communication through both network and Unix
domain sockets. For example, the MySQL database server mysqld can accept client connections from remote
hosts, but it usually also offers a Unix domain socket at /var/run/mysqld/mysqld.sock.
10.10.2 Listing Unix Domain Sockets
You can view a list of Unix domain sockets currently in use on your system with lsof -U:
# lsof -U
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
mysqld 19701 mysql 12u unix 0xe4defcc0 0t0 35201227
/var/run/mysqld/mysqld.sock
chromium- 26534 juser 5u unix 0xeeac9b00 0t0 42445141
socket
tlsmgr 30480 postfix 5u unix 0xc3384240 0t0 17009106
socket
tlsmgr 30480 postfix 6u unix 0xe20161c0 0t0 10965
private/tlsmgr
www.EBooksWorld.ir
--snip--
The listing will be quite long because many modern applications make extensive use of unnamed sockets. You
can identify the unnamed ones because you’ll see socket in the NAME output column.
www.EBooksWorld.ir
Chapter 11. Introduction to Shell Scripts
If you can enter commands into the shell, you can write shell scripts (also known as Bourne shell scripts). A
shell script is a series of commands written in a file; the shell reads the commands from the file just as it would
if you typed them into a terminal.
11.1 Shell Script Basics
Bourne shell scripts generally start with the following line, which indicates that the /bin/sh program should
execute the commands in the script file. (Make sure that no whitespace appears at the beginning of the script
file.)
#!/bin/sh
The #! part is called a shebang; you’ll see it in other scripts in this book. You can list any commands that you
want the shell to execute following the #!/bin/sh line. For example:
#!/bin/sh
#
# Print something, then run ls
echo About to run the ls command.
ls
NOTE
A # character at the beginning of a line indicates that the line is a comment; that is, the shell
ignores anything on a line after a #. Use comments to explain parts of your scripts that are difficult
to understand.
After creating a shell script and setting its permissions, you can run it by placing the script file in one of the
directories in your command path and then running the script name on the command line. You can also
run ./script if the script is located in your current working directory, or you can use the full pathname.
As with any program on Unix systems, you need to set the executable bit for a shell script file, but you must
also set the read bit in order for the shell to read the file. The easiest way to do this is as follows:
$ chmod +rx script
This chmod command allows other users to read and execute script. If you don’t want that, use the absolute
mode 700 instead (and refer to 2.17 File Modes and Permissions for a refresher on permissions).
With the basics behind us, let’s look at some of the limitations of shell scripts.
www.EBooksWorld.ir
11.1.1 Limitations of Shell Scripts
The Bourne shell manipulates commands and files with relative ease. In 2.14 Shell Input and Output, you saw
the way the shell can redirect output, one of the important elements of shell script programming. However,
the shell script is only one tool for Unix programming, and although scripts have considerable power, they
also have limitations.
One of the main strengths of shell scripts is that they can simplify and automate tasks that you can otherwise
perform at the shell prompt, like manipulating batches of files. But if you’re trying to pick apart strings,
perform repeated arithmetic computations, or access complex databases, or if you want functions and complex
control structures, you’re better off using a scripting language like Python, Perl, or awk, or perhaps even a
compiled language like C. (This is important, so we’ll repeat it throughout the chapter.)
Finally, be aware of your shell script sizes. Keep your shell scripts short. Bourne shell scripts aren’t meant to
be big (though you will undoubtedly encounter some monstrosities).
11.2 Quoting and Literals
One of the most confusing elements of working with the shell and scripts is when to use quotation marks (or
quotes) and other punctuation, and why it’s sometimes necessary to do so. Let’s say you want to print the
string $100 and you do the following:
$ echo $100
00
Why did this print 00? Because the shell saw $1, which is a shell variable (we’ll cover it soon). So you might
think that if you surround it with double quotes, the shell will leave the $1 alone. But it still doesn’t work:
$ echo "$100"
00
Then you ask a friend, who says that you need to use single quotes instead:
$ echo '$100'
$100
Why did this particular incantation work?
11.2.1 Literals
When you use quotes, you’re often trying to create a literal, a string that you want the shell to pass to the
command line untouched. In addition to the $ in the example that you just saw, other similar circumstances
include when you want to pass a * character to a command such as grep instead of having the shell expand
it, and when you need to need to use a semicolon (;) in a command.
When writing scripts and working on the command line, just remember what happens whenever the shell runs
a command:
1. Before running the command, the shell looks for variables, globs, and other substitutions and performs
the substitutions if they appear.
2. The shell passes the results of the substitutions to the command.
Problems involving literals can be subtle. Let’s say you’re looking for all entries in /etc/passwd that match the
regular expression r.*t (that is, a line that contains an r followed by a t later in the line, which would enable
you to search for usernames such as root and ruth and robot). You can run this command:
www.EBooksWorld.ir
$ grep r.*t /etc/passwd
It works most of the time, but sometimes it mysteriously fails. Why? The answer is probably in your current
directory. If that directory contains files with names such as r.input and r.output, then the shell expands r.*t
to r.input r.output and creates this command:
$ grep r.input r.output /etc/passwd
The key to avoiding problems like this is to first recognize the characters that can get you in trouble and then
apply the correct kind of quotes to protect the characters.
11.2.2 Single Quotes
The easiest way to create a literal and make the shell leave a string alone is to enclose the entire string in single
quotes, as in this example with grep and the * character:
$ grep 'r.*t' /etc/passwd
As far as the shell is concerned, all characters between the two single quotes, including spaces, make up a
single parameter. Therefore, the following command does not work, because it asks the grep command to
search for the string r.*t /etc/passwd in the standard input (because there’s only one parameter to
grep):
$ grep 'r.*t /etc/passwd'
When you need to use a literal, you should always turn to single quotes first, because you’re guaranteed that
the shell won’t try any substitutions. As a result, it’s a generally clean syntax. However, sometimes you need
a little more flexibility, so you can turn to double quotes.
11.2.3 Double Quotes
Double quotes (") work just like single quotes, except that the shell expands any variables that appear within
double quotes. You can see the difference by running the following command and then replacing the double
quotes with single quotes and running it again.
$ echo "There is no * in my path: $PATH"
When you run the command, notice that the shell substitutes for $PATH but does not substitute for the *.
NOTE
If you’re using double quotes when printing large amounts of text, consider using a here
document, as described in 11.9 Here Documents.
11.2.4 Passing a Literal Single Quote
One tricky part to using literals with the Bourne shell comes when passing a literal single quote to a command.
One way to do this is to place a backslash before the single quote character:
$ echo I don\'t like contractions inside shell scripts.
The backslash and quote must appear outside any pair of single quotes, and a string such as 'don\'t results
in a syntax error. Oddly enough, you can enclose the single quote inside double quotes, as shown in the
following example (the output is identical to that of the preceding command):
$ echo "I don't like contractions inside shell scripts."
If you’re in a bind and you need a general rule to quote an entire string with no substitutions, follow this
procedure:
www.EBooksWorld.ir
1. Change all instances of ' (single quote) to '\'' (single quote, backslash, single quote, single quote).
2. Enclose the entire string in single quotes.
Therefore, you can quote an awkward string such as this isn't a forward slash: \ as follows:
$ echo 'this isn'\''t a forward slash: \'
NOTE
It’s worth repeating that when you quote a string, the shell treats everything inside the quotes as a
single parameter. Therefore, a b c counts as three parameters, but a "b c" is only two.
11.3 Special Variables
Most shell scripts understand command-line parameters and interact with the commands that they run. To take
your scripts from being just a simple list of commands to becoming more flexible shell script programs, you
need to know how to use the special Bourne shell variables. These special variables are like any other shell
variable as described in 2.8 Environment and Shell Variables, except that you cannot change the values of
certain ones.
NOTE
After reading the next few sections, you’ll understand why shell scripts accumulate many special
characters as they are written. If you’re trying to understand a shell script and you come across a
line that looks completely incomprehensible, pick it apart piece by piece.
11.3.1 Individual Arguments: $1, $2, ...
$1, $2, and all variables named as positive nonzero integers contain the values of the script parameters, or
arguments. For example, say the name of the following script is pshow:
#!/bin/sh
echo First argument: $1
echo Third argument: $3
Try running the script as follows to see how it prints the arguments:
$ ./pshow one two three
First argument: one
Third argument: three
The built-in shell command shift can be used with argument variables to remove the first argument ($1)
and advance the rest of the arguments forward. Specifically, $2 becomes $1, $3 becomes $2, and so on. For
example, assume that the name of the following script is shiftex:
#!/bin/sh
echo Argument: $1
shift
echo Argument: $1
shift
echo Argument: $1
www.EBooksWorld.ir
Run it like this to see it work:
$ ./shiftex one two three
Argument: one
Argument: two
Argument: three
As you can see, shiftex prints all three arguments by printing the first, shifting the remaining arguments,
and repeating.
11.3.2 Number of Arguments: $#
The $# variable holds the number of arguments passed to a script and is especially important when running
shift in a loop to pick through arguments. When $# is 0, no arguments remain, so $1 is empty. (See 11.6
Loops for a description of loops.)
11.3.3 All Arguments: $@
The $@ variable represents all of a script’s arguments, and it is very useful for passing them to a command
inside the script. For example, Ghostscript commands (gs) are usually long and complicated. Suppose you
want a shortcut for rasterizing a PostScript file at 150 dpi, using the standard output stream, while also leaving
the door open for passing other options to gs. You could write a script like this to allow for additional
command-line options:
#!/bin/sh
gs -q -dBATCH -dNOPAUSE -dSAFER -sOutputFile=- -sDEVICE=pnmraw $@
NOTE
If a line in your shell script gets too long for your text editor, you can split it up with a backslash
( \). For example, you can alter the preceding script as follows:
#!/bin/sh
gs -q -dBATCH -dNOPAUSE -dSAFER \
-sOutputFile=- -sDEVICE=pnmraw $@
11.3.4 Script Name: $0
The $0 variable holds the name of the script, and it is useful for generating diagnostic messages. For example,
say your script needs to report an invalid argument that is stored in the $BADPARM variable. You can print the
diagnostic message with the following line so that the script name appears in the error message:
echo $0: bad option $BADPARM
All diagnostic error messages should go to the standard error. Recall from 2.14.1 Standard Error that 2>&1
redirects the standard error to the standard output. For writing to the standard error, you can reverse the process
with 1>&2. To do this for the preceding example, use this:
echo $0: bad option $BADPARM 1>&2
11.3.5 Process ID: $$
The $$ variable holds the process ID of the shell.
www.EBooksWorld.ir
11.3.6 Exit Code: $?
The $? variable holds the exit code of the last command that the shell executed. Exit codes, which are critical
to mastering shell scripts, are discussed next.
11.4 Exit Codes
When a Unix program finishes, it leaves an exit code for the parent process that started the program. The exit
code is a number and is sometimes called an error code or exit value. When the exit code is zero (0), it typically
means that the program ran without a problem. However, if the program has an error, it usually exits with a
number other than 0 (but not always, as you’ll see next).
The shell holds the exit code of the last command in the $? special variable, so you can check it out at your
shell prompt:
$ ls / > /dev/null
$ echo $?
0
$ ls /asdfasdf > /dev/null
ls: /asdfasdf: No such file or directory
$ echo $?
1
You can see that the successful command returned 0 and the unsuccessful command returned 1 (assuming, of
course, that you don’t have a directory named /asdfasdf on your system).
If you intend to use the exit code of a command, you must use or store the code immediately after running the
command. For example, if you run echo $? twice in a row, the output of the second command is always 0
because the first echo command completes successfully.
When writing shell code that aborts a script abnormally, use something like exit 1 to pass an exit code of
1 back to whatever parent process ran the script. (You may want to use different numbers for different
conditions.)
One thing to note is that some programs like diff and grep use nonzero exit codes to indicate normal
conditions. For example, grep returns 0 if it finds something matching a pattern and 1 if it doesn’t. For these
programs, an exit code of 1 is not an error; grep and diff use the exit code 2 for real problems. If you think
a program is using a nonzero exit code to indicate success, read its manual page. The exit codes are usually
explained in the EXIT VALUE or DIAGNOSTICS section.
11.5 Conditionals
The Bourne shell has special constructs for conditionals, such as if/then/ else and case statements. For
example, this simple script with an if conditional checks to see whether the script’s first argument is hi:
#!/bin/sh
if [ $1 = hi ]; then
echo 'The first argument was "hi"'
else
www.EBooksWorld.ir
echo -n 'The first argument was not "hi" -- '
echo It was '"'$1'"'
fi
The words if, then, else, and fi in the preceding script are shell keywords; everything else is a command.
This distinction is extremely important because one of the commands is [ $1 = "hi" ] and the [ character
is an actual program on a Unix system, not special shell syntax. (This is actually not quite true, as you’ll soon
learn, but treat it as a separate command in your head for now.) All Unix systems have a command called
[ that performs tests for shell script conditionals. This program is also known as test and careful
examination of [ and test should reveal that they share an inode, or that one is a symbolic link to the other.
Understanding the exit codes in 11.4 Exit Codes is vital, because this is how the whole process works:
1. The shell runs the command after the if keyword and collects the exit code of that command.
2. If the exit code is 0, the shell executes the commands that follow the then keyword, stopping when it
reaches an else or fi keyword.
3. If the exit code is not 0 and there is an else clause, the shell runs the commands after the else
keyword.
4. The conditional ends at fi.
11.5.1 Getting Around Empty Parameter Lists
There is a slight problem with the conditional in the preceding example due to a very common mistake: $1
could be empty, because the user might not enter a parameter. Without a parameter, the test reads [ = hi ],
and the [ command aborts with an error. You can fix this by enclosing the parameter in quotes in one of two
ways (both of which are common):
if [ "$1" = hi ]; then
if [ x"$1" = x"hi" ]; then
11.5.2 Using Other Commands for Tests
The stuff following if is always a command. Therefore, if you want to put the then keyword on the same
line, you need a semicolon (;) after the test command. If you skip the semicolon, the shell passes then as a
parameter to the test command. (If you don’t like the semicolon, you can put the then keyword on a separate
line.)
There are many possibilities for using other commands instead of the [ command. Here’s an example that
uses grep:
#!/bin/sh
if grep -q daemon /etc/passwd; then
echo The daemon user is in the passwd file.
else
echo There is a big problem. daemon is not in the passwd file.
fi
11.5.3 elif
There is also an elif keyword that lets you string if conditionals together, as shown below. But don’t get
www.EBooksWorld.ir
too carried away with elif, because the case construct that you’ll see in 11.5.6 Matching Strings with case
is often more appropriate.
#!/bin/sh
if [ "$1" = "hi" ]; then
echo 'The first argument was "hi"'
elif [ "$2" = "bye" ]; then
echo 'The second argument was "bye"'
else
echo -n 'The first argument was not "hi" and the second was not "bye"-
- '
echo They were '"'$1'"' and '"'$2'"'
fi
11.5.4 && and || Logical Constructs
There are two quick one-line conditional constructs that you may see from time to time: && (“and”) and ||
(“or”). The && construct works like this:
command1 && command2
Here, the shell runs command1, and if the exit code is 0, the shell also runs command2. The || construct is
similar; if the command before a || returns a nonzero exit code, the shell runs the second command.
The constructs && and || often find their way into use in if tests, and in both cases, the exit code of the last
command run determines how the shell processes the conditional. In the case of the && construct, if the first
command fails, the shell uses its exit code for the if statement, but if the first command succeeds, the shell
uses the exit code of the second command for the conditional. In the case of the || construct, the shell uses
the exit code of the first command if successful, or the exit code of the second if the first is unsuccessful.
For example:
#!/bin/sh
if [ "$1" = hi ] || [ "$1" = bye ]; then
echo 'The first argument was "'$1'"'
fi
If your conditionals include the test ([) command, as shown here, you can use -a and -o instead of && and
||, as described in the next section.
11.5.5 Testing Conditions
You’ve seen how [ works: The exit code is 0 if the test is true and nonzero when the test fails. You also know
how to test string equality with [ str1 = str2 ]. However, remember that shell scripts are well suited to
operations on entire files because the most useful [ tests involve file properties. For example, the following
line checks whether file is a regular file (not a directory or special file):
[ -f file ]
In a script, you might see the -f test in a loop similar to this next one, which tests all of the items in the current
www.EBooksWorld.ir
working directory (you’ll learn more about loops in general shortly):
for filename in *; do
if [ -f $filename ]; then
ls -l $filename
file $filename
else
echo $filename is not a regular file.
fi
done
You can invert a test by placing the ! operator before the test arguments. For example, [ ! -f file ]
returns true if file is not a regular file. Furthermore, the -a and -o flags are the logical “and” and “or”
operators (for example, [ -f file1 -a file2 ]).
NOTE
Because the test command is so widely used in scripts, many versions of the Bourne shell
(including bash) incorporate the test command as a built-in. This can speed up scripts because
the shell doesn’t have to run a separate command for each test.
There are dozens of test operations, all of which fall into three general categories: file tests, string tests, and
arithmetic tests. The info manual contains complete online documentation, but the test(1) manual page is a
fast reference. The following sections outline the main tests. (I’ve omitted some of the less common ones.)
File Tests
Most file tests, like -f, are called unary operations because they require only one argument: the file to test.
For example, here are two important file tests:
o -e Returns true if a file exists
o -s Returns true if a file is not empty
Several operations inspect a file’s type, meaning that they can determine whether something is a regular file,
a directory, or some kind of special device, as listed in Table 11-1. There are also a number of unary operations
that check a file’s permissions, as listed in Table 11-2. (See 2.17 File Modes and Permissions for an overview
of permissions.)
Table 11-1. File Type Operators
Operator Tests For
-f Regular file
-d Directory
-h Symbolic link
-b Block device
-c Character device
www.EBooksWorld.ir
Operator Tests For
-p Named pipe
-S Socket
NOTE
The test command follows symbolic links (except for the -h test). That is, if link is a symbolic
link to a regular file, [ -f link ] returns an exit code of true (0).
Table 11-2. File Permissions Operators
Operator Operator
-r Readable
-w Writable
-x Executable
-u Setuid
-g Setgid
-k “Sticky”
Finally, three binary operators (tests that need two files as arguments) are used in file tests, but they’re not
terribly common. Consider this command that includes -nt (newer than):
[ file1 -nt file2 ]
This exits true if file1 has a newer modification date than file2. The -ot (older than) operator does the
opposite. And if you need to detect identical hard links, -ef compares two files and returns true if they share
inode numbers and devices.
String Tests
You’ve seen the binary string operator = that returns true if its operands are equal. The != operator returns
true if its operands are not equal. And there are two unary string operations:
o -z Returns true if its argument is empty ([ -z "" ] returns 0)
o -n Returns true if its argument is not empty ([ -n "" ] returns 1)
Arithmetic Tests
It’s important to recognize that the equal sign (=) looks for string equality, not numeric equality. Therefore,
[ 1 = 1 ] returns 0 (true), but [ 01 = 1 ] returns false. When working with numbers, use -eq instead
of the equal sign: [ 01 -eq 1 ] returns true. Table 11-3 provides the full list of numeric comparison
operators.
Table 11-3. Arithmetic Comparison Operators
www.EBooksWorld.ir
Operator Returns True When the First Argument Is . . . the Second
-eq Equal to
-ne Not equal to
-lt Less than
-gt Greater than
-le Less than or equal to
-ge Greater than or equal to
11.5.6 Matching Strings with case
The case keyword forms another conditional construct that is exceptionally useful for matching strings. The
case conditional does not execute any test commands and therefore does not evaluate exit codes. However,
it can do pattern matching. This example should tell most of the story:
#!/bin/sh
case $1 in
bye)
echo Fine, bye.
;;
hi|hello)
echo Nice to see you.
;;
what*)
echo Whatever.
;;
*)
echo 'Huh?'
;;
esac
The shell executes this as follows:
1. The script matches $1 against each case value demarcated with the ) character.
2. If a case value matches $1, the shell executes the commands below the case until it encounters ;;, at
which point it skips to the esac keyword.
3. The conditional ends with esac.
For each case value, you can match a single string (like bye in the preceding example) or multiple strings
www.EBooksWorld.ir
with | (hi|hello returns true if $1 equals hi or hello), or you can use the * or ? patterns (what*). To
make a default case that catches all possible values other than the case values specified, use a single * as
shown by the final case in the preceding example.
NOTE
Each case must end with a double semicolon (;;) or you risk a syntax error.
11.6 Loops
There are two kinds of loops in the Bourne shell: for and while loops.
11.6.1 for Loops
The for loop (which is a “for each” loop) is the most common. Here’s an example:
#!/bin/sh
for str in one two three four; do
echo $str
done
In this listing, for, in, do, and done are all shell keywords. The shell does the following:
1. Sets the variable str to the first of the four space-delimited values following the in keyword (one).
2. Runs the echo command between the do and done.
3. Goes back to the for line, setting str to the next value (two), runs the commands between do and
done, and repeats the process until it’s through with the values following the in keyword.
The output of this script looks like this:
one
two
three
four
11.6.2 while Loops
The Bourne shell’s while loop uses exit codes, like the if conditional. For example, this script does 10
iterations:
#!/bin/sh
FILE=/tmp/whiletest.$$;
echo firstline > $FILE
while tail -10 $FILE | grep -q firstline; do
# add lines to $FILE until tail -10 $FILE no longer prints "firstline"
echo -n Number of lines in $FILE:' '
wc -l $FILE | awk '{print $1}'
echo newline >> $FILE
www.EBooksWorld.ir
done
rm -f $FILE
Here, the exit code of grep -q firstline is the test. As soon as the exit code is nonzero (in this case,
when the string firstline no longer appears in the last 10 lines in $FILE), the loop exits.
You can break out of a while loop with the break statement. The Bourne shell also has an until loop that
works just like while, except that it breaks the loop when it encounters a zero exit code rather than a nonzero
exit code. This said, you shouldn’t need to use the while and until loops very often. In fact, if you find
that you need to use while, you should probably be using a language like awk or Python instead.
11.7 Command Substitution
The Bourne shell can redirect a command’s standard output back to the shell’s own command line. That is,
you can use a command’s output as an argument to another command, or you can store the command output
in a shell variable by enclosing a command in $().
This example stores a command inside the FLAGS variable. The bold in the second line shows the command
substitution.
#!/bin/sh
FLAGS=$(grep ^flags /proc/cpuinfo | sed 's/.*://' | head -1)
echo Your processor supports:
for f in $FLAGS; do
case $f in
fpu) MSG="floating point unit"
;;
3dnow) MSG="3DNOW graphics extensions"
;;
mtrr) MSG="memory type range register"
;;
*) MSG="unknown"
;;
esac
echo $f: $MSG
done
This example is somewhat complicated because it demonstrates that you can use both single quotes and
pipelines inside the command substitution. The result of the grep command is sent to the sed command
(more about sed in 11.10.3 sed), which removes anything matching the expression .*:, and the result of
sed is passed to head.
It’s easy to go overboard with command substitution. For example, don’t use $(ls) in a script because using
www.EBooksWorld.ir
the shell to expand * is faster. Also, if you want to invoke a command on several filenames that you get as a
result of a find command, consider using a pipeline to xargs rather than command substitution, or use the
-exec option (see 11.10.4 xargs).
NOTE
The traditional syntax for command substitution is to enclose the command in back-ticks (``), and
you’ll see this in many shell scripts. The $() syntax is a newer form, but it is a POSIX standard
and is generally easier to read and write.
11.8 Temporary File Management
It’s sometimes necessary to create a temporary file to collect output for use by a later command. When making
such a file, make sure that the filename is distinct enough that no other programs will accidentally write to it.
Here’s how to use the mktemp command to create temporary filenames. This script shows you the device
interrupts that have occurred in the last two seconds:
#!/bin/sh
TMPFILE1=$(mktemp /tmp/im1.XXXXXX)
TMPFILE2=$(mktemp /tmp/im2.XXXXXX)
cat /proc/interrupts > $TMPFILE1
sleep 2
cat /proc/interrupts > $TMPFILE2
diff $TMPFILE1 $TMPFILE2
rm -f $TMPFILE1 $TMPFILE2
The argument to mktemp is a template. The mktemp command converts the XXXXXX to a unique set of
characters and creates an empty file with that name. Notice that this script uses variable names to store the
filenames so that you only have to change one line if you want to change a filename.
NOTE
Not all Unix flavors come with mktemp. If you’re having portability problems, it’s best to install the
GNU coreutils package for your operating system.
Another problem with scripts that employ temporary files is that if the script is aborted, the temporary files
could be left behind. In the preceding example, pressing CTRL-C before the second cat command leaves a
temporary file in /tmp. Avoid this if possible. Instead, use the trap command to create a signal handler to
catch the signal that CTRL-C generates and remove the temporary files, as in this handler:
#!/bin/sh
TMPFILE1=$(mktemp /tmp/im1.XXXXXX)
TMPFILE2=$(mktemp /tmp/im2.XXXXXX)
trap "rm -f $TMPFILE1 $TMPFILE2; exit 1" INT
--snip--
You must use exit in the handler to explicitly end script execution, or the shell will continue running as usual
www.EBooksWorld.ir
after running the signal handler.
NOTE
You don’t need to supply an argument to mktemp; if you don’t, the template will begin with a
/tmp/tmp. prefix.
11.9 Here Documents
Say you want to print a large section of text or feed a lot of text to another command. Rather than use several
echo commands, you can use the shell’s here document feature, as shown in the following script:
#!/bin/sh
DATE=$(date)
cat <<EOF
Date: $DATE
The output above is from the Unix date command.
It's not a very interesting command.
EOF
The items in bold control the here document. The <<EOF tells the shell to redirect all lines that follow the
standard input of the command that precedes <<EOF, which in this case is cat. The redirection stops as soon
as the EOF marker occurs on a line by itself. The marker can actually be any string, but remember to use the
same marker at the beginning and end of the here document. Also, convention dictates that the marker be in
all uppercase letters.
Notice the shell variable $DATE in the here document. The shell expands shell variables inside here documents,
which is especially useful when you’re printing out reports that contain many variables.
11.10 Important Shell Script Utilities
Several programs are particularly useful in shell scripts. Certain utilities such as basename are really only
practical when used with other programs, and therefore don’t often find a place outside shell scripts. However,
others such as awk can be quite useful on the command line, too.
11.10.1 basename
If you need to strip the extension from a filename or get rid of the directories in a full pathname, use the
basename command. Try these examples on the command line to see how the command works:
$ basename example.html .html
$ basename /usr/local/bin/example
In both cases, basename returns example. The first command strips the .html suffix from example.html,
and the second removes the directories from the full pathname.
This example shows how you can use basename in a script to convert GIF image files to the PNG format:
#!/bin/sh
for file in *.gif; do
www.EBooksWorld.ir
# exit if there are no files
if [ ! -f $file ]; then
exit
fi
b=$(basename $file .gif)
echo Converting $b.gif to $b.png...
giftopnm $b.gif | pnmtopng > $b.png
done
11.10.2 awk
The awk command is not a simple single-purpose command; it’s actually a powerful programming language.
Unfortunately, awk usage is now something of a lost art, having been replaced by larger languages such as
Python.
The are entire books on the subject of awk, including The AWK Programming Language by Alfred V. Aho,
Brian W. Kernighan, and Peter J. Weinberger (Addison-Wesley, 1988). This said, many, many people use awk
to do one thing—to pick a single field out of an input stream like this:
$ ls -l | awk '{print $5}'
This command prints the fifth field of the ls output (the file size). The result is a list of file sizes.
11.10.3 sed
The sed program (sed stands for stream editor) is an automatic text editor that takes an input stream (a file
or the standard input), alters it according to some expression, and prints the results to standard output. In many
respects, sed is like ed, the original Unix text editor. It has dozens of operations, matching tools, and
addressing capabilities. As with awk, entire books have been written about sed including a quick reference
covering both, sed & awk Pocket Reference, 2nd edition, by Arnold Robbins (O’Reilly, 2002).
Although sed is a big program, and an in-depth analysis is beyond the scope of this book, it’s easy to see how
it works. In general, sed takes an address and an operation as one argument. The address is a set of lines, and
the command determines what to do with the lines.
A very common task for sed is to substitute some text for a regular expression (see 2.5.1 grep), like this:
$ sed 's/exp/text/'
So if you wanted to replace the first colon in /etc/passwd with a % and send the result to the standard output,
you’d do it like this:
$ sed 's/:/%/' /etc/passwd
To substitute all colons in /etc/passwd, add a g modifier to the end of the operation, like this:
$ sed 's/:/%/g' /etc/passwd
Here’s a command that operates on a per-line basis; it reads /etc/passwd and deletes lines three through six
and sends the result to the standard output:
$ sed 3,6d /etc/passwd
In this example, 3,6 is the address (a range of lines), and d is the operation (delete). If you omit the address,
www.EBooksWorld.ir
sed operates on all lines in its input stream. The two most common sed operations are probably s (search
and replace) and d.
You can also use a regular expression as the address. This command deletes any line that matches the regular
expression exp:
$ sed '/exp/d'
11.10.4 xargs
When you have to run one command on a huge number of files, the command or shell may respond that it
can’t fit all of the arguments in its buffer. Use xargs to get around this problem by running a command on
each filename in its standard input stream.
Many people use xargs with the find command. For example, the script below can help you verify that
every file in the current directory tree that ends with .gif is actually a GIF (Graphic Interchange Format) image:
$ find . -name '*.gif' -print | xargs file
In the example above, xargs runs the file command. However, this invocation can cause errors or leave
your system open to security problems, because filenames can include spaces and newlines. When writing a
script, use the following form instead, which changes the find output separator and the xargs argument
delimiter from a newline to a NULL character:
$ find . -name '*.gif' -print0 | xargs -0 file
xargs starts a lot of processes, so don’t expect great performance if you have a large list of files.
You may need to add two dashes (--) to the end of your xargs command if there is a chance that any of the
target files start with a single dash (-). The double dash (--) can be used to tell a program that any arguments
that follow the double dash are filenames, not options. However, keep in mind that not all programs support
the use of a double dash.
There’s an alternative to xargs when using find: the -exec option. However, the syntax is somewhat
tricky because you need to supply a {} to substitute the filename and a literal ; to indicate the end of the
command. Here’s how to perform the preceding task using only find:
$ find . -name '*.gif' -exec file {} \;
11.10.5 expr
If you need to use arithmetic operations in your shell scripts, the expr command can help (and even do some
string operations). For example, the command expr 1 + 2 prints 3. (Run expr --help for a full list of
operations.)
The expr command is a clumsy, slow way of doing math. If you find yourself using it frequently, you should
probably be using a language like Python instead of a shell script.
11.10.6 exec
The exec command is a built-in shell feature that replaces the current shell process with the program you
name after exec. It carries out the exec() system call that you learned about in Chapter 1. This feature is
designed for saving system resources, but remember that there’s no return; when you run exec in a shell
script, the script and shell running the script are gone, replaced by the new command.
To test this in a shell window, try running exec cat. After you press CTRL-D or CTRL-C to terminate the
cat program, your window should disappear because its child process no longer exists.
www.EBooksWorld.ir
11.11 Subshells
Say you need to alter the environment in a shell slightly but don’t want a permanent change. You can change
and restore a part of the environment (such as the path or working directory) using shell variables, but that’s
a clumsy way to go about things. The easy way around these kinds of problems is to use a subshell, an entirely
new shell process that you can create just to run a command or two. The new shell has a copy of the original
shell’s environment, and when the new shell exits, any changes you made to its shell environment disappear,
leaving the initial shell to run as normal.
To use a subshell, put the commands to be executed by the subshell in parentheses. For example, the following
line executes the command uglyprogram in uglydir and leaves the original shell intact:
$ (cd uglydir; uglyprogram)
This example shows how to add a component to the path that might cause problems as a permanent change:
$ (PATH=/usr/confusing:$PATH; uglyprogram)
Using a subshell to make a single-use alteration to an environment variable is such a common task that there
is even a built-in syntax that avoids the subshell:
$ PATH=/usr/confusing:$PATH uglyprogram
Pipes and background processes work with subshells, too. The following example uses tar to archive the
entire directory tree within orig and then unpacks the archive into the new directory target, which effectively
duplicates the files and folders in orig (this is useful because it preserves ownership and permissions, and it’s
generally faster than using a command such as cp -r):
$ tar cf - orig | (cd target; tar xvf -)
WARNING
Double-check this sort of command before you run it to make sure that the target directory exists
and is completely separate from the orig directory.
11.12 Including Other Files in Scripts
If you need to include another file in your shell script, use the dot (.) operator. For example, this runs the
commands in the file config.sh:
. config.sh
This “include” file syntax does not start a subshell, and it can be useful for a group of scripts that need to use
a single configuration file.
11.13 Reading User Input
The read command reads a line of text from the standard input and stores the text in a variable. For example,
the following command stores the input in $var:
$ read var
This is a built-in shell command that can be useful in conjunction with other shell features not mentioned in
this book.
www.EBooksWorld.ir
11.14 When (Not) to Use Shell Scripts
The shell is so feature-rich that it’s difficult to condense its important elements into a single chapter. If you’re
interested in what else the shell can do, have a look at some of the books on shell programming, such as Unix
Shell Programming, 3rd edition, by Stephen G. Kochan and Patrick Wood (SAMS Publishing, 2003), or the
shell script discussion in The UNIX Programming Environment by Bran W. Kernighan and Rob Pike (Prentice
Hall, 1984).
However, at a certain point (especially when you start using the read built-in), you have to ask yourself if
you’re still using the right tool for the job. Remember what shell scripts do best: manipulate simple files and
commands. As stated earlier, if you find yourself writing something that looks convoluted, especially if it
involves complicated string or arithmetic operations, you should probably look to a scripting language like
Python, Perl, or awk.
www.EBooksWorld.ir
Chapter 12. Moving Files Across the Network
This chapter surveys options for moving and sharing files between machines on a network. We’ll start by
looking at some ways to copy files other than the scp and sftp utilities that you’ve already seen. Then we’ll
briefly look at true file sharing, where you attach a directory on one machine to another machine.
This chapter describes some alternative ways to transfer files because not every file transfer problem is the
same. Sometimes you need to provide quick, temporary access to machines that you don’t know much about,
sometimes you need to efficiently maintain copies of large directory structures, and sometimes you need more
constant access.
12.1 Quick Copy
Let’s say you want to copy a file (or files) from your machine to another one on your network, and you don’t
care about copying it back or need to do anything fancy. You just want to do it quickly. There’s a convenient
way to do this with Python. Just go to the directory containing the file(s) and run
$ python -m SimpleHTTPServer
This starts a basic web server that makes the directory available to any browser on the network. It usually runs
on port 8000, so if the machine you run this on is at 10.1.2.4, go to http://10.1.2.4:8000 on the destination and
you’ll be able to grab what you need.
12.2 rsync
If you want to move an entire directory structure around, you can do so with scp -r—or if you need a little
more performance, tar in a pipeline:
$ tar cBvf - directory | ssh remote_host tar xBvpf -
These methods get the job done but are not very flexible. In particular, after the transfer completes, the remote
host may not have an exact copy of the directory. If directory already exists on the remote machine and
contains some extraneous files, those files persist after the transfer.
If you need to do this sort of thing regularly (and especially if you plan to automate the process), use a
dedicated synchronizer system. On Linux, rsync is the standard synchronizer, offering good performance
and many useful ways to perform transfers. We’ll cover some of the essential rsync operation modes and
look at some of its peculiarities.
12.2.1 rsync Basics
To get rsync working between two hosts, the rsync program must be installed on both the source and
destination, and you’ll need a way to access one machine from the other. The easiest way to transfer files is to
use a remote shell account, and we’ll assume that you want to transfer files using SSH access. However,
www.EBooksWorld.ir
remember that rsync can be handy even for copying files and directories between locations on a single
machine, such as from one filesystem to another.
On the surface, the rsync command is not much different from scp. In fact, you can run rsync with the
same arguments. For example, to copy a group of files to your home directory on host, enter
$ rsync file1 file2 ... host:
On any modern system, rsync assumes that you’re using SSH to connect to the remote host.
Beware of this error message:
rsync not found
rsync: connection unexpectedly closed (0 bytes read so far)
rsync error: error in rsync protocol data stream (code 12) at io.c(165)
This notice says that your remote shell can’t find rsync on its system. If rsync isn’t in the remote path but
is on the system, use --rsync-path=path to manually specify its location.
If your username is different on the remote host, add user@ to the hostname, where user is your username
on host:
$ rsync file1 file2 ... user@host:
Unless you supply extra options, rsync copies only files. In fact, if you specify just the options described so
far and you supply a directory dir as an argument, you’ll see this message:
skipping directory dir
To transfer entire directory hierarchies—complete with symbolic links, permissions, modes, and devices—
use the -a option. Furthermore, if you want to copy to some place other than your home directory on the
remote host, place this destination after the remote host, like this:
$ rsync -a dir host:destination_dir
Copying directories can be tricky, so if you’re not exactly sure what will happen when you transfer the files,
use the -nv option combination. The -n option tells rsync to operate in “dry run” mode—that is, to run a
trial without actually copying any files. The -v option is for verbose mode, which shows details about the
transfer and the files involved:
$ rsync -nva dir host:destination_dir
The output looks like this:
building file list ... done
ml/nftrans/nftrans.html
[more files]
wrote 2183 bytes read 24 bytes 401.27 bytes/sec
12.2.2 Making Exact Copies of a Directory Structure
By default, rsync copies files and directories without considering the previous contents of the destination
directory. For example, if you transferred the directory d containing the files a and b to a machine that already
had a file named d/c, the destination would contain d/a, d/b, and d/c after the rsync.
To make an exact replica of the source directory, you must delete files in the destination directory that do not
exist in the source directory, such as d/c in this example. Use the --delete option to do that:
www.EBooksWorld.ir
$ rsync -a --delete dir host:destination_dir
WARNING
This can be dangerous, because you should typically inspect the destination directory to see if
there’s anything that you’ll inadvertently delete. Remember, if you’re not certain about your
transfer, use the -n option to perform a dry run so that you’ll know exactly when rsync wants to
delete a file.
12.2.3 Using the Trailing Slash
Be particularly careful when specifying a directory as the source in an rsync command line. Consider the
basic command that we’ve been working with so far:
$ rsync -a dir host:dest_dir
Upon completion, you’ll have a directory dir inside dest_dir on host. Figure 12-1 shows an example of how
rsync normally handles a directory with files named a and b. However, adding a slash (/) significantly
changes the behavior:
$ rsync -a dir/ host:dest_dir
Here, rsync copies everything inside dir to dest_dir on host without actually creating dir on the destination
host. Therefore, you can think of a transfer of dir/ as an operation similar to cp dir/* dest_dir on the
local filesystem.
For example, say you have a directory dir containing the files a and b (dir/a and dir/b). You run the trailing-
slash version of the command to transfer them to the dest_dir directory on host:
$ rsync -a dir/ host:dest_dir
When the transfer completes, dest_dir contains copies of a and b but not dir. If, however, you had omitted the
trailing / on dir, dest_dir would have gotten a copy of dir with a and b inside. Then, as a result of the transfer,
you’d have files and directories named dest_dir/dir/a and dest_dir/dir/b on the remote host. Figure 12-2
illustrates how rsync handles the directory structure from Figure 12-1 when using a trailing slash.
When transferring files and directories to a remote host, accidentally adding a / after a path would normally
be nothing more than a nuisance; you could go to the remote host, add the dir directory, and put all of the
transferred items back in dir. Unfortunately, you must be careful to avoid disaster when combining the trailing
/ with the --delete option, because you can easily remove unrelated files this way.
www.EBooksWorld.ir
Figure 12-1. Normal rsync copy
Figure 12-2. Effect of trailing slash in rsync
NOTE
Be wary of your shell’s automatic filename completion feature. GNU readline and many other
completion libraries tack trailing slashes onto completed directory names.
12.2.4 Excluding Files and Directories
One very important feature of rsync is its ability to exclude files and directories from a transfer operation.
For example, say you’d like to transfer a local directory called src to host, but you want to exclude anything
named .git. You can do it like this:
$ rsync -a --exclude=.git src host:
Note that this command excludes all files and directories named .git because --exclude takes a pattern, not
an absolute filename. To exclude one specific item, specify an absolute path that starts with /, as shown here:
$ rsync -a --exclude=/src/.git src host:
NOTE
The first / in /src/.git in this command is not the root directory of your system but rather the
base directory of the transfer.
Here are a few more tips on how to exclude patterns:
o You can have as many --exclude parameters as you like.
o If you use the same patterns repeatedly, place them in a plaintext file (one pattern per line) and use --
exclude-from=file.
o To exclude directories named item but include files with this name, use a trailing slash: --
exclude=item/.
o The exclude pattern is based on a full file or directory name component and may contain simple globs
(wildcards). For example, t*s matches this, but it does not match ethers.
o If you exclude a directory or filename but find that your pattern is too restrictive, use --include to
specifically include another file or directory.
12.2.5 Transfer Integrity, Safeguards, and Verbose Modes
To speed operation, rsync uses a quick check to determine whether any files on the transfer source are
already on the destination. The quick check uses a combination of the file size and its last-modified date. The
first time you transfer an entire directory hierarchy to a remote host, rsync sees that none of the files already
exist at the destination, and it transfers everything. Testing your transfer with rsync -n verifies this for you.
After running rsync once, run it again using rsync -v. This time you should see that no files show up in
www.EBooksWorld.ir
the transfer list because the file set exists on both ends, with the same modification dates.
When the files on the source side are not identical to the files on the destination side, rsync transfers the
source files and overwrites any files that exist on the remote side. The default behavior may be inadequate,
though, because you may need additional reassurance that files are indeed the same before skipping over them
in transfers, or you may want to put in some extra safeguards. Here are some options that come in handy:
o --checksum (abbreviation: -c) Compute checksums (mostly unique signatures) of the files to see if
they’re the same. This consumes additional I/O and CPU resources during transfers, but if you’re dealing
with sensitive data or files that often have uniform sizes, this option is a must.
o --ignore-existing Doesn’t clobber files already on the target side.
o --backup (abbreviation: -b) Doesn’t clobber files already on the target but rather renames these
existing files by adding a ~ suffix to their names before transferring the new files.
o --suffix=s Changes the suffix used with --backup from ~ to s.
o --update (abbreviation: -u) Doesn’t clobber any file on the target that has a later date than the
corresponding file on the source.
With no special options, rsync operates quietly, only producing output when there is a problem. However,
you can use rsync -v for verbose mode or rsync -vv for even more details. (You can tack on as many
v options as you like, but two is probably more than you need.) For a comprehensive summary after the
transfer, use rsync --stats.
12.2.6 Compression
Many users like the -z option in conjunction with -a to compress the data before transmission:
$ rsync -az dir host:destination_dir
Compression can improve performance in certain situations, such as when uploading a large amount of data
across a slow connection (like the slow upstream link on many DSL connections) or when the latency between
the two hosts is high. However, across a fast local area network, the two endpoint machines can be constrained
by the CPU time that it takes to compress and decompress data, so uncompressed transfer may be faster.
12.2.7 Limiting Bandwidth
It’s easy to clog the uplink of Internet connections when uploading a large amount of data to a remote host.
Even though you won’t be using your (normally large) downlink capacity during such a transfer, your
connection will still seem quite slow if you let rsync go as fast as it can, because outgoing TCP packets such
as HTTP requests will have to compete with your transfers for bandwidth on your uplink.
To get around this, use --bwlimit to give your uplink a little breathing room. For example, to limit the
bandwidth to 10,000 Kpbs you might do something like this:
$ rsync --bwlimit=10000 -a dir host:destination_dir
12.2.8 Transferring Files to Your Computer
The rsync command isn’t just for copying files from your local machine to a remote host. You can also
transfer files from a remote machine to your local host by placing the remote host and remote source path as
the first argument on the command line. Therefore, to transfer src_dir on the host to dest_dir on the
local host, run this command:
$ rsync -a host:src_dir dest_dir
www.EBooksWorld.ir
NOTE
As mentioned before, you can use rsync to duplicate directories on your local machines if you
omit host: entirely.
12.2.9 Further rsync Topics
Whenever you need to copy numerous files, rsync should be one of the first utilities that comes to mind.
Running rsync in batch mode is particularly useful, and you’ll find a number of options to employ auxiliary
files related to command options, logging, and transfer state. In particular, the state files make long transfers
faster and easier to resume when interrupted.
You’ll also find rsync useful for making backups. For example, you can attach Internet storage, such as
Amazon’s S3, to your Linux system and then use rsync --delete to periodically synchronize a filesystem
with the network storage to create a very effective backup system.
There are many more command-line options than those described here. For a rough overview, run rsync -
-help. You’ll find more detailed information in the rsync(1) manual page as well as at the rsync home
page: http://rsync.samba.org/.
12.3 Introduction to File Sharing
Your Linux machine probably doesn’t live alone on your network, and when you have multiple machines on
a network, there’s nearly always a reason to share files between them. For the remainder of this chapter, we’ll
primarily be concerned with file sharing between Windows and Mac OS X machines, because it’s interesting
to see how Linux adapts to completely foreign environments. For the purpose of sharing files between Linux
machines, or for accessing files from a Network Area Storage (NAS) device, we’ll briefly talk about using
Network File System (NFS) as a client.
12.4 Sharing Files with Samba
If you have machines running Windows, you’ll probably want to permit access to your Linux system’s files
and printers from those Windows machines using the standard Windows network protocol, Server Message
Block (SMB). Mac OS X also supports SMB file sharing.
The standard file-sharing software suite for Unix is called Samba. Not only does Samba allow your network’s
Windows computers to get to your Linux system, but it works the other way around: You can print and access
files on Windows servers from your Linux machine with the Samba client software.
To set up a Samba server, perform these steps:
1. Create an smb.conf file.
2. Add file-sharing sections to smb.conf.
3. Add printer-sharing sections to smb.conf.
4. Start the Samba daemons nmbd and smbd.
When you install Samba from a distribution package, your system should perform the steps listed above using
some reasonable defaults for the server. However, it probably won’t be able to determine which particular
shares (resources) on your Linux machine you offer to clients.
NOTE
The discussion of Samba in this chapter is brief and limited to getting Windows machines on a
single subnet to see a standalone Linux machine through the Windows Network Places browser.
There are countless ways to configure Samba, because there are many possibilities for access
www.EBooksWorld.ir
control and network topology. For the gory details on how to configure a large-scale server, see
Using Samba, 3rd edition (O’Reilly, 2007), a much more extensive guide, and visit the Samba
website, http://www.samba.org/.
12.4.1 Configuring the Server
The central Samba configuration file is smb.conf, which most distributions place in an etc directory such as
/etc/samba. However, you may have to hunt around to find this file, as it may also be in a lib directory such
as /usr/local/ samba/lib.
The smb.conf file is similar to the XDG style that you’ve seen elsewhere (such as the systemd configuration
format) and breaks down into several sections denoted with square brackets (such as [global] and
[printers]). The [global] section in smb.conf contains general options that apply to the entire server
and all shares. These options primarily pertain to network configuration and access control. The sample
[global] section below shows how to set the server name, description, and workgroup:
[global]
# server name
netbios name = name
# server description
server string = My server via Samba
# workgroup
workgroup = MYNETWORK
These parameters work like this:
o netbios name The server name. If you omit this parameter, Samba uses the Unix hostname.
o server string A short description of the server. The default is the Samba version number.
o workgroup The SMB workgroup name. If you’re on a Windows domain, set this parameter to the name
of your domain.
12.4.2 Server Access Control
You can add options to your smb.conf file to limit the machines and users that can access your Samba server.
The following list includes many options that you can set in your [global] section and in the sections that
control individual shares (as described later in the chapter):
o interfaces Set this to have Samba listen on the given networks or interfaces. For example:
o interfaces = 10.23.2.0/255.255.255.0
interfaces = eth0
o bind interfaces only Set this to yes when using the interfaces parameter in order to limit
access to machines that you can reach on those interfaces.
o valid users Set this to allow the given users access. For example:
valid users = jruser, bill
o guest ok Set this parameter to true to make a share available to anonymous users on the network.
o guest only Set this parameter to true to allow anonymous access only.
www.EBooksWorld.ir
o browseable Set this to make shares viewable by network browsers. If you set this parameter to no for
any shares, you’ll still be able to access the shares on the Samba server, but you’ll need to know their exact
names in order to be able to access them.
12.4.3 Passwords
In general, you should only allow access to your Samba server with password authentication. Unfortunately,
the basic password system on Unix is different than that on Windows, so unless you specify clear-text network
passwords or authenticate passwords with a Windows server, you must set up an alternative password system.
This section shows you how to set up an alternative password system using Samba’s Trivial Database (TDB)
backend, which is appropriate for small networks.
First, use these entries in your smb.conf [global] section to define the Samba password database
characteristics:
# use the tdb for Samba to enable encrypted passwords
security = user
passdb backend = tdbsam
obey pam restrictions = yes
smb passwd file = /etc/samba/passwd_smb
These lines allow you to manipulate the Samba password database with the smbpasswd command. The
obey pam restrictions parameter ensures that any user changing their password with the
smbpasswd command must obey any rules that PAM enforces for normal password changes. For the
passdb backend parameter, you can add an optional pathname for the TDB file after a colon; for example,
tdbsam:/etc/samba/private/passwd.tdb.
NOTE
If you have access to a Windows domain, you can set security = domain to make Samba use
the domain’s usernames and eliminate the need for a password database. However, in order for
domain users to access the machine running Samba, each domain user must have a local
account with the same username on the machine running Samba.
Adding and Deleting Users
The first thing you need to do in order to give a Windows user access to your Samba server is to add the user
to the password database with the smbpasswd -a command:
# smbpasswd -a username
The username parameter to the smbpasswd command must be a valid username on your Linux system.
Like the regular system’s passwd program, smbpasswd asks you to enter the new user’s password twice.
If the password passes any necessary security checks, smbpasswd confirms that it has created the new user.
To remove a user, use the -x option to smbpasswd:
# smbpasswd -x username
To temporarily deactivate a user instead, use the -d option; the -e option will reenable the user:
# smbpasswd -d username
# smbpasswd -e username
www.EBooksWorld.ir
Changing Passwords
You can change a Samba password as the superuser by using smbpasswd with no options or keywords other
than the username:
# smbpasswd username
However, if the Samba server is running, any user can change their own Samba password by entering
smbpasswd by itself on the command line.
Finally, here’s one place in your configuration to beware of. If you see a line like this in your smb.conf file, be
careful:
unix password sync = yes
This line causes smbpasswd to change a user’s normal password in addition to the Samba password. The
result can be very confusing, especially when a user changes their Samba password to something that’s not
their Linux password and discovers that they can no longer log in. Some distributions set this parameter by
default in their Samba server packages!
12.4.4 Starting the Server
You may need to start your server if you didn’t install Samba from a distribution package. To do so, run nmbd
and smbd with the following arguments, where smb_config_file is the full path of your smb.conf file:
# nmbd -D -s smb_config_file
# smbd -D -s smb_config_file
The nmbd daemon is a NetBIOS name server, and smbd does the actual work of handling share requests. The
-D option specifies daemon mode. If you alter the smb.conf file while smbd is running, you can notify the
daemon of the changes with a HUP signal or use your distribution’s service restart command (such as
systemctl or initctl).
12.4.5 Diagnostics and Log Files
If something goes wrong when starting one of the Samba servers, an error message appears on the command
line. However, runtime diagnostic messages go to the log.nmbd and log.smbd log files, which are usually in a
/var/log directory, such as /var/log/samba. You’ll also find other log files there, such as individual logs for
each individual client.
12.4.6 Configuring a File Share
To export a directory to SMB clients (that is, to share a directory with a client), add a section like this to your
smb.conf file, where label is what you would like to call the share and path is the full directory path:
[label]
path = path
comment = share description
guest ok = no
writable = yes
printable = no
These parameters are useful in directory shares:
o guest ok Allows guest access to the share. The public parameter is a synonym.
www.EBooksWorld.ir
o writable A yes or true setting here marks the share as read-write. Do not allow guest access to a read-
write share.
o printable Specifies a printing share. This parameter must be set to no or false for a directory share.
o veto files Prevents the export of any files that match the given patterns. You must enclose each pattern
between forward slashes (so that it looks like /pattern/). This example bars object files, as well as any
file or directory named bin:
veto files = /*.o/bin/
12.4.7 Home Directories
You can add a section called [homes] to your smb.conf file if you want to export home directories to users.
The section should look like this:
[homes]
comment = home directories
browseable = no
writable = yes
By default, Samba reads the logged-in user’s /etc/passwd entry to determine their home directory for
[homes]. However, if you don’t want Samba to follow this behavior (that is, you want to keep the Windows
home directories in a different place than the regular Linux home directories), you can use the %S substitution
in a path parameter. For example, here’s how you would switch a user’s [homes] directory to /u/user :
path = /u/%S
Samba substitutes the current username for the %S .
12.4.8 Sharing Printers
You can export all of your printers to Windows clients by adding a [printers] section to your smb.conf
file. Here’s how the section looks when you’re using CUPS, the standard Unix printing system:
[printers]
comment = Printers
browseable = yes
printing = CUPS
path = cups
printable = yes
writable = no
To use the printing = CUPS parameter, your Samba installation must be configured and linked against
the CUPS library.
NOTE
Depending on your configuration, you may also want to allow guest access to your printers with
the guest ok = yes option rather than give a Samba password or account to everyone who
needs to access the printers. For example, it’s easy to limit printer access to a single subnet with
firewall rules.
www.EBooksWorld.ir
12.4.9 Using the Samba Client
The Samba client program smbclient can print to and access remote Windows shares. This program comes
in handy when you are in an environment where you must interact with Windows servers that don’t offer a
Unix-friendly means of communication.
To get started with smbclient use the -L option to get a list of shares from a remote server named SERVER:
$ smbclient -L -U username SERVER
You do not need -U username if your Linux username is the same as your username on SERVER .
After running this command, smbclient asks for a password. To try to access a share as a guest, press
ENTER; otherwise, enter your password on SERVER. Upon success, you should get a share list like this:
Sharename Type Comment
--------- ---- -------
Software Disk Software distribution
Scratch Disk Scratch space
IPC$ IPC IPC Service
ADMIN$ IPC IPC Service
Printer1 Printer Printer in room 231A
Printer2 Printer Printer in basement
Use the Type field to help you make sense of each share and pay attention only to the Disk and Printer
shares (the IPC shares are for remote management). This list has two disk shares and two printer shares. Use
the name in the Sharename column to access each share.
12.4.10 Accessing Files as a Client
If you need only casual access to files in a disk share, use the following command. (Again, you can omit the
-U username if your Linux username matches your username on the server.)
$ smbclient -U username '\\SERVER\sharename'
Upon success, you will get a prompt like this, indicating that you can now transfer files:
smb: \>
In this file transfer mode, smbclient is similar to the Unix ftp, and you can run these commands:
o get file Copies file from the remote server to the current local directory.
o put file Copies file from the local machine to the remote server.
o cd dir Changes the directory on the remote server to dir .
o lcd localdir Changes the current local directory to localdir .
o pwd Prints the current directory on the remote server, including the server and share names.
o !command Runs command on the local host. Two particularly handy commands are !pwd and !ls to
determine directory and file status on the local side.
o help Shows a full list of commands.
www.EBooksWorld.ir
Using the CIFS Filesystem
If you need frequent, regular access to files on a Windows server, you can attach a share directly to your
system with mount. The command syntax is shown below. Notice the use of SERVER:sharename rather
than the normal \\SERVER\sharename format.
# mount -t cifs SERVER:sharename mountpoint -o
user=username,pass=password
In order to use mount like this, you must have the Common Internet File System (CIFS) utilities available
for Samba. Most distributions offer these as a separate package.
12.5 NFS Clients
The standard system for file sharing among Unix systems is NFS; there are many different versions of NFS
for different scenarios. You can serve NFS over TCP and UDP, with a large number of authentication and
encryption techniques. Because there are so many options, NFS can be a big topic, so we’ll just stick to the
basics of NFS clients.
To mount a remote directory on a server with NFS, use the same basic syntax as for mounting a CIFS directory:
# mount -t nfs server:directory mountpoint
Technically, you don’t need the -t nfs option because mount should figure this out for you, but you may
want to investigate the options in the nfs(5) manual page. (You’ll find several different options for security
using the sec option. Many administrators on small, closed networks use host-based access control. However,
more sophisticated methods, such as Kerberos-based authentication, require additional configuration on other
parts of your system.)
When you find that you’re making greater use of filesystems over a network, set up the automounter so that
your system will mount the filesystems only when you actually try to use them in order to prevent problems
with dependencies on boot. The traditional automounting tool is called automount, with a newer version
called amd, but much of this is now being supplanted by the automount unit type in systemd.
12.6 Further Network File Service Options and Limitations
Setting up an NFS server to share files to other Linux machines is more complicated than using a simple NFS
client. You need to run the server daemons (mountd and nfsd) and set up the /etc/exports file to reflect the
directories that you’re sharing. However, we won’t cover NFS servers primarily because shared storage over
a network is often made much more convenient by simply purchasing an NAS device to handle it for you.
Many of these devices are Linux based, so they’ll naturally have NFS server support. Vendors add value to
their NAS devices by offering their own administration tools to take the pain out of tedious tasks such as
setting up RAID configurations and cloud backups.
Speaking of cloud backups, another network file service option is cloud storage. This can be handy when you
need the extra storage that comes with automatic backups and you don’t mind an extra hit on performance.
It’s especially useful when you don’t need the service for a long time or don’t need to access it very much.
You can usually mount Internet storage much as you would NFS.
Although NFS and other file-sharing systems work well for casual use, don’t expect great performance. Read-
only access to larger files should work well, such as when you’re streaming audio or video, because you’re
reading data in large, predictable chunks that don’t require much back-and-forth communication between the
file server and its client. As long as the network is fast enough and the client has enough memory, a server can
supply data as needed.
www.EBooksWorld.ir
Local storage is much faster for tasks involving many small files, such as compiling software packages and
starting desktop environments. The picture becomes more complicated when you have a larger network with
many users accessing many different machines, because there are tradeoffs between convenience, performance,
and ease of administration.
Chapter 13. User Environments
This book’s primary focus is on the Linux system that normally lies underneath server processes and
interactive user sessions. But eventually, the system and the user have to meet somewhere. Startup files play
an important role at this point, because they set defaults for the shell and other interactive programs. They
determine how the system behaves when a user logs in.
Most users don’t pay close attention to their startup files, only touching them when they want to add something
for convenience, such as an alias. Over time, the files become cluttered with unnecessary environment
variables and tests that can lead to annoying (or quite serious) problems.
If you’ve had your Linux machine for a while, you may notice that your home directory accumulates a
bafflingly large array of startup files over time. These are sometimes called dot files because they nearly
always start with a dot (.). Many of these are automatically created when you first run a program, and you’ll
never need to change them. This chapter primarily covers shell startup files, which are the ones you’re most
likely to modify or rewrite from scratch. Let’s first look at how much care you need to take when working on
these files.
13.1 Guidelines for Creating Startup Files
When designing startup files, keep the user in mind. If you’re the only user on a machine, you don’t have
much to worry about because errors only affect you and they’re easy enough to fix. However, if you’re creating
startup files meant to be the defaults for all new users on a machine or network, or if you think that someone
might copy your files for use on a different machine, your task becomes considerably more difficult. If you
make an error in a startup file for 10 users, you might end up fixing this error 10 times.
Keep two essential goals in mind when creating startup files for other users:
o Simplicity. Keep the number of startup files small, and keep the files as small and simple as possible so
that they are easy to modify but hard to break. Each item in a startup file is just one more thing that can
break.
o Readability. Use extensive comments in files so that the users get a good picture of what each part of a file
does.
13.2 When to Alter Startup Files
Before making a change to a startup file, ask yourself whether you really should be making that change. Here
are some good reasons for changing startup files:
www.EBooksWorld.ir
o You want to change the default prompt.
o You need to accommodate some critical locally installed software. (Consider using wrapper scripts first,
though.)
o Your existing startup files are broken.
If everything in your Linux distribution works, be careful. Sometimes the default startup files interact with
other files in /etc.
That said, you probably wouldn’t be reading this chapter if you weren’t interested in changing the defaults, so
let’s examine what’s important.
13.3 Shell Startup File Elements
What goes into a shell startup file? Some things might seem obvious, such as the path and a prompt setting.
But what exactly should be in the path, and what does a reasonable prompt look like? And how much is too
much to put in a startup file?
The next few sections discuss the essentials of a shell startup file—from the command path, prompt, and
aliases through the permissions mask.
13.3.1 The Command Path
The most important part of any shell startup file is the command path. The path should cover the directories
that contain every application of interest to a regular user. At the very least, the path should contain these
components, in order:
/usr/local/bin
/usr/bin
/bin
This order ensures that you can override standard default programs with site-specific variants located in
/usr/local.
Most Linux distributions install executables for nearly all packaged software in /usr/bin. There are occasional
differences, such as putting games in /usr/games and graphical applications in a separate location, so check
your system’s defaults first. And make sure that every general-use program on the system is available through
one of the directories listed above. If not, your system is probably getting out of control. Don’t change the
default path in your user environment to accommodate a new software installation directory. A cheap way to
accommodate separate installation directories is to use symbolic links in /usr/local/bin.
Many users use a bin directory of their own to store shell scripts and programs, so you may want to add this
to the front of the path:
$HOME/bin
NOTE
A newer convention is to place binaries in $HOME/.local/bin.
If you’re interested in systems utilities (such as traceroute, ping, and lsmod), add the sbin directories
to your path:
/usr/local/sbin
/usr/sbin
www.EBooksWorld.ir
/sbin
Adding Dot (.) to the Path
There is one small but controversial command path component to discuss: the dot. Placing a dot (.) in your
path allows you to run programs in the current directory without using ./ in front of the program name. This
may seem convenient when writing scripts or compiling programs, but it’s a bad idea for two reasons:
o It can be a security problem. You should never put a dot at the front of the path. Here’s an example of what
can happen: An attacker could put a Trojan horse named ls in an archive distributed on the Internet. Even
if a dot were at the end of the path, you’d still be vulnerable to typos such as sl or ks.
o It is inconsistent and can be confusing. A dot in a path can mean that a command’s behavior will change
according to the current directory.
13.3.2 The Manual Page Path
The traditional manual page path was determined by the MANPATH environment variable, but you shouldn’t
set it because doing so overrides the system defaults in /etc/manpath.config.
13.3.3 The Prompt
Experienced users tend to avoid long, complicated, useless prompts. In comparison, many administrators and
distributions drag everything into a default prompt. Your choice should reflect your users’ needs; place the
current working directory, hostname, and username in the prompt if it really helps.
Above all, avoid characters that mean something significant to the shell, such as these:
{ } = & < >
NOTE
Take extra care to avoid the > character, which can cause erratic, empty files to appear in your
current directory if you accidentally copy and paste a section of your shell window (recall that >
redirects output to a file).
Even a shell’s default prompt isn’t ideal. For example, the default bash prompt contains the shell name and
version number.
This simple prompt setting for bash ends with the customary $ (the traditional csh prompt ends with %):
PS1='\u\$ '
The \u is a substitution for the current username (see the PROMPTING section of the bash(1) manual page).
Other popular substitutions include the following:
o \h The hostname (the short form, without domain names)
o \! The history number
o \w The current directory. Because this can become long, you can limit the display to just the final
component with \W.
o \$ $ if running as a user account, # if root
13.3.4 Aliases
Among the stickier points of modern user environments is the role of aliases, a shell feature that substitutes
one string for another before executing a command. These can be efficient shortcuts that save some typing.
However, aliases also have these drawbacks:
o It can be tricky to manipulate arguments.
www.EBooksWorld.ir
o They are confusing; a shell’s built-in which command can tell you if something is an alias, but it won’t tell
you where it was defined.
o They are frowned upon in subshells and noninteractive shells; they do not work in other shells.
Given these disadvantages, you should probably avoid aliases whenever possible because it’s easier to write
a shell function or an entirely new shell script. Modern computers can start and execute shells so quickly that
the difference between an alias and an entirely new command should mean nothing to you.
That said, aliases do come in handy when you wish to alter a part of the shell’s environment. You can’t change
an environment variable with a shell script, because scripts run as subshells. (You can also define shell
functions to perform this task.)
13.3.5 The Permissions Mask
As described in Chapter 2, a shell’s built-in umask (permissions mask) facility sets your default permissions.
You should run umask in one of your startup files to make certain that any program you run creates files with
your desired permissions. The two reasonable choices are these:
o 077 This mask is the most restrictive permissions mask because it doesn’t give any other users access to
new files and directories. This is often appropriate on a multi-user system where you don’t want other users
to look at any of your files. However, when set as the default, it can sometimes lead to problems when your
users want to share files but don’t understand how to set permissions correctly. (Inexperienced users have a
tendency to set files to a world-writable mode.)
o 022 This mask gives other users read access to new files and directories. This can be important on a single-
user system because many daemons that run as pseudo-users are not be able to see files and directories
created with the more restrictive 077 umask.
NOTE
Certain applications (especially mail programs) override the umask, changing it to 077 because
they feel that their files are the business of no one but the file owner.
13.4 Startup File Order and Examples
Now that you know what to put into shell startup files, it’s time to see some specific examples. Surprisingly,
one of the most difficult and confusing parts of creating startup files is determining which of several startup
files to use. The next sections cover the two most popular Unix shells: bash and tcsh.
13.4.1 The bash Shell
In bash, you can choose from the startup filenames .bash_profile, .profile, .bash_login, and .bashrc. Which
one is appropriate for your command path, manual page path, prompt, aliases, and permissions mask? The
answer is that you should have a .bashrc file accompanied by a .bash_profile symbolic link pointing to .bashrc
because there are a few different kinds of bash shell instance types.
The two main shell instance types are interactive and noninteractive, but of those, only interactive shells are
of interest because noninteractive shells (such as those that run shell scripts) usually don’t read any startup
files. Interactive shells are the ones that you use to run commands from a terminal, such as the ones you’ve
seen in this book, and they can be classified as login or non-login.
Login Shells
Traditionally, a login shell is what you get when you first log in to a system with the terminal using a program
such as /bin/login. Logging in remotely with SSH also gives you a login shell. The basic idea is that the login
shell is an initial shell. You can tell if a shell is a login shell by running echo $0; if the first character is a -,
www.EBooksWorld.ir
the shell’s a login shell.
When bash runs as a login shell, it runs /etc/profile. Then it looks for a user’s .bash_profile, .bash_login,
and .profile files, running only the first one that it sees.
As strange as it sounds, it’s possible to run a noninteractive shell as a login shell to force it to run startup files.
To do so, start the shell with the -l or --login option.
Non-Login Shells
A non-login shell is an additional shell that you run after you log in. It’s simply any interactive shell that’s not
a login shell. Windowing system terminal programs (xterm, GNOME Terminal, and so on) start non-login
shells unless you specifically ask for a login shell.
Upon starting up as a non-login shell, bash runs /etc/bash.bashrc and then runs the user’s .bashrc.
The Consequences of Two Kinds of Shells
The reasoning behind the two different startup filesystems is that in the old days, users logged in through a
traditional terminal with a login shell, then started non-login subshells with windowing systems or the
screen program. For the non-login subshells, it was deemed a waste to repeatedly set the user environment
and run a bunch of programs that had already been run. With login shells, you could run fancy startup
commands in a file such as .bash_profile, leaving only aliases and other “lightweight” things to your .bashrc.
Nowadays, most desktop users log in through a graphical display manager (you’ll learn more about these in
the next chapter). Most of these start with one noninteractive login shell in order to preserve the login versus
non-login model described above. When they do not, you need to set up your entire environment (path, manual
path, and so on) in your .bashrc, or you’ll never see any of your environment in your terminal window shells.
However, you also need a .bash_profile if you ever want to log in on the console or remotely, because those
login shells don’t ever bother with .bashrc.
Example .bashrc
In order to satisfy both non-login and login shells, how would you create a .bashrc that can also be used as
your .bash_profile? Here’s one very elementary (yet perfectly sufficient) example:
# Command path.
PATH=/usr/local/bin:/usr/bin:/bin:/usr/games
PATH=$HOME/bin:$PATH
# PS1 is the regular prompt.
# Substitutions include:
# \u username \h hostname \w current directory
# \! history number \s shell name \$ $ if regular user
PS1='\u\$ '
# EDITOR and VISUAL determine the editor that programs such as less
# and mail clients invoke when asked to edit a file.
EDITOR=vi
www.EBooksWorld.ir
VISUAL=vi
# PAGER is the default text file viewer for programs such as man.
PAGER=less
# These are some handy options for less.
# A different style is LESS=FRX
# (F=quit at end, R=show raw characters, X=don't use alt screen)
LESS=meiX
# You must export environment variables.
export PATH EDITOR VISUAL PAGER LESS
# By default, give other users read-only access to most new files.
umask 022
As described earlier, you can share this .bashrc file with .bash_profile via a symbolic link, or you can make
the relationship even clearer by creating .bash_profile as this one-liner:
. $HOME/.bashrc
Checking for Login and Interactive Shells
With a .bashrc matching your .bash_profile, you don’t normally run extra commands for login shells. However,
if you want to define different actions for login and non-login shells, you can add the following test to
your .bashrc, which checks the shell’s $- variable for an i character:
case $- in
*i*) # interactive commands go here
command
--snip--
;;
*) # non-interactive commands go here
command
--snip-
;;
esac
13.4.2 The tcsh Shell
The standard csh on virtually all Linux systems is tcsh, an enhanced C shell that popularized features such
www.EBooksWorld.ir
as command-line editing and multi-mode filename and command completion. Even if you don’t use tcsh as
the default new user shell (we suggest using bash), you should still provide tcsh startup files in case your
users happen to come across tcsh.
You don’t have to worry about the difference between login shells and non-login shells in tcsh. Upon startup,
tcsh looks for a .tcshrc file. Failing this, it looks for the csh shell’s .cshrc startup file. The reason for this
order is that you can use the .tcshrc file for tcsh extensions that don’t work in csh. You should probably
stick to using the traditional .cshrc instead of .tcshrc; it’s highly unlikely that anyone will ever use your startup
files with csh. And if a user actually does come across csh on some other system, your .cshrc will work.
Example .cshrc
Here is sample .cshrc file:
# Command path.
setenv PATH /usr/local/bin:/usr/bin:/bin:$HOME/bin
# EDITOR and VISUAL determine the editor that programs such as less
# and mail clients invoke when asked to edit a file.
setenv EDITOR vi
setenv VISUAL vi
# PAGER is the default text file viewer for programs such as man.
setenv PAGER less
# These are some handy options for less.
setenv LESS meiX
# By default, give other users read-only access to most new files.
umask 022
# Customize the prompt.
# Substitutions include:
# %n username %m hostname %/ current directory
# %h history number %l current terminal %% %
set prompt="%m%% "
13.5 Default User Settings
The best way to write startup files and choose defaults for new users is to experiment with a new test user on
the system. Create the test user with an empty home directory and refrain from copying your own startup files
www.EBooksWorld.ir
to the test user’s directory. Write the new startup files from scratch.
When you think you have a working setup, log in as the new test user in all possible ways (on the console,
remotely, and so on). Make sure that you test as many things as possible, including the windowing system
operation and manual pages. When you’re happy with the test user, create a second test user, copying the
startup files from the first test user. If everything still works, you now have a new set of startup files that you
can distribute to new users.
The following sections outline reasonable defaults for new users.
13.5.1 Shell Defaults
The default shell for any new user on a Linux system should be bash because:
o Users interact with the same shell that they use to write shell scripts (for example, csh is a notoriously bad
scripting tool—don’t even think about it).
o bash is standard on Linux systems.
o bash uses GNU readline, and therefore its interface is identical to that of many other tools.
o bash gives you fine, easy-to-understand control over I/O redirection and file handles.
However, many seasoned Unix wizards use shells such as csh and tcsh simply because they can’t bear to
switch. Of course, you can choose any shell you like, but choose bash if you don’t have any preference, and
use bash as the default shell for any new user on the system. (A user can change his or her shell with the
chsh command to suit individual preferences.)
NOTE
There are plenty of other shells out there (rc, ksh, zsh, es, and so on). Some are not appropriate
as beginner shells, but zsh and fish are sometimes popular with new users looking for an
alternative shell.
13.5.2 Editor
On a traditional system, the default editor should be vi or emacs. These are the only editors virtually
guaranteed to exist on nearly any Unix system, which means they’ll cause the least trouble in the long run for
a new user. However, Linux distributions often configure nano to be the default editor, because it’s easier for
beginners to use.
As with shell startup files, avoid large default editor startup files. A little set showmatch in the .exrc
startup file never hurt anyone but steer clear of anything that significantly changes the editor’s behavior or
appearance, such as the showmode feature, auto-indentation, and wrap margins.
13.5.3 Pager
It’s perfectly reasonable to set the default PAGER environment variable to less.
13.6 Startup File Pitfalls
Avoid these in startup files:
o Don’t put any kind of graphical command in a shell startup file.
o Don’t set the DISPLAY environment variable in a shell startup file.
o Don’t set the terminal type in a shell startup file.
o Don’t skimp on descriptive comments in default startup files.
www.EBooksWorld.ir
o Don’t run commands in a startup file that print to the standard output.
o Never set LD_LIBRARY_PATH in a shell startup file (see 15.1.4 Shared Libraries).
13.7 Further Startup Topics
Because this book deals only with the underlying Linux system, we won’t cover windowing environment
startup files. This is a large issue indeed, because the display manager that logs you in to a modern Linux
system has its own set of startup files, such as .xsession, .xinitrc, and the endless combinations of GNOME-
and KDE-related items.
The windowing choices may seem bewildering, and there is no one common way to start a windowing
environment in Linux. The next chapter describes some of the many possibilities. However, when you
determine what your system does, you may get a little carried away with the files that relate to your graphical
environment. That’s fine, but don’t carry it over to new users. The same tenet of keeping things simple in shell
startup files works wonders for GUI startup files, too. In fact, you probably don’t need to change your GUI
startup files at all.
www.EBooksWorld.ir
Chapter 14. A Brief Survey of the Linux Desktop
This chapter is a quick introduction to the components found in a typical Linux desktop system. Of all of the
different kinds of software that you can find on Linux systems, the desktop arena is one of the wildest and
most colorful because there are so many environments and applications to choose from, and most distributions
make it relatively easy for you to try them out.
Unlike other parts of a Linux system, such as storage and networking, there isn’t much of a hierarchy of layers
involved in creating a desktop structure. Instead, each component performs a specific task, communicating
with other components as necessary. Some components do share common building blocks (in particular,
libraries for graphical toolkits), and these can be thought of as simple abstraction layers, but that’s about as
deep as it goes.
This chapter offers a high-level discussion of desktop components in general, but we’ll look at two pieces in
a little more detail: the X Window System, which is the core infrastructure behind most desktops, and D-Bus,
an interprocess communication service used in many parts of the system. We’ll limit the hands-on discussion
and examples to a few diagnostic utilities that, while not terribly useful day-to-day (most GUIs don’t require
you to enter shell commands in order to interact with them), will help you understand the underlying
mechanics of the system and perhaps provide some entertainment along the way. We’ll also take a quick look
at printing.
14.1 Desktop Components
Linux desktop configurations offer a great deal of flexibility. Most of what the Linux user experiences (the
“look and feel” of the desktop) comes from applications or building blocks of applications. If you don’t like a
particular application, you can usually find an alternative. And if what you’re looking for doesn’t exist, you
can write it yourself. Linux developers tend to have a wide variety of preferences for how a desktop should
act, which makes for a lot of choices.
In order to work together, all applications need to have something in common, and at the core of nearly
everything on most Linux desktops is the X (X Window System) server. Think of X as sort of the “kernel” of
the desktop that manages everything from rendering windows to configuring displays to handling input from
devices such as keyboards and mice. The X server is also the one component that you won’t easily find a
replacement for (see 14.4 The Future of X).
The X server is just a server and does not dictate the way anything should act or appear. Instead, X client
programs handle the user interface. Basic X client applications, such as terminal windows and web browsers,
make connections to the X server and ask to draw windows. In response, the X server figures out where to
place the windows and renders them. The X server also channels input back to the client when appropriate.
14.1.1 Window Managers
X clients don’t have to act like windowed user applications; they can act as services for other clients or provide
www.EBooksWorld.ir
other interface functions. A window manager is perhaps the most important client service application because
it figures out how to arrange windows on screen and provides interactive decorations like title bars that allow
the user to move and minimize windows. These elements are central to the user experience.
There are many window manager implementations. Examples such as Mutter/GNOME Shell and Compiz are
meant to be more or less standalone, while others are built into environments such as Xfce. Most window
managers included in the standard Linux distributions strive for maximum user comfort, but others provide
specific visual effects or take a minimalist approach. There’s not likely to ever be a standard Linux window
manager because user tastes and requirements are diverse and constantly changing; as a result, new window
managers appear all the time.
14.1.2 Toolkits
Desktop applications include certain common elements, such as buttons and menus, called widgets. To speed
up development and provide a common look, programmers use graphical toolkits to provide these elements.
On operating systems such as Windows or Mac OS X, the vendor provides a common toolkit, and most
programmers use that. On Linux, the GTK+ toolkit is one of the most common, but you’ll also frequently see
widgets built on the Qt framework and others.
Toolkits usually consist of shared libraries and support files such as images and theme information.
14.1.3 Desktop Environments
Although toolkits provide the user with a uniform outward appearance, some details of a desktop require a
degree of cooperation between different applications. For example, one application may wish to share data
with another or update a common notification bar on a desktop. To provide for these needs, toolkits and other
libraries are bundled into larger packages called desktop environments. GNOME, KDE, Unity, and Xfce are
some common Linux desktop environments.
Toolkits are at the core of most desktop environments, but to create a unified desktop, environments must also
include numerous support files, such as icons and configurations, that make up themes. All of this is bound
together with documents that describe design conventions, such as how application menus and titles should
appear and how applications should react to certain system events.
14.1.4 Applications
At the top of the desktop are applications, such as web browsers and the terminal window. X applications can
range from crude (such as the ancient xclock program) to complex (such as the Chrome web browser and
LibreOffice suite). These applications normally stand alone, but they often use interprocess communication
to become aware of pertinent events. For example, an application can express interest when you attach a new
storage device or when you receive new email or an instant message. This communication usually occurs over
D-Bus, described in 14.5 D-Bus.
14.2 A Closer Look at the X Window System
The X Window System (http://www.x.org/) has historically been very large, with the base distribution
including the X server, client support libraries, and clients. Due to the emergence of desktop environments
such as GNOME and KDE, the role of the X distribution has changed over time, with the focus now more on
the core server that manages rendering and input devices, as well as a simplified client library.
The X server is easy to identify on your system. It’s called X. Check for it in a process listing; you’ll usually
see it running with a number of options like this:
/usr/bin/X :0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -
novtswitch
www.EBooksWorld.ir
The :0 shown here is called the display, an identifier representing one or more monitors that you access with
a common keyboard and/or mouse. Usually, the display just corresponds to the single monitor you attach to
your computer, but you can put multiple monitors under the same display. When using an X session, the
DISPLAY environment variable is set to the display identifier.
NOTE
Displays can be further subdivided into screens, such as :0.0 and :0.1, but this has become
increasingly rare because X extensions, such as RandR, can combine multiple monitors into one
larger virtual screen.
On Linux, an X server runs on a virtual terminal. In this example, the vt7 argument tells us that it’s been told
to run on /dev/tty7 (normally, the server starts on the first virtual terminal available). You can run more than
one X server at a time on Linux by running them on separate virtual terminals, but if you do, each server needs
a unique display identifier. You can switch between the servers with the CTRL-ALT-FN keys or the chvt
command.
14.2.1 Display Managers
You normally don’t start the X server with a command line because starting the server doesn’t define any
clients that are supposed to run on the server. If you start the server by itself, you’ll just get a blank screen.
Instead, the most common way to start an X server is with a display manager, a program that starts the server
and puts a login box on the screen. When you log in, the display manager starts a set of clients, such as a
window manager and file manager, so that you can start to use the machine.
There are many different display managers, such as gdm (for GNOME) and kdm (for KDE). The lightdm
in the argument list for the X server invocation above is a cross-platform display manager meant to be able to
start GNOME or KDE sessions.
To start an X session from a virtual console instead of using a display manager, you can run the startx or
xinit command. However, the session you get will likely be a very simple one that looks completely unlike
that of a display manager, because the mechanics and startup files are different.
14.2.2 Network Transparency
One feature of X is network transparency. Because clients talk to the server using a protocol, it’s possible to
run clients across a network to a server running on a different machine directly over the network, with the X
server listening for TCP connections on port 6000. Clients connecting to that port could authenticate, then
send windows to the server.
Unfortunately, this method does not normally offer any encryption and is insecure as a result. To close this
hole, most distributions now disable the X server’s network listener (with the -nolisten tcp option to
the server, as seen in Note). However, you can still run X clients from a remote machine with SSH tunneling,
as described in Chapter 10, by connecting the X server’s Unix domain socket to a socket on the remote
machine.
14.3 Exploring X Clients
Although one doesn’t normally think of working with a graphical user interface from the command line, there
are several utilities that allow you to explore the parts of the X Window System. In particular, you can inspect
clients as they run.
One of the simplest tools is xwininfo. When run without any arguments, it asks you to click on a window:
$ xwininfo
www.EBooksWorld.ir
xwininfo: Please select the window about which you
would like information by clicking the
mouse in that window.
After you click, it prints a list of information about the window, such as its location and size:
xwininfo: Window id: 0x5400024 "xterm"
Absolute upper-left X: 1075
Absolute upper-left Y: 594
--snip--
Notice the window ID here—the X server and window managers use this identifier to keep track of windows.
To get a list of all window IDs and clients, use the xlsclients -l command.
NOTE
There is a special window called the root window; it’s the background on the display. However,
you may never see this window (see Desktop Background).
14.3.1 X Events
X clients get their input and other information about the state of the server through a system of events. X
events work like other asynchronous interprocess communication events such as udev events and D-Bus
events: The X server receives information from a source such as an input device, then redistributes that input
as an event to any interested X client.
You can experiment with events with the xev command. Running it opens a new window that you can mouse
into, click, and type. As you do so, xev generates output describing the X events that it receives from the
server. For example, here’s sample output for mouse movement:
$ xev
--snip--
MotionNotify event, serial 36, synthetic NO, window 0x6800001,
root 0xbb, subw 0x0, time 43937883, (47,174), root:(1692,486),
state 0x0, is_hint 0, same_screen YES
MotionNotify event, serial 36, synthetic NO, window 0x6800001,
root 0xbb, subw 0x0, time 43937891, (43,177), root:(1688,489),
state 0x0, is_hint 0, same_screen YES
Notice the coordinates in parentheses. The first pair represents the x-and y-coordinates of the mouse pointer
inside the window, and the second (root:) is the location of the pointer on the entire display.
Other low-level events include key presses and button clicks, but a few more advanced ones indicate whether
the mouse has entered or exited the window, or if the window has gained or lost focus from the window
manager. For example, here are corresponding exit and unfocus events:
LeaveNotify event, serial 36, synthetic NO, window 0x6800001,
www.EBooksWorld.ir
root 0xbb, subw 0x0, time 44348653, (55,185), root:(1679,420),
mode NotifyNormal, detail NotifyNonlinear, same_screen YES,
focus YES, state 0
FocusOut event, serial 36, synthetic NO, window 0x6800001,
mode NotifyNormal, detail NotifyNonlinear
One common use of xev is to extract keycodes and key symbols for different keyboards when remapping the
keyboard. Here’s the output from pressing the L key; the keycode here is 46:
KeyPress event, serial 32, synthetic NO, window 0x4c00001,
root 0xbb, subw 0x0, time 2084270084, (131,120), root:(197,172),
state 0x0, keycode 46 (keysym 0x6c, l), same_screen YES,
XLookupString gives 1 bytes: (6c) "l"
XmbLookupString gives 1 bytes: (6c) "l"
XFilterEvent returns: False
You can also attach xev to an existing window ID with the -id id option. (Use the ID that you get from
xwininfo as id) or monitor the root window with -root.)
14.3.2 Understanding X Input and Preference Settings
One of the most potentially baffling characteristics of X is that there’s often more than one way to set
preferences, and some methods may not work. For example, one common keyboard preference on Linux
systems is to remap the Caps Lock key to a Control key. There are a number of ways to do this, from making
small adjustments with the old xmodmap command to providing an entirely new keyboard map with the
setxkbmap utility. How do you know which ones (if any) to use? It’s a matter of knowing which pieces of
the system have responsibility, but determining this can be difficult. Keep in mind that a desktop environment
may provide its own settings and overrides.
With this said, here are a few pointers on the underlying infrastructure.
Input Devices (General)
The X server uses the X Input Extension to manage input from many different devices. There are two basic
types of input device—keyboard and pointer (mouse)—and you can attach as many devices as you like. In
order to use more than one of the same type of device simultaneously, the X Input Extension creates a “virtual
core” device that funnels device input to the X server. The core device is called the master; the physical devices
that you plug in to the machine become slaves.
To see the device configuration on your machine, try running the xinput --list command:
$ xinput --list
Virtual core pointer id=2 [master pointer (3)]
Virtual core XTEST pointer id=4 [slave pointer (2)]
Logitech Unifying Device id=8 [slave pointer (2)]
Virtual core keyboard id=3 [master keyboard (2)]
www.EBooksWorld.ir
Virtual core XTEST keyboard id=5 [slave keyboard (3)]
Power Button id=6 [slave keyboard (3)]
Power Button id=7 [slave keyboard (3)]
Cypress USB Keyboard id=9 [slave keyboard (3)]
Each device has an associated ID that you can use with xinput and other commands. In this output, IDs 2
and 3 are the core devices, and IDs 8 and 9 are the real devices. Notice that the power buttons on the machine
are also treated as X input devices.
Most X clients listen for input from the core devices, because there is no reason for them to be concerned
about which particular device originates an event. In fact, most clients know nothing about the X Input
Extension. However, a client can use the extension to single out a particular device.
Each device has a set of associated properties. To view the properties, use xinput with the device number,
as in this example:
$ xinput --list-props 8
Device 'Logitech Unifying Device. Wireless PID:4026':
Device Enabled (126): 1
Coordinate Transformation Matrix (128): 1.000000, 0.000000,
0.000000,
0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 1.000000
Device Accel Profile (256): 0
Device Accel Constant Deceleration (257): 1.000000
Device Accel Adaptive Deceleration (258): 1.000000
Device Accel Velocity Scaling (259): 10.000000
--snip--
As you can see, there are a number of very interesting properties that you can change with the --set-prop
option (See the xinput(1) manual page for more information.)
Mouse
You can manipulate device-related settings with the xinput command, and many of the most useful pertain
to the mouse (pointer). You can change many settings directly as properties, but it’s usually easier with the
specialized --set-ptr-feedback and --set-button-map options to xinput. For example, if you
have a three-button mouse at dev on which you’d like to reverse the order of buttons (this is handy for left-
handed users), try this:
$ xinput --set-button-map dev 3 2 1
Keyboard
The many different keyboard layouts available internationally present particular difficulties for integration
into any windowing system. X has always had an internal keyboard-mapping capability in its core protocol
that you can manipulate with the xmodmap command, but any reasonably modern system uses the XKB (the
X keyboard extension) to gain finer control.
XKB is complicated, so much so that many people still use xmodmap when they need to make quick changes.
www.EBooksWorld.ir
The basic idea behind XKB is that you can define a keyboard map and compile it with the xkbcomp command,
then load and activate that map in the X server with the setxkbmap command. Two especially interesting
features of the system are these:
o You can define partial maps to supplement existing maps. This is especially handy for tasks such as
changing your Caps Lock key into a Control key, and it is used by many graphical keyboard preference
utilities in desktop environments.
o You can define individual maps for each attached keyboard.
Desktop Background
The old X command xsetroot allows you to set the background color and other characteristics of the root
window, but it produces no effect on most machines because the root window is never visible. Instead, most
desktop environments place a big window in the back of all of your other windows in order to enable features
such as “active wallpaper” and desktop file browsing. There are ways to change the background from the
command line (for example, with the gsettings command in some GNOME installations), but if you
actually want to do this, you probably have too much time on your hands.
xset
Probably the oldest preference command is xset. It’s not used much anymore, but you can run a quick xset
q to get the status of a few features. Perhaps the most useful are the screensaver and Display Power
Management Signaling (DPMS) settings.
14.4 The Future of X
As you were reading the preceding discussion, you may have gotten the feeling that X is a really old system
that’s been poked at a lot in order to get it to do new tricks. You wouldn’t be far off. The X Window System
was first developed in the 1980s. Although its evolution over the years has been significant (flexibility was an
important part of its original design), you can push the original architecture only so far.
One sign of the age of the X Window System is that the server itself supports an extremely large number of
libraries, many for backward compatibility. But perhaps more significantly, the idea of having a server manage
clients, their windows, and act as an intermediary for the window memory has become a burden on
performance. It’s much faster to allow applications to render the contents of their windows directly in the
display memory, with a lighter-weight window manager, called a compositing window manager, to arrange
the windows and do minimal management of the display memory.
A new standard based on this idea, Wayland, has started to gain traction. The most significant piece of Wayland
is a protocol that defines how clients talk to the compositing window manager. Other pieces include input
device management and an X-compatibility system. As a protocol, Wayland also maintains the idea of network
transparency. Many pieces of the Linux desktop now support Wayland, such as GNOME and KDE.
But Wayland isn’t the only alternative to X. As of this writing, another project, Mir, has similar goals, though
its architecture takes a somewhat different approach. At some point, there will be widespread adoption of at
least one system, which may or may not be one of these.
These new developments are significant because they won’t be limited to the Linux desktop. Due to its poor
performance and gigantic footprint, the X Window System is not suitable for environments such as tablets and
smartphones, so manufacturers have so far used alternative systems to drive embedded Linux displays.
However, standardized direct rendering can make for a more cost-effective way to support these displays.
www.EBooksWorld.ir
14.5 D-Bus
One of the most important developments to come out of the Linux desktop is the Desktop Bus (D-Bus), a
message-passing system. D-Bus is important because it serves as an interprocess communication mechanism
that allows desktop applications to talk to each other, and because most Linux systems use it to notify processes
of system events, such as inserting a USB drive.
D-Bus itself consists of a library that standardizes interprocess communication with a protocol and supporting
functions for any two processes to talk to each other. By itself, this library doesn’t offer much more than a
fancy version of normal IPC facilities such as Unix domain sockets. What makes D-Bus useful is a central
“hub” called dbus-daemon. Processes that need to react to events can connect to dbus-daemon and
register to receive certain kinds of events. Processes also create the events. For example, the process udisks-
daemon listens to ubus for disk events and sends them to dbus-daemon, which then retransmits the events
to applications interested in disk events.
14.5.1 System and Session Instances
D-Bus has become a more integral part of the Linux system, and it now goes beyond the desktop. For example,
both systemd and Upstart have D-Bus channels of communication. However, adding dependencies to desktop
tools inside the core system goes against a core design rule of Linux.
To address this problem, there are actually two kinds of dbus-daemon instances (processes) that can run.
The first is the system instance, which is started by init at boot time with the --system option. The system
instance usually runs as a D-Bus user, and its configuration file is /etc/dbus-1/system.conf (though you
probably shouldn’t change the configuration). Processes can connect to the system instance through the
/var/run/dbus/system_bus_socket Unix domain socket.
Independent of the system D-Bus instance, there is an optional session instance that runs only when you start
a desktop session. Desktop applications that you run connect to this instance.
14.5.2 Monitoring D-Bus Messages
One of the best ways to see the difference between the system and session dbus-daemon instances is to
monitor the events that go over the bus. Try using the dbus-monitor utility in system mode like this:
$ dbus-monitor --system
signal sender=org.freedesktop.DBus -> dest=:1.952 serial=2 path=/org/
freedesktop/DBus; interface=org.freedesktop.DBus; member=NameAcquired
string ":1.952"
The startup message here indicates that the monitor connected and acquired a name. You shouldn’t see much
activity when you run it like this, because the system instance usually isn’t very busy. To see something happen,
try plugging in a USB storage device.
By comparison, session instances have much more to do. Assuming you’ve logged in to a desktop session, try
this:
$ dbus-monitor --session
Now move your mouse around to different windows; if your desktop is D-Bus aware, you should get a flurry
of messages indicating activated windows.
www.EBooksWorld.ir
14.6 Printing
Printing a document on Linux is a multistage process. It goes like this:
1. The program doing the printing usually converts the document into PostScript form. This step is optional.
2. The program sends the document to a print server.
3. The print server receives the document and places it on a print queue.
4. When the document’s turn in the queue arrives, the print server sends the document to a print filter.
5. If the document is not in PostScript form, a print filter might perform a conversion.
6. If the destination printer does not understand PostScript, a printer driver converts the document to a
printer-compatible format.
7. The printer driver adds optional instructions to the document, such as paper tray and duplexing options.
8. The print server uses a backend to send the document to the printer.
The most confusing part of this process is why so much revolves around PostScript. PostScript is actually a
programming language, so when you print a file using it, you’re sending a program to the printer. PostScript
serves as a standard for printing in Unix-like systems, much as the .tar format serves as an archiving standard.
(Some applications now use PDF output, but this is relatively easy to convert.)
We’ll talk more about the print format later; first, let’s look at the queuing system.
14.6.1 CUPS
The standard printing system in Linux is CUPS (http://www.cups.org/), which is the same system used on Mac
OS X. The CUPS server daemon is called cupsd, and you can use the lpr command as a simple client to
send files to the daemon.
One significant feature of CUPS is that it implements Internet Print Protocol (IPP), a system that allows for
HTTP-like transactions among clients and servers on TCP port 631. In fact, if you have CUPS running on
your system, you can probably connect to http://localhost:631/ to see your current configuration and check on
any printer jobs. Most network printers and print servers support IPP, as does Windows, which can make
setting up remote printers a relatively simple task.
You probably won’t be able to administer the system from the web interface, because the default setup isn’t
very secure. Instead, your distribution likely has a graphical settings interface to add and modify printers.
These tools manipulate the configuration files, normally found in /etc/cups. It’s usually best to let these tools
do the work for you, because configuration can be complicated. And even if you do run into a problem and
need to configure manually, it’s usually best to create a printer using the graphical tools so that you have
somewhere to start.
14.6.2 Format Conversion and Print Filters
Many printers, including nearly all low-end models, do not understand PostScript or PDF. In order for Linux
to support one of these printers, it must convert documents to a format specific to the printer. CUPS sends the
document to a Raster Image Processor (RIP) to produce a bitmap. The RIP almost always uses the Ghostscript
(gs) program to do most of the real work, but it’s somewhat complicated because the bitmap must fit the
format of the printer. Therefore, the printer drivers that CUPS uses consult the PostScript Printer Definition
(PPD) file for the specific printer to figure out settings such as resolution and paper sizes.
www.EBooksWorld.ir
14.7 Other Desktop Topics
One interesting characteristic of the Linux desktop environment is that you can generally choose which pieces
you want to use and stop using the ones that you dislike. For a survey of many of the desktop projects, have a
look at the mailing lists and project links for the various projects at http://www.freedesktop.org/. Elsewhere,
you’ll find other desktop projects, such as Ayatana, Unity, and Mir.
Another major development in the Linux desktop is the Chromium OS open source project and its Google
Chrome OS counterpart found on Chromebook PCs. This is a Linux system that uses much of the desktop
technology described in this chapter but is centered around the Chromium/ Chrome web browsers. Much of
what’s found on a traditional desktop has been stripped away in Chrome OS.
www.EBooksWorld.ir
Chapter 15. Development Tools
Linux and Unix are very popular with programmers, not just due to the overwhelming array of tools and
environments available but also because the system is exceptionally well documented and transparent. On a
Linux machine, you don’t have to be a programmer to take advantage of development tools, but when working
with the system, you should know something about programming tools because they play a larger role in
managing Unix systems than in other operating systems. At the very least, you should be able to identify
development utilities and have some idea of how to run them.
This chapter packs a lot of information into a small space, but you don’t need to master everything here. You
can easily skim the material and come back later. The discussion of shared libraries is likely the most important
thing that you need to know. But to understand where shared libraries come from, you first need some
background on how to build programs.
15.1 The C Compiler
Knowing how to run the C programming language compiler can give you a great deal of insight into the origin
of the programs that you see on your Linux system. The source code for most Linux utilities, and for many
applications on Linux systems, is written in C or C++. We’ll primarily use examples in C for this chapter, but
you’ll be able to carry the information over to C++.
C programs follow a traditional development process: You write programs, you compile them, and they run.
That is, when you write a C program and want to run it, you must compile the source code that you wrote into
a binary low-level form that the computer understands. You can compare this to the scripting languages that
we’ll discuss later, where you don’t need to compile anything.
NOTE
By default, most distributions do not include the tools necessary to compile C code because these
tools occupy a fairly large amount of space. If you can’t find some of the tools described here, you
can install the build-essential package for Debian/Ubuntu or the Chapter 15 yum groupinstall for
Fedora/CentOS. Failing that, try a package search for “C compiler.”
The C compiler executable on most Unix systems is the GNU C complier, gcc, though the newer clang
compiler from the LLVM project is gaining popularity. C source code files end with .c. Take a look at the
single, self-contained C source code file called hello.c, which you can find in The C Programming Language,
2nd edition, by Brian W. Kernighan and Dennis M. Ritchie (Prentice Hall, 1988):
#include <stdio.h>
main() {
printf("Hello, World.\n");
www.EBooksWorld.ir
}
Put this source code in a file called hello.c and then run this command:
$ cc hello.c
The result is an executable named a.out, which you can run like any other executable on the system. However,
you should probably give the executable another name (such as hello). To do this, use the compiler’s -o option:
$ cc -o hello hello.c
For small programs, there isn’t much more to compiling than that. You might need to add an extra include
directory or library (see 15.1.2 Header (Include) Files and Directories and 15.1.3 Linking with Libraries), but
let’s look at slightly larger programs before getting into those topics.
15.1.1 Multiple Source Files
Most C programs are too large to reasonably fit inside a single source code file. Mammoth files become too
disorganized for the programmer, and compilers sometimes even have trouble parsing large files. Therefore,
developers group components of the source code together, giving each piece its own file.
When compiling most .c files, you don’t create an executable right away. Instead, use the compiler’s -c option
on each file to create object files. To see how this works, let’s say you have two files, main.c and aux.c. The
following two compiler commands do most of the work of building the program:
$ cc -c main.c
$ cc -c aux.c
The preceding two commands compile the two source files into the two object files main.o and aux.o.
An object file is a binary file that a processor can almost understand, except that there are still a few loose
ends. First, the operating system doesn’t know how to run an object file, and second, you likely need to
combine several object files and some system libraries to make a complete program.
To build a fully functioning executable from one or more object files, you must run the linker, the ld command
in Unix. Programmers rarely use ld on the command line, because the C compiler knows how to run the
linker program. So to create an executable called myprog from the two object files above, run this command
to link them:
$ cc -o myprog main.o aux.o
Although you can compile multiple source files by hand, as the preceding example shows, it can be hard to
keep track of them all during the compiling process when the number of source files multiplies. The make
system described in 15.2 make is the traditional Unix standard for managing compiles. This system is
especially important in managing the files described in the next two sections.
15.1.2 Header (Include) Files and Directories
C header files are additional source code files that usually contain type and library function declarations. For
example, stdio.h is a header file (see the simple program in 15.1 The C Compiler).
Unfortunately, a great number of compiler problems crop up with header files. Most glitches occur when the
compiler can’t find header files and libraries. There are even some cases where a programmer forgets to
include a required header file, causing some of the source code to not compile.
Fixing Include File Problems
Tracking down the correct include files isn’t always easy. Sometimes there are several include files with the
www.EBooksWorld.ir
same names in different directories, and it’s not clear which is the correct one. When the compiler can’t find
an include file, the error message looks like this:
badinclude.c:1:22: fatal error: notfound.h: No such file or directory
This message reports that the compiler can’t find the notfound.h header file that the badinclude.c file
references. This specific error is a direct result of this directive on line 1 of badinclude.c:
#include <notfound.h>
The default include directory in Unix is /usr/include; the compiler always looks there unless you explicitly
tell it not to. However, you can make the compiler look in other include directories (most paths that contain
header files have include somewhere in the name).
NOTE
You’ll learn more about how to find missing include files in Chapter 16.
For example, let’s say that you find notfound.h in /usr/junk/include. You can make the compiler see this
directory with the -I option:
$ cc -c -I/usr/junk/include badinclude.c
Now the compiler should no longer stumble on the line of code in badinclude.c that references the header file.
You should also beware of includes that use double quotes (" ") instead of angle brackets (< >), like this:
#include "myheader.h"
Double quotes mean that the header file is not in a system include directory but that the compiler should
otherwise search its include path. It often means that the include file is in the same directory as the source file.
If you encounter a problem with double quotes, you’re probably trying to compile incomplete source code.
What Is the C Preprocessor (cpp)?
It turns out that the C compiler does not actually do the work of looking for all of these include files. That task
falls to the C preprocessor, a program that the compiler runs on your source code before parsing the actual
program. The preprocessor rewrites source code into a form that the compiler understands; it’s a tool for
making source code easier to read (and for providing shortcuts).
Preprocessor commands in the source code are called directives, and they start with the # character. There are
three basic types of directives:
o Include files. An #include directive instructs the preprocessor to include an entire file. Note that the
compiler’s -I flag is actually an option that causes the preprocessor to search a specified directory for
include files, as you saw in the previous section.
o Macro definitions. A line such as #define BLAH something tells the preprocessor to substitute
something for all occurrences of BLAH in the source code. Convention dictates that macros appear in all
uppercase, but it should come as no shock that programmers sometimes use macros whose names look like
functions and variables. (Every now and then, this causes a world of headaches. Many programmers make a
sport out of abusing the preprocessor.)
NOTE
Instead of defining macros within your source code, you can also define macros by passing
parameters to the compiler: -DBLAH=something works like the directive above.
o Conditionals. You can mark out certain pieces of code with #ifdef, #if, and #endif. The #ifdef
MACRO directive checks to see whether the preprocessor macro MACRO is defined, and #if condition
tests to see whether condition is nonzero. For both directives, if the condition following the “if
www.EBooksWorld.ir
statement” is false, the preprocessor does not pass any of the program text between the #if and the next
#endif to the compiler. If you plan to look at any C code, you’d better get used to this.
An example of a conditional directive follows. When the preprocessor sees the following code, it checks to
see whether the macro DEBUG is defined and, if so, passes the line containing fprintf() on to the compiler.
Otherwise, the preprocessor skips this line and continues to process the file after the #endif:
#ifdef DEBUG
fprintf(stderr, "This is a debugging message.\n");
#endif
NOTE
The C preprocessor doesn’t know anything about C syntax, variables, functions, and other
elements. It understands only its own macros and directives.
On Unix, the C preprocessor’s name is cpp, but you can also run it with gcc -E. However, you’ll rarely
need to run the preprocessor by itself.
15.1.3 Linking with Libraries
The C compiler doesn’t know enough about your system to create a useful program all by itself. You need
libraries to build complete programs. A C library is a collection of common precompiled functions that you
can build into your program. For example, many executables use the math library because it provides
trigonometric functions and the like.
Libraries come into play primarily at link time, when the linker program creates an executable from object
files. For example, if you have a program that uses the gobject library but you forget to tell the compiler to
link against that library, you’ll see linker errors like this:
badobject.o(.text+0x28): undefined reference to 'g_object_new'
The most important parts of these error messages are in bold. When the linker program examined the
badobject.o object file, it couldn’t find the function that appears in bold, and as a consequence, it couldn’t
create the executable. In this particular case, you might suspect that you forgot the gobject library because the
missing function is g_object_new().
NOTE
Undefined references do not always mean that you’re missing a library. One of the program’s
object files could be missing in the link command. It’s usually easy to differentiate between library
functions and functions in your object files, though.
To fix this problem, you must first find the gobject library and then use the compiler’s -l option to link against
the library. As with include files, libraries are scattered throughout the system (/usr/lib is the system default
location), though most libraries reside in a subdirectory named lib. For the preceding example, the basic
gobject library file is libgobject.a, so the library name is gobject. Putting it all together, you would link the
program like this:
$ cc -o badobject badobject.o -lgobject
You must tell the linker about nonstandard library locations; the parameter for this is -L. Let’s say that the
badobject program requires libcrud.a in /usr/junk/lib. To compile and create the executable, use a
command like this:
$ cc -o badobject badobject.o -lgobject -L/usr/junk/lib -lcrud
www.EBooksWorld.ir
NOTE
If you want to search a library for a particular function, use the nm command. Be prepared for a lot
of output. For example, try this: nm libgobject.a. (You might need to use the locate
command to find libgobject.a; many distributions now put libraries in architecture-specific
subdirectories in /usr/lib.)
15.1.4 Shared Libraries
A library file ending with .a (such as libgobject.a) is called a static library. When you link a program against
a static library, the linker copies machine code from the library file into your executable. Therefore, the final
executable does not need the original library file to run, and furthermore, the executable’s behavior never
changes.
However, library sizes are always increasing, as is the number of libraries in use, and this makes static libraries
wasteful in terms of disk space and memory. In addition, if a static library is later found to be inadequate or
insecure, there’s no way to change any executable linked against it, short of recompiling the executable.
Shared libraries counter these problems. When you run a program linked against one, the system loads the
library’s code into the process memory space only when necessary. Many processes can share the same shared
library code in memory. And if you need to slightly modify the library code, you can generally do so without
recompiling any programs.
Shared libraries have their own costs: difficult management and a somewhat complicated linking procedure.
However, you can bring shared libraries under control if you know four things:
o How to list the shared libraries that an executable needs
o How an executable looks for shared libraries
o How to link a program against a shared library
o The common shared library pitfalls
The following sections tell you how to use and maintain your system’s shared libraries. If you’re interested in
how shared libraries work or if you want to know about linkers in general, you can check out Linkers and
Loaders by John R. Levine (Morgan Kaufmann, 1999), “The Inside Story on Shared Libraries and Dynamic
Loading” by David M. Beazley, Brian D. Ward, and Ian R. Cooke (Computing in Science & Engineering,
September/October 2001), or online resources such as the Program Library HOWTO
(http://dwheeler.com/program-library/). The ld.so(8) manual page is also worth a read.
Listing Shared Library Dependencies
Shared library files usually reside in the same places as static libraries. The two standard library directories on
a Linux system are /lib and /usr/lib. The /lib directory should not contain static libraries.
A shared library has a suffix that contains .so (shared object), as in libc-2.15.so and libc.so.6. To see what
shared libraries a program uses, run ldd prog, where prog is the executable name. Here’s an example for
the shell:
$ ldd /bin/bash
linux-gate.so.1 => (0xb7799000)
libtinfo.so.5 => /lib/i386-linux-gnu/libtinfo.so.5 (0xb7765000)
libdl.so.2 => /lib/i386-linux-gnu/libdl.so.2 (0xb7760000)
libc.so.6 => /lib/i386-linux-gnu/libc.so.6 (0xb75b5000)
www.EBooksWorld.ir
/lib/ld-linux.so.2 (0xb779a000)
In the interest of optimal performance and flexibility, executables alone don’t usually know the locations of
their shared libraries; they know only the names of the libraries, and perhaps a little hint about where to find
them. A small program named ld.so (the runtime dynamic linker/loader) finds and loads shared libraries for
a program at runtime. The preceding ldd output shows the library names on the left—that’s what the
executable knows. The right side shows where ld.so finds the library.
The final line of output here shows the actual location of ld.so: ld-linux.so.2.
How ld.so Finds Shared Libraries
One of the common trouble points for shared libraries is that the dynamic linker cannot find a library. The first
place the dynamic linker should normally look for shared libraries is an executable’s preconfigured runtime
library search path (rpath), if it exists. You’ll see how to create this path shortly.
Next, the dynamic linker looks in a system cache, /etc/ld.so.cache, to see if the library is in a standard location.
This is a fast cache of the names of library files found in directories listed in the cache configuration file /etc/
ld.so.conf.
NOTE
As is typical of many of the Linux configuration files that you’ve seen, ld.so.conf may include a
number of files in a directory such as /etc/ld.so.conf.d.
Each line in ld.so.conf is a directory that you want to include in the cache. The list of directories is usually
short, containing something like this:
/lib/i686-linux-gnu
/usr/lib/i686-linux-gnu
The standard library directories /lib and /usr/lib are implicit, which means that you don’t need to include them
in /etc/ld.so.conf.
If you alter ld.so.conf or make a change to one of the shared library directories, you must rebuild the
/etc/ld.so.cache file by hand with the following command:
# ldconfig -v
The -v option provides detailed information on libraries that ldconfig adds to the cache and any changes
that it detects.
There is one more place that ld.so looks for shared libraries: the environment variable
LD_LIBRARY_PATH. We’ll talk about this soon.
Don’t get into the habit of adding stuff to /etc/ld.so.conf. You should know what shared libraries are in the
system cache, and if you put every bizarre little shared library directory into the cache, you risk conflicts and
an extremely disorganized system. When you compile software that needs an obscure library path, give your
executable a built-in runtime library search path. Let’s see how to do that.
Linking Programs Against Shared Libraries
Let’s say you have a shared library named libweird.so.1 in /opt/obscure/lib that you need to link myprog
against. Link the program as follows:
$ cc -o myprog myprog.o -Wl,-rpath=/opt/obscure/lib -L/opt/obscure/lib
-lweird
The -Wl,-rpath option tells the linker to include a following directory into the executable’s runtime library
www.EBooksWorld.ir
search path. However, even if you use -Wl,-rpath, you still need the -L flag.
If you have a pre-existing binary, you can also use the patchelf program to insert a different runtime library
search path, but it’s generally better to do this at compile time.
Problems with Shared Libraries
Shared libraries provide remarkable flexibility, not to mention some really incredible hacks, but it’s also
possible to abuse them to the point where your system becomes an utter and complete mess. Three particularly
bad things can happen:
o Missing libraries
o Terrible performance
o Mismatched libraries
The number one cause of all shared library problems is the environment variable named LD_LIBRARY_PATH.
Setting this variable to a colon-delimited set of directory names makes ld.so search the given directories
before anything else when looking for a shared library. This is a cheap way to make programs work when you
move a library around, if you don’t have the program’s source code and can’t use patchelf, or if you’re
just too lazy to recompile the executables. Unfortunately, you get what you pay for.
Never set LD_LIBRARY_PATH in shell startup files or when compiling software. When the dynamic runtime
linker encounters this variable, it must often search through the entire contents of each specified directory
more times than you’d care to know. This causes a big performance hit, but more importantly, you can get
conflicts and mismatched libraries because the runtime linker looks in these directories for every program.
If you must use LD_LIBRARY_PATH to run some crummy program for which you don’t have the source (or
an application that you’d rather not compile, like Mozilla or some other beast), use a wrapper script. Let’s say
your executable is /opt/crummy/bin/crummy.bin and needs some shared libraries in /opt/crummy/lib. Write a
wrapper script called crummy that looks like this:
#!/bin/sh
LD_LIBRARY_PATH=/opt/crummy/lib
export LD_LIBRARY_PATH
exec /opt/crummy/bin/crummy.bin $@
Avoiding LD_LIBRARY_PATH prevents most shared library problems. But one other significant problem
that occasionally comes up with developers is that a library’s application programming interface (API) may
change slightly from one minor version to another, breaking installed software. The best solutions here are
preventive: Either use a consistent methodology to install shared libraries with -Wl,-rpath to create a
runtime link path or simply use the static versions of obscure libraries.
15.2 make
A program with more than one source code file or that requires strange compiler options is too cumbersome
to compile by hand. This problem has been around for years, and the traditional Unix compile management
utility that eases these pains is called make. You should know a little about make if you’re running a Unix
system, because system utilities sometimes rely on make to operate. However, this chapter is only the tip of
the iceberg. There are entire books on make, such as Managing Projects with GNU Make by Robert
Mecklenburg (O’Reilly, 2004). In addition, most Linux packages are built using an additional layer around
make or a similar tool. There are many build systems out there; we’ll look at one named autotools in
Chapter 16. make is a big system, but it’s not very difficult to get an idea of how it works. When you see a
www.EBooksWorld.ir
file named Makefile or makefile, you know that you’re dealing with make. (Try running make to see if you
can build anything.)
The basic idea behind make is the target, a goal that you want to achieve. A target can be a file (a .o file, an
executable, and so on) or a label. In addition, some targets depend on other targets; for instance, you need a
complete set of .o files before you can link your executable. These requirements are called dependencies.
To build a target, make follows a rule, such as a rule for how to go from a .c source file to a .o object file.
make already knows several rules, but you can customize these existing rules and create your own.
15.2.1 A Sample Makefile
The following very simple Makefile builds a program called myprog from aux.c and main.c:
# object files
OBJS=aux.o main.o
all: myprog
myprog: $(OBJS)
$(CC) -o myprog $(OBJS)
The # in the first line of this Makefile denotes a comment.
The next line is just a macro definition; it sets the OBJS variable to two object filenames. This will be
important later. For now, take note of how you define the macro and also how you reference it later ($(OBJS)).
The next item in the Makefile contains its first target, all. The first target is always the default, the target that
make wants to build when you run make by itself on the command line.
The rule for building a target comes after the colon. For all, this Makefile says that you need to satisfy
something called myprog. This is the first dependency in the file; all depends on myprog. Note that
myprog can be an actual file or the target of another rule. In this case, it’s both (the rule for all and the
target of OBJS).
To build myprog, this Makefile uses the macro $(OBJS) in the dependencies. The macro expands to aux.o
and main.o, so myprog depends on these two files (they must be actual files, because there aren’t any targets
with those names anywhere in the Makefile).
This Makefile assumes that you have two C source files named aux.c and main.c in the same directory.
Running make on the Makefile yields the following output, showing the commands that make is running:
$ make
cc -c -o aux.o aux.c
cc -c -o main.o main.c
cc -o myprog aux.o main.o
A diagram of the dependencies is shown in Figure 15-1.
www.EBooksWorld.ir
Figure 15-1. Makefile dependencies
15.2.2 Built-in Rules
So how does make know how to go from aux.c to aux.o? After all, aux.c is not in the Makefile. The answer
is that make follows its built-in rules. It knows to look for a .c file when you want a .o file, and furthermore,
it knows how to run cc -c on that .c file to get to its goal of creating a .o file.
15.2.3 Final Program Build
The final step in getting to myprog is a little tricky, but the idea is clear enough. After you have the two object
files in $(OBJS), you can run the C compiler according to the following line (where $(CC) expands to the
compiler name):
$(CC) -o myprog $(OBJS)
The whitespace before $(CC) is a tab. You must insert a tab before any real command, on its own line.
Watch out for this:
Makefile:7: *** missing separator. Stop.
An error like this means that the Makefile is broken. The tab is the separator, and if there is no separator or
there’s some other interference, you’ll see this error.
15.2.4 Staying Up-to-Date
One last make fundamental is that targets should be up-to-date with their dependencies. If you type make
twice in a row for the preceding example, the first command builds myprog, but the second yields this output:
make: Nothing to be done for 'all'.
This second time through, make looked at its rules and noticed that myprog already exists, so it didn’t build
myprog again because none of the dependencies had changed since it was last built. To experiment with this,
do the following:
1. Run touch aux.c.
2. Run make again. This time, make determines that aux.c is newer than the aux.o already in the directory,
so it compiles aux.o again.
www.EBooksWorld.ir
3. myprog depends on aux.o, and now aux.o is newer than the preexisting myprog, so make must create
myprog again.
This type of chain reaction is very typical.
15.2.5 Command-Line Arguments and Options
You can get a great deal of mileage out of make if you know how its command-line arguments and options
work.
One of the most useful options is to specify a single target on the command line. For the preceding Makefile,
you can run make aux.o if you want only the aux.o file.
You can also define a macro on the command line. For example, to use the clang compiler, try
$ make CC=clang
Here, make uses your definition of CC instead of its default compiler, cc. Command-line macros come in
handy when testing preprocessor definitions and libraries, especially with the CFLAGS and LDFLAGS macros
that we’ll discuss shortly.
In fact, you don’t even need a Makefile to run make. If built-in make rules match a target, you can just ask
make to try to create the target. For example, if you have the source to a very simple program called blah.c,
try make blah. The make run proceeds like this:
$ make blah
cc blah.o -o blah
This use of make works only for the most elementary C programs; if your program needs a library or special
include directory, you should probably write a Makefile. Running make without a Makefile is actually most
useful when you’re dealing with something like Fortran, Lex, or Yacc and don’t know how the compiler or
utility works. Why not let make try to figure it out for you? Even if make fails to create the target, it will
probably still give you a pretty good hint as to how to use the tool.
Two make options stand out from the rest:
o -n Prints the commands necessary for a build but prevents make from actually running any commands
o -f file Tells make to read from file instead of Makefile or makefile
15.2.6 Standard Macros and Variables
make has many special macros and variables. It’s difficult to tell the difference between a macro and a variable,
so we’ll use the term macro to mean something that usually doesn’t change after make starts building targets.
As you saw earlier, you can set macros at the start of your Makefile. These are the most common macros:
o CFLAGS C compiler options. When creating object code from a .c file, make passes this as an argument to
the compiler.
o LDFLAGS Like CFLAGS, but they’re for the linker when creating an executable from object code.
o LDLIBS If you use LDFLAGS but do not want to combine the library name options with the search path,
put the library name options in this file.
o CC The C compiler. The default is cc.
o CPPFLAGS C preprocessor options. When make runs the C preprocessor in some way, it passes this
macro’s expansion on as an argument.
o CXXFLAGS GNU make uses this for C++ compiler flags.
www.EBooksWorld.ir
A make variable changes as you build targets. Because you never set make variables by hand, the following
list includes the $.
o $@ When inside a rule, this expands to the current target.
o $* Expands to the basename of the current target. For example, if you’re building blah.o, this expands to
blah.
The most comprehensive list of make variables on Linux is the make info manual.
NOTE
Keep in mind that GNU make has many extensions, built-in rules, and features that other variants
do not have. This is fine as long as you’re running Linux, but if you step off onto a Solaris or BSD
machine and expect the same stuff to work, you might be in for a surprise. However, that’s the
problem that multi-platform build systems such as GNU autotools solve.
15.2.7 Conventional Targets
Most Makefiles contain several standard targets that perform auxiliary tasks related to compiles.
o clean The clean target is ubiquitous; a make clean usually instructs make to remove all of the
object files and executables so that you can make a fresh start or pack up the software. Here’s an example
rule for the myprog Makefile:
o clean:
rm -f $(OBJS) myprog
o distclean A Makefile created by way of the GNU autotools system always has a distclean target to
remove everything that wasn’t part of the original distribution, including the Makefile. You’ll see more of
this in Chapter 16. On very rare occasions, you might find that a developer opts not to remove the
executable with this target, preferring something like realclean instead.
o install Copies files and compiled programs to what the Makefile thinks is the proper place on the
system. This can be dangerous, so always run a make -n install first to see what will happen without
actually running any commands.
o test or check Some developers provide test or check targets to make sure that everything works
after performing a build.
o depend Creates dependencies by calling the compiler with -M to examine the source code. This is an
unusual-looking target because it often changes the Makefile itself. This is no longer common practice, but
if you come across some instructions telling you to use this rule, make sure to do so.
o all Often the first target in the Makefile. You’ll often see references to this target instead of an actual
executable.
15.2.8 Organizing a Makefile
Even though there are many different Makefile styles, most programmers adhere to some general rules of
thumb. For one, in the first part of the Makefile (inside the macro definitions), you should see libraries and
includes grouped according to package:
MYPACKAGE_INCLUDES=-I/usr/local/include/mypackage
MYPACKAGE_LIB=-L/usr/local/lib/mypackage -lmypackage
PNG_INCLUDES=-I/usr/local/include
PNG_LIB=-L/usr/local/lib -lpng
www.EBooksWorld.ir
Each type of compiler and linker flag often gets a macro like this:
CFLAGS=$(CFLAGS) $(MYPACKAGE_INCLUDES) $(PNG_INCLUDES)
LDFLAGS=$(LDFLAGS) $(MYPACKAGE_LIB) $(PNG_LIB)
Object files are usually grouped according to executables. For example, say you have a package that creates
executables called boring and trite. Each has its own .c source file and requires the code in util.c. You
might see something like this:
UTIL_OBJS=util.o
BORING_OBJS=$(UTIL_OBJS) boring.o
TRITE_OBJS=$(UTIL_OBJS) trite.o
PROGS=boring trite
The rest of the Makefile might look like this:
all: $(PROGS)
boring: $(BORING_OBJS)
$(CC) -o $@ $(BORING_OBJS) $(LDFLAGS)
trite: $(TRITE_OBJS)
$(CC) -o $@ $(TRITE_OBJS) $(LDFLAGS)
You could combine the two executable targets into one rule, but it’s usually not a good idea to do so because
you would not easily be able to move a rule to another Makefile, delete an executable, or group executables
differently. Furthermore, the dependencies would be incorrect: If you had just one rule for boring and
trite, trite would depend on boring.c, boring would depend on trite.c, and make would always try to
rebuild both programs whenever you changed one of the two source files.
NOTE
If you need to define a special rule for an object file, put the rule for the object file just above the
rule that builds the executable. If several executables use the same object file, put the object rule
above all of the executable rules.
15.3 Debuggers
The standard debugger on Linux systems is gdb; user-friendly frontends such as the Eclipse IDE and Emacs
systems are also available. To enable full debugging in your programs, run the compiler with -g to write a
symbol table and other debugging information into the executable. To start gdb on an executable named
program, run
$ gdb program
You should get a (gdb) prompt. To run program with the command-line argument options, enter this at
the (gdb) prompt:
(gdb) run options
www.EBooksWorld.ir
If the program works, it should start, run, and exit as normal. However, if there’s a problem, gdb stops, prints
the failed source code, and throws you back to the (gdb) prompt. Because the source code fragment often
hints at the problem, you’ll probably want to print the value of a particular variable that the trouble may be
related to. (The print command also works for arrays and C structures.)
(gdb) print variable
To make gdb stop the program at any point in the original source code, use the breakpoint feature. In the
following command, file is a source code file, and line_num is the line number in that file where gdb
should stop:
(gdb) break file:line_num
To tell gdb to continue executing the program, use
(gdb) continue
To clear a breakpoint, enter
(gdb) clear file:line_num
This section has provided only the briefest introduction to gdb, which includes an extensive manual that you
can read online, in print, or buy as Debugging with GDB, 10th edition, by Richard M. Stallman et al. (GNU
Press, 2011). The Art of Debugging by Norman Matloff and Peter Jay Salzman (No Starch Press, 2008) is
another guide to debugging.
NOTE
If you’re interested in rooting out memory problems and running profiling tests, try Valgrind
( http://valgrind.org/).
15.4 Lex and Yacc
You might encounter Lex and Yacc when compiling programs that read configuration files or commands.
These tools are building blocks for programming languages.
o Lex is a tokenizer that transforms text into numbered tags with labels. The GNU/Linux version is named
flex. You may need a -ll or -lfl linker flag in conjunction with Lex.
o Yacc is a parser that attempts to read tokens according to a grammar. The GNU parser is bison; to get
Yacc compatibility, run bison -y. You may need the -ly linker flag.
15.5 Scripting Languages
A long time ago, the average Unix systems manager didn’t have to worry much about scripting languages
other than the Bourne shell and awk. Shell scripts (discussed in Chapter 11) continue to be an important part
of Unix, but awk has faded somewhat from the scripting arena. However, many powerful successors have
arrived, and many systems programs have actually switched from C to scripting languages (such as the
sensible version of the whois program). Let’s look at some scripting basics.
The first thing you need to know about any scripting language is that the first line of a script looks like the
shebang of a Bourne shell script. For example, a Python script starts out like this:
#!/usr/bin/python
Or this:
#!/usr/bin/env python
www.EBooksWorld.ir
In Unix, any executable text file that starts with #! is a script. The pathname following this prefix is the
scripting language interpreter executable. When Unix tries to run an executable file that starts with a #!
shebang, it runs the program following the #! with the rest of the file as the standard input. Therefore, even
this is a script:
#!/usr/bin/tail -2
This program won't print this line,
but it will print this line...
and this line, too.
The first line of a shell script often contains one of the most common basic script problems: an invalid path to
the scripting language interpreter. For example, say you named the previous script myscript. What if tail
were actually in /bin instead of /usr/bin on your system? In that case, running myscript would produce this
error:
bash: ./myscript: /usr/bin/tail: bad interpreter: No such file or
directory
Don’t expect more than one argument in the script’s first line to work. That is, the -2 in the preceding example
might work, but if you add another argument, the system could decide to treat the -2 and the new argument
as one big argument, spaces and all. This can vary from system to system; don’t test your patience on
something as insignificant as this.
Now, let’s look at a few of the languages out there.
15.5.1 Python
Python is a scripting language with a strong following and an array of powerful features, such as text
processing, database access, networking, and multithreading. It has a powerful interactive mode and a very
organized object model.
Python’s executable is python, and it’s usually in /usr/bin. However, Python isn’t used just from the
command line for scripts. One place you’ll find it is as a tool to build websites. Python Essential Reference,
4th edition, by David M. Beazley (Addison-Wesley, 2009) is a great reference with a small tutorial at the
beginning to get you started.
15.5.2 Perl
One of the older third-party Unix scripting languages is Perl. It’s the original “Swiss army chainsaw” of
programming tools. Although Perl has lost a fair amount of ground to Python in recent years, it excels in
particular at text processing, conversion, and file manipulation, and you may find many tools built with it.
Learning Perl, 6th edition, by Randal L. Schwartz, brian d foy, and Tom Phoenix(O’Reilly, 2011) is a tutorial-
style introduction; a larger reference is Modern Perl by Chromatic (Onyx Neon Press, 2014).
15.5.3 Other Scripting Languages
You might also encounter these scripting languages:
o PHP. This is a hypertext-processing language often found in dynamic web scripts. Some people use PHP
for standalone scripts. The PHP website is at http://www.php.net/.
o Ruby. Object-oriented fanatics and many web developers enjoy programming in this language
(http://www.ruby-lang.org/).
www.EBooksWorld.ir
o JavaScript. This language is used inside web browsers primarily to manipulate dynamic content. Most
experienced programmers shun it as a standalone scripting language due to its many flaws, but it’s nearly
impossible to avoid when doing web programming. You might find an implementation called Node.js with
an executable name of node on your system.
o Emacs Lisp. A variety of the Lisp programming language used by the Emacs text editor.
o Matlab, Octave. Matlab is a commercial matrix and mathematical programming language and library.
There is a very similar free software project called Octave.
o R. A popular free statistical analysis language. See http://www.r-project.org/ and The Art of R Programming
by Norman Matloff (No Starch Press, 2011) for more information.
o Mathematica. Another commercial mathematical programming language with libraries. m4 This is a
macro-processing language, usually found only in the GNU autotools.
o Tcl. Tcl (tool command language) is a simple scripting language usually associated with the Tk graphical
user interface toolkit and Expect, an automation utility. Although Tcl does not enjoy the widespread use that
it once did, don’t discount its power. Many veteran developers prefer Tk, especially for its embedded
capabilities. See http://www.tcl.tk/ for more on Tk.
15.6 Java
Java is a compiled language like C, with a simpler syntax and powerful support for object-oriented
programming. It has a few niches in Unix systems. For one, it’s often used as a web application environment,
and it’s popular for specialized applications. For example, Android applications are usually written in Java.
Even though it’s not often seen on a typical Linux desktop, you should know how Java works, at least for
standalone applications.
There are two kinds of Java compilers: native compilers for producing machine code for your system (like a
C compiler) and bytecode compilers for use by a bytecode interpreter (sometimes called a virtual machine,
which is different from the virtual machine offered by a hypervisor, as described in Chapter 17). You’ll
practically always encounter bytecode on Linux.
Java bytecode files end in .class. The Java runtime environment (JRE) contains all of the programs you need
to run Java bytecode. To run a bytecode file, use
$ java file.class
You might also encounter bytecode files that end in .jar, which are collections of archived .class files. To run
a .jar file, use this syntax:
$ java -jar file.jar
Sometimes you need to set the JAVA_HOME environment variable to your Java installation prefix. If you’re
really unlucky, you might need to use CLASSPATH to include any directories containing classes that your
program expects. This is a colon-delimited set of directories like the regular PATH variable for executables.
If you need to compile a .java file into bytecode, you need the Java Development Kit (JDK). You can run the
javac compiler from JDK to create some .class files:
$ javac file.java
JDK also comes with jar, a program that can create and pick apart .jar files. It works like tar.
www.EBooksWorld.ir
15.7 Looking Forward: Compiling Packages
The world of compilers and scripting languages is vast and constantly expanding. As of this writing, new
compiled languages such as Go (golang) and Swift are gaining popularity.
The LLVM compiler infrastructure set (http://llvm.org/) has significantly eased compiler development. If
you’re interested in how to design and implement a compiler, two good books are Compilers: Principles,
Techniques, and Tools, 2nd edition, by Alfred V. Aho et al. (Addison-Wesley, 2006) and Modern Compiler
Design, 2nd edition, by Dick Grune et al. (Springer, 2012). For scripting language development, it’s usually
best to look for online resources, as the implementations vary widely.
Now that you know the basics of the programming tools on the system, you’re ready to see what they can do.
The next chapter is all about how you can build packages on Linux from source code.
www.EBooksWorld.ir
Chapter 16. Introduction to Compiling Software From C Source Code
Most nonproprietary third-party Unix software packages come as source code that you can build and install.
One reason for this is that Unix (and Linux itself) has so many different flavors and architectures that it would
be difficult to distribute binary packages for all possible platform combinations. The other reason, which is at
least as important, is that widespread source code distribution throughout the Unix community encourages
users to contribute bug fixes and new features to software, giving meaning to the term open source.
You can get nearly everything you see on a Linux system as source code—from the kernel and C library to
the web browsers. It’s even possible to update and augment your entire system by (re-)installing parts of your
system from the source code. However, you probably shouldn’t update your machine by installing everything
from source code, unless you really enjoy the process or have some other reason.
Linux distributions typically provide easier ways to update core parts of the system, such as the programs in
/bin, and one particularly important property of distributions is that they usually fix security problems very
quickly. But don’t expect your distribution to provide everything for you. Here are some reasons why you may
want to install certain packages yourself:
o To control configuration options.
o To install the software anywhere you like. You can even install several different versions of the same
package.
o To control the version that you install. Distributions don’t always stay up-to-date with the latest versions of
all packages, particularly add-ons to software packages (such as Python libraries).
o To better understand how a package works.
16.1 Software Build Systems
There are many programming environments on Linux, from traditional C to interpreted scripting languages
such as Python. Each typically has at least one distinct system for building and installing packages in addition
to the tools that a Linux distribution provides.
We’re going to look at compiling and installing C source code in this chapter with only one of these build
systems—the configuration scripts generated from the GNU autotools suite. This system is generally
considered stable, and many of the basic Linux utilities use it. Because it’s based on existing tools such as
make, after you see it in action, you’ll be able to transfer your knowledge to other build systems.
Installing a package from C source code usually involves the following steps:
1. Unpack the source code archive.
2. Configure the package.
3. Run make to build the programs.
www.EBooksWorld.ir
4. Run make install or a distribution-specific install command to install the package.
NOTE
You should understand the basics in Chapter 15 before proceeding with this chapter.
16.2 Unpacking C Source Packages
A package’s source code distribution usually comes as a .tar.gz, .tar.bz2, or .tar.xz file, and you should unpack
the file as described in 2.18 Archiving and Compressing Files. Before you unpack, though, verify the contents
of the archive with tar tvf or tar ztvf, because some packages don’t create their own subdirectories
in the directory where you extract the archive.
Output like this means that the package is probably okay to unpack:
package-1.23/Makefile.in
package-1.23/README
package-1.23/main.c
package-1.23/bar.c
--snip--
However, you may find that not all files are in a common directory (like package-1.23 in the preceding
example):
Makefile
README
main.c
--snip--
Extracting an archive like this one can leave a big mess in your current directory. To avoid that, create a new
directory and cd there before extracting the contents of the archive.
Finally, beware of packages that contain files with absolute pathnames like this:
/etc/passwd
/etc/inetd.conf
You likely won’t come across anything like this, but if you do, remove the archive from your system. It
probably contains a Trojan horse or some other malicious code.
16.2.1 Where to Start
Once you’ve extracted the contents of a source archive and have a bunch of files in front of you, try to get a
feel for the package. In particular, look for the files README and INSTALL. Always look at any README
files first because they often contain a description of the package, a small manual, installation hints, and other
useful information. Many packages also come with INSTALL files with instructions on how to compile and
install the package. Pay particular attention to special compiler options and definitions.
In addition to README and INSTALL files, you will find other package files that roughly fall into three
categories:
o Files relating to the make system, such as Makefile, Makefile.in, configure, and CMakeLists.txt. Some very
old packages come with a Makefile that you may need to modify, but most use a configuration utility such
www.EBooksWorld.ir
as GNU autoconf or CMake. They come with a script or configuration file (such as configure or
CMakeLists.txt) to help generate a Makefile from Makefile.in based on your system settings and
configuration options.
o Source code files ending in .c, .h, or .cc. C source code files may appear just about anywhere in a package
directory. C++ source code files usually have .cc, .C, or .cxx suffixes.
o Object files ending in .o or binaries. Normally, there aren’t any object files in source code distributions, but
you might find some in rare cases when the package maintainer is not permitted to release certain source
code and you need to do something special in order to use the object files. In most cases, object (or binary
executable) files in a source distribution mean that the package wasn’t put together well, and you should
run make clean to make sure that you get a fresh compile.
16.3 GNU Autoconf
Even though C source code is usually fairly portable, differences on each platform make it impossible to
compile most packages with a single Makefile. Early solutions to this problem were to provide individual
Makefiles for every operating system or to provide a Makefile that was easy to modify. This approach evolved
into scripts that generate Makefiles based on an analysis of the system used to build the package.
GNU autoconf is a popular system for automatic Makefile generation. Packages using this system come with
files named configure, Makefile.in, and config.h.in. The .in files are templates; the idea is to run the
configure script in order to discover the characteristics of your system, then make substitutions in the .in
files to create the real build files. For the end user, it’s easy; to generate a Makefile from Makefile.in, run
configure:
$ ./configure
You should get a lot of diagnostic output as the script checks your system for prerequisites. If all goes well,
configure creates one or more Makefiles and a config.h file, as well as a cache file (config.cache), so that
it doesn’t need to run certain tests again.
Now you can run make to compile the package. A successful configure step doesn’t necessarily mean that
the make step will work, but the chances are pretty good. (See 16.6 Troubleshooting Compiles and
Installations for troubleshooting failed configures and compiles.)
Let’s get some firsthand experience with the process.
NOTE
At this point, you must have all of the required build tools available on your system. For Debian
and Ubuntu, the easiest way is to install the build-essential package; in Fedora-like systems, use
the Chapter 15 groupinstall.
16.3.1 An Autoconf Example
Before discussing how you can change the behavior of autoconf, let’s look at a simple example so that you
know what to expect. You’ll install the GNU coreutils package in your own home directory (to make sure that
you don’t mess up your system). Get the package from http://ftp.gnu.org/gnu/coreutils/ (the latest version is
usually the best), unpack it, change to its directory, and configure it like this:
$ ./configure --prefix=$HOME/mycoreutils
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
--snip--
www.EBooksWorld.ir
config.status: executing po-directories commands
config.status: creating po/POTFILES
config.status: creating po/Makefile
Now run make:
$ make
GEN lib/alloca.h
GEN lib/c++defs.h
--snip--
make[2]: Leaving directory '/home/juser/coreutils-8.22/gnulib-tests'
make[1]: Leaving directory '/home/juser/coreutils-8.22'
Next, try to run one of the executables that you just created, such as ./src/ls, and try running make check to
run a series of tests on the package. (This might take a while, but it’s interesting to see.)
Finally, you’re ready to install the package. Do a dry run with make -n first to see what make install
does without actually doing the install:
$ make -n install
Browse through the output, and if nothing seems strange (such as installing anywhere other than your
mycoreutils directory), do the install for real:
$ make install
You should now have a subdirectory named mycoreutils in your home directory that contains bin, share, and
other subdirectories. Check out some of the programs in bin (you just built many of the basic tools that you
learned in Chapter 2). Finally, because you configured the mycoreutils directory to be independent of the rest
of your system, you can remove it completely without worrying about causing damage.
16.3.2 Installing Using a Packaging Tool
On most distributions, it’s possible to install new software as a package that you can maintain later with your
distribution’s packaging tools. Debian-based distributions such as Ubuntu are perhaps the easiest; rather than
running a plain make install, you can do it with the checkinstall utility, as follows:
# checkinstall make install
Use the --pkgname=name option to give your new package a specific name.
Creating an RPM package is a little more involved, because you must first create a directory tree for your
package(s). You can do this with the rpmdev-setuptree command; when complete, you can use the
rpmbuild utility to work through the rest of the steps. It’s best to follow an online tutorial for this process.
16.3.3 configure Script Options
You’ve just seen one of the most useful options for the configure script: using --prefix to specify the
installation directory. By default, the install target from an autoconf-generated Makefile uses a prefix of
/usr/local—that is, binary programs go in /usr/local/bin, libraries go in /usr/local/lib, and so on. You will often
want to change that prefix like this:
$ ./configure --prefix=new_prefix
www.EBooksWorld.ir
Most versions of configure have a --help option that lists other configuration options. Unfortunately,
the list is usually so long that it’s sometimes hard to figure out what might be important, so here are some
essential options:
o --bindir=directory Installs executables in directory.
o --sbindir=directory Installs system executables in directory.
o --libdir=directory Installs libraries in directory.
o --disable-shared Prevents the package from building shared libraries. Depending on the library, this
can save hassles later on (see 15.1.4 Shared Libraries).
o --with-package=directory Tells configure that package is in directory. This is handy
when a necessary library is in a nonstandard location. Unfortunately, not all configure scripts recognize
this type of option, and it can be difficult to determine the exact syntax.
Using Separate Build Directories
You can create separate build directories if you want to experiment with some of these options. To do so,
create a new directory anywhere on the system and, from that directory, run the configure script in the
original package source code directory. You’ll find that configure then makes a symbolic link farm in your
new build directory, where all of the links point back to the source tree in the original package directory. (Some
developers prefer that you build packages this way, because the original source tree is never modified. This is
also useful if you want to build for more than one platform or configuration option set using the same source
package.)
16.3.4 Environment Variables
You can influence configure with environment variables that the configure script puts into make
variables. The most important ones are CPPFLAGS, CFLAGS, and LDFLAGS. But be aware that configure
can be very picky about environment variables. For example, you should normally use CPPFLAGS instead of
CFLAGS for header file directories, because configure often runs the preprocessor independently of the
compiler.
In bash, the easiest way to send an environment variable to configure is by placing the variable
assignment in front of ./configure on the command line. For example, to define a DEBUG macro for the
preprocessor, use this command:
$ CPPFLAGS=-DDEBUG ./configure
NOTE
You can also pass a variable as an option to configure; for example:
$ ./configure CPPFLAGS=-DDEBUG
Environment variables are especially handy when configure doesn’t know where to look for third-party
include files and libraries. For example, to make the preprocessor search in include_dir, run this
command:
$ CPPFLAGS=-Iinclude_dir ./configure
As shown in 15.2.6 Standard Macros and Variables, to make the linker look in lib_dir, use this command:
$ LDFLAGS=-Llib_dir ./configure
If lib_dir has shared libraries (see 15.1.4 Shared Libraries), the previous command probably won’t set the
runtime dynamic linker path. In that case, use the -rpath linker option in addition to -L:
www.EBooksWorld.ir
$ LDFLAGS="-Llib_dir -Wl,-rpath=lib_dir" ./configure
Be careful when setting variables. A small slip can trip up the compiler and cause configure to fail. For
example, say you forget the - in -I, as shown here:
$ CPPFLAGS=Iinclude_dir ./configure
This yields an error like this:
configure: error: C compiler cannot create executables
See 'config.log' for more details
Digging through the config.log generated from this failed attempt yields this:
configure:5037: checking whether the C compiler works
configure:5059: gcc Iinclude_dir conftest.c >&5
gcc: error: Iinclude_dir: No such file or directory
configure:5063: $? = 1
configure:5101: result: no
16.3.5 Autoconf Targets
Once you get configure working, you’ll find that the Makefile that it generates has a number of other
useful targets in addition to the standard all and install:
o make clean As described in Chapter 15, this removes all object files, executables, and libraries.
o make distclean This is similar to make clean except that it removes all automatically generated
files, including Makefiles, config.h, config.log, and so on. The idea is that the source tree should look like a
newly unpacked distribution after running make distclean.
o make check Some packages come with a battery of tests to verify that the compiled programs work
properly; the command make check runs the tests.
o make install-strip This is like make install except that it strips the symbol table and other
debugging information from executables and libraries when installing. Stripped binaries require much less
space.
16.3.6 Autoconf Log Files
If something goes wrong during the configure process and the cause isn’t obvious, you can examine config.log
to find the problem. Unfortunately, config.log is often a gigantic file, which can make it difficult to locate the
exact source of the problem.
The general approach to finding the problem is to go to the very end of config.log (for example, by pressing
G in less) and then page back up until you see the problem. However, there is still a lot of stuff at the end
because configure dumps its entire environment there, including output variables, cache variables, and
other definitions. So rather than going to the end and paging up, go to the end and search backward for a string
such as for more details or some other part near the end of the failed configure output. (Remember
that you can initiate a reverse search in less with the ? command.) There’s a good chance that the error will
be just above what your search finds.
16.3.7 pkg-config
There are so many third-party libraries that keeping all of them in a common location can be messy. However,
www.EBooksWorld.ir
installing each with a separate prefix can lead to problems when building packages that require these third-
party libraries. For example, if you want to compile OpenSSH, you need the OpenSSL library. How do you
tell the OpenSSH configuration process the location of the OpenSSL libraries and which libraries are required?
Many libraries now use the pkg-config program not only to advertise the locations of their include files
and libraries but also to specify the exact flags that you need to compile and link a program. The syntax is as
follows:
$ pkg-config options package1 package2 ...
For example, to find the libraries required for OpenSSL, you can run this command:
$ pkg-config --libs openssl
The output should be something like this:
-lssl -lcrypto
To see all libraries that pkg-config knows about, run this command:
$ pkg-config --list-all
How pkg-config Works
If you look behind the scenes, you will find that pkg-config finds package information by reading
configuration files that end with .pc. For example, here is openssl.pc for the OpenSSL socket library, as seen
on an Ubuntu system (located in /usr/lib/i386-linux-gnu/pkgconfig):
prefix=/usr
exec_prefix=${prefix}
libdir=${exec_prefix}/lib/i386-linux-gnu
includedir=${prefix}/include
Name: OpenSSL
Description: Secure Sockets Layer and cryptography libraries and tools
Version: 1.0.1
Requires:
Libs: -L${libdir} -lssl -lcrypto
Libs.private: -ldl -lz
Cflags: -I${includedir} exec_prefix=${prefix}
You can change this file, for example, by adding -Wl,-rpath=${libdir} to the library flags to set a
runtime dynamic linker path. However, the bigger question is how pkg-config finds the .pc files in the
first place. By default, pkg-config looks in the lib/pkgconfig directory of its installation prefix. For
example, a pkg-config installed with a /usr/local prefix looks in /usr/local/lib/ pkgconfig.
Installing pkg-config Files in Nonstandard Locations
Unfortunately, by default, pkg-config does not read any .pc files outside its installation prefix. So a .pc
file that’s in a nonstandard location, such as /opt/ openssl/lib/pkgconfig/openssl.pc, will be out of the reach of
any stock pkg-config installation. There are two basic ways to make .pc files available outside of the pkg-
www.EBooksWorld.ir
config installation prefix:
o Make symbolic links (or copies) from the actual .pc files to the central pkgconfig directory.
o Set your PKG_CONFIG_PATH environment variable to include any extra pkgconfig directories. This
strategy does not work well on a system-wide basis.
16.4 Installation Practice
Knowing how to build and install software is good, but knowing when and where to install your own packages
is even more useful. Linux distributions try to cram in as much software as possible at installation, and you
should always check whether it would be best to install a package yourself instead. Here are the advantages
of doing installs on your own:
o You can customize package defaults.
o When installing a package, you often get a clearer picture of how to use the package.
o You control the release that you run.
o It’s easier to back up a custom package.
o It’s easier to distribute self-installed packages across a network (as long as the architecture is consistent and
the installation location is relatively isolated).
Here are the disadvantages:
o It takes time.
o Custom packages do not automatically upgrade themselves. Distributions keep most packages up-to-date
without requiring much work. This is a particular concern for packages that interact with the network,
because you want to ensure that you always have the latest security updates.
o If you don’t actually use the package, you’re wasting your time.
o There is a potential for misconfiguring packages.
There’s not much point in installing packages such as the ones in the coreutils package that you built earlier
in the chapter (ls, cat, and so on) unless you’re building a very custom system. On the other hand, if you
have a vital interest in network servers such as Apache, the best way to get complete control is to install the
servers yourself.
16.4.1 Where to Install
The default prefix in GNU autoconf and many other packages is /usr/local, the traditional directory for locally
installed software. Operating system upgrades ignore /usr/local, so you won’t lose anything installed there
during an operating system upgrade and for small local software installations, /usr/local is fine. The only
problem is that if you have a lot of custom software installed, this can turn into a terrible mess. Thousands of
odd little files can make their way into the /usr/local hierarchy, and you may have no idea where the files came
from.
If things really start to get unruly, you should create your own packages as described in 16.3.2 Installing Using
a Packaging Tool.
16.5 Applying a Patch
Most changes to software source code are available as branches of the developer’s online version of the source
code (such as a git repository). However, every now and then, you might get a patch that you need to apply
against source code to fix bugs or add features. You may also see the term diff used as a synonym for patch,
www.EBooksWorld.ir
because the diff program produces the patch.
The beginning of a patch looks something like this:
--- src/file.c.orig 2015-07-17 14:29:12.000000000 +0100
+++ src/file.c 2015-09-18 10:22:17.000000000 +0100
@@ -2,16 +2,12 @@
Patches usually contain alterations to more than one file. Search the patch for three dashes in a row (---) to
see the files that have alterations and always look at the beginning of a patch to determine the required working
directory. Notice that the preceding example refers to src/file.c. Therefore, you should change to the directory
that contains src before applying the patch, not to the src directory itself.
To apply the patch, run the patch command:
$ patch -p0 < patch_file
If everything goes well, patch exits without a fuss, leaving you with an updated set of files. However, patch
may ask you this question:
File to patch:
This usually means that you are not in the correct directory, but it could also indicate that your source code
does not match the source code in the patch. In this case, you’re probably out of luck: Even if you could
identify some of the files to patch, others would not be properly updated, leaving you with source code that
you could not compile.
In some cases, you might come across a patch that refers to a package version like this:
--- package-3.42/src/file.c.orig 2015-07-17 14:29:12.000000000 +0100
+++ package-3.42/src/file.c 2015-09-18 10:22:17.000000000 +0100
If you have a slightly different version number (or you just renamed the directory), you can tell patch to
strip leading path components. For example, say you were in the directory that contains src (as before). To tell
patch to ignore the package-3.42/ part of the path (that is, strip one leading path component), use -p1:
$ patch -p1 < patch_file
16.6 Troubleshooting Compiles and Installations
If you understand the difference between compiler errors, compiler warnings, linker errors, and shared library
problems as described in Chapter 15, you shouldn’t have too much trouble fixing many of the glitches that
arise when building software. This section covers some common problems. Although you’re unlikely to run
into any of these when building using autoconf, it never hurts to know what these kinds of problems look like.
Before covering specifics, make sure that you can read certain kinds of make output. It’s important to know
the difference between an error and an ignored error. The following is a real error that you need to investigate:
make: *** [target] Error 1
However, some Makefiles suspect that an error condition might occur but know that these errors are harmless.
You can usually disregard any messages like this:
make: *** [target] Error 1 (ignored)
Furthermore, GNU make often calls itself many times in large packages, with each instance of make in the
error message marked with [N], where N is a number. You can often quickly find the error by looking at the
www.EBooksWorld.ir
make error that comes directly after the compiler error message. For example:
[compiler error message involving file.c]
make[3]: *** [file.o] Error 1
make[3]: Leaving directory '/home/src/package-5.0/src'
make[2]: *** [all] Error 2
make[2]: Leaving directory '/home/src/package-5.0/src'
make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory
'/home/src/package-5.0/'
make: *** [all] Error 2
The first three lines practically give it away: The trouble centers around file.c located in /home/src/package-
5.0/src. Unfortunately, there is so much extra output that it can be difficult to spot the important details.
Learning how to filter out the subsequent make errors goes a long way toward digging out the real cause.
16.6.1 Specific Errors
Here are some common build errors that you might encounter.
Problem
Compiler error message:
src.c:22: conflicting types for 'item'
/usr/include/file.h:47: previous declaration of 'item'
Explanation and Fix
The programmer made an erroneous redeclaration of item on line 22 of src.c. You can usually fix this by
removing the offending line (with a comment, an #ifdef, or whatever works).
Problem
Compiler error message:
src.c:37: 'time_t' undeclared (first use this function)
--snip--
src.c:37: parse error before '...'
Explanation and Fix
The programmer forgot a critical header file. The manual pages are the best way to find the missing header
file. First, look at the offending line (in this case, line 37 in src.c). It’s probably a variable declaration like the
following:
time_t v1;
Search forward for v1 in the program for its use around a function call. For example:
v1 = time(NULL);
Now run man 2 time or man 3 time to look for system and library calls named time(). In this case,
the section 2 manual page has what you need:
SYNOPSIS
www.EBooksWorld.ir
#include <time.h>
time_t time(time_t *t);
This means that time() requires time.h. Place #include <time.h> at the beginning of src.c and try
again.
Problem
Compiler (preprocessor) error message:
src.c:4: pkg.h: No such file or directory
(long list of errors follows)
Explanation and Fix
The compiler ran the C preprocessor on src.c but could not find the pkg.h include file. The source code likely
depends on a library that you need to install, or you may just need to provide the compiler with the nonstandard
include path. Usually, you will just need to add a -I include path option to the C preprocessor flags
(CPPFLAGS). (Keep in mind that you might also need a -L linker flag to go along with the include files.)
If it doesn’t look as though you’re missing a library, there’s an outside chance that you’re attempting a compile
for an operating system that this source code does not support. Check the Makefile and README files for
details about platforms.
If you’re running a Debian-based distribution, try the apt-file command on the header filename:
$ apt-file search pkg.h
This might find the development package that you need. For distributions that provide yum, you can try this
instead:
$ yum provides */pkg.h
Problem
make error message:
make: prog: Command not found
Explanation and Fix
To build the package, you need prog on your system. If prog is something like cc, gcc, or ld, you don’t
have the development utilities installed on your system. On the other hand, if you think prog is already
installed on your system, try altering the Makefile to specify the full pathname of prog.
In rare cases, make builds prog and then uses prog immediately, assuming that the current directory (.) is
in your command path. If your $PATH does not include the current directory, you can edit the Makefile and
change prog to ./prog. Alternatively, you could append . to your path temporarily.
16.7 Looking Forward
We’ve only touched on the basics of building software. Here are some more topics that you can explore after
you get the hang of your own builds:
o Understanding how to use build systems other than autoconf, such as CMake and SCons.
www.EBooksWorld.ir
o Setting up builds for your own software. If you’re writing your own software, you want to choose a build
system and learn to use it. For GNU autoconf packaging, Autotools by John Calcote (No Starch Press,
2010) can help you out.
o Compiling the Linux kernel. The kernel’s build system is completely different from that of other tools. It
has its own configuration system tailored to customizing your own kernel and modules. The procedure is
straightforward, though, and if you understand how the boot loader works, you won’t have any trouble with
it. However, you should be careful when doing so; make sure that you always keep your old kernel handy in
case you can’t boot with a new one.
o Distribution-specific source packages. Linux distributions maintain their own versions of software source
code as special source packages. Sometimes you can find useful patches that expand functionality or fix
problems in otherwise unmaintained packages. The source package management systems include tools for
automatic builds, such as Debian’s debuild and the RPM-based mock.
Building software is often a stepping-stone to learning about programming and software development. The
tools you’ve seen in the past two chapters take the mystery out of where your system software came from. It’s
not difficult to take the next steps of looking inside the source code, making changes, and creating your own
software.
www.EBooksWorld.ir
Chapter 17. Building on the Basics
The chapters in this book have covered the fundamental components of a Linux system, from low-level kernel
and process organization, to networking, to some of the tools used to build software. With all of that behind
you, what can you do now? Quite a lot, as it turns out! Because Linux supports nearly every kind of non-
proprietary programming environment, it’s only natural that a plethora of applications is available. Let’s look
at a few application areas where Linux excels and see how what you’ve learned in this book relates.
17.1 Web Servers and Applications
Linux is a popular operating system for web servers, and the reigning monarch of Linux application servers
is the Apache HTTP Server (usually referred to as just “Apache”). Another web server that you’ll often hear
about is Tomcat (also an Apache project), which provides support for Java-based applications.
By themselves, web servers don’t do much—they can serve files, but that’s about it. The end goal of most web
servers such as Apache is to provide an underlying platform to serve web applications. For example, Wikipedia
is built on the MediaWiki package, which you can use to set up your own wiki. Content management systems
like Wordpress and Drupal let you build your own blogs and media sites. All of these applications are built on
programming languages that run especially well on Linux. For example, MediaWiki, Wordpress, and Drupal
are all written in PHP.
The building blocks that make up web applications are highly modular, so it’s easy to add your own extensions
and create applications with frameworks such as Django, Flask, and Rails, which offer facilities for common
web infrastructure and features, such as templates, multiple users, and database support.
A well-functioning web server depends on a solid operating system foundation. In particular, the material in
Chapter 8 through Chapter 10 is particularly important. Your network configuration must be flawless, but
perhaps more importantly, you must understand resource management. Adequately-sized, efficient memory
and disk are critical, especially if you plan to use a database in your application.
17.2 Databases
Databases are specialized services for storing and retrieving data, and many different database servers and
systems run on Linux. Two primary features of databases make them attractive: They offer easy, uniform ways
to manage individual pieces and groups of data, and superior access performance.
Databases make it easier for applications to examine and alter data, especially when compared with parsing
and changing text files. For example, the /etc/passwd and /etc/shadow files on a Linux system can become
difficult to maintain over a network of machines. Instead, you can set up a database that offers user information
LDAP (Lightweight Directory Access Protocol) to feed this information into the Linux authentication system.
The configuration on the Linux client side is easy; all you need to do is edit the /etc/ nsswitch.conf file and
add a little extra configuration.
www.EBooksWorld.ir
The primary reason that databases generally offer superior performance when retrieving data is that they use
indexing to keep track of data locations. For example, say you have a set of data representing a directory
containing first and last names and telephone numbers. You can use a database to place an index on any of
these attributes, like the last name. Then, when looking up a person by last name, the database simply consults
the index for the last name rather than searching the entire directory.
17.2.1 Types of Databases
Databases come in two basic forms: relational and non-relational. Relational databases (also called Relational
Database Management Systems, or RDBMS), such as MySQL, PostgreSQL, Oracle, and MariaDB, are
general-purpose databases that excel in tying different sets of data together. For example, say you have two
sets of data, one with postal (ZIP) codes and names, and another with the postal codes and their corresponding
states. A relational database would allow you to very quickly retrieve all of the names located in a particular
state. You normally talk to relational databases using a programming language called SQL (Structured Query
Language).
Non-relational databases, sometimes known as NoSQL databases, tend to solve particular problems that
relational databases don’t easily handle. For example, document-store databases, such as MongoDB, attempt
to make storing and indexing entire documents easier. Key-value databases, such as redis, tend to focus on
performance. NoSQL databases don’t have a common query language like SQL for access. Instead, you’ll talk
to them using a variety of interfaces and commands.
The disk and memory performance issues discussed in Chapter 8 are extremely important in most database
implementations because there’s a trade-off between how much you can store in RAM (which is fast) versus
on disk. Most larger database systems also involve significant networking because they’re distributed over
many servers. The most common such network setup is called replication, where one database is basically
copied to a number of database servers to increase the number of clients that connect to the servers.
17.3 Virtualization
In most large organizations, it’s inefficient to dedicate hardware to specific server tasks because installing an
operating system tailored to one task on one server means that you’re limited to that task until you reinstall it.
Virtual machine technology makes it possible to simultaneously install one or more operating systems (often
called guests) on a single piece of hardware, and then activate and deactivate the systems at will. You can even
move and copy the virtual machines to other machines.
There are many virtualization systems for Linux, such as the kernel’s KVM (kernel virtual machine) and Xen.
Virtual machines are especially handy for web servers and database servers. Although it’s possible to set up a
single Apache server to serve several websites, this comes at a cost of flexibility and maintainability. If those
sites are all run by different users, you have to manage the servers and the users together. Instead, it’s usually
preferable to set up virtual machines on one physical server with their own supporting users, so that they don’t
interfere with each other and you can alter and move them at will.
The software that operates virtual machines is called a hypervisor. The hypervisor manipulates many pieces
of the lower levels of a Linux system that you’ve seen in this book with the result that, if you install a Linux
guest on a virtual machine, it should behave just like any other installed Linux system.
17.4 Distributed and On-Demand Computing
To ease local resource management, you can build sophisticated tools on top of virtual machine technology.
The term cloud computing is a catch-all term that’s often used as label for this area. More specifically,
infrastructure as a service (IaaS ) refers to systems that allow you to provision and control basic computing
resources such as CPU, memory, storage, and networking on a remote server. The OpenStack project is one
www.EBooksWorld.ir
such API and platform that includes IaaS.
Moving up past the raw infrastructure, you can also provision platform resources such as the operating system,
database servers, and web servers. Systems that offer resources on this level are said to be platform as a service
(PaaS).
Linux is central to many of these computing services, as it’s often the underlying operating system behind all
of it. Nearly all of the elements that you’ve seen in this book, starting with the kernel, are reflected throughout
these systems.
17.5 Embedded Systems
An embedded system is anything designed to serve a specific purpose, such as a music player, video streamer,
or thermostat. Compare this to a desktop or server system that can handle many different kinds of tasks (but
may not do one specific thing very well).
You can think of embedded systems as almost the opposite of distributed computing; rather than expanding
the scale of the operating system, an embedded system usually (but not always) shrinks it, often into a small
device. Android is perhaps the most widespread embedded version of Linux in use today.
Embedded systems often combine specialized hardware with software. For example, you can set up a PC to
do anything a wireless router can by adding enough network hardware and correctly configuring a Linux
installation. But it’s usually preferable to buy a smaller, dedicated device consisting of the necessary hardware
and eliminate any hardware that isn’t necessary. For example, a router needs more network ports than most
desktops but doesn’t need video or sound hardware. And once you have custom hardware, you must tailor the
system’s software, such as the operating system internals and user interface. OpenWRT, mentioned in
Chapter 9, is one such customized Linux distribution.
Interest in embedded systems is increasing as more capable small hardware is introduced, particularly system-
on-a-chip (SoC) designs that can cram a processor, memory, and peripheral interfaces into a small space. For
example, the Raspberry Pi and BeagleBone single-board computers are based around such a design, with
several Linux variants to choose from as an operating system. These devices have easily accessible output and
sensor input that connects to language interfaces such as Python, making them popular for prototyping and
small gadgets.
Embedded versions of Linux vary in how many features from the server/ desktop version can be carried over.
Small, very limited devices must strip out everything except the bare minimum because of lack of space,
which often means that even the shell and core utilities come in the form of a single BusyBox executable.
These systems tend to exhibit the most differences between a full-featured Linux installation, and you’ll often
see older software on them, such as System V init.
You’ll normally develop software for embedded devices using a regular desktop machine. More powerful
devices, such as the Raspberry Pi, have the luxury of more storage and the power to run newer and more
complete software, so you can even natively run many development tools on them.
Regardless of the differences, though, embedded devices still share the Linux genes described in this book:
You’ll see a kernel, a bunch of devices, network interfaces, and an init alongside a bunch of user processes.
Embedded kernels tend to be close (or identical) to regular kernel releases, simply with many features disabled.
As you work your way up through user space, though, the differences become more pronounced.
17.6 Final Remarks
Whatever your goals for gaining a better understanding of Linux systems, I hope that you’ve found this book
to be helpful. My goal has been to instill you with confidence when you need to get inside your system to
www.EBooksWorld.ir
make changes or do something new. At this point, you should feel like you’re really in control of your system.
Now go and push it around a little and have some fun.
www.EBooksWorld.ir
Appendix A. Bibliography
Abrahams, Paul W., and Bruce Larson, UNIX for the Impatient, 2nd ed. Boston: Addison-Wesley Professional,
1995.
Aho, Alfred V., Brian W. Kernighan, and Peter J. Weinberger, The AWK Programming Language. Boston:
Addison-Wesley, 1988.
Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman, Compilers: Principles, Techniques, and
Tools, 2nd ed. Boston: Addison-Wesley, 2006.
Barrett, Daniel J., Richard E. Silverman, and Robert G. Byrnes, SSH, The Secure Shell: The Definitive Guide,
2nd ed. Sebastopol: O’Reilly, 2005.
Beazley, David M., Python Essential Reference, 4th ed. Boston: Addison-Wesley, 2009.
Beazley, David M., Brian D. Ward, and Ian R. Cooke, “The Inside Story on Shared Libraries and Dynamic
Loading.” Computing in Science & Engineering 3, no. 5 (September/October 2001): 90-97.
Calcote, John, Autotools: A Practitioner’s Guide to GNU Autoconf, Automake, and Libtool. San Francisco:
No Starch Press, 2010.
Carter, Gerald, Jay Ts, and Robert Eckstein, Using Samba: A File and Print Server for Linux, Unix & Mac OS
X, 3rd ed. Sebastopol: O’Reilly, 2007.
Christiansen, Tom, brian d foy, Larry Wall, and Jon Orwant, Programming Perl: Unmatched Power for
Processing and Scripting, 4th ed. Sebastopol: O’Reilly, 2012.
Chromatic, Modern Perl, rev. ed. Hillsboro: Onyx Neon Press, 2014.
Davies, Joshua, Implementing SSL/TLS Using Cryptography and PKI. Hoboken: Wiley, 2011.
Filesystem Hierarchy Standard Group, “Filesystem Hierarchy Standard, Version 2.3,” edited by Rusty Russell,
Daniel Quinlan, and Christopher Yeoh, 2004, http://www.pathname.com/fhs/.
Friedl, Jeffrey E. F., Mastering Regular Expressions: Understand Your Data and Be More Productive, 3rd ed.
Sebastopol: O’Reilly, 2006.
Gregg, Brendan, Systems Performance: Enterprise and the Cloud. Upper Saddle River: Prentice Hall, 2013.
Grune, Dick, Kees van Reeuwijk, Henri E. Bal, Ceriel J.H. Jacobs, and Koen Langendoen, Modern Compiler
Design, 2nd ed. New York: Springer, 2012.
Hopcroft, John E., Rajeev Motwani, and Jeffrey D. Ullman, Introduction to Automata Theory, Languages and
Computation, 3rd ed. Upper Saddle River: Prentice Hall, 2006.
Kernighan, Brian W., and Rob Pike, The UNIX Programming Environment. Upper Saddle River: Prentice Hall,
1983.
Kernighan, Brian W., and Dennis M. Ritchie, The C Programming Language, 2nd ed. Upper Saddle River:
Prentice Hall, 1988.
Kochan, Stephen G., and Patrick Wood, Unix Shell Programming, 3rd ed. Indianapolis: SAMS Publishing,
2003.
Levine, John R., Linkers and Loaders. San Francisco: Morgan Kaufmann, 1999.
Liu, Cricket, and Paul Albitz, DNS and BIND, 5th ed. Sebastopol: O’Reilly, 2006.
Lucas, Michael W., SSH Mastery: OpenSSH, PuTTY, Tunnels and Keys. Tilted Windmill Press, 2012.
Matloff, Norman, The Art of R Programming: A Tour of Statistical Software Design. San Francisco: No Starch
www.EBooksWorld.ir
Press, 2011.
Matloff, Norman, and Peter Jay Salzman, The Art of Debugging with GDB, DDD, and Eclipse. San Francisco:
No Starch Press, 2008.
Mecklenburg, Robert, Managing Projects with GNU Make: The Power of GNU Make for Building Anything,
3rd ed. Sebastopol: O’Reilly, 2004.
The New Hacker’s Dictionary, 3rd ed. Edited by Eric S. Raymond. Cambridge: MIT Press, 1996.
Peek, Jerry, Grace Todino-Gonguet, and John Strang, Learning The UNIX Operating System: A Concise Guide
for the New User, 5th ed. Sebastopol: O’Reilly, 2001.
Pike, Rob, Dave Presotto, Sean Dorward, Bob Flandrena, Ken Thompson, Howard Trickey, and Phil
Winterbottom, “Plan 9 from Bell Labs.” Bell Labs. Accessed July 10, 2014, http://plan9.bell-
labs.com/sys/doc/9.html.
Robbins, Arnold, sed & awk Pocket Reference: Text Processing with Regular Expressions, 2nd ed. Sebastopol:
O’Reilly, 2002.
Robbins, Arnold, Elbert Hannah, and Linda Lamb, Learning the vi and Vim Editors: Unix Text Processing,
7th ed. Sebastopol: O’Reilly, 2008.
Salus, Peter H., The Daemon, the Gnu, and the Penguin. Reed Media Services, 2008.
Samar, V., and R. Schemers, “Unified Login with Pluggable Authentication Modules (PAM),” October 1995,
Open Software Foundation (RFC 86.0), http://www.opengroup.org/rfc/mirror-rfc/rfc86.0.txt.
Schneier, Bruce, Applied Cryptography: Protocols, Algorithms, and Source Code in C, 2nd ed. Hoboken:
Wiley, 1996.
Shotts, William E. Jr., The Linux Command Line: A Complete Introduction. San Francisco: No Starch Press,
2012
Schwartz, Randal L., brian d foy, and Tom Phoenix, Learning Perl: Making Easy Things Easy and Hard
Things Possible, 6th ed. Sebastopol: O’Reilly, 2011.
Silberschatz, Abraham, Peter B. Galvin, and Greg Gagne, Operating System Concepts, 9th ed. Hoboken: Wiley,
2012.
Stallman, Richard M., GNU Emacs Manual, 17th ed. Boston: Free Software Foundation, 2012.
http://www.gnu.org/software/emacs/manual/.
Stallman, Richard M., Roland Pesch, Stan Shebs, Etienne Suvasa, and Matt Lee, Debugging with GDB: The
GNU Source-Level Debugger, 10th ed. Boston: GNU Press, 2011.
http://sourceware.org/gdb/current/onlinedocs/gdb/.
Stevens, W. Richard, UNIX Network Programming, Volume 2: Interprocess Communications, 2nd ed. Upper
Saddle River: Prentice Hall, 1998.
Stevens, W. Richard, Bill Fenner, and Andrew M. Rudoff, Unix Network Programming, Volume 1: The Sockets
Networking API, 3rd ed. Boston: Addison-Wesley Professional, 2003.
Tanenbaum, Andrew S., and Herbert Bos, Modern Operating Systems, 4th ed. Upper Saddle River: Prentice
Hall, 2014.
Tanenbaum, Andrew S., and David J. Wetherall, Computer Networks, 5th ed. Upper Saddle River: Prentice
Hall, 2010.
www.EBooksWorld.ir
Index
A NOTE ON THE DIGITAL INDEX
A link in an index entry is displayed as the section title in which that entry appears.
Because some sections have multiple index markers, it is not unusual for an entry to have
several links to the same section. Clicking on any link will take you directly to the place in
the text in which the marker appears.
Symbols
<, 2.14.1 Standard Error
<<, 11.8 Temporary File Management
>, 2.13 Getting Online Help
>>, 2.13 Getting Online Help
[, 11.4 Exit Codes
$, A Hands-On Approach, Basic Commands and Directory Hierarchy, 2.8 Environment and Shell
Variables, Adding Dot (.) to the Path
$#, 11.3.1 Individual Arguments: $1, $2, ...
$$, 11.3.3 All Arguments: $@
$0, 11.3.3 All Arguments: $@
$1, 11.3.1 Individual Arguments: $1, $2, ...
$?, 11.3.3 All Arguments: $@
(see also exit code)
$@, 11.3.1 Individual Arguments: $1, $2, ...
#, A Hands-On Approach
#, 2.2.1 The Shell Window
(see also root)
#!, Introduction to Shell Scripts, 15.4 Lex and Yacc
|, 2.5.1 grep, 2.13 Getting Online Help, 2.18.4 zcat
/, 2.19 Linux Directory Hierarchy Essentials, How the Linux Kernel Boots, 5.1 Startup
Messages, 5.5 GRUB Introduction
*, 2.4.1 cd, 2.5.7 head and tail
*, 11.2 Quoting and Literals
(see also regular expressions)
A
abstraction, The Big Picture
administrator, 1.4 User Space (see root)
www.EBooksWorld.ir
alias, Adding Dot (.) to the Path
ALSA, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
Apache, 17.1 Web Servers and Applications
Apple partition, 4.2 Filesystems
application layer, 9.1.1 Packets, Network Applications and Services
archive, 2.18 Archiving and Compressing Files, Table-of-Contents Mode, Table-of-Contents Mode,
Introduction to Compiling Software From C Source Code
table of contents, Table-of-Contents Mode
testing, Table-of-Contents Mode, Introduction to Compiling Software From C Source Code
ARP, 9.22 Ethernet, IP, and ARP
at, 7.6.2 System Crontab Files
ATA, 3.6.1 USB Storage and SCSI
autoconf, 16.2.1 Where to Start
autotools, GNU, Introduction to Compiling Software From C Source Code
autotools, 16.6.1 Specific Errors
(see also autoconf)
Avahi, 9.12.3 Caching and Zero-Configuration DNS, 10.5.1 lsof
awk, 11.10.1 basename
B
basename, 11.8 Temporary File Management
bash, Basic Commands and Directory Hierarchy, 13.4.1 The bash Shell
(see also Bourne Shell)
startup file, 13.4.1 The bash Shell
bg, 2.16.2 Killing Processes
/bin, 2.19 Linux Directory Hierarchy Essentials
/bin/bash, Basic Commands and Directory Hierarchy (see bash)
/bin/sh, Basic Commands and Directory Hierarchy (see Bourne Shell)
BIOS, 5.4 Boot Loaders, 5.8.1 MBR Boot
boot partition, 5.8.1 MBR Boot
bison, 15.4 Lex and Yacc
blkid, 4.2.3 Mounting a Filesystem
block bitmap, 4.5.1 Viewing Inode Details
blockdev, 4.1.2 Changing Partition Tables
block device, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and
More, 3.6 In-Depth: SCSI and the Linux Kernel, 3.6.3 Generic SCSI Devices, Disks and
www.EBooksWorld.ir
Filesystems, 4.1.2 Changing Partition Tables
/boot, 2.19 Linux Directory Hierarchy Essentials, File Navigation
boot, How the Linux Kernel Boots, How the Linux Kernel Boots, How the Linux Kernel
Boots, 5.4 Boot Loaders, 5.4 Boot Loaders, Listing Devices, File Navigation, Installing
GRUB on an External Storage Device, Installing GRUB on an External Storage Device, 5.7
Chainloading Other Operating Systems, 5.7 Chainloading Other Operating Systems, 9.9
Boot-Activated Network Configuration
(see also init)
loader, How the Linux Kernel Boots, 5.4 Boot Loaders, 5.4 Boot Loaders, Listing Devices,
File Navigation, Installing GRUB on an External Storage Device, Installing GRUB on an
External Storage Device, 5.7 Chainloading Other Operating Systems, 5.7 Chainloading
Other Operating Systems
chainloading, Installing GRUB on an External Storage Device
filesystem access, 5.4 Boot Loaders, Listing Devices
GRUB, File Navigation
internals, 5.7 Chainloading Other Operating Systems
multi-stage, 5.7 Chainloading Other Operating Systems
for systems other than Linux, Installing GRUB on an External Storage Device
messages, How the Linux Kernel Boots
network configuration, 9.9 Boot-Activated Network Configuration
Bourne Shell, Basic Commands and Directory Hierarchy, Basic Commands and
Directory Hierarchy, Basic Commands and Directory Hierarchy, Basic Commands and
Directory Hierarchy
basic use, Basic Commands and Directory Hierarchy
Bourne-again, Basic Commands and Directory Hierarchy
script, Basic Commands and Directory Hierarchy (see shell script)
building software, Introduction to Compiling Software From C Source Code, 16.6
Troubleshooting Compiles and Installations
bunzip2, 2.18.4 zcat
bus error, Not a directory, Is a directory
BusyBox, 17.5 Embedded Systems
bzip2, 2.18.4 zcat
C
C, 15.1 The C Compiler, Fixing Include File Problems, 15.2.3 Final Program Build, 15.2.5
Command-Line Arguments and Options, 16.3.4 Environment Variables, 16.6 Troubleshooting
www.EBooksWorld.ir
Compiles and Installations, 16.6.1 Specific Errors
compiler, 15.2.3 Final Program Build, 16.6 Troubleshooting Compiles and Installations
preprocessor, Fixing Include File Problems, 15.2.5 Command-Line Arguments and Options,
16.3.4 Environment Variables, 16.6.1 Specific Errors
case, 11.5.6 Matching Strings with case
cat, 2.2.1 The Shell Window
cd, 2.3.5 rm
chainloading, Installing GRUB on an External Storage Device
character device, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and
More
child process, 8.3.1 strace
Chrome OS, 14.6.1 CUPS
chsh, Basic Commands and Directory Hierarchy, 2.5.7 head and tail, 7.10 PAM
chvt, Display Modes and Virtual Consoles, 14.2 A Closer Look at the X Window System
CIDR, 9.3.3 Common Subnet Masks and CIDR Notation
clang, 15.1 The C Compiler
CLASSPATH, 15.5.3 Other Scripting Languages
clobber, 2.13 Getting Online Help
cloud computing, 17.3 Virtualization
CMake, 16.2 Unpacking C Source Packages, 16.6.1 Specific Errors
command-line editing, 2.10 Special Characters
command substitution, 11.6.2 while Loops
compiling, 15.1 The C Compiler
compositing window manager, xset
compressing files, 2.18 Archiving and Compressing Files, 12.2.5 Transfer Integrity, Safeguards,
and Verbose Modes
concatenating files, 2.2.1 The Shell Window
configuration file, 2.19 Linux Directory Hierarchy Essentials, System Configuration: Logging,
System Time, Batch Jobs, and Users
configure, 16.2.1 Where to Start
context switch, 1.3 The Kernel
control group, 6.4.5 Adding Units to systemd
controlling terminal, 3.4.1 Hard Disks: /dev/sd*
coreboot, 5.4.1 Boot Loader Tasks
coreutils, 16.2.1 Where to Start, Installing pkg-config Files in Nonstandard Locations
www.EBooksWorld.ir
cp, 2.3.1 ls
cpio, 6.8 The Initial RAM Filesystem
cpp, Fixing Include File Problems, 15.2.5 Command-Line Arguments and Options, 16.3.4
Environment Variables, 16.6.1 Specific Errors
CPU, The Big Picture, 1.3.1 Process Management, A Closer Look at Processes and Resource
Utilization, 8.3.2 ltrace, 8.4.2 Viewing Threads, Major Page Faults
multiple, 1.3.1 Process Management, 8.3.2 ltrace
time, A Closer Look at Processes and Resource Utilization, 8.4.2 Viewing Threads, Major
Page Faults
CPU time, 2.16.2 Killing Processes
cron, 7.5.2 Network Time
csh, Checking for Login and Interactive Shells
CTRL-C, 2.2.3 Standard Input and Standard Output
CTRL-D, 2.2.1 The Shell Window
CUPS, 14.5.2 Monitoring D-Bus Messages
curl, Network Applications and Services
current working directory, 2.3.5 rm, 2.5.1 grep, 8.1 Tracking Processes
cylinder, 4.1.3 Disk and Partition Geometry
D
daemon, System Configuration: Logging, System Time, Batch Jobs, and Users
database, 17.1 Web Servers and Applications
date, 7.3.5 Working with Groups
D-Bus (Desktop Bus), 3.5.4 Monitoring Devices, 6.4.6 systemd Process Tracking and
Synchronization, 9.10 Problems with Manual and Boot-Activated Network Configuration, 14.1.1
Window Managers, xset, 14.5 D-Bus, 14.5 D-Bus
instance, 14.5 D-Bus
monitoring, 14.5 D-Bus
dd, 3.2 The sysfs Device Path, 4.2.11 Checking and Repairing Filesystems
debugfs, The Worst Case
debugger, 15.2.8 Organizing a Makefile
default gateway, 9.4 Routes and the Kernel Routing Table, 9.8 Introduction to Network
Interface Configuration
demand paging, 8.9.1 How Memory Works
desktop, A Brief Survey of the Linux Desktop, 14.1.1 Window Managers, Input Devices
(General)
www.EBooksWorld.ir
background, Input Devices (General)
environment, 14.1.1 Window Managers
Desktop Bus, 3.5.4 Monitoring Devices (see D–Bus)
/dev, 2.19 Linux Directory Hierarchy Essentials, 3.1 Device Files
device, 1.2 Hardware: Understanding Main Memory, 1.3.3 Device Drivers and Management,
2.19 Linux Directory Hierarchy Essentials, 2.19 Linux Directory Hierarchy Essentials,
Devices, 3.1 Device Files, 3.1 Device Files, 3.1 Device Files, 3.1 Device Files, 3.1 Device Files,
3.1 Device Files, 3.1 Device Files, 3.1 Device Files, 3.1 Device Files, 3.1 Device Files, 3.1
Device Files, 3.1 Device Files, 3.2 The sysfs Device Path, 3.2 The sysfs Device Path, 3.4 Device
Name Summary, 3.4.1 Hard Disks: /dev/sd*, 3.4.1 Hard Disks: /dev/sd*, Display Modes and
Virtual Consoles, Display Modes and Virtual Consoles, 3.4.7 Audio Devices: /dev/snd/*,
/dev/dsp, /dev/audio, and More, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and
More, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More, 3.4.7 Audio Devices:
/dev/snd/*, /dev/dsp, /dev/audio, and More, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp,
/dev/audio, and More, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More, 3.4.7
Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More, 3.4.7 Audio Devices: /dev/snd/*,
/dev/dsp, /dev/audio, and More, 3.5.2 udevd Operation and Configuration, 3.5.2 udevd
Operation and Configuration, 3.6 In-Depth: SCSI and the Linux Kernel, 3.6.3 Generic SCSI
Devices, 3.6.3 Generic SCSI Devices, Disks and Filesystems, 4.1.2 Changing Partition Tables,
4.2 Filesystems, 4.2.8 The /etc/fstab Filesystem Table, 4.2.8 The /etc/fstab Filesystem Table,
How the Linux Kernel Boots, 10.9 Sockets: How Processes Communicate with the Network
audio, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
block, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More, 3.6
In-Depth: SCSI and the Linux Kernel, 3.6.3 Generic SCSI Devices, Disks and Filesystems,
4.1.2 Changing Partition Tables
character, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
copy, 3.2 The sysfs Device Path
creating file, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
disk, 3.1 Device Files
driver, 1.2 Hardware: Understanding Main Memory, 1.3.3 Device Drivers and Management,
How the Linux Kernel Boots
file, 2.19 Linux Directory Hierarchy Essentials, 3.1 Device Files, 3.4.7 Audio Devices:
/dev/snd/*, /dev/dsp, /dev/audio, and More, 4.2.8 The /etc/fstab Filesystem Table
finding, 3.2 The sysfs Device Path
information, 3.1 Device Files, 3.5.2 udevd Operation and Configuration
www.EBooksWorld.ir
initialization, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
major and minor numbers, 3.1 Device Files
monitor, 3.5.2 udevd Operation and Configuration
name, 3.1 Device Files
network, 3.1 Device Files
node, 2.19 Linux Directory Hierarchy Essentials, 3.1 Device Files, 3.4.7 Audio Devices:
/dev/snd/*, /dev/dsp, /dev/audio, and More, 4.2.8 The /etc/fstab Filesystem Table
optical, 3.4.1 Hard Disks: /dev/sd*, 3.6.3 Generic SCSI Devices, 4.2 Filesystems
parallel, Display Modes and Virtual Consoles
pipe, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
SCSI, 3.4 Device Name Summary (see SCSI)
serial, Display Modes and Virtual Consoles
socket, 3.1 Device Files, 10.9 Sockets: How Processes Communicate with the Network
terminal, 3.4.1 Hard Disks: /dev/sd*
types, 3.1 Device Files
/dev/hd*, 3.4.1 Hard Disks: /dev/sd*
/dev/lp*, Display Modes and Virtual Consoles
/dev/null, 3.1 Device Files
/dev/parport*, Display Modes and Virtual Consoles
/dev/pts, 3.4.1 Hard Disks: /dev/sd*
/dev/sd*, 3.4 Device Name Summary
/dev/sg*, 3.4.1 Hard Disks: /dev/sd*, 3.6.3 Generic SCSI Devices
/dev/snd, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
/dev/sr*, 3.4.1 Hard Disks: /dev/sd*, 3.6.3 Generic SCSI Devices
devtmpfs, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
/dev/tty*, 3.4.1 Hard Disks: /dev/sd*
/dev/zero, 3.2 The sysfs Device Path
df, 4.2.9 Alternatives to /etc/fstab
DHCP, 9.15 Revisiting a Simple Local Network
diff, 2.5.3 pwd, 11.4 Exit Codes, 16.5 Applying a Patch
directory, 2.2.3 Standard Input and Standard Output, 2.3.5 rm, 2.3.5 rm, 2.3.5 rm, 2.3.5
rm, 2.3.5 rm, 2.4.1 cd, 2.4.1 cd, 2.4.1 cd, 2.5.1 grep, Not a directory, Is a directory, 2.16.4
Background Processes, 2.17.1 Modifying Permissions, 2.19 Linux Directory Hierarchy
Essentials, 2.19 Linux Directory Hierarchy Essentials, 2.19 Linux Directory Hierarchy
Essentials, 4.5 Inside a Traditional Filesystem, 4.5 Inside a Traditional Filesystem, How
www.EBooksWorld.ir
the Linux Kernel Boots, 5.1 Startup Messages, 5.5 GRUB Introduction, 7.3.1 The
/etc/passwd File, 8.1 Tracking Processes
change, 2.3.5 rm
create, 2.4.1 cd
current, 2.3.5 rm, 2.5.1 grep, 8.1 Tracking Processes
errors, Not a directory, Is a directory
hierarchy, 2.3.5 rm, 2.19 Linux Directory Hierarchy Essentials
home, 2.4.1 cd, 2.19 Linux Directory Hierarchy Essentials, 7.3.1 The /etc/passwd File
internal structure, 4.5 Inside a Traditional Filesystem
listing contents, 2.2.3 Standard Input and Standard Output
parent, 2.3.5 rm, 4.5 Inside a Traditional Filesystem
permissions, 2.17.1 Modifying Permissions
remove, 2.4.1 cd
root, 2.19 Linux Directory Hierarchy Essentials, How the Linux Kernel Boots, 5.1 Startup
Messages, 5.5 GRUB Introduction
disk, 3.1 Device Files, 3.2 The sysfs Device Path, 3.2 The sysfs Device Path, 3.4 Device
Name Summary, 3.4 Device Name Summary, 3.4 Device Name Summary, 3.4 Device
Name Summary, 3.4.1 Hard Disks: /dev/sd*, 3.5.2 udevd Operation and
Configuration, 3.6 In-Depth: SCSI and the Linux Kernel, 3.6.1 USB Storage and
SCSI, Disks and Filesystems, Disks and Filesystems, Disks and Filesystems, 4.1
Partitioning Disk Devices, 4.1.1 Viewing a Partition Table, 4.1.2 Changing Partition
Tables, 4.1.3 Disk and Partition Geometry, 4.1.3 Disk and Partition Geometry, 4.2.1
Filesystem Types, 4.2.4 Filesystem UUID, 4.2.4 Filesystem UUID, 4.2.8 The /etc/fstab
Filesystem Table, 4.2.9 Alternatives to /etc/fstab, 4.3 swap space, 4.5.2 Working with
Filesystems in User Space, Major Page Faults, 8.11.2 Per-Process I/O Utilization and
Monitoring: iotop, 8.12 Per-Process Monitoring with pidstat
addressing, 4.1.3 Disk and Partition Geometry
buffer, 4.2.4 Filesystem UUID
cache, 4.2.4 Filesystem UUID
capacity, 4.1.1 Viewing a Partition Table
copy, 3.2 The sysfs Device Path
device, 3.4 Device Name Summary, Disks and Filesystems
device file, 3.1 Device Files
format, 4.1 Partitioning Disk Devices, 4.2.1 Filesystem Types
geometry, 4.1.2 Changing Partition Tables
www.EBooksWorld.ir
monitoring usage, Major Page Faults
partition, 3.4 Device Name Summary (see partition)
PATA, 3.4.1 Hard Disks: /dev/sd*
quota, 8.12 Per-Process Monitoring with pidstat
raw access, 3.2 The sysfs Device Path, Disks and Filesystems
SATA, 3.4 Device Name Summary, 3.5.2 udevd Operation and Configuration, 3.6.1 USB
Storage and SCSI
scheduling priority, 8.11.2 Per-Process I/O Utilization and Monitoring: iotop
schematic, Disks and Filesystems
SCSI, 3.4 Device Name Summary, 3.6 In-Depth: SCSI and the Linux Kernel
solid-state, 4.1.3 Disk and Partition Geometry, 4.5.2 Working with Filesystems in User Space
swap, 4.2.8 The /etc/fstab Filesystem Table, 4.3 swap space
usage, 4.2.9 Alternatives to /etc/fstab
display, 3.4.1 Hard Disks: /dev/sd*, 14.2 A Closer Look at the X Window System,
14.2 A Closer Look at the X Window System
manager, 14.2 A Closer Look at the X Window System
modes, 3.4.1 Hard Disks: /dev/sd*
dmesg, 3.3 dd and Devices, How the Linux Kernel Boots
dmesg, Troubleshooting
(see also kernel: log)
DNS (Domain Name Service), 9.5.1 ping, Unmanaged Interfaces
documentation, 2.12 Text Editors
Domain Name Service (DNS), 9.5.1 ping, Unmanaged Interfaces
dot file, 2.5.7 head and tail, User Environments
DPMS, xset
du, 4.2.9 Alternatives to /etc/fstab
E
e2fsck., 4.2.8 The /etc/fstab Filesystem Table, 4.2.11 Checking and Repairing Filesystems
echo, 2.2.1 The Shell Window, 2.3.5 rm
EDITOR, 13.5 Default User Settings
effective user ID (euid), 7.8 Understanding User IDs and User Switching
EFI, 5.4 Boot Loaders, 5.5.3 GRUB Installation, Installing GRUB on an External Storage Device,
5.8.1 MBR Boot
ESP, 5.8.1 MBR Boot
secure boot, Installing GRUB on an External Storage Device
www.EBooksWorld.ir
efilinux, 5.4.1 Boot Loader Tasks
egrep, 2.4.4 Shell Globbing (Wildcards)
elapsed time, 8.4.2 Viewing Threads
Emacs, 2.10 Special Characters
embedded system, 17.3 Virtualization
encryption, 7.10.3 PAM and Passwords, 10.2 Network Servers
environment variable, 2.5.7 head and tail, 11.10.4 xargs
error message, 2.13 Getting Online Help, 8.3.1 strace
ESP, 5.8.1 MBR Boot
(see also EFI)
/etc, 2.19 Linux Directory Hierarchy Essentials, System Configuration: Logging, System
Time, Batch Jobs, and Users
/etc/fstab, 3.4 Device Name Summary, 4.2.4 Filesystem UUID, Long Options
/etc/hosts, 9.12 Resolving Hostnames
/etc/init.d, 6.6.2 The System V init Link Farm
/etc/inittab, 6.5.6 Upstart Runlevels and System V Compatibility
/etc/ld.so.cache, Listing Shared Library Dependencies
/etc/ld.so.conf, Listing Shared Library Dependencies
/etc/localtime, 7.5 Setting the Time
/etc/login.defs, 7.10.3 PAM and Passwords
/etc/mtab, 4.2.6 Filesystem Mount Options
/etc/nologin, 6.7 Shutting Down Your System
/etc/nsswitch.conf, 9.12 Resolving Hostnames, 17.1 Web Servers and Applications
/etc/passwd, 2.13 Getting Online Help, Troubleshooting, Security Implications, 17.1 Web
Servers and Applications
/etc/profile, 13.4.1 The bash Shell
/etc/rc.d, 6.6 System V init
/etc/resolv.conf, 9.12 Resolving Hostnames
/etc/services, 9.14.2 Establishing TCP Connections
/etc/shadow, 7.3.1 The /etc/passwd File
/etc/shells, 7.3.1 The /etc/passwd File, 7.10 PAM
Ethernet, 9.5.3 DNS and host, 9.22 Ethernet, IP, and ARP, 9.22 Ethernet, IP, and ARP
wireless, 9.22 Ethernet, IP, and ARP
euid (effective user ID), 7.8 Understanding User IDs and User Switching
exec(), 1.3.3 Device Drivers and Management, 8.2.2 Using lsof, 11.10.4 xargs
www.EBooksWorld.ir
executable, 2.17 File Modes and Permissions, 2.19 Linux Directory Hierarchy Essentials,
4.2.6 Filesystem Mount Options, 15.1 The C Compiler, 15.4 Lex and Yacc
exit code, 11.3.3 All Arguments: $@
export, 2.8 Environment and Shell Variables
F
fdisk, 4.1 Partitioning Disk Devices
fg, 2.16.2 Killing Processes
files, 1.4 User Space, 2.2.3 Standard Input and Standard Output, 2.2.3 Standard Input and
Standard Output, 2.2.3 Standard Input and Standard Output, 2.2.3 Standard Input and Standard
Output, 2.3.1 ls, 2.3.1 ls, 2.3.1 ls, 2.3.1 ls, 2.3.5 rm, 2.4.4 Shell Globbing (Wildcards), 2.5.3 pwd, 2.5.3
pwd, 2.5.3 pwd, 2.5.3 pwd, 2.5.7 head and tail, 2.13 Getting Online Help, 2.14.1 Standard Error,
2.15.1 Anatomy of a UNIX Error Message, Not a directory, Is a directory, 2.16.4 Background
Processes, 2.16.4 Background Processes, 2.16.4 Background Processes, 2.16.4 Background
Processes, 2.17.2 Symbolic Links, 2.18 Archiving and Compressing Files, 2.19 Linux Directory
Hierarchy Essentials, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and
More, 4.2.8 The /etc/fstab Filesystem Table, 4.4 Looking Forward: Disks and User Space, 4.5 Inside
a Traditional Filesystem, 4.5 Inside a Traditional Filesystem, 8.1 Tracking Processes, 8.1 Tracking
Processes, 11.5.5 Testing Conditions, File Tests, 12.2.5 Transfer Integrity, Safeguards, and Verbose
Modes, 12.2.9 Further rsync Topics, User Environments
comparing with another file, 2.5.3 pwd
compressing, 2.18 Archiving and Compressing Files, 12.2.5 Transfer Integrity, Safeguards,
and Verbose Modes
copying, 2.3.1 ls
creating empty, 2.3.1 ls
deleting, 2.3.5 rm, 4.5 Inside a Traditional Filesystem
descriptor, 8.1 Tracking Processes
details, 2.2.3 Standard Input and Standard Output
device, 2.19 Linux Directory Hierarchy Essentials, 3.1 Device Files, 3.4.7 Audio Devices:
/dev/snd/*, /dev/dsp, /dev/audio, and More, 4.2.8 The /etc/fstab Filesystem Table
dot, 2.5.7 head and tail, User Environments
errors, 2.15.1 Anatomy of a UNIX Error Message
find, 2.5.3 pwd
find text in, 2.4.4 Shell Globbing (Wildcards)
format, 2.5.3 pwd
group, 2.2.3 Standard Input and Standard Output, 2.16.4 Background Processes
www.EBooksWorld.ir
identify, 11.5.5 Testing Conditions
link, 2.17.2 Symbolic Links, 4.4 Looking Forward: Disks and User Space, File Tests
link count, 4.5 Inside a Traditional Filesystem
listing, 2.2.3 Standard Input and Standard Output
mode, 2.16.4 Background Processes
move, 2.3.1 ls
open, 8.1 Tracking Processes
owner, 2.2.3 Standard Input and Standard Output, 2.16.4 Background Processes
permissions, Not a directory, Is a directory (see permissions)
redirecting, 2.13 Getting Online Help, 2.14.1 Standard Error
command input from, 2.14.1 Standard Error
command output to, 2.13 Getting Online Help
regular, 2.16.4 Background Processes
rename, 2.3.1 ls
sharing, 1.4 User Space, 12.2.9 Further rsync Topics
across a network, 12.2.9 Further rsync Topics
with other users, 1.4 User Space
socket, 3.1 Device Files, 10.9 Sockets: How Processes Communicate with the Network
swap, 4.3 swap space
temporary, 11.7 Command Substitution
test, 11.5.5 Testing Conditions
transfering, 2.3.1 ls, 2.16.4 Background Processes, 2.17.1 Modifying Permissions, 3.1 Device
Files, 8.2.1 Reading the lsof Output, Starting the SSH Server, Moving Files Across the Network,
Moving Files Across the Network, 12.1 Quick Copy
with Python, Moving Files Across the Network
rsync, 12.1 Quick Copy
SSH, Starting the SSH Server
type, 2.16.4 Background Processes, 2.17.1 Modifying Permissions, 3.1 Device Files, 8.2.1
Reading the lsof Output
updating timestamp, 2.3.1 ls
filesystem, 2.19 Linux Directory Hierarchy Essentials, 2.19 Linux Directory Hierarchy
Essentials, 3.4 Device Name Summary, Disks and Filesystems, 4.1 Partitioning Disk Devices,
4.1.3 Disk and Partition Geometry, 4.2 Filesystems, 4.2 Filesystems, 4.2 Filesystems, 4.2
Filesystems, 4.2 Filesystems, 4.2 Filesystems, 4.2 Filesystems, 4.2.1 Filesystem Types, 4.2.1
Filesystem Types, 4.2.1 Filesystem Types, 4.2.2 Creating a Filesystem, 4.2.2 Creating a
www.EBooksWorld.ir
Filesystem, 4.2.3 Mounting a Filesystem, 4.2.4 Filesystem UUID, 4.2.6 Filesystem Mount
Options, 4.2.6 Filesystem Mount Options, Long Options, Long Options, Long Options, 4.2.9
Alternatives to /etc/fstab, 4.2.9 Alternatives to /etc/fstab, 4.2.11 Checking and Repairing
Filesystems, 4.2.11 Checking and Repairing Filesystems, 4.2.11 Checking and Repairing
Filesystems, 4.2.11 Checking and Repairing Filesystems, The Worst Case, The Worst Case,
4.4 Looking Forward: Disks and User Space, 4.5.1 Viewing Inode Details, 4.5.2 Working
with Filesystems in User Space, 5.2 Kernel Initialization and Boot Options, 5.2 Kernel
Initialization and Boot Options, 5.5 GRUB Introduction, 6.3 Identifying Your init, 6.4.9
systemd Auxiliary Programs, 12.4.10 Accessing Files as a Client, 12.4.10 Accessing Files as
a Client
Btrfs, 4.2.1 Filesystem Types, 4.5.2 Working with Filesystems in User Space
capacity, 4.2.9 Alternatives to /etc/fstab
check, 4.2.11 Checking and Repairing Filesystems
CIFS, 12.4.10 Accessing Files as a Client
creating, 4.1 Partitioning Disk Devices, 4.2.1 Filesystem Types
currently attached, 4.2.2 Creating a Filesystem
ext2/ext3/ext4, 4.2 Filesystems, 4.2.11 Checking and Repairing Filesystems
FAT, 4.2 Filesystems
HFS+, 4.2 Filesystems
hierarchy, 2.19 Linux Directory Hierarchy Essentials
internal structure, 4.2.1 Filesystem Types, 4.4 Looking Forward: Disks and User Space
ISO 9660, 4.2 Filesystems, 4.2.6 Filesystem Mount Options
journal, 4.2 Filesystems, 4.2.11 Checking and Repairing Filesystems
mount, 4.2.2 Creating a Filesystem, 4.2.4 Filesystem UUID, 6.3 Identifying Your init, 6.4.9
systemd Auxiliary Programs
options, 4.2.4 Filesystem UUID
NFS, 12.4.10 Accessing Files as a Client
proc, 2.19 Linux Directory Hierarchy Essentials, Long Options, The Worst Case
read-only, 4.2.6 Filesystem Mount Options, 5.2 Kernel Initialization and Boot Options
remount, Long Options
repair, 4.2.11 Checking and Repairing Filesystems
tmpfs, The Worst Case
type, 4.2 Filesystems
usage, 4.2.9 Alternatives to /etc/fstab
user space, 4.2 Filesystems, 4.5.1 Viewing Inode Details
www.EBooksWorld.ir
interface, 4.5.1 Viewing Inode Details
UUID, 3.4 Device Name Summary, 4.2.3 Mounting a Filesystem, Long Options, 5.2
Kernel Initialization and Boot Options, 5.5 GRUB Introduction
find, 2.5.3 pwd, 11.10.3 sed
finding command, 2.12 Text Editors
firewall, 9.20 Routers and Linux, 9.21.1 Linux Firewall Basics, 9.21.2 Setting Firewall
Rules
rule, 9.21.1 Linux Firewall Basics
strategy, 9.21.2 Setting Firewall Rules
flex, 15.4 Lex and Yacc
for, 11.5.6 Matching Strings with case
fork(), 1.3.3 Device Drivers and Management, 6.4.5 Adding Units to systemd, A
Service Job: tty1, 8.2.2 Using lsof, 8.3.2 ltrace, 10.1.1 A Closer Look
frame, 9.5.3 DNS and host
free, 4.3 swap space
fsck, 4.2.8 The /etc/fstab Filesystem Table, 4.2.11 Checking and Repairing
Filesystems
FTP, SSH File Transfer Clients, 10.7.1 Typical Vulnerabilities
G
gateway, 9.2 Network Layers, 9.4 Routes and the Kernel Routing Table
gcc, 15.1 The C Compiler
gdb, 15.2.8 Organizing a Makefile
gdisk, 4.1 Partitioning Disk Devices
GECOS, 7.3.1 The /etc/passwd File
geteuid(), Security Implications
getty, Display Modes and Virtual Consoles, Enabling Units and the [Install] Section, A Service Job:
tty1, 6.6 System V init, 7.3.5 Working with Groups
Ghostscript, 14.6.1 CUPS
glob, 2.4.1 cd, 2.5.7 head and tail
glob, 11.2 Quoting and Literals
(see also regular expression)
GNU autotools, Introduction to Compiling Software From C Source Code
GNU autotools, 16.6.1 Specific Errors
(see also autoconf)
gparted, Disks and Filesystems
www.EBooksWorld.ir
GPT, Disks and Filesystems, Listing Devices
grep, 2.4.4 Shell Globbing (Wildcards), 11.4 Exit Codes
group, 1.5 Users, 2.16.4 Background Processes, 2.17 File Modes and Permissions, 7.3.1 The
/etc/passwd File, Changing /etc/passwd as the Superuser
listing, 2.17 File Modes and Permissions
permissions, 2.16.4 Background Processes
groups, 2.17 File Modes and Permissions
GRUB, 5.4.1 Boot Loader Tasks, 5.4.1 Boot Loader Tasks, 5.4.1 Boot Loader Tasks, 5.5
GRUB Introduction, 5.5 GRUB Introduction, 5.5 GRUB Introduction, 5.5 GRUB
Introduction, Listing Devices, File Navigation, File Navigation, 5.5.2 GRUB
Configuration, Generating a New Configuration File, 5.5.3 GRUB Installation, 5.8.1
MBR Boot
boot command, File Navigation
command line, 5.5 GRUB Introduction
configuration, 5.4.1 Boot Loader Tasks, File Navigation
devices, 5.5 GRUB Introduction
filesystem access, Listing Devices
insmod, 5.5 GRUB Introduction
install, Generating a New Configuration File
internals, 5.8.1 MBR Boot
menu, 5.4.1 Boot Loader Tasks, 5.5.2 GRUB Configuration
on removable media, 5.5.3 GRUB Installation
root, 5.5 GRUB Introduction
grub-mkconfig, 5.5.2 GRUB Configuration
GTK+, 14.1.1 Window Managers
guest operating system, 17.2 Databases
gunzip, 2.18 Archiving and Compressing Files
gzip, 2.18 Archiving and Compressing Files
H
halt, 6.7 Shutting Down Your System
hard link, 2.17.2 Symbolic Links, 4.4 Looking Forward: Disks and User Space, File Tests
hardware operation, 1.2 Hardware: Understanding Main Memory
head, 2.5.7 head and tail, 4.1.3 Disk and Partition Geometry
header file, 2.19 Linux Directory Hierarchy Essentials, 15.1.1 Multiple Source Files, 16.3.4
Environment Variables, 16.3.7 pkg-config, 16.6.1 Specific Errors
www.EBooksWorld.ir
locating, 16.6.1 Specific Errors
help, 2.12 Text Editors
here document, 11.8 Temporary File Management
/home, 2.19 Linux Directory Hierarchy Essentials
home directory, 2.4.1 cd, 2.19 Linux Directory Hierarchy Essentials, 7.3.1 The /etc/passwd File
host, Understanding your Network and its Configuration, 9.5.1 ping
host key, 10.3 Secure Shell (SSH)
HTTP, Network Applications and Services
hypervisor, 17.3 Virtualization
I
ICMP, 9.4.1 The Default Gateway
ifconfig, 9.3 The Internet Layer, 9.7 Understanding Kernel Network Interfaces
if/then/else, 11.4 Exit Codes
image, 1.2 Hardware: Understanding Main Memory
include file, 15.1.1 Multiple Source Files, 16.3.4 Environment Variables, 16.3.5 Autoconf Targets
inetd, SSH File Transfer Clients
info, 2.13 Getting Online Help, 2.20.2 /etc/sudoers
init, How the Linux Kernel Boots
init, How User Space Starts, How User Space Starts, How User Space Starts, How User Space
Starts, 6.1 Introduction to init, 6.3 Identifying Your init, Instances and Handoff, Instances and
Handoff, 6.5.4 Upstart Operation, 6.5.4 Upstart Operation, 6.5.6 Upstart Runlevels and System V
Compatibility, 6.6.1 System V init: Startup Command Sequence
(see also systemd; Upstart)
identifying, 6.3 Identifying Your init
process tracking, How User Space Starts
runlevel, 6.1 Introduction to init, Instances and Handoff, 6.5.4 Upstart Operation, 6.5.6
Upstart Runlevels and System V Compatibility
systemd, Instances and Handoff
System V, 6.5.6 Upstart Runlevels and System V Compatibility
Upstart, 6.5.4 Upstart Operation
sequence, How User Space Starts, 6.6.1 System V init: Startup Command Sequence
System V, How User Space Starts, Instances and Handoff, 6.5.4 Upstart Operation
initctl, 6.5.2 Upstart Jobs
initramfs, 5.5 GRUB Introduction, 5.8.3 How GRUB Works, 6.7 Shutting Down Your System
initrd, 6.8 The Initial RAM Filesystem
www.EBooksWorld.ir
(see also initramfs)
inode, 4.2.11 Checking and Repairing Filesystems, 4.4 Looking Forward: Disks and User
Space, 4.5 Inside a Traditional Filesystem, File Tests
root, 4.5 Inside a Traditional Filesystem
installing software, Introduction to Compiling Software From C Source Code, Installing
pkg-config Files in Nonstandard Locations
interactive shell, 13.4.1 The bash Shell
Internet layer, network, 9.1.1 Packets
(see also IP)
iostat, 8.10 Monitoring CPU and Memory Performance with vmstat
iotop, 8.11.1 Using iostat
IP, 9.2 Network Layers, 9.2 Network Layers, 9.2 Network Layers, 9.3.1 Viewing Your
Computer’s IP Addresses, 9.7 Understanding Kernel Network Interfaces, 9.8
Introduction to Network Interface Configuration, 9.16.1 The Linux DHCP Client,
9.17 Configuring Linux as a Router, 9.17 Configuring Linux as a Router, 9.17
Configuring Linux as a Router, 9.20 Routers and Linux, 9.21 Firewalls, 9.21
Firewalls
address, 9.2 Network Layers, 9.7 Understanding Kernel Network Interfaces, 9.17
Configuring Linux as a Router
chain, 9.21 Firewalls
filter, 9.20 Routers and Linux
forwarding, 9.17 Configuring Linux as a Router
subnet, 9.2 Network Layers, 9.3.1 Viewing Your Computer’s IP Addresses, 9.8 Introduction
to Network Interface Configuration, 9.16.1 The Linux DHCP Client, 9.17 Configuring
Linux as a Router, 9.21 Firewalls
choosing, 9.17 Configuring Linux as a Router
mask, 9.3.1 Viewing Your Computer’s IP Addresses, 9.8 Introduction to Network Interface
Configuration
routing between, 9.16.1 The Linux DHCP Client
table, 9.21 Firewalls
IPP, 14.5.2 Monitoring D-Bus Messages
iptables, 9.21.1 Linux Firewall Basics
IPv4, 9.2 Network Layers
IPv6, 9.2 Network Layers
www.EBooksWorld.ir
J
Java, 15.5.3 Other Scripting Languages
job control, 2.16.2 Killing Processes
jobs, 2.16.2 Killing Processes
K
kernel, The Big Picture, 2.19.2 The /usr Directory, 2.19.2 The /usr Directory, 3.1 Device Files, 3.5.4
Monitoring Devices, 3.5.4 Monitoring Devices, Disks and Filesystems, 4.1.1 Viewing a Partition
Table, 4.2.4 Filesystem UUID, 4.2.4 Filesystem UUID, 4.3.3 How Much Swap Do You Need?, How
the Linux Kernel Boots, How the Linux Kernel Boots, How the Linux Kernel Boots, How the Linux
Kernel Boots, 5.1 Startup Messages, 5.2 Kernel Initialization and Boot Options, 5.4 Boot Loaders,
5.5 GRUB Introduction, Troubleshooting, A Closer Look at Processes and Resource Utilization, 9.4
Routes and the Kernel Routing Table, 9.7 Understanding Kernel Network Interfaces, 16.7 Looking
Forward
as a resource, A Closer Look at Processes and Resource Utilization
boot, How the Linux Kernel Boots, 5.1 Startup Messages
boot messages, How the Linux Kernel Boots
compiling, 16.7 Looking Forward
disk buffer, 4.2.4 Filesystem UUID
disk cache, 4.2.4 Filesystem UUID
disk I/O system, Disks and Filesystems, 4.3.3 How Much Swap Do You Need?
load, How the Linux Kernel Boots, 5.4 Boot Loaders
location, 2.19.2 The /usr Directory
log, 3.5.4 Monitoring Devices, Troubleshooting
modules, 2.19.2 The /usr Directory
network interface, 3.1 Device Files, 9.7 Understanding Kernel Network Interfaces
parameters, 5.2 Kernel Initialization and Boot Options, 5.5 GRUB Introduction
reading partition table, 4.1.1 Viewing a Partition Table
ring buffer, How the Linux Kernel Boots
routing table, 9.4 Routes and the Kernel Routing Table
SCSI subsystem, 3.5.4 Monitoring Devices
kernel mode, 1.1 Levels and Layers of Abstraction in a Linux System
kernel space, 1.1 Levels and Layers of Abstraction in a Linux System
keyboard, 14.3.1 X Events
kill, 2.16 Listing and Manipulating Processes
www.EBooksWorld.ir
L
LAN, Understanding your Network and its Configuration
layer, The Big Picture, Understanding your Network and its Configuration
network, Understanding your Network and its Configuration
LBA, 4.1.3 Disk and Partition Geometry, 5.4 Boot Loaders
LDAP, 17.1 Web Servers and Applications
ldconfig, Listing Shared Library Dependencies
ldd, 15.1.4 Shared Libraries
LD_LIBRARY_PATH, 13.5.2 Editor, Listing Shared Library Dependencies
ld.so, 15.1.4 Shared Libraries
less, 2.5.1 grep, The Consequences of Two Kinds of Shells, 13.5.2 Editor, 16.3.5 Autoconf Targets
level, The Big Picture, 1.3.4 System Calls and Support
in user space, 1.3.4 System Calls and Support
Lex, 15.3 Debuggers
/lib, 2.19 Linux Directory Hierarchy Essentials
libata, 3.6 In-Depth: SCSI and the Linux Kernel, 3.6.1 USB Storage and SCSI
library, 2.19 Linux Directory Hierarchy Essentials, 2.19 Linux Directory Hierarchy
Essentials, 8.2.2 Using lsof, 8.3.2 ltrace, What Is the C Preprocessor (cpp)?, 15.1.3 Linking
with Libraries, Listing Shared Library Dependencies, 15.2.5 Command-Line Arguments
and Options, 16.3.2 Installing Using a Packaging Tool, 16.3.5 Autoconf Targets, 16.3.7 pkg-
config
linking against, What Is the C Preprocessor (cpp)?, Listing Shared Library Dependencies,
15.2.5 Command-Line Arguments and Options
shared, 2.19 Linux Directory Hierarchy Essentials, 8.2.2 Using lsof, 8.3.2 ltrace, 15.1.3
Linking with Libraries, 16.3.2 Installing Using a Packaging Tool, 16.3.7 pkg-config
system calls, 8.2.2 Using lsof
trace, 8.3.2 ltrace
LILO, 5.4.1 Boot Loader Tasks
link, 2.17.1 Modifying Permissions, 2.17.2 Symbolic Links, 4.4 Looking Forward: Disks
and User Space, 4.5 Inside a Traditional Filesystem, 6.6.2 The System V init Link Farm,
File Tests
count, 4.5 Inside a Traditional Filesystem
farm, 6.6.2 The System V init Link Farm
hard, 2.17.2 Symbolic Links, 4.4 Looking Forward: Disks and User Space, File Tests
symbolic, 2.17.1 Modifying Permissions
www.EBooksWorld.ir
listen, 9.14.1 TCP Ports and Connections, 10.5.1 lsof
literal, 11.2 Quoting and Literals
LLVM, 15.1 The C Compiler, 15.6 Java
ln, 2.17.1 Modifying Permissions, 4.4 Looking Forward: Disks and User Space, 4.5
Inside a Traditional Filesystem
loadable kernel modules, 2.19.2 The /usr Directory
load average, 8.7 Adjusting Process Priorities
LOADLIN, 5.4.1 Boot Loader Tasks
localhost, 9.11.3 NetworkManager Configuration, 9.12.4 /etc/nsswitch.conf
locate, 2.5.3 pwd
log, 1.4 User Space, 3.5.4 Monitoring Devices, 6.4.4 systemd Operation, 6.5.3 Upstart
Configuration, 6.5.4 Upstart Operation, System Configuration: Logging, System
Time, Batch Jobs, and Users, Troubleshooting
(see also kernel, log; syslog)
kernel, 3.5.4 Monitoring Devices, Troubleshooting
syslog, System Configuration: Logging, System Time, Batch Jobs, and Users
system, 6.4.4 systemd Operation
Upstart, 6.5.3 Upstart Configuration, 6.5.4 Upstart Operation
logger, Troubleshooting
login, 7.3.5 Working with Groups
login shell, 13.4.1 The bash Shell
logrotate, Troubleshooting
loops, 11.5.6 Matching Strings with case
lost+found, 4.2.11 Checking and Repairing Filesystems, 4.5.1 Viewing Inode
Details
ls, 2.2.3 Standard Input and Standard Output
lsof, 8.1 Tracking Processes, 10.5.1 lsof, 10.10.1 Advantages for Developers
network, 10.5.1 lsof
Unix domain socket, 10.10.1 Advantages for Developers
lsscsi, 3.4 Device Name Summary, 3.6 In-Depth: SCSI and the Linux Kernel,
3.6.3 Generic SCSI Devices
lsusb, 3.6.1 USB Storage and SCSI
ltrace, 8.3.2 ltrace
M
MAC address, 9.5.3 DNS and host, 9.11.3 NetworkManager Configuration, 9.22 Ethernet, IP, and
www.EBooksWorld.ir
ARP
main memory, 1.1 Levels and Layers of Abstraction in a Linux System (see memory)
make, 15.2 make
Makefile, 15.2 make, 15.2 make, 15.2 make, 15.2.1 A Sample Makefile, 15.2.3 Final Program Build,
15.2.6 Standard Macros and Variables, 15.2.6 Standard Macros and Variables, 15.2.8 Organizing
a Makefile, 16.3.5 Autoconf Targets
dependency, 15.2 make, 15.2.8 Organizing a Makefile
organization, 15.2.6 Standard Macros and Variables
rule, 15.2 make
separator, 15.2.1 A Sample Makefile
staying up-to-date, 15.2.3 Final Program Build
target, 15.2 make, 15.2.6 Standard Macros and Variables, 16.3.5 Autoconf Targets
standard, 15.2.6 Standard Macros and Variables, 16.3.5 Autoconf Targets
man, 2.12 Text Editors
(see also manual page)
manual page, 2.12 Text Editors, 2.19.2 The /usr Directory, Adding Dot (.) to the Path
MBR, Disks and Filesystems, Listing Devices, 5.7 Chainloading Other Operating Systems
boot, 5.7 Chainloading Other Operating Systems
mDNS, 9.12.3 Caching and Zero-Configuration DNS
/media, 2.19 Linux Directory Hierarchy Essentials
memory, 1.1 Levels and Layers of Abstraction in a Linux System, 1.1 Levels and Layers
of Abstraction in a Linux System, 1.3.1 Process Management, 1.3.1 Process Management,
4.1 Partitioning Disk Devices, 4.2.8 The /etc/fstab Filesystem Table, The Worst Case, 4.3
swap space, 4.3 swap space, 4.3 swap space, 4.3 swap space, 4.3.3 How Much Swap Do
You Need?, 5.1 Startup Messages, Generating a New Configuration File, 8.8.1 Using
uptime, 8.8.1 Using uptime, 8.9.1 How Memory Works, 8.9.1 How Memory Works,
Major Page Faults
capacity, 4.3 swap space, 8.8.1 Using uptime
insufficient, The Worst Case, 4.3.3 How Much Swap Do You Need?, 8.8.1 Using uptime
management, 1.3.1 Process Management, 5.1 Startup Messages, 8.9.1 How Memory Works
monitoring usage, Major Page Faults
page, 8.9.1 How Memory Works
protection, 1.1 Levels and Layers of Abstraction in a Linux System
swap, 4.1 Partitioning Disk Devices, 4.2.8 The /etc/fstab Filesystem Table, 4.3 swap space,
4.3 swap space
www.EBooksWorld.ir
partitions, 4.1 Partitioning Disk Devices, 4.3 swap space
test, Generating a New Configuration File
virtual, 1.3.1 Process Management, 4.3 swap space
Mir, xset
mkdir, 2.4.1 cd
mkfs, 4.2.1 Filesystem Types
mknod, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
mkswap, 4.3 swap space
MMU, 1.3.1 Process Management, 8.9.1 How Memory Works
modules, kernel, 2.19.2 The /usr Directory
mount, 4.2.2 Creating a Filesystem, 14.3.2 Understanding X Input and Preference
Settings
(see also filesystem: mount)
mouse, 14.3.2 Understanding X Input and Preference Settings
multitasking, 1.3 The Kernel
mv, 2.3.1 ls
N
NAT, 9.17 Configuring Linux as a Router
netcat, 10.5.2 tcpdump
netstat, 9.14.1 TCP Ports and Connections, 10.4 The inetd and xinetd Daemons
network, 3.1 Device Files, Understanding your Network and its Configuration, Understanding your
Network and its Configuration, Understanding your Network and its Configuration,
Understanding your Network and its Configuration, Understanding your Network and its
Configuration, Understanding your Network and its Configuration, 9.1.1 Packets, 9.1.1 Packets,
9.1.1 Packets, 9.1.1 Packets, 9.1.1 Packets, 9.2 Network Layers, 9.2 Network Layers, 9.3 The
Internet Layer, 9.3.1 Viewing Your Computer’s IP Addresses, 9.3.3 Common Subnet Masks and
CIDR Notation, 9.4 Routes and the Kernel Routing Table, 9.4.1 The Default Gateway, 9.5.1 ping,
9.5.1 ping, 9.7 Understanding Kernel Network Interfaces, 9.7 Understanding Kernel Network
Interfaces, 9.9 Boot-Activated Network Configuration, 9.11.3 NetworkManager Configuration,
9.12.4 /etc/nsswitch.conf, 9.14.1 TCP Ports and Connections, 9.14.1 TCP Ports and Connections,
9.14.1 TCP Ports and Connections, 9.14.1 TCP Ports and Connections, 9.15 Revisiting a Simple
Local Network, 9.15 Revisiting a Simple Local Network, 9.16.1 The Linux DHCP Client, 9.17
Configuring Linux as a Router, 9.19 Network Address Translation (IP Masquerading), 9.20
Routers and Linux, 9.21.1 Linux Firewall Basics, 9.21.2 Setting Firewall Rules, Network
Applications and Services, Network Applications and Services, Network Applications and Services,
www.EBooksWorld.ir
10.1.1 A Closer Look, 10.5.1 lsof, 10.5.1 lsof, Filtering by Protocol and Port
application layer, 9.1.1 Packets, Network Applications and Services
client, 9.14.1 TCP Ports and Connections
configuration, 9.3 The Internet Layer, 9.7 Understanding Kernel Network Interfaces, 9.15
Revisiting a Simple Local Network
connection, 9.14.1 TCP Ports and Connections, Network Applications and Services, 10.5.1
lsof
firewall, 9.20 Routers and Linux, 9.21.1 Linux Firewall Basics, 9.21.2 Setting Firewall Rules
rule, 9.21.1 Linux Firewall Basics
strategy, 9.21.2 Setting Firewall Rules
host, Understanding your Network and its Configuration, 9.5.1 ping
interface, 3.1 Device Files, 9.7 Understanding Kernel Network Interfaces
Internet layer, 9.1.1 Packets
layer, Understanding your Network and its Configuration
localhost, 9.11.3 NetworkManager Configuration, 9.12.4 /etc/nsswitch.conf
packet, Understanding your Network and its Configuration
physical layer, 9.1.1 Packets
port, 9.14.1 TCP Ports and Connections, Network Applications and Services
prefix, 9.3.1 Viewing Your Computer’s IP Addresses
private, 9.17 Configuring Linux as a Router
promiscuous mode, Filtering by Protocol and Port
route, 9.3.3 Common Subnet Masks and CIDR Notation, 9.5.1 ping
router, Understanding your Network and its Configuration, 9.2 Network Layers, 9.4
Routes and the Kernel Routing Table, 9.16.1 The Linux DHCP Client, 9.19 Network
Address Translation (IP Masquerading)
server, 9.14.1 TCP Ports and Connections, 10.1.1 A Closer Look
simple, Understanding your Network and its Configuration, 9.2 Network Layers, 9.15
Revisiting a Simple Local Network
stack, 9.1.1 Packets
transport layer, 9.1.1 Packets
troubleshooting, 9.4.1 The Default Gateway, 10.5.1 lsof
wireless, 9.9 Boot-Activated Network Configuration
network configuration manager, 9.10 Problems with Manual and Boot-Activated Network
Configuration
NetworkManager, 9.10 Problems with Manual and Boot-Activated Network Configuration,
www.EBooksWorld.ir
9.23.1 iw
Network Time Protocol (NTP), 7.5 Setting the Time, 9.14.4 Characteristics of TCP
NFS, 12.4.10 Accessing Files as a Client
nftables, 9.21 Firewalls
nice value, 8.6 Measuring CPU Time
nmap, 10.5.3 netcat
NTP (Network Time Protocol), 7.5 Setting the Time, 9.14.4 Characteristics of TCP
O
object file, 15.1.1 Multiple Source Files
OOM killer, 4.3.3 How Much Swap Do You Need?
open(), 8.3.1 strace
open source, Introduction to Compiling Software From C Source Code
OpenWRT, 9.20 Routers and Linux, 17.5 Embedded Systems
/opt, 2.19 Linux Directory Hierarchy Essentials
OSS, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
P
package, 16.3.1 An Autoconf Example, Installing pkg-config Files in Nonstandard Locations, 16.6.1
Specific Errors
packet, Understanding your Network and its Configuration
page, 1.3.1 Process Management, 8.9.1 How Memory Works, 8.9.1 How Memory Works, 8.9.1 How
Memory Works
fault, 8.9.1 How Memory Works
table, 1.3.1 Process Management, 8.9.1 How Memory Works
PAGER, 13.5.2 Editor
pager, 2.5.1 grep, 13.5.2 Editor
PAM (Pluggable Authentication Modules), 7.9.1 Using Libraries for User Information
parallel port, Display Modes and Virtual Consoles
parted, Disks and Filesystems
partition, 3.4 Device Name Summary, Disks and Filesystems, Disks and Filesystems, 4.1
Partitioning Disk Devices, 4.1 Partitioning Disk Devices, 4.1 Partitioning Disk Devices, 4.1
Partitioning Disk Devices, 4.1 Partitioning Disk Devices, 4.1.1 Viewing a Partition Table, 4.1.1
Viewing a Partition Table, 4.1.1 Viewing a Partition Table, 4.1.2 Changing Partition Tables,
4.1.3 Disk and Partition Geometry, 4.2 Filesystems, 4.2 Filesystems, 4.2.9 Alternatives to
/etc/fstab, 4.3 swap space
www.EBooksWorld.ir
alignment, 4.1.3 Disk and Partition Geometry
altering table, Disks and Filesystems
Apple, 4.2 Filesystems
capacity, 4.1.1 Viewing a Partition Table, 4.2.9 Alternatives to /etc/fstab
extended, 4.1 Partitioning Disk Devices
geometry, 4.1.2 Changing Partition Tables
logical, 4.1 Partitioning Disk Devices
primary, 4.1 Partitioning Disk Devices
reading table, 4.1.1 Viewing a Partition Table
swap, 4.1 Partitioning Disk Devices, 4.3 swap space
system ID, 4.1.1 Viewing a Partition Table
table, Disks and Filesystems
viewing, 4.1 Partitioning Disk Devices
Windows, 4.2 Filesystems
passwd, 2.5.7 head and tail, 2.17 File Modes and Permissions, 7.3.1 The /etc/passwd File
password, 2.5.7 head and tail, 2.13 Getting Online Help, Troubleshooting, Security
Implications, 7.10.3 PAM and Passwords, 17.1 Web Servers and Applications
changing, 2.5.7 head and tail, 7.10.3 PAM and Passwords
file, 2.13 Getting Online Help, Troubleshooting, Security Implications, 17.1 Web Servers
and Applications
patch, 16.5 Applying a Patch
patchelf, Linking Programs Against Shared Libraries
path, 2.3.5 rm
PATH, 2.8 Environment and Shell Variables, User Environments
path, 2.3.5 rm, 2.3.5 rm, 2.8 Environment and Shell Variables, User Environments
absolute, 2.3.5 rm
command, 2.8 Environment and Shell Variables, User Environments
relative, 2.3.5 rm
pathname, 2.3.5 rm (see path)
performance, 4.3.3 How Much Swap Do You Need?, A Closer Look at Processes and
Resource Utilization
memory, 4.3.3 How Much Swap Do You Need?
Perl, 2.5.1 grep, 15.5 Scripting Languages
permissions, Not a directory, Is a directory, 2.16.4 Background Processes, 2.16.4
Background Processes, 2.16.4 Background Processes, 2.16.4 Background
www.EBooksWorld.ir
Processes, 2.16.4 Background Processes, 2.16.4 Background Processes, 2.16.4
Background Processes, 2.17 File Modes and Permissions, 2.17 File Modes and
Permissions, 2.17 File Modes and Permissions, 2.17.1 Modifying Permissions,
2.17.1 Modifying Permissions, Table-of-Contents Mode, File Tests, 13.3.4 Aliases
bits, 2.17 File Modes and Permissions
changing, 2.17 File Modes and Permissions
default, 2.17.1 Modifying Permissions, 13.3.4 Aliases
directory, 2.17.1 Modifying Permissions
execute, 2.17 File Modes and Permissions
group, 2.16.4 Background Processes
other, 2.16.4 Background Processes
preserving, Table-of-Contents Mode
read, 2.16.4 Background Processes
testing, File Tests
user, 2.16.4 Background Processes
world, 2.16.4 Background Processes
write, 2.16.4 Background Processes
physical layer, 9.1.1 Packets, 9.5.3 DNS and host
Pico, 2.12 Text Editors
PID (process ID), Not a directory, Is a directory, 8.4.2 Viewing Threads, 11.3.3
All Arguments: $@
pidstat, 8.11.2 Per-Process I/O Utilization and Monitoring: iotop
ping, 9.4.1 The Default Gateway
pipe, 2.5.1 grep, 2.13 Getting Online Help, 2.18.4 zcat, 3.1 Device Files, 3.4.7
Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
named, 3.1 Device Files, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More
pkg-config, 16.3.5 Autoconf Targets
Pluggable Authentication Modules (PAM), 7.9.1 Using Libraries for User
Information
plymouth, 3.4.1 Hard Disks: /dev/sd*
port scan, 10.5.3 netcat
printing, Display Modes and Virtual Consoles, 14.5.2 Monitoring D-Bus
Messages
private network, 9.17 Configuring Linux as a Router
/proc, 2.19 Linux Directory Hierarchy Essentials, Long Options, The
www.EBooksWorld.ir
Worst Case
process, The Big Picture, 1.3 The Kernel, 1.3.1 Process Management, 1.3.3
Device Drivers and Management, 1.4 User Space, Not a directory, Is a
directory, Not a directory, Is a directory, Not a directory, Is a directory,
2.16 Listing and Manipulating Processes, 2.16 Listing and Manipulating
Processes, 2.16 Listing and Manipulating Processes, 2.16.2 Killing
Processes, 2.16.2 Killing Processes, 2.19 Linux Directory Hierarchy
Essentials, The Worst Case, 4.3.3 How Much Swap Do You Need?, 4.3.3
How Much Swap Do You Need?, 7.8 Understanding User IDs and User
Switching, 8.1 Tracking Processes, 8.1 Tracking Processes, 8.1 Tracking
Processes, 8.3.1 strace, 8.4.2 Viewing Threads, 8.6 Measuring CPU Time,
8.10 Monitoring CPU and Memory Performance with vmstat, 8.11.2 Per-
Process I/O Utilization and Monitoring: iotop, 8.12 Per-Process
Monitoring with pidstat, 11.3.3 All Arguments: $@
accounting, 8.12 Per-Process Monitoring with pidstat
background, 2.16.2 Killing Processes
blocked, 8.10 Monitoring CPU and Memory Performance with vmstat
child, 8.3.1 strace
continue, 2.16.2 Killing Processes
ID, Not a directory, Is a directory, 8.4.2 Viewing Threads, 11.3.3 All Arguments: $@
interface, 2.19 Linux Directory Hierarchy Essentials
list, Not a directory, Is a directory
management, 1.3 The Kernel
memory, 1.3.1 Process Management, 4.3.3 How Much Swap Do You Need?, 8.1 Tracking
Processes
monitoring, 8.11.2 Per-Process I/O Utilization and Monitoring: iotop
open files, 8.1 Tracking Processes
owner, 1.4 User Space, 7.8 Understanding User IDs and User Switching
priority, 8.6 Measuring CPU Time
starting new, 1.3.3 Device Drivers and Management
status, 2.16 Listing and Manipulating Processes
stop, 2.16 Listing and Manipulating Processes
terminate, 2.16 Listing and Manipulating Processes
tracking, 8.1 Tracking Processes
unexpected termination, 4.3.3 How Much Swap Do You Need?
www.EBooksWorld.ir
.profile, 13.4.1 The bash Shell
prompt (shell), Basic Commands and Directory Hierarchy, 2.8
Environment and Shell Variables, Adding Dot (.) to the Path
ps, Not a directory, Is a directory, 7.8 Understanding User IDs and
User Switching, Major Page Faults
pseudodevice, 1.3.4 System Calls and Support
pseudoterminal, 3.4.1 Hard Disks: /dev/sd*
pulseaudio, 3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and
More
pwd, 2.5.1 grep
Python, 15.4 Lex and Yacc
Q
Qt, 14.1.1 Window Managers
R
Raspberry Pi, 17.5 Embedded Systems
real-time clock, 7.3.5 Working with Groups
real user ID (ruid), 7.8 Understanding User IDs and User Switching
reboot, 6.7 Shutting Down Your System
redraw display, 2.16.4 Background Processes
regular expressions, 2.5.1 grep
regular file, 2.16.4 Background Processes
relational database, 17.2 Databases
remote login, 10.2 Network Servers
renice, 8.7 Adjusting Process Priorities
replication, 17.2 Databases
resource monitoring, 8.4.2 Viewing Threads
reverse isearch, 2.16.4 Background Processes
RIP, 14.6.1 CUPS
rm, 2.3.5 rm
rmdir, 2.4.1 cd
root, 1.4 User Space, 2.2.1 The Shell Window, 2.19 Linux Directory Hierarchy Essentials, 2.19.2
The /usr Directory, How the Linux Kernel Boots, 5.1 Startup Messages, 5.5 GRUB Introduction
directory, 2.19 Linux Directory Hierarchy Essentials, How the Linux Kernel Boots, 5.1
Startup Messages, 5.5 GRUB Introduction
www.EBooksWorld.ir
prompt, 2.2.1 The Shell Window
running programs as, 2.19.2 The /usr Directory
route, 9.3.3 Common Subnet Masks and CIDR Notation, 9.8 Introduction to Network Interface
Configuration
route (network), 9.3.3 Common Subnet Masks and CIDR Notation, 9.5.1 ping, 9.7
Understanding Kernel Network Interfaces
configuration, 9.7 Understanding Kernel Network Interfaces
router, Understanding your Network and its Configuration, 9.2 Network Layers, 9.4 Routes
and the Kernel Routing Table, 9.16.1 The Linux DHCP Client, 9.19 Network Address
Translation (IP Masquerading)
RPC, 10.5.4 Port Scanning
rsync, Moving Files Across the Network, Moving Files Across the Network, 12.2.1 rsync
Basics, 12.2.3 Using the Trailing Slash, 12.2.4 Excluding Files and Directories, 12.2.5
Transfer Integrity, Safeguards, and Verbose Modes, 12.2.5 Transfer Integrity, Safeguards,
and Verbose Modes, 12.2.5 Transfer Integrity, Safeguards, and Verbose Modes
bandwidth, 12.2.5 Transfer Integrity, Safeguards, and Verbose Modes
compression, 12.2.5 Transfer Integrity, Safeguards, and Verbose Modes
copying, Moving Files Across the Network, 12.2.5 Transfer Integrity, Safeguards, and
Verbose Modes
from remote host, 12.2.5 Transfer Integrity, Safeguards, and Verbose Modes
to remote host, Moving Files Across the Network
exact copy, 12.2.1 rsync Basics
excluding files, 12.2.3 Using the Trailing Slash
verifying transfer, 12.2.4 Excluding Files and Directories
rsyslogd, 7.2.1 The System Logger
ruid (real user ID), 7.8 Understanding User IDs and User Switching
runlevel, 6.1 Introduction to init, Instances and Handoff, 6.5.4 Upstart Operation, 6.5.6
Upstart Runlevels and System V Compatibility
System V, 6.5.6 Upstart Runlevels and System V Compatibility
systemd, Instances and Handoff
Upstart, 6.5.4 Upstart Operation
run-parts, Modifying the Boot Sequence
runtime, 2.19 Linux Directory Hierarchy Essentials, Listing Shared Library
Dependencies
information, 2.19 Linux Directory Hierarchy Essentials
www.EBooksWorld.ir
library search path, Listing Shared Library Dependencies
S


ENGLISH
FREE AUDIO
website and app
www.dkefe.com
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
Author
Thomas Booth worked for 10 years as an English-language
teacher in Poland and Russia. He now lives in England, where
he works as an editor and English-language materials writer,
notably of course books and vocabulary textbooks.
ENGLISH
ENGLISH VOCABULARY BUILD ER
F O R E V E R Y O N E
4
ContentsUS Editors Kayla Dugger, Jenny Siklos
Senior Editor Laura Sandford
Project Editor Thomas Booth
Senior Art Editors Amy Child, Anna Hall
Art Editors Raymond Bryant, Michelle Staples,
Jemma Westing
Illustrators Edward Byrne, Michael Parkin, Gus Scott
Project Manager Christine Stroyan
Jacket Designer Surabhi Wadhwa
Jacket Editor Claire Gell
Jacket Design Development Manager Sophia MTT
Producer, Pre-production Gillian Reid
Producers Alex Bell, Anna Vallarino
Publisher Andrew Macintyre
Art Director Karen Self
Publishing Director Jonathan Metcalf
DK India
Project Art Editor Sanjay Chauhan
Art Editor Meenal Goel
Assistant Art Editor Devika Khosla
Project Editor Nisha Shaw
Illustrator Arun Pottirayil
Jacket Designer Juhi Sheth
Managing Jackets Editor Saloni Singh
Pre-production Manager Balwant Singh
Senior DTP Designer Vishal Bhatia
Managing Art Editor Sudakshina Basu
Managing Editor Rohan Sinha
First American Edition, 2018
Published in the United States by DK Publishing,
345 Hudson Street, New York, New York 10014
18 19 20 21 22 10 9 8 7 6 5 4 3 2 1
001—305538—Jan/2018
Copyright © 2018 Dorling Kindersley Limited
DK, a Division of Penguin Random House LLC
All rights reserved.
Without limiting the rights under copyright reserved above, no
part of this publication may be reproduced, stored in or introduced
into a retrieval system, or transmitted in any form or by any means
(electronic, mechanical, photocopying, recording, or otherwise)
without the prior written permission of the copyright owner.
Published in Great Britain by Dorling Kindersley Limited.
A catalog record for this book is available from the
Library of Congress.
ISBN 978-1-4654-6483-5
DK books are available at special discounts when purchased in
bulk for sales promotions, premiums, fund-raising, or educational
use. For details, contact DK Publishing Special Markets, 345
Hudson Street, NewYork, New York 10014 or SpecialSales@dk.com.
Printed in China
A WORLD OF IDEAS:
SEE ALL THERE IS TO KNOW
www.dk.com
Countries and nationalities 10
Numbers 14
Time expressions 18
Daily routines 22
Describing things: facts 26
Describing things: opinions 30
Sharing information 34
Common English idioms 38
Around the house 42
Kitchen implements and toiletries 46
HOME
How to use this book 8
GETTING STARTED
5
Studying 102
Speaking a foreign language 106
Communication and beliefs 110
Crime and the law 114
The body 62
Clothes 66
Accessories and beauty products 70
Appearance 74
Personality traits 78
Feelings and moods 82
Family tree 86
Family and relationships 90
Baby equipment and toys 94
Education 98
PEOPLE
Chores and cleaning 50
Tools and gardening 54
Moving and renting 58
FOOD AND DRINK
Meat, fish, dairy, and snacks 118
Fruit and nuts 122
Vegetables 126
Bread, desserts, and condiments 130
Drinking and eating 134
Eating in and eating out 138
WORK
Jobs 142
Working conditions 146
6
Transportation and travel 182
Driving a car 186
Maps and directions 190
Travel and accommodation 194
Travel and tourism 198
TRAVEL
THE ENVIRONMENT
Weather and climate 210
Geographical features 214
Environmental concerns 218
ANIMALS
Pets and farm animals 222
Wild animals 226
Birds and bugs 230
Fish, whales, and sea creatures 234
Free time activities 238
Abilities and actions 242
ACTIVITIES
Industries and departments 150
Office equipment 154
Money and finance 158
Working 162
Meeting and presenting 166
Work and business idioms 170
Applying for a job 174
Workplace skills and abilities 178
Camping and cycling 202
Beach 206
7
Answers 322
Word list 340
Acknowledgments 360
ARTS AND THE MEDIA
Books and reading 258
Music 262
Movies and plays 266
TV 270
Media and celebrity 274
Sickness 278
Medicine and treatment 282
Healthy eating 286
Fitness and well-being 290
HEALTH
SCIENCE AND TECHNOLOGY
AROUND TOWN
Around town 294
Shopping 298
At the supermarket 302
Urban life 306
Technology and gadgets 310
Technology and the future 314
Science 318
Sports 246
Soccer 250
Sports equipment and venues 254
8
How to use this book
Teaching spreads
Each unit of English for Everyone: English Vocabulary Builder
consists of a teaching spread and a practice spread. Teaching
spreads give you an illustrated vocabulary list on a particular
topic. Practice spreads include a variety of exercises to reinforce
what you have learned. Supporting audio
for each teaching spread is available on
the website and app. The best way to
learn spoken vocabulary is to listen to the
audio and repeat each word and phrase
on the spread. If you have difficulty
understanding a word or phrase, look it
up in your dictionary or the word list at
the back of this book.
PRACTICE SPREAD
TEACHING SPREAD
258 259
BOOKS
READING AND GENRES
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
Unit number The book is
divided into units. The unit
number helps you keep
track of your progress.
Modules Most teaching spreads are
broken down into modules covering
different aspects of a topic.
Module number Every module is
identified with a unique number, so
you can easily locate the related audio.
Write-on lines You
are encouraged to
write your own
translations of English
words to create your
own reference pages.
Sample sentences
Some modules show
useful English phrases
in the context of a
sample sentence.
Definitions Idiomatic English
phrases are accompanied
by definitions.
Audio support All teaching modules are
supported by audio recordings to help you
recognize and pronounce spoken vocabulary.
Supporting graphics Visual cues
help you understand and
remember new vocabulary.
296 297
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
AROUND TOWN
Around town
9
Practice exercises
Each teaching spread is followed by exercises that help to fix
new words and phrases in your memory. Working through
the exercises will help you to remember what you have
learned and to use and recognize new English vocabulary.
Answers are provided for every exercise.
FREE AUDIO
website and app
www.dkefe.com
Space for writing You are
encouraged to write your answers
in the book for future reference.
Sample answer
The first question
of each exercise
is answered for
you, to help make
the task easy to
understand.
Supporting graphics Visual
cues are given to help you
understand the exercises.
Exercise number Each exercise is
identified with a unique number, so
you can easily locate answers.
Exercise instruction Each exercise
is introduced with a brief instruction,
telling you what you need to do.
Listening exercise This
symbol indicates that
you should listen to an
audio track in order to
answer the questions in
the exercise.
Audio
English for Everyone: English Vocabulary Builder
features extensive supporting audio resources. Every
word and phrase in the teaching spreads is recorded,
and you are encouraged to listen to the audio and
repeat the words and phrases out loud, until you are
confident you understand and can pronounce what
has been said.
LISTENING EXERCISES
This symbol indicates that you should
listen to an audio track in order to
answer the questions in the exercise.
SUPPORTING AUDIO
This symbol indicates that audio
recordings of the words and phrases in a
module are available for you to listen to.
Answers
This book is designed to make
it easy to monitor your progress.
Answers are provided for every
exercise, so you can see how well
you have understood and
remembered the vocabulary you
have learned.
Exercise numbers
Match these numbers
to the unique identifier
at the top-left corner
of each exercise.
Answers Find the answers
to every exercise printed
at the back of the book.
156
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
EACH
MISS
10
Countries and nationalities
COUNTRIES
11
NATIONALITIES
12
FIND EIGHT MORE COUNTRIES IN THE GRID THAT MATCH THE FLAGS
MARK THE CORRECT COUNTRY FOR EACH FLAG
13
WRITE THE WORDS FROM THE
PANEL IN THE CORRECT GROUPS
NATIONALITIESCOUNTRIES
WRITE THE CORRECT
COUNTRY UNDER EACH FLAG
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
14
Numbers
NUMBERS
ORDINAL NUMBERS
15
LARGE NUMBERS
FRACTIONS, DECIMALS, AND PERCENTAGES
16
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
MATCH THE NUMBERS
TO THE CORRECT WORDS
17
LISTEN TO THE AUDIO AND
MARK THE CORRECT NUMBER
FOR EACH WORD YOU HEAR
WRITE THE CORRECT WORDS
NEXT TO EACH NUMBER
WRITE THE CORRECT WORDS UNDER EACH FRACTION
18
Time expressions
THE CALENDAR
19
SEASONS AND FREQUENCY
20
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
21
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
22
DAILY ROUTINES
Daily routines
23
24
MARK THE CORRECT PICTURE FOR EACH EXPRESSION
MATCH THE PICTURES TO THE CORRECT EXPRESSIONS
25
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
26
Describing things: facts
COLORS (US) / COLOURS (UK)
MATERIALS
27
ADJECTIVES
28
REWRITE THE WORDS, CORRECTING THE SPELLINGS
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE WORDS FROM THE
PANEL NEXT TO THEIR OPPOSITES
29
MARK THE CORRECT PICTURE FOR EACH WORD
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
30
OPINION ADJECTIVES
Describing things: opinions
31
GOOD
BAD
32
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
NEGATIVEPOSITIVE
33
LISTEN TO THE AUDIO AND
WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD
UNDER EACH PICTURE
34
Sharing information
BUSINESS CARDS
CONTACT DETAILS
35
FORMS OF COMMUNICATION
SENDING EMAILS
36
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
37
WRITE THE CORRECT WORD UNDER EACH PICTURE
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
38
Common English idioms
COMMON ENGLISH IDIOMS
[to have a sudden loss of confidence] [to feel unwell, sick, or ill]
[to help someone with something] [alert, knowledgeable, or competent]
[a nuisance, annoying, or difficult] [to take care of or watch carefully]
[completely and utterly
in love with someone]
[to describe exactly what is causing
a situation or problem]
[to hear information or news
through gossip or rumor]
[under time pressure
to get something done]
39
[to be kind and good-natured] [to be unwilling to commit or make a decision]
[to not completely believe
something or someone]
[to confront the consequences
of your actions]
[to tease or fool someone]
[to tell a secret to someone who
shouldn’t know about it]
[someone who seeks and gets approval
from a person in a position of authority]
[to do something the easiest or shortest
way, at the expense of high standards]
[an overreaction or a lack of restraint] [to let yourself go or relax]
40
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE PICTURES TO THE CORRECT SENTENCES
41
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
42
Around the house
HOMES, ROOMS, AND FURNITURE
43
44
MATCH THE PICTURES
TO THE CORRECT WORDS
CIRCLE THE WORD THAT DOES
NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
45
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURES BELOW, THEN WRITE THE NAME OF EACH
OBJECT UNDER THE CORRECT ROOM
KITCHEN BATHROOM LIVING ROOM BEDROOM
46
KITCHEN IMPLEMENTS
Kitchen implements and toiletries
47
TOILETRIES AND BATHROOM EQUIPMENT
48
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT ROOM
MARK THE BEGINNING AND END OF EACH WORD IN THE CHAIN
OF LETTERS, THEN WRITE THE WORDS YOU FIND
BATHROOMKITCHEN
49
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
50
Chores and cleaning
HOUSEHOLD CHORES
51
LAUNDRY AND CLEANING
52
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
REWRITE THE WORDS OR EXPRESSIONS, CORRECTING THE SPELLINGS
53
MATCH THE EXPRESSIONS TO
THE CORRECT PICTURES
LISTEN TO THE AUDIO AND
WRITE THE EXPRESSION THAT IS
SHOWN IN EACH PICTURE
COMPLETE THE EXPRESSION
FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
54
Tools and gardening
TOOLS AND HOME IMPROVEMENT
55
HOME IMPROVEMENT VERBS
GARDENING EQUIPMENT
GARDENING VERBS
56
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
57
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
GARDENING
EQUIPMENTTOOLS
58
Moving and renting
ACCOMMODATION, MOVING, AND RENTING
59
USEFUL EXPRESSIONS
[money that a tenant pays to a landlord
before moving into a property]
[a letter describing your character
and ability to pay your rent]
[an informal party that you give after
moving into a new house or apartment]
[the rent covers the bills such as
electricity, water, and gas]
[houses and apartments that are for sale
or rented out]
[a part of town where most buildings
are houses or apartments]
[belonging to the area where you live]
[a person you share your house
or apartment with]
[a person who pays to live in your house]
[to announce to your landlord that
you wish to move out]
60
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
61
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
houses and apartments that are for sale or
rented out
a letter describing your character and ability
to pay rent
a part of town where most buildings are houses
or apartments
belonging to the area where you live
money that a tenant pays to a landlord before
moving into a property
the rent covers the bills such as electricity, water,
and gas
62
The body
PARTS OF THE BODY
63
VERBS
64
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FROM
THE PANEL FOR EACH LABEL
65
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
66
Clothes
CLOTHES
67
DESCRIBING CLOTHES AND STYLES
VERBS
68
WRITE THE
CORRECT WORD
UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE
THE CORRECT WORD FOR EACH LABEL
REWRITE THE WORDS, CORRECTING
THE SPELLINGS
69
FIND EIGHT MORE WORDS FOR DESCRIBING CLOTHES IN THE GRID
THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
70
ACCESSORIES
Accessories and beauty products
71
MAKE-UP AND BEAUTY PRODUCTS
SHOES
72
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
73
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
74
Appearance
HAIR
VERBS
75
APPEARANCE AND STYLE
EYES
76
WRITE THE CORRECT WORDS
UNDER EACH PICTURE
MATCH THE WORDS TO
THE CORRECT PICTURES
77
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
78
DESCRIBING PERSONALITY
Personality traits
79
80
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
WRITE THE CORRECT WORD UNDER EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
81
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
82
Feelings and moods
FEELINGS AND MOODS
83
84
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
85
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
WRITE THE WORDS FROM
THE PANEL NEXT TO THEIR
OPPOSITES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
86
Family tree
JAMAL’S FAMILY
DEBBIE’S FAMILY ANA’S FAMILY
87
GROWING UP
ROGER’S FAMILY LOGAN’S FAMILY
RELATIONSHIPS
88
FILL IN THE GAPS ON JAMAL’S FAMILY TREE
MATCH THE PICTURES TO THE CORRECT WORDS
89
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
FILL IN THE GAPS ON
LOGAN’S FAMILY TREE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
90
Family and relationships
[to have respect and admiration for someone]
[to have characteristics
of a parent or relative]
[to care for a child and teach them how to behave] [to develop from a child to an adult]
[to begin to love someone] [to end a romantic relationship]
[to have a good relationship
with someone]
[to stop being friends with someone,
often after an argument]
[to slowly become less friendly
or close to someone] [to become friendly with a person]
USEFUL EXPRESSIONS
91
[a friend who you know very well] [to share an interest or opinion]
[to have a child] [to be a common feature of a family]
[to meet someone unexpectedly] [to be strict about something]
[to agree with or have similar opinions
to someone]
[to like someone quickly
and easily]
[to speak out in support of someone]
[to have a very high opinion
of someone]
92
MATCH THE PICTURES TO THE CORRECT SENTENCES
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
93
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
94
Baby equipment and toys
EQUIPMENT AND CLOTHES
95
TOYS AND GAMES
96
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO,
THEN NUMBER THE PICTURES
IN THE ORDER YOU HEAR THEM
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
97
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE CORRECT
PLACES ON THE GRID
TOYSEQUIPMENT
98
SUBJECTS
Education
99
STUDYING AND EXAMS (NOUNS)
STUDYING AND EXAMS (VERBS)
100
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
101
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
WRITE THE CORRECT WORD
UNDER EACH PICTURE
102
Studying
USEFUL EXPRESSIONS
[to have a year away from education or work] [to register to start something]
[someone studying for a
first degree at college or university]
[study carried out following graduation
from a first degree]
[a student in their first year at
college or university]
[a period of time in an academic calendar,
during which classes are held]
[to be awarded a diploma / qualification
after college or university] [to go to lessons or lectures]
[to provide comments and advice on
how somebody is doing something]
[to answer questions or perform
actions to show how much you
know about something]
103
[to finish something within a given time] [to fail to finish something within a given time]
[grading based on work done
over a long period] [to perform excellently on a test]
[a first, rough version of a piece of written work]
[to consider and describe the similarities
and differences between things]
[completely different] [an obvious difference]
[a significant level of difference][surprisingly not alike]
104
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
105
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to fail to finish something within a given time
someone studying for a first degree at college or university
a first, rough version of a piece of written work
a student in their first year at college or university
grading based on work done over a long period
to perform excellently on a test
106
Speaking a foreign language
USEFUL EXPRESSIONS
[language that is not technically perfect,
but clear enough for basic communication]
[able to use a language easily,
without making many mistakes]
[a person who speaks a language
as their first language]
[able to speak two languages fluently] [the set of words that make up a language]
[the ability to understand
spoken language]
[not as fluent in a language
as you used to be]
[the way in which people from a
country or region pronounce a word]
[the way a specific word is spoken]
[the way in which you make
sentences from separate words]
107
[the ability to communicate
using spoken language]
[the ability to understand written materials]
[the ability to communicate
using written words]
[a shared language that allows people from
various countries to understand each other]
[a piece of writing that has been changed
from one language to another]
[difficulty communicating with someone
who speaks another language]
[to be able to express basic information
and ideas to people]
[to speak without making mistakes]
[to be able to learn something in little time]
[to be able to understand languages
without difficulty]
108
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
WRITE THE CORRECT EXPRESSION NEXT TO ITS DEFINITION
the way people from a country or region pronounce a word
able to speak two languages fluently
a person who speaks a language as their first language
the ability to communicate using spoken language
to speak without making mistakes
the set of words that make up a language
able to use a language easily, without making many mistakes
the way in which you make sentences from separate words
109
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
110
Communication and beliefs
USEFUL EXPRESSIONS
[to say something that is not true to
avoid upsetting someone] [to say something indirectly]
[to talk about other people,
often in a negative way]
[to think that something exists
or is true]
[to have an idea about
something with little evidence]
[to wish for good luck, or avoid bad luck] [to hope for something to happen]
[somebody who tells an authority
figure when another person has done
something wrong]
[to have a strong feeling that something
is not right]
[to say things that may not be true]
111
[a group of values] [a firm and unchangeable conviction]
[stories, sayings, and traditions
from a certain area or culture][good fortune with no skill involved]
[a single piece of good fortune]
[good fortune the first
time you do something]
[a positive / negative sign about
something that will happen]
[a modern story that is untrue,
but believed by many]
[a traditional story with magic,
usually written for children]
[information or news transmitted
by people telling other people]
112
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
113
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to hope for something to happen
good fortune with no skill involved
a modern story that is untrue, but believed by many
stories, sayings, and traditions from a certain area or culture
to talk about other people, often in a negative way
to wish for good luck, or avoid bad luck
114
Crime and the law
CRIME
PUNISHMENT AND THE LAW
115
USEFUL EXPRESSIONS
[to break the law] [to spend time in prison]
[to use the power of the law to take
and question somebody] [to make people obey a rule or a law]
[a lot of crimes happening suddenly
in the same area]
[crime committed in a public place]
[financial, nonviolent crime]
[to decide on a punishment in
accordance with the law]
[to decide officially that someone
has (not) broken the law]
[to come to a decision about
somebody’s guilt or innocence]
116
WRITE THE CORRECT WORD
UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
117
MARK THE SENTENCES THAT ARE CORRECT
FILL IN THE GAPS USING THE WORDS IN THE PANEL
118
Meat, fish, dairy, and snacks
MEAT
FISH AND SEAFOOD
119
DAIRY
FAST FOOD AND LIGHT SNACKS
120
LOOK AT THE PICTURES BELOW, THEN WRITE THE ANSWERS UNDER THE
CORRECT HEADING
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
FAST FOODMEAT DAIRYSEAFOOD
121
MATCH THE PICTURES
TO THE CORRECT WORDS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
122
FRUIT
Fruit and nuts
123
NUTS AND DRIED FRUIT
124
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
125
CIRCLE THE WORD THAT DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
126
Vegetables
VEGETABLES
127
128
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
129
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING
IN THE MISSING LETTERS
130
BREAD, PASTA, AND DESSERTS
Bread, desserts, and condiments
131
FLAVORINGS AND CONDIMENTS
132
MARK THE CORRECT PICTURE FOR EACH WORD
MATCH THE PICTURES TO THE CORRECT WORDS
133
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS
SHOWN IN EACH PICTURE
REWRITE THE WORDS, CORRECTING THE SPELLINGS
134
Drinking and eating
DRINKS
FOOD AND DRINK CONTAINERS
135
FOOD AND DRINK: ADJECTIVES EATING AND DRINKING
136
MATCH THE WORDS TO THE
CORRECT PICTURES
FILL IN THE MISSING LETTERS
FOR EACH WORD
137
WRITE THE CORRECT VERB UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
138
Eating in and eating out
MEALS
FOOD PREPARATION
139
EATING OUT: VERBS
EATING OUT: NOUNS
140
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
141
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
142
Jobs
JOBS
143
144
MARK THE CORRECT JOB FOR THE PERSON IN EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN
THE CHAIN OF LETTERS
145
MATCH THE WORDS TO THE CORRECT PICTURES
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
146
Working conditions
EMPLOYMENT VERBS
147
PAY AND CONDITIONS
[an amount of money paid per hour]
[extras given to employees in
addition to their usual pay]
[an amount of money paid
per week or month]
[a fixed, regular payment, often
expressed as an annual sum]
[a new job at the same company that is
more senior or better paid]
[to lose your job because it is no
longer necessary]
[a reduction in pay]
[an increase in pay]
[additional pay for extra hours worked]
[money added to a person’s salary
as a reward for good performance]
148
FIND SEVEN MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT VERB UNDER EACH PICTURE
149
WRITE THE CORRECT WORD OR PHRASE NEXT TO ITS DEFINITION,
FILLING IN THE MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
extras given to employees in addition to their usual pay
an amount of money paid per week or month
a reduction in pay
an increase in pay
an amount of money paid per hour
additional pay for extra hours worked
150
Industries and departments
INDUSTRIES
151
DEPARTMENTS
[deals with organization and internal
and external communication]
[ensures that all manufacturing
stages run smoothly]
[researches and develops
future products for a company]
[buys goods and raw materials
for manufacturers and
other companies]
[deals with employee relations
and matters such as hiring staff]
[sells products to buyers
and outside markets]
[deals with money matters, from
paying bills to projecting sales]
[carries out cleaning, maintenance, and
building operation services]
[promotes products for
companies to the market]
[ensures that all contracts and
company activities are legal]
[presents and maintains a positive
public image for a company]
[sets up and maintains all
technological systems
in an organization]
152
MATCH THE WORDS TO THE
CORRECT PICTURES
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
153
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
THEY ARE MENTIONED
WRITE THE NAME OF THE DEPARTMENT NEXT TO ITS DEFINITION
ensures that all manufacturing stages run smoothly
deals with employee relations and matters such as hiring staff
deals with money matters, from paying bills to projecting sales
ensures that all contracts and company activities are legal
deals with organization and internal and external communication
presents and maintains a positive public image for a company
sells products to buyers and outside markets
promotes products for companies to the market
154
Office equipment
IN THE OFFICE
EQUIPMENT
155
STATIONERY
156
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
157
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
158
Money and finance
MONEY
159
FINANCE
[money coming into a business]
[to get into a situation where
you owe people money]
[the amount of money that is
available to spend on something ]
[to lose money by spending more
than you earn]
[extra money the bank allows you
to spend]
[the amount of one currency that you
get when you change it for another]
[to earn just enough to cover the
costs of producing a product]
[to no longer be able to exist
as a business]
[an amount of money spent] [a major decline in economic activity]
160
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
161
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
162
Working
USEFUL EXPRESSIONS
[a job with regular hours]
[to suddenly become more successful]
[knowledge and skill gained through
doing something yourself]
[a position with the lowest level
of responsibility or pay]
[to be forced to leave your job
for doing something wrong]
[the conditions in which you work]
[progression within a profession,
in a job, or through a series of jobs]
[a position without many
prospects for promotion]
[to lose your job because the company
can no longer give you work]
[to have a job]
163
[to stop doing a job voluntarily]
[to aim to achieve a particular goal]
[to employ someone]
[to be busy with a task or
many tasks]
[to do more than you are required to do]
[to deal with something directly]
[to make more progress than others]
[very busy with too much work]
[extremely busy]
[compromise]
164
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
to make more progress than others
to suddenly become more successful
to employ someone
compromise
to stop doing a job voluntarily
a job with regular hours
165
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
CROSS OUT THE INCORRECT WORD IN EACH SENTENCE
166
Meeting and presenting
USEFUL EXPRESSIONS
[to go to a meeting]
[included in a list of things to discuss]
[a telephone call with a number
of people at the same time]
[a vote made by raising hands in
the air to show agreement]
[to present a formal talk
to an audience]
[not present]
[a group of people who manage
a business or organization]
[when everyone agrees]
[to answer questions]
[to write a record of what is said
during a meeting]
167
[to come to an agreement
about an issue]
[any matter discussed in a meeting
that is not on the agenda]
[the primary aim]
[a plan for achieving a particular goal]
[to give a brief summary]
[to look again at the written record
of a past meeting]
[to conclude or finish something]
[to disturb a meeting or say
something before someone
else has finished speaking]
[proposals for specific
action to be taken] [to have no time left for something]
168
MATCH THE PICTURES TO THE CORRECT SENTENCES
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
169
MARK THE SENTENCES THAT ARE CORRECT
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
included in a list of things to discuss
to give a brief summary
to go to a meeting
the primary aim
to come to an agreement about an issue
not present
to have no time left for something
to present a formal talk to an audience
proposals for specific action to be taken
a plan for achieving a particular goal
170
Work and business idioms
WORKPLACE IDIOMS
[the normal daily routine at a company]
[administration, paperwork,
or rules and regulations]
[owing money or making a loss]
[it is your turn to do
or say something]
[to start something]
[a situation with no
negative outcome]
[to think about something
in an original way]
[to change the desired end result]
[to start work on something
that needs doing]
[to waste money]
171
BUSINESS IDIOMS
[ahead of your competitors
in a certain field]
[in agreement
about something]
[to do something strictly according
to the rules]
[to talk to someone briefly in order
to catch up or get an update]
[to confirm or settle an
agreement or contract]
[an increase or decrease in speed
from what is normal]
[a strategy worked out beforehand]
[simply and quickly]
[a rough estimate]
[to dominate a particular market]
172
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
173
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
174
Applying for a job
RÉSUMÉ HEADINGS
175
VERBS
USEFUL EXPRESSIONS
[a long list of achievements]
[having a lot of contact with customers]
[an expert understanding of something]
[highly skilled at something]
[taught how to do something]
[having control over someone or something]
176
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE RÉSUMÉ AND WRITE THE CORRECT WORD FROM THE
PANEL FOR EACH LABEL
177
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
WRITE THE CORRECT WORD UNDER EACH PICTURE
178
PROFESSIONAL ATTRIBUTES
Workplace skills and abilities
179
FOR THE WORKPLACE
180
MARK THE CORRECT WORD FOR EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
181
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
MATCH THE PICTURES TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
182
FORMS OF TRANSPORTATION
Transportation and travel
183
VERBSTRAVEL
184
MATCH THE VERBS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
185
FIND NINE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
186
DRIVING VOCABULARY
Driving a car
187
VERBS
188
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT EXPRESSION UNDER EACH PICTURE
189
MARK THE CORRECT EXPRESSION FOR EACH PICTURE
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
190
Maps and directions
MAPS AND DIRECTIONS
191
PREPOSITIONS OF PLACE VERBS
192
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
WRITE THE CORRECT WORD UNDER EACH PICTURE
193
MATCH THE PICTURES
TO THE CORRECT VERBS
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE
FOR EACH WORD YOU HEAR
194
Travel and accommodation
VERBS
GOING ON VACATION (US) / HOLIDAY (UK)
195
WHERE TO STAY
VERBS
196
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
MATCH THE PICTURES TO THE CORRECT VERBS
197
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
198
Travel and tourism
USEFUL EXPRESSIONS
[to go somewhere relaxing for a break]
[unique and unrepeatable]
[a feeling of confusion or distress
when visiting a different place or culture]
[in a bad condition through lack of
care or repair]
[a desire to travel or move]
[a place that attracts too
many tourists]
[to be sad because you miss
your home and family]
[a long way from other people,
buildings, and roads]
[not changed, damaged,
or built on by people]
[a desire for exciting experiences]
199
[to explore an area or place]
[to pause a trip in one
place before continuing]
[at a time of year when a tourist
destination is less popular]
[a stage in a trip from
one place to another]
[to feel excited about something
that is going to happen]
[to go to the station or airport to
say goodbye to someone]
[a vacation, particularly a short one]
[to find out how interesting
something is]
[to book something several days
or weeks before you need it]
[totally unable to find your way]
200
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
REWRITE THE SENTENCES, CORRECTING THE ERRORS
201
MARK THE SENTENCES THAT ARE CORRECT
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
202
Camping and cycling
CAMPING
203
CYCLING
204
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
MATCH THE PICTURES
TO THE CORRECT WORDS
WRITE THE CORRECT WORD UNDER EACH PICTURE
205
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
206
Beach
AT THE BEACH
207
208
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE BEGINNING AND ENDING OF EACH WORD OR EXPRESSION
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
209
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
210
Weather and climate
WEATHER
211
TEMPERATURE ADJECTIVES
212
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT WORDS
213
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
214
GEOGRAPHICAL FEATURES
Geographical features
215
216
MARK THE BEGINNING AND ENDING OF EACH GEOGRAPHICAL FEATURE
IN THE CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
WRITE THE CORRECT WORD UNDER EACH PICTURE
217
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR EACH LABEL
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
218
Environmental concerns
USEFUL EXPRESSIONS
[the increase in the Earth’s temperature]
[gases that cause the greenhouse
effect, heating up the Earth]
[to use a supply of something,
such as fuel or energy]
[to deal with the problem of pollution]
[types of energy that do not
damage the environment]
[changes in the Earth’s weather patterns]
[fuels based on oil, coal, and gas]
[to lower the level of carbon dioxide
produced by your actions]
[energy that does not use fossil fuels]
[energy from sources that do
not run out]
219
[causing damage to the environment]
[energy created using sunlight]
[energy created using the wind]
[at risk of extinction]
[the act of damaging something
so badly that it cannot survive
or be repaired]
[very bad results]
[a panel that turns
sunlight into electricity]
[a place with many turbines for
generating wind power]
[no longer existing]
[permanent change that cannot
be undone]
220
WRITE THE CORRECT PHRASE NEXT TO ITS DEFINITION, FILLING IN THE
MISSING LETTERS
MATCH THE PICTURES TO THE CORRECT SENTENCES
221
REWRITE THE SENTENCES, CORRECTING THE ERRORS
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT
DESCRIBE EACH PICTURE
222
Pets and farm animals
PETS AND FARM ANIMALS
223
ANIMAL VERBS ANIMAL EQUIPMENT
224
MATCH THE PICTURES
TO THE CORRECT WORDS
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
225
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
226
WILD ANIMALS
Wild animals
227
VERBS
228
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN IN
EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
229
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
230
Birds and bugs
BIRDS
231
INSECTS AND BUGS
VERBS FOR BIRDS AND BUGS
232
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
MATCH THE PICTURES TO THE CORRECT VERBS
BIRDSBUGS
233
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
MARK THE WORDS YOU HEAR
COMPLETE THE WORD FOR EACH PICTURE, FILLING IN THE
MISSING LETTERS
234
Fish, whales, and sea creatures
FISH AND SEA CREATURES
235
WHALES
236
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
237
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
WRITE THE CORRECT WORD
UNDER EACH PICTURE
238
FREE TIME ACTIVITIES
Free time activities
239
240
MARK THE CORRECT VERB FOR THE ACTIVITY IN EACH PICTURE
MATCH THE ACTIVITIES TO THE CORRECT PICTURES
241
LISTEN TO THE AUDIO AND WRITE THE ACTIVITY THAT IS
SHOWN IN EACH PICTURE
WRITE THE CORRECT ACTIVITY UNDER EACH PICTURE
242
Abilities and actions
ABILITIES AND ACTIONS
243
244
LISTEN TO THE AUDIO, THEN NUMBER THE ACTIONS IN THE
ORDER YOU HEAR THEM
WRITE THE CORRECT ACTION UNDER EACH PICTURE
245
MATCH THE ACTIONS TO THE CORRECT PICTURES
MARK THE CORRECT PICTURE FOR EACH ACTION
246
SPORTS
Sports
247
ADVENTURE SPORTS
248
MARK THE BEGINNING AND ENDING OF EACH SPORT IN THE
CHAIN OF LETTERS, THEN WRITE THE WORDS YOU FIND
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
249
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH SPORT YOU HEAR
COMPLETE THE WORDS FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
250
Soccer
TIMINGS AND RULES
SOCCER GAME
251
VERBS
252
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
WRITE THE CORRECT WORD OR EXPRESSION UNDER EACH PICTURE
253
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE WORDS TO THE CORRECT PICTURES
254
EQUIPMENT
Sports equipment and venues
255
VENUES
256
MATCH THE WORDS TO THE CORRECT PICTURES
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
257
REWRITE THE WORDS, CORRECTING THE SPELLINGS
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
VENUESEQUIPMENT
258
BOOKS
Books and reading
USEFUL EXPRESSIONS
[highly positive reviews]
[a series of events that make up a story]
[a novel that makes you want
to read more]
[to take a quick look inside a book]
[a book that sells a large number of copies]
[containing difficult or intellectual ideas]
259
READING AND GENRES
260
WRITE THE CORRECT WORD UNDER EACH PICTURE
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
261
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
262
Music
VERBS
MUSICAL INSTRUMENTS
263
MUSICAL GENRES
PERFORMANCE
264
MARK THE CORRECT WORD OR EXPRESSION FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
265
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
MATCH THE PICTURES
TO THE CORRECT WORDS
266
Movies and plays
MOVIES
267
PLAYS AND SHOWS
268
MATCH THE PICTURES TO THE CORRECT WORDS
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LISTEN TO THE AUDIO AND
CIRCLE THE WORDS YOU HEAR
269
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT
WORD FOR EACH LABEL
270
VERBS
WATCHING TELEVISION
TV
271
TV SHOWS AND CHANNELS
272
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
MATCH THE PICTURES
TO THE CORRECT WORDS
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
273
FIND EIGHT MORE WORDS IN THE GRID THAT MATCH THE PICTURES
WRITE THE CORRECT WORD UNDER EACH PICTURE
274
Media and celebrity
USEFUL EXPRESSIONS
[to make something more
dramatic or exciting than it is]
[to use something or someone
for your own gain]
[someone who is known by most people]
[to make somebody feel more
important than they are]
[the large text at the top of
a newspaper page]
[to reveal something hidden]
[to become a famous person]
[to be very famous]
[seen and well known by the public]
[news that is widely reported]
275
[the popular culture that surrounds
famous people]
[a competition with performances by
entertainers showcasing their skills]
[photographers who take pictures of
famous people without their consent]
[a carpet for important guests
to walk or stand on at an event]
[an interview that no other source
has obtained]
[the thing that somebody or something
is known for, often said jokingly]
[a show based on or around
real-life events]
[the first night of a show or movie]
[a very rapid rise, often in a career]
[designed or intended to get
your attention quickly]
276
REWRITE THE SENTENCES, CORRECTING THE ERRORS
MATCH THE PICTURES TO THE CORRECT SENTENCES
277
MATCH THE BEGINNINGS OF THE SENTENCES TO THE CORRECT ENDINGS
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
278
Sickness
ADJECTIVES FOR SICKNESS
SICKNESS AND CONDITIONS
279
VERBS FOR SYMPTOMS
SYMPTOMS
ACCIDENTS AND INJURIES
280
LISTEN TO THE AUDIO AND WRITE THE WORD THAT IS SHOWN
IN EACH PICTURE
MARK THE CORRECT PICTURE FOR EACH WORD
281
FILL IN THE GAPS, PUTTING THE WORDS FROM THE PANEL INTO THE
CORRECT CATEGORIES
LOOK AT THE PICTURE CLUES AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
INJURIESSICKNESS
282
Medicine and treatment
MEDICINE AND TREATMENT
283
FIRST AID
VERBS
284
MATCH THE WORDS TO THE
CORRECT PICTURES
REWRITE THE WORDS,
CORRECTING THE SPELLINGS
285
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
MARK THE BEGINNING AND ENDING OF EACH WORD IN THE
CHAIN OF LETTERS
LISTEN TO THE AUDIO, THEN NUMBER THE PICTURES IN THE ORDER
YOU HEAR THEM
286
Healthy eating
NUTRITION AND DIETS
287
USEFUL EXPRESSIONS
[the amount of food you eat in one meal]
[to eat or drink less of something]
[to stop eating or drinking something]
[to try to avoid gaining weight]
[unable to eat or drink something
without having a bad reaction]
[containing a large amount of something]
[containing a small amount of something]
[containing a lot of something healthy]
[to avoid eating too much of something]
[food that is quick and easy to make]
288
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO AND
MARK THE CORRECT PICTURE FOR
EACH WORD YOU HEAR
289
MARK THE SENTENCES THAT ARE CORRECT
REWRITE THE SENTENCES, CORRECTING THE ERRORS
290
Fitness and well-being
AT THE GYM
VERBS FOR FITNESS
291
WELL-BEING
FITNESS
292
MARK THE CORRECT WORD FOR EACH PICTURE
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
293
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
294
AROUND TOWN
Around town
295
296
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD
FOR EACH LABEL
FIND FIVE MORE WORDS IN THE GRID THAT MATCH THE PICTURES
297
WRITE THE CORRECT WORD UNDER EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
298
Shopping
STORES (US) / SHOPS (UK)
VERBS
299
USEFUL EXPRESSIONS
[searching for goods that are
cheaper than normal]
[an open-air market that sells
old or used items]
[looking at goods in store windows
without buying them]
[having only a small amount of
money to spend]
[to reduce prices dramatically]
[a low-quality product that costs
more than it should]
[a 50 percent reduction]
[a good price]
[costing too much]
[to compare prices at various stores]
300
WRITE THE CORRECT WORD UNDER EACH PICTURE
MARK THE CORRECT WORD FOR EACH PICTURE
301
LISTEN TO THE AUDIO AND COMPLETE THE SENTENCES THAT DESCRIBE
EACH PICTURE
MATCH THE DEFINITIONS TO THE CORRECT PHRASES
a good price
to reduce prices dramatically
having only a small amount of money to spend
an open-air market that sells old or used items
to compare prices at various stores
a low-quality product that costs more than it should
searching for goods that are cheaper than normal
costing too much
302
AT THE CHECKOUT
SUPERMARKET
At the supermarket
303
DEPARTMENT STORE
304
REWRITE THE WORDS, CORRECTING THE SPELLINGS
LOOK AT THE PICTURE AND WRITE THE CORRECT WORD FOR
EACH LABEL
305
COMPLETE THE WORD FOR
EACH PICTURE, FILLING IN THE
MISSING LETTERS
MATCH THE WORDS TO THE
CORRECT PICTURES
LISTEN TO THE AUDIO, THEN
NUMBER THE PICTURES IN THE
ORDER YOU HEAR THEM
306
Urban life
USEFUL EXPRESSIONS
[the period of the day when most
people travel to or from work]
[a larger number of shops,
restaurants, and services]
[the frequency of crimes
in an area]
[a line of traffic that is unable
to move]
[buildings that have not been
repaired for many years]
[containing people or cultures
from around the world]
[an urban area that is outside the
center of a town or city]
[buildings that have been
important in history]
[outdoor areas with grass or vegetation]
[illegal damage to or
destruction of property]
307
[nighttime entertainment such
as bars, cafés, and nightclubs]
[a place that attracts large
numbers of tourists]
[harmful substances in air or water]
[how quickly people lead their lives]
[when there are too many
people in one place]
[repairs that are made to roads]
[a festival that often involves
people dancing in the street] [the chances you have of finding a job]
[active and full of energy]
[the basic services
that a city needs to run well]
308
FILL IN THE GAPS USING THE WORDS IN THE PANEL
MATCH THE PICTURES TO THE CORRECT SENTENCES
309
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
310
Technology and gadgets
DIGITAL TECHNOLOGY
311
VERBS
312
WRITE THE CORRECT WORD UNDER EACH PICTURE
MATCH THE VERBS TO THE CORRECT PICTURES
313
LISTEN TO THE AUDIO
AND WRITE THE WORD THAT
IS SHOWN IN EACH PICTURE
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
LOOK AT THE PICTURE CLUES
AND WRITE THE ANSWERS IN THE
CORRECT PLACES ON THE GRID
314
Technology and the future
USEFUL EXPRESSIONS
[to affect something powerfully] [inventiveness or creation of new ideas]
[to say what you think might
happen in the future]
[a huge change in ideas or methods]
[what will happen in the future]
[eventually, after a long time]
[an era based on digital information,
when technology is dominant]
[extremely modern and innovative]
[the way things are likely to
develop in the future]
[the most recent version of a product]
315
[an important discovery or achievement] [able to use computer technology effectively]
[very modern and up-to-date]
[a person who enjoys using
new technology]
[a person who dislikes or refuses
to use new technology]
[no longer needed or useful
because of a new invention]
[much more advanced than its competitors]
[to design something to work in the
future, even if technology changes]
[sure to happen at some
point in the future]
[the results will only become clear
in the future]
316
CROSS OUT THE INCORRECT WORDS IN EACH SENTENCE
MATCH THE PICTURES TO THE CORRECT SENTENCES
317
FILL IN THE GAPS, PUTTING THE WORDS IN THE CORRECT ORDER
LISTEN TO THE AUDIO, THEN NUMBER THE SENTENCES
IN THE ORDER YOU HEAR THEM
318
SCIENCE AND SCIENTIFIC EQUIPMENT
319
VERBS
320
CIRCLE THE WORD THAT
DOES NOT BELONG IN EACH LIST
LOOK AT THE PICTURE AND
WRITE THE CORRECT WORD FOR
EACH LABEL
REWRITE THE WORDS, CORRECTING THE SPELLINGS
321
MARK THE CORRECT WORD ILLUSTRATED IN EACH PICTURE
LISTEN TO THE AUDIO AND MARK THE CORRECT PICTURE FOR EACH
WORD YOU HEAR
322
Answers
COUNTRIES:
Russia, United Kingdom / UK, Poland,
Pakistan, Japan
NATIONALITIES:
Russian, British, Polish,
Pakistani, Japanese
323
POSITIVE:
fantastic, breathtaking, incredible,
fun, amazing, exciting
NEGATIVE:
awful, disastrous, annoying,
nasty, disgusting, terrible
324
KITCHEN:
dishwasher, refrigerator / fridge,
stove (US) / cooker (UK),
cabinet (US) / cupboard (UK)
BATHROOM:
bathtub (US) / bath (UK), toilet,
sink, shower
LIVING ROOM:
armchair, cushion,
couch (US) / sofa (UK),
television / TV
BEDROOM:
bed, bedside table,
lamp, wardrobe
KITCHEN:
whisk, knife, frying pan,
bowl, plate, cup
BATHROOM:
mouthwash, conditioner, sponge,
shampoo, soap, toothbrush
TOOLS:
paintbrush, hammer, hacksaw,
plane, file, jigsaw
GARDENING EQUIPMENT:
hoe, rake, sprinkler,
hose, wheelbarrow, trowel
325
326
EQUIPMENT:
baby monitor, bottle, bib,
potty, high chair, wet wipe
TOYS:
spinning top, puppet,
building blocks, playing cards
kite, slide
327
MEAT:
sausages, chicken,
lamb, ham
SEAFOOD:
sardines, salmon,
lobster, sushi
DAIRY:
milk, fried egg,
butter, cheese
FAST FOOD:
hot dog, fries (US) / chips (UK),
pizza, kebab
328
329
330
331
332
333
334
BUGS:
moth, spider, wasp,
caterpillar, ant, snail
BIRDS:
hawk, vulture, penguin,
duck, swan, dove
335
336
EQUIPMENT:
skis, pool cue, fishing rod,
helmet, roller skates, baseball bat
VENUES:
tennis court, ice rink, stadium,
ski slope, golf course, running track
337
SICKNESS:
food poisoning, diabetes,
appendicitis, chickenpox,
mumps, cold
INJURIES:
broken bone, wound, bruise,
burn, sting, cut
338
339
340
artichokes 30
article 63
artist 34
ask directions 46
asparagus 30
assertive 18
assistant 35
asthma 68
ATM 38
attachment 7
attend a meeting 40
attend classes 24
attention to detail 43
attention-grabbing 67
attic 9
attract 78
aubergines 30
audience 65
August 3
aunt 20
Australia 1
author 63
auto repair shop 45
autobiography 63
autumn 3
avenue 46
avocados 30
awful 6
ax / axe 12
Bbaby 20
baby carriage 22
baby changing facilities 74
baby equipment 22
baby monitor 22
babygro 22
back up 76
backache 68
backpack 16, 49
bacon 28
bad 6
bad omen 26
badge 16
badminton 60
bag 32
bagel 31
bait 62
bake 33, 58
baker 73
balanced diet 70
balcony (building) 9
balcony (theater / theatre) 65
bald 17
ball 22, 61, 62
allergies 68, 70
all-inclusive 47
alternative energy 53
always 3
amazed 19
amazing 6
ambitious 43
ambulance 69
American 1
American football 60
amused 19
anemone 57
angry 19
ankle 14
annoyed 19
annoying 6
annual leave 35
annual vacation 35
ant 56
antelope 55
antiseptic 69
antiseptic wipes 69
anxious 19
any other business 40
AOB 40
apartment block 9
apartments 13, 47
appearance 17
appendicitis 68
appetizer 33
applause 65
apple 29
application form 42
apply for a job 42
appointment 69
apprentice 35
approachable 18
apricot 29
April 3
aquarium 54
archery 60
architect 34
architecture 23
Argentina 1
Argentinian 1
arm 14
armadillo 55
armband 62
armchair 9
aromatherapy 71
arrange flowers 58
arrest somebody 27
arrive late 4
arrogant 18
arrow 62
art 23
Numbers refer to the unit number.
Words separated by a forward slash
usually indicate the differences between
US and UK spelling.
Aabilities 59
able to drive 43
abseiling 60
absent 40
accent 25
accessories 16
accident 68
accommodation 13, 47
Accounts (department) 36
accurate 43
ache 68
across from 46
act 59
action movie 65
action points 40
actions 59
actor 34
acupuncture 71
adaptable 43
add 33, 59
adhesive bandage 69
adhesive tape 37, 69
administration 43
Administration (department) 36
adults 20
advertising industry 36
adverts 66
aerobics 71
aeroplane 44
aerospace industry 36
afternoon 3
aftershave 16
against the clock 8
agriculture 36
ahead 46
ahead of the game 41
air bed 49
air mattress 49
airplane 44
airport 44, 72
alarm goes off 4
album 64
Alice band 16
Allen keys 12
allergic to something 70
Word list
341
ball is in your court 41
ballet 65
balloon 22
ballpark figure 41
banana 29
band 64
bandage 69
bank 38, 73
bank loan 38
bank statement 38
bar (goalpost) 61
bar (pub) 33, 72
barbeque 49
bargain 74
bargain-hunting 73
bark 54
baseball 60
baseball bat 62
basement 9, 74
basil 31
basket 49, 54, 74
basketball 60
bat 55
bath 4, 9
bathrobe 15
bathroom 9
bathroom equipment 10
bathtub 9
battery 76, 78
be booked 61
be delayed 47
be laid off 35
be on the fence 8
be sent off 61
beach 50, 52, 58
beach ball 50
beak 56
beaker 78
beans 30
bear 55
beard 17
beautiful 6, 17
beauty 16, 74
beaver 55
become a celebrity 67
bed 4, 9
bed and breakfast 47
bedroom 9
bedside table 9
bee 56
beef 28
beer 32
beetle 56
beginner’s luck 26
behind 46
beliefs 26
believe in something 26
belt 16
bend in the road 46
benefits 35
bestseller 63
between 46
bib 22
bicycle 44, 49
bicycle lane 49
big 5
bike 44, 49
bike rack 49
bilingual 25
bill 33
bills 13, 38
bin 9, 37
bin liner 11
binder clip 37
biography 63
biologist 78
biology 23, 78
bird seed 54
birds 56
birdwatching 58
biscuit 31
bison 55
bite 32, 68
bitter 32
black 5
black hair 17
blackberries 29
blackcurrants 29
bleach 11
bleat 54
bleed 68
blender 10
blink 14
blizzard 51
block 46
block of flats 9
blond hair 17
blood test 69
blouse 15
blow 59
blue 5
blue eyes 17
blue whale 57
blueberries 29
blush (action) 14
blush / blusher (make-up) 16
boar 55
board a plane 47
board games 22, 58
board of directors 40
boarding pass 47
boat 44
bodyboarding 50
body, parts of 14
bodysuit 22
boil 33, 78
boiled egg 28
boiling 51
boiling point 51
bolt 12
bonnet (car) 45
bonus 35
book 63
book a holiday 47
book a vacation 47
book club 58
book in advance 48
bookcase 9
booked 61
bookshop 73
bookstore 73
boot (car) 45
boot camp 71
booties 22
boots 16
bored 19
boring 6
bottle 22, 32
bottle opener 10
bottom of the career ladder 39
boutique 73
bow (archery) 62
bow (gesture) 14
bow tie 16
bowl (container) 10, 32
bowling 60
bowling pins 62
box 32
box office 65
boxer shorts 15
boxes 13
boxing 60
boxing gloves 62
boxing ring 62
boy 20
boyfriend 20
bra 15
bracelet 16
brakes 45, 49
brave 18
Brazil 1
Brazilian 1
bread 31
break down 45
break even 38
break up with someone 21
breakfast 4, 33
breakfast TV 66
342
breakthrough 77
breast 28
breathe 14
breathtaking 6
bribery 27
bridge 72
briefcase 16
brilliant 6
bring someone up 21
bring up someone 21
British 1
broccoli 30
broil 33
broken bone 68
brooch 16
broom 11
brother 20
brother-in-law 20
brown 5
brown eyes 17
brown hair 17
browse the internet 58
bruise 68
brunch 33
brush 11
brush your hair 4
brush your teeth 4
bucket 11
bucket and spade 50
buckle 16
budget 38
buffalo 55
buffet 33
buggy 22
bugs 56
build a fire 49
building blocks 22
building bricks 22
bulb 76
bull 54
bulletin board 37
bump into someone 21
bungalow 13
bungee jumping 60
Bunsen burner 78
burger 28
burglary 27
burn 68, 78
burrow 55
bus 44
bus station 72
bus stop 44
business 41
business as usual 41
business card 7
business studies 23
businesslike attitude 43
businessman 34
businesswoman 34
busk 64
butcher 34, 73
butter 28
butterfly 56
butternut squash 30
button 15
buy 73
buy groceries 4
buzz 56
Ccabbage 30
cabin 47
cabinet 9
cable TV 66
café 4, 33, 72
cage 54
cake 31
calcium 70
calendar 3, 37
call a friend 4
call friends 58
call in sick 35
call your family 4
calm 18, 19, 43
calorie-controlled diet 70
calories 70
camel 44, 55
camera 76
camper van 49
campfire 49
camping 49, 58
camping stove 49
campsite 49
can 32
can opener 10
Canada 1
Canadian 1
candy 31
canoeing 60
canyon 52
cap 16
car 45
car accident 45
car park 45
car theft 27
car wash 45
caravan 49
carbohydrates 70
carbonated 32
cards 58
career path 39
career summary 42
caring 18
carnival 75
carrier bag 74
carrots 30
carry 59
carton 32
cartoon 65, 66
cash machine 38
cash register 38, 74
cashew nut 29
cashier 74
cast 65
castle 72
casual 17
cat 54
catch 59
catch a train 44
catch the bus 4
catch the train 4
catch-up TV 66
catering industry 36
caterpillar 56
cauliflower 30
cautious 18
cave 52
celebrity 67
celebrity culture 67
cell phone 37
cell phone number 7
cello 64
cells 78
Celsius 51
cemetery 72
century 3
cereal 31
chain 49
chair 9, 37
chalet 47
change (clothes) 15
change a lightbulb 12
change channel 66
change money 38
change of pace 41
change the sheets 11
changing mat 22
changing room 71, 74
changing table 22
channel 66
chapter 63
chat show 66
check (payment) 38
check (restaurant) 33
check in 47
check out 47
check out something 48
check something out 48
check the oil 45
check the tires / tyres 45
343
check your emails 4
checked / checkered 15
checkout 74
cheek 14
cheerful 19
cheese 28
cheesecake 31
cheetah 55
chef 33, 34
chemical industry 36
chemicals 78
chemist 78
chemistry 23, 78
cheque 38
cherries 29
chess 58
chest 14
chest of drawers 9
chew 32
chicken 28, 54, 56
chickenpox 68
child-care provider 34
children 20
children’s department 74
children’s show 66
children’s TV 66
chili / chilli flakes 31
chill out 71
chilled 32
chilly 51
chin 14
China 1
Chinese 1
chipmunk 55
chips 28
chives 31
chocolate 31
choir 64
cholesterol 70
choose 73
chop 33
chopping board 10
chopsticks 10
chores 11
church 72
chutney 31
cilantro 31
cinema 65, 72
circle 65
circuit training 71
city 7, 72
city centre 72
claim to fame 67
clam 57
clap 14
clarinet 64
class 23
classical 64
classroom 23
claw(s) 54, 56, 57
clean 5
clean the bathroom 11
clean the windows 11
clean up 11
cleaner 34
cleaning 11
cleaning fluid 11
clear distinction 24
clear the table 4, 11
click 76
click with someone 21
client 35
cliff 52
climate 51
climate change 53
climb 59
climbing frame 22
clinch the deal 41
clinic 69
clipboard 37
cloning 78
close friend 21
closed 74
cloth 11
clothes 15
clothes line 11
cloud 51
cloudy 51
coach 44
coat 15
cockpit 44
cockroach 56
coconut 29
cod 28
coffee 4, 32
coins 38
cola 32
colander 10
cold (sickness) 68
cold (temperature) 5, 51
cold feet 8
collaborate 42
collar (pet) 54
collar (shirt) 15
colleague 35
collect stamps 58
college 23
coloring / colouring book 63
colors / colours 5
comb 16
comedy 65, 66
comic 63
commercial break 66
commercial district 72
commit a crime 27
commuters 44
company 35
company name 7
compare and contrast 24
compass 46
competitive 43
compose 64
composer 64
computer 37
computer desk 76
computer literate 77
computing 43
concert 58, 64
concert hall 72
condiments 31
conditioner 10
conduct 64
conductor 64
conference call 40
confident 18, 19, 43
confused 19
confusing 6
considerate 18
construction industry 36
construction worker 34
consume 53
contact 7
containers 32
continuous assessment 24
convenience food 70
convenient 74
conversational 25
cook 58
cook dinner 4
cookbook 63
cooker 9
cookie 31
cooking show 66
cool 51, 78
cool down 71
coordinate 42
copy 59
coriander 31
corkscrew 10
corn 30
corner 46, 61
corner kick 61
corner the market 41
correction fluid 37
cosmetics 74
cosmopolitan 75
costume drama 66
costumes 65
cot 22
cottage 13
cottage cheese 28
344
cotton 15
cotton pads 69
cotton wool 69
couch 9
couch potato 66
cough 14, 68
counseling / counselling 71
count 59
countries 1
country 64
countryside 52
courgettes 30
course book 63
cousin 20
cover 63
cover / covering letter 42
cow 54
co-worker 35
crab 28, 50, 57
cranberries 29
crawl 59
cream (colour) 5
cream (dairy) 28
creative 43
credit card 38
crib 22
cricket 60
crime 27, 66
crime drama 65
crime fiction 63
crime rate 75
crime wave 27
criminal record 27
crisps 28
critical 18
croak 54
crockery 10
crocodile 55
croissant 31
crossroads 46
cross-trainer 71
crow (bird) 56
crow (cockerel) 54
cruise 47
cry 14
crystals 78
cucumbers 30
cuff 15
cufflinks 16
culture shock 48
cup 10
cupboard 9
cupcake 31
curious 19
curly hair 17
currant 29
currency 38
current affairs 66
curtain 65
cushion 9
customer 74
customer service 43, 74
customer-focused 43
cut (food preparation) 33
cut (wound) 68
cut corners 8
cut down on something 70
cutlery 10
cutting board 10
cutting-edge 77
cycle pump 49
cycling 49, 60
cycling helmet 49
cycling trails 49
Czech Republic 1
Ddad 20
daily 3
dairy 28, 70
dairy-free 70
dance 59, 64
dark green 5
dark skin 17
data analysis 43
date 29
daughter 20
day 3
day off 35
dead-end job 39
debit card 38
debt 38
decade 3
December 3
decide 59
decimals 2
decision-making 43
deck chair 50
deep 5
deep breathing 71
deer 55
defender 61
degree (qualification) 23, 24
degrees (temperature) 51
delayed 47
delete 7, 76
delicatessen 73
delicious 6, 32
delighted 19
denim 5, 15
dental floss 10
dentist 34
deodorant 10
department store 74
departments (workplace) 36
departure gate 47
deposit 13
depressed 19
derelict buildings 75
desert 52
design and technology 23
designer 34
designer labels 74
desk 9, 37
desktop computer 76
desserts 31, 33
destruction 53
detached houses 13
determined 43
detox 70
diabetes 68
dialog / dialogue 65
diaper 22
diarrhea / diarrhoea 68
diary 37
dictionary 63
diesel 45
dig 59
digital age 77
dine 32
dining room 9
dinner 4, 33
dinnerware 10
diploma 23
dire consequences 53
direct flight 47
direction 46
director 65
dirty 5
disappointed 19
disappointing 6
disastrous 6
discus 60
disgusted 19
disgusting 6, 32
dishes 4, 11
dishonest 18
dishwasher 9
dishwashing liquid 11
dissolve 78
distance 46
distracted 19
diving 60
diving board 62
DNA 78
do 59
do exercise 58
do homework 4
do karaoke 58
do pottery 58
345
do puzzles 58
do something by the book 41
do the dishes 4, 11
do the gardening 58
do the housework 4
do the ironing 11
do the laundry 11
do the weeding 12
do up 15
do yoga 58
doctor 34, 69
doctor’s surgery 69
documentary 66
dog 54
doghouse 54
doll 22
dollhouse / doll’s house 22
dolphin 57
donkey 54
door 9
dorm 47
double room 47
dove 56
download 76
downpour 51
downstairs 9
downtown 72
draft 7
drama 23, 65, 66
draw (art) 58
draw (sports result) 61
drawer 37
drawing pin 37
dress 15
dresser 9
dressing gown 15
drift apart 21
drill 12
drink 32
drink tea or coffee 4
drink water 69
drive 4
drive a car 44
driver 34
driver’s licence / license 45
driving 45
drop a hint 26
drop someone off 45
drought 51
drug dealing 27
drum 64
dry 51
dry cleaners 73
dry the dishes 11
dry your hair 4
drying clip 11
duck 54, 56
dummy 22
dumplings 31
duplex 13
dust 11
duster 11
dustpan 11
Eeagle 56
ear 14
earn 35
earphones 76
earrings 16
ears 54
east 46
eat 32
eat breakfast 4
eat dinner 4
eat lunch 4
eat something in moderation 70
eccentric 18
economic downturn 38
economics 23
ecstatic 19
eczema 68
education 23, 36, 42
eel 57
efficient 43
egg 28
egg white 28
eggplants 30
Egypt 1
Egyptian 1
eight 2
eighteen 2
eighth 2
eighty 2
elbow 14
electric guitar 64
electric shock 78
electrical appliances 74
electrician 34
electronics industry 36
elegant 17
elephant 55
elevator 74
eleven 2
eleventh 2
elliptical 71
email 7
email address 7
embarrassed 19
employee 35
employer 35
employment 35
encore 65
encyclopedia 63
endangered 53
energetic 43
energy 70
energy drink 32
energy industry 36
enforce the law 27
engine 44, 45
engineer 34
engineering 23
English 23
enrol on 24
enroll in 24
en-suite bathroom 47
entertainment industry 36
enthusiastic 18
entrée 33
envelope 37
environment 53
episode 66
eraser 37
e-reader 63, 76
escalator 74
essay 23
estate agent 13
evaporate 78
evening 3
evening class 58
every day 3
every other day 3
exam 23
exchange 73
exchange business cards 7
exchange rate 38
excited 19
exciting 6
exclusive interview 67
excursion 47
exercise 58, 69, 71
exercise bike 71
exercise book 23
exercise class 71
exercise mat 71
exhausted 19
exit 74
expenditure 38
experiment 78
exploit 67
expose 67
extinct 53
extraordinary 6
eyebrow 14
eyelashes 14
eyeliner 16
eyes 14, 17
eyeshadow 16
346
Ffabric 5
face 14
face the music 8
face wash 10
facial hair 17
Facilities (department) 36
factory 72
Fahrenheit 51
fail 23
fair skin 17
fairy tale 26
fall (action) 59
fall (season) 3
fall in love with someone 21
fall out with someone 21
families 20, 21
fans 61
fantastic 6
fantasy 63
far 5
farm animals 54
farmer 34
farming 36
farmland 52
fashion designer 34
fashion industry 36
fast food 28, 33
fast learner 43
fasten 15
fast-paced 75
father 20
feather 56
February 3
feed the cat 4
feed the dog 4
feed the pets 11
feedback 24
feel better 69
feel homesick 48
feel under the weather 8
feelings 19
female 20
ferret 54
ferry 44
festival 64
fever 68
fiber / fibre 70
fiction 63
field (land) 52
field (sports) 61, 62
fifteen 2
fifth 2
fifty 2
fifty percent off 73
fig 29
file 12
files 37
filing cabinet 37
fill out a form 42
fill up 45
film 65
film star 65
fin 57
final whistle 61
finance 38
Finance (department) 36
finance industry 36
find somebody guilty 27
find somebody not guilty 27
fine 27
finger 14
finish work 4
fire station 72
fired 39
firefighter 34
first 2
first aid kit 69
first draft 24
first floor 74
first name 7
fish 28, 54, 57
fish dealer 73
fish slice 10
fish tank 54
fishing 60
fishing industry 36
fishing rod 62
fishmonger 73
fit 15, 73
fit a carpet 12
fitness 71
five 2
fix a puncture 49
fixed menu 33
flag 61
flamingo 56
flap 56
flashlight 49
flask 32, 49
flat tire / tyre 45
flats 13
flavorings 31
flea market 73
flexible 43
flick through 63
flight attendant 34
flip through 63
flip-flops 16, 50
flippers 50, 62
float 62, 78
flood 51
florist 73
flour 31
flu 68
fluent in (languages) 25, 43
flute 64
fly 56, 59
fly a kite 58
fog 51
foggy 51
fold clothes 11
folders 37
folding chair 49
folding table 49
folklore 26
food court 74
food industry 36
food poisoning 68
food stall 33
foot 14
football 60
football boots 62
footpath 46
foraging 58
forehead 14
forest 52
fork (cutlery) 10
fork (gardening) 12
formal 17
fortnight 3
forty 2
forward (email action) 7
forward (soccer player) 61
fossil fuels 53
foundation 16
fountain 72
four 2
fourteen 2
fourth 2
fox 55
fractions 2
frame 49
France 1
fraud 27
freckles 17
free time activities 58
freeway 46
freeze 78
freezer 9
freezing 51
freezing point 51
French 1
fresh 32
fresher 24
freshman 24
Friday 3
fridge 9
fried egg 28
friendly 18
347
friends 4
fries 28
frightened 19
frightening 6
frizzy hair 17
frog 55
front desk 47
frost 51
frosty 51
frown 14
fruit 29
fruit salad 31
frustrated 19
fry 33
frying pan 10
fuel 45
full time 61
fun 6
funny 18
fur 54
furious 19
furnished 13
furniture 9
future-proof 77
Ggadgets 76
gain weight 69
gale 51
gallop 54
game plan 41
game show 66
games 22
garage 45
garbage bag 11
garden 9
gardener 34
gardening 12, 58
garlic 30
gas station 45, 72, 78
gasoline 45
gazelle 55
gear 49
gecko 54
generous 18
genetic engineering 78
geographical features 52
geography 23
geology 23
gerbil 54
German 1
Germany 1
get a degree 24
get ahead 39
get along with someone 21
get away from it all 48
get changed 15
get cold feet 8
get down to business 41
get dressed 4
get fired 35
get in a taxi 44
get into debt 38
get off a bike 49
get off a bus 44
get on a bike 49
get on a bus 44
get on with someone 21
get out of a taxi 44
get the ball rolling 41
get up 4
get your hair cut 17
getaway 48
geyser 52
gill 57
ginger 31
giraffe 55
girl 20
girlfriend 20
give a presentation 40
give and take 39
give birth 21
give notice 13
give someone a lift 44
give someone a ride 44
give someone feedback on something 24
give something up 70
give up something 70
glacier 52
glamorous 17
glass 5, 32
glasses 16
glide 56
global warming 53
gloves 16
glowing reviews 63
gluten-free 70
go abroad 47
go ahead 46
go birdwatching 58
go camping 58
go foraging 58
go home 4
go jogging 58
go left 46
go on a cruise 47
go on a holiday 47
go on a vacation 47
go on an excursion 47
go on holiday 58
go on maternity leave 35
go on vacation 58
go out 4, 38, 58
go past 46
go right 46
go shopping 58
go sightseeing 47
go straight on 46
go the extra mile 39
go to a book club 58
go to a café 4
go to a concert 58
go to a party 58
go to an evening class 58
go to bed 4
go to school 4
go to somebody’s head 67
go to the beach 58
go to the gym 58
go to the shops 11
go to the store 11
go to work 4
goalkeeper 61
goalpost 61
goat 54
goatee 17
goggles 62
golden raisin 29
golf 60
golf club 62
golf course 62
gone off 32
good 6
good deal 73
good ear for languages 25
good omen 26
good source of something 70
goose 54, 56
gooseberries 29
gorilla 55
gossip 26
gossip magazine 63
government building 72
GPS 76
graduate 23, 24
graffiti 27
grammar 25
grandchildren 20
granddaughter 20
grandson 20
grapefruit 29
grapes 29
grassland 52
grate 33
grateful 6, 19
grater 10
gray / grey 5
gray / grey eyes 17
gray / grey hair 17
great 6
348
greater choice 75
Greece 1
Greek 1
green 5
green energy sources 53
green eyes 17
green spaces 75
greengrocer 73
greenhouse gases 53
grill 33
grin 14
ground floor 74
groundsheet 49
group 64
grow up 21
grow your hair 17
guarantee 74
guava 29
guesthouse 47
guidebook 47, 63
guided tour 47
guilty 27
guinea pig 54
guitar 64
guitar player 64
gulp 32
guy rope 49
guyline 49
gym 58, 71
gymnastics 60, 62
Hhacking 27
hacksaw 12
haggle 73
hailstone 51
hair 17
hair band 16
hair cut 17
hair dye 16
hair gel 16
hair spray 16
hairbrush 16
hairdresser 34
half 2
half time 61
ham 28
hammer 12
hamster 54
hand 14
handbag 16
handkerchief 16
handlebar 49
handsome 17
hands-on experience 39
hang clothes 11
hang gliding 60
happy 19
hard drive 76
hard shoulder 46
hardback 63
hardware store 73
hardworking 43
harmful to the environment 53
harmless 6
harmonica 64
harness 62
hat 16
hatch 56
have a bath 4
have a break 4
have a car accident 45
have a day off 35
have a good ear for languages 25
have a heart of gold 8
have a picnic 58
have a shower 4
have a sneaking suspicion 26
have an impact on something 77
have an interview 42
have breakfast 4
have dinner 4
have lunch 4
have serious doubts 26
have serious misgivings 26
have something in common 21
have tea or coffee 4
have your hair cut 17
have your hands full 39
have your name in lights 67
hawk 56
hay fever 68
hazel eyes 17
hazelnut 29
head 14
head over heels 8
headache 68
headlight 45
headline 63
headline news 67
headquarters 35
headset 37
heal 69
healthcare 36
healthy eating 70
hear something on the grapevine 8
heart of gold 8
heart rate 71
heat 78
heatwave 51
heavy 5
hedge 52
helicopter 44
helmet 62
herbal tea 32
herbs 31
here 46
hero 65
hex keys 12
high 5
high blood pressure 68
high chair 22
high heels 16
high in something 70
high jump 60
high tide 52
highbrow 63
highlighter 37
hike 58
hill 52
hip 14
hip-hop 64
hippopotamus 55
hiss 54
historic buildings 75
historic quarter 72
history 23
hit 59
hit the nail on the head 8
hitchhike 44
hockey 60
hockey stick 62
hoe 12
hold 59
hold a position 39
hold your breath 14
hole punch 37
holiday 47, 58
home furnishings 74
home improvements 12
homework 4, 23
honest 18, 43
honey 31
hood (car) 45
hood (clothing) 15
hook 62
hooliganism 27
hoot 56
hop 54
hopelessly lost 48
horoscope 63
horrible 6
horror 65
horse 44, 54
horse riding 60
hose 12
hospital 69, 72
hospitality 36
host 66
hostel 47
349
hot 5, 32
hot air balloon 44, 51
hot chocolate 32
hot dog 28
hot drink container 32, 49
hot tub 71
hotel 47, 72
hour 3
hourly 3
hourly rate 35
house 9
house number 7
household chores 11
household name 67
housemate 13
house-warming party 13
housework 4
Human Resources / HR (department) 36
humidity 51
hummingbird 56
humor / humour 63
humpback whale 57
hundred 2
hunt 55
hurdles 62
hurricane 51
hurt 68
husband 20
hypothesis 78
Iice 51
ice cream 31
ice hockey 60
ice rink 62
ice skates 62
ice tea 32
iceberg 52
iced 32
icy 51
iguana 54
ill 31, 68
illustration 63
immature 18
impact 77
impatient 18
important 6
impulsive 18
in a nutshell 41
in front of 46
in the long run 77
in the public eye 67
in the red 41
inbox 7
including utilities 13
income 38
incredible 6
independent 43
in-depth knowledge 42
India 1
Indian 1
indicate 45
indicator 45
indigestion 68
Indonesia 1
industries 36
infection 68
information technology 23
Information Technology (department) 36
infrastructure 75
inhaler 69
initiative 43
injection 69
injury time 61
innovation 77
innovative 43
insect repellent 49
insects 56
insensitive 18
insomnia 68
insurance 45
intelligent 18
interest rate 38
interested 19
interesting 6
interests 42
intern 35
interpersonal skills 43
interrupt 40
intersection 46
interview 42, 66
intrigued 19
introduce yourself 7
invoice 38
iron 70
iron a shirt 4, 11
ironing 11
ironing board 11
irreversible change 53
irritated 19
irritating 6
island 52
IT 43
IT (department) 36
itchy 68
itchy feet 48
Jjacket 15
jaguar 55
jam 31
janitor 34
January 3
Japan 1
Japanese 1
jar 32
javelin 60
jazz 64
jealous 19
jeans 15
jellyfish 57
jet ski 50
jewelers / jewellers 73
jewelry / jewellery 16
jigsaw (tool) 12
jigsaw puzzle 22
job ad / advert 42
job title 7
jobs 34, 42
jockey shorts 15
jog 71
jogging 58
journalism 36
journalist 34
judge 27, 34
judo 60
juice 32
July 3
jump 59
jump rope 22, 71
jumper 15
junction 46
June 3
junk mail 7
jury 27
Kkangaroo 55
karaoke 58
kayaking 60
kebab 28
keep an eye on 8
keep fit 71
kennel 54
ketchup 31
kettle 10
key 46
key skills 42
keyboard 64, 76
keys 13
kick 59, 61
kickoff 61
350
killer whale 57
kilometer / kilometre 46
kind 18
kitchen 9
kitchen implements 10
kitchen knife 10
kitchenware 74
kite 22, 50
kiwi (bird) 56
kiwi fruit 29
knee 14
knickers 15
knife 10
knit 58
knock on wood 26
koala 55
Llaboratory 23, 78
laces 16
ladder 12
ladle 10
ladybird 56
ladybug 56
laid-back 18
laid off 35, 39
lake 52
lamb 28
lamp 9, 37
land at the airport 47
landlord 13
language barrier 25
languages 23, 25
laptop 37, 76
last name 7
latest model 77
latin 64
laugh 14
laundry 11
laundry basket 11
laundry detergent 11
laundry service 47
law 23, 27
law court 27, 72
lawn 9
lawn mower 12
lawyer 27, 34
lazy 18
lead (electrical) 76
lead (for a pet) 54
leadership 43
lease 13
leash 54
leather 5, 15
leave the house 4
leave work 4
lecture 23
lecturer 23
leeks 30
left 46
leg 14, 28
leg of a journey 48
leg of a trip 48
Legal (department) 36
leggings 15
legs 54
legumes 70
leisure center / centre 72
lemon 29
lemonade 32
lemongrass 31
lend a hand 8
leopard 55
let the cat out of the bag 8
let your hair down 8
letter 7, 37
lettuce 30
level 12
librarian 34
library 23, 72
lick 14, 59
lie down 69
life preserver 50
life ring 50
lifeguard 50
lifejacket 62
lift 44, 59, 74
light 5, 9
light shower 51
lighting 51, 74
light-years ahead 77
lime 29
line 74
linesman 61
lingerie 74
lingua franca 25
lion 55
lips 14
lipstick 16
liquid 78
listen 59, 64
listen to music 58
listen to the radio 4
listening 25
litter box 54
litter tray 54
little 5
lively nightlife 75
living room 9
lizard 55
llama 54
load the dishwasher 11
lobster 28, 57
local 13
lock 49
locker room 71
lockers 71
locust 56
lodger 13
log in 76
log out 76
lonely 19
long 5
long hair 17
long jump 60
look around 48
look forward to something 48
look up to someone 21
loose 5
lorry 44
lose 61
lose weight 69
loud 5
lovely 6
low 5
low in something 70
low tide 52
loyalty card 74
lucky 19
luggage 47
lunch 4, 33
lychees 29
lyrics 64
Mmackerel 28
mad 19
made redundant 35, 39
magnet 78
magnificent 6
mail 7
main character 65
main course 33
main objective 40
main road 46
make 59
make a loss 38
make a reservation 33, 47
make a wish 26
make curtains 12
make friends with someone 21
make models 58
make predictions 77
make the bed 4, 11
make yourself understood 25
male 20
manager 35, 42, 61
mandarin 29
mango 29
351
manufacturing industry 36
maps 46
marbles 22
March 3
margarine 28
Marketing (department) 36
marmalade 31
mascara 16
mascot 61
mash 33
massage 71
materials 5
maternity leave 35
math / maths 23
mature 18
May 3
mayonnaise 31
meadow 52
meals 33, 58
mean 18
measles 68
meat 28
mechanic 34, 45
media 67
medical treatment 69
medication / medicine (healthcare) 69
medicine (subject) 23
mediocre 6
meditate 71
medium height 17
meerkat 55
meet a deadline 24
meet friends 58
meetings 40
melon 29
melt 78
memo 7
memory card 76
men’s wear 74
menu 33
meow 54
meringue 31
metal 5
meteoric rise 67
meter / metre 46
Mexican 1
Mexico 1
microphone 64
microscope 78
microwave 10
middle name 7
middle-aged 17
midfielder 61
migraine 68
mild 51
mile 46
milk 28
milkshake 32
millennium 3
million 2
mince 33
minerals 70
mining industry 36
mint 31
minus 51
minute 3
miserable 19
miss a deadline 24
miss a train 44
mix 33
mobile 22
mobile banking 38
mobile number 7
mobile phone 37
moisturizer 10, 16
mole (animal) 55
mole (skin) 17
molecules 78
molt / moult 54
mom 20
Monday 3
money 38
Mongolia 1
Mongolian 1
mongoose 55
monkey 55
monkey wrench 12
month 3
monthly 3
moods 19
moose 55
mop the floor 11
moped 44
morning 3
mortar 10, 78
mortgage 38
Moses basket 22
mosque 72
mosquito 56
moth 56
mother 20
motivated 43
motor home 49
motor racing 60
motorbike / motorcycle 44
motorway 46
mountain 52
mountain bike 49
mountain range 52
mouse (animal) 54
mouse (computer) 76
mouse mat 76
mouse pad 76
mousse 31
moustache 17
mouth 14
mouthwash 10
move 59
move in 13
move out 13
move the goalposts 41
movie 65
movie star 65
movie theater 65, 72
moving 13
moving truck 13
mow the lawn 12
mug 10
mugging 27
multiplex 65
mum 20
mumps 68
museum 72
mushrooms 30
music 23, 64
music channel 66
music store 64
musical 65
musical instrument 58
musician 34
mussel 28, 57
mustache 17
mustard 31
Nnail 12
nail polish 16
name 7
napkin 33
nappy 22
narrow 5
nasty 6
nationalities 1
native speaker 25
nature documentary 66
nature writing 63
navy blue 5
near 5
neck 14
necklace 16
nectarine 29
negotiate 42
negotiating 43
nephew 20
nervous 18, 19
net 61, 62
Netherlands 1
never 3
New Zealand 1
news 66
352
news anchor 66
newspaper 63
newspaper headline 67
newsreader 66
next to 46
nibble 32
nice 6
niece 20
night 3
nightclub 72
nine 2
nineteen 2
nine-to-five 39
nine-to-five job 35
ninety 2
ninety-nine percent 2
ninth 2
no vacancies 47
nod 14
non-carbonated 32
non-fiction 63
noodles 31
north 46
northeast 46
northwest 46
nose 14
nosebleed 68
nostrils 14
not guilty 27
note 7
notepad 37
notes 38
notice board 37
nought point five 2
novel 63
November 3
numbers 2
numeracy 43
nurse 34, 69
nursery 22
nuts 12, 29
Ooars 62
oasis 52
observe 78
obsolete 77
ocean 52
October 3
octopus 28, 57
odd 6
off (food) 32
off the beaten path 48
off the beaten track 48
off, percent 73
office building 72
office equipment 37
Office Services (department) 36
often 3
oil (car) 45
oil (cooking) 31
ointment 69
old 17
old-fashioned 6
olive skin 17
omelet / omelette 28
on a tight budget 73
on the agenda 40
on the ball 8
on the corner 46
on the fence 8
on the left 46
on the right 46
on the same page 41
once a week 3
once-in-a-lifetime 48
one 2
one hundred 2
one million 2
one percent 2
one point seven 2
one thousand 2
one-way street 46
one-way ticket 47
onions 30
online banking 38
online chat 7
online shopping 74
only a matter of time 77
only child 20
only time will tell 77
open 74
opening night 67
open-plan 13
opera 64, 65
opera house 65
operation 69
opinions 6
opposite 46
optimistic 18
orange (colour) 5
orange (fruit) 29
orangeade 32
orchestra 64
orchestra pit 65
orchestra seating 65
order 33
organization 43
organize 42
organized 43
ostrich 56
otter 57
out of date 77
out of season 48
outbox 7
outgoing 18
outlay 38
outstanding 6
over the top 8
overcast 51
overcrowding 75
overdraft 38
overpriced 73
overtake 45
overtime 4, 35
owl 56
oyster 28, 57
PPA 34
pace of life 75
pacifier 22
pack 13, 59
pack your bags 47
packet 32
paddle 62
page 63
page-turner 63
pail and shovel 50
pain 68
pain in the neck 8
painful 68
painkillers 69
paint 12, 58
paint a room 12
paint the house 12
paintbrush 12
pajamas 15
Pakistan 1
Pakistani 1
pale green 5
pale skin 17
pancakes 31
panda 55
panties 15
pants 15
pantyhose 15
paparazzi 67
papaya 29
paper 5
paper clips 37
paperback 63
paragliding 60
paramedic 34, 69
park (recreation area) 72
park (vehicle) 45
parking attendant 45
parking lot 45
parking meter 45
353
parking space 13
parking ticket 45
parrot 54, 56
parsley 31
partner 20
part-time 35
party 58
pass (overtake) 45
pass (succeed) 23
pass with flying colors / colours 24
passengers 44
passion fruit 29
passionate 18
passport 47
passport control 47
past 46
pasta 31
patient (hospital) 69
patient (personality trait) 18, 43
pavement 46
paws 54
pay 35, 73
pay cut 35
pay rise 35
pay separately 33
peach 29
peak 52
peanut 29
peanut butter 31
pear 29
peas 30
peck 56
pedal 49
pedestrian crossing 45
pedestrianized street 46
pedestrians 44
peel 33
peeler 10
peg 11
pelican 56
pen 37
penalty 61
penalty spot 61
pencil 37
pencil sharpener 37
penguin 56
pepper 31
peppers 30
percentages 2, 73
perform 64
performance 65
perfume 16
perfumery 74
period drama 66
permanent 35
personal assistant 34
personal statement 42
personal trainer 71
personality traits 18
perspire 14
pescatarian 70
pestle 10, 78
pestle and mortar 10
petrol 45
petrol station 45, 72
petroleum engineering 36
pets 54
pharmaceutical industry 36
pharmacy 72
Philippines 1
philosophy 23
phone 37
phone call 7
photocopier 37
photographer 34
phrasebook 47
physical education 23
physical therapy 69
physicist 78
physics 23, 78
physiotherapy 69
pick someone up 45
pick something up quickly 25
pickpocketing 27
picnic 58
picnic basket 50
picnic blanket 50
pig 54
pigeon 56
Pilates 71
pills 69
pilot 34
pin 16
PIN 38
pineapple 29
pink 5
pistachio 29
pitch (sports) 61, 62
pitch a tent 49
pizza 28
plain (adjective) 15
plain (landscape) 52
plan your route 46
plane 12
planner 37
plant bulbs 12
plaster 69
plaster the walls 12
plastic 5
plate 10
plateau 52
platform 44
play (action) 59
play a musical instrument 58
play board games 58
play cards 58
play chess 58
play the trumpet 64
play video games 58
playground 22
playing cards 22
playpen 22
plays (performance) 65
pleasant 6
pleased 19
pliers 12
plot 63
plug in 76
plum 29
plumber 34
poach 33
poached egg 28
pocket 15
point 59
Poland 1
polar bear 55
polar opposites 24
polar region 52
police 27
police officer 34
police station 72
Polish 1
polish 11
polite 18
polka dot 15
pollution 75
pomegranate 29
pond 52
ponytail 17
pool 60
pool cue 62
pop 64
popcorn 65
pork 28
porpoise 57
port 44
portfolio 42
portion 70
Portugal 1
Portuguese 1
post 7
post office 72
postcode 7
postgraduate 24
potatoes 30
pothole 49
pottery 58
potty 22
pour 33, 78
power cord 76
PR 36
354
practical 43
practice / practise 64
pram 22
prawn 28
prescription 69
presentation 40
presenter 66
press-up 71
pretty 6
preview 66
price tag 74
print 7
printer 37
prison 27
problem-solving 43
processed food 70
Production (department) 36
professional 43
professional achievements 42
professional attributes 43
professor 23
proficient in 42
program / programme 65
programme (TV) 66
project management 43
projector 37
promotion 35
pronunciation 25
property 13, 36
props 65
protein 70
proud 19
proven track record 42
prowl 55
prune trees 12
psychologist 34
psychology 23
Public Relations 36
public speaking 43
pudding 33
puddle 51
pull 59
pulling your leg 8
pulses 70
punctual 43
puppet 22
Purchasing (department) 36
pure luck 26
purple 5
purr 54
purse 16, 38
push 59
push-up 71
put on (clothes) 15
put on make-up 4
put the children to bed 4
put up shelves 12
put your foot down 21
puzzles 58, 63
pyjamas 15
Qquack 54
qualification 23
quarter 2
queue 74
quiet 5
quince 29
quiz show 66
Rrabbit 54
rabbit hutch 54
raccoon 55
racing bike 49
rain 51
rain forest / rainforest 52
rainbow 51
raincoat 15
raindrop 51
rainy 51
raise 35
raisin 29
rake 12
ranch house 13
rap 64
rapids 52
raspberries 29
rattle 22
ray 57
razor 10
reach a consensus 40
reach a verdict 27
reaction 78
read 58
read a map 46
read a newspaper 4
reading 25, 63
real estate 13, 36
reality show 67
reality TV 66
realtor 13
reasonable 18
receipt 38, 74
reception 47
receptionist 34
record 64, 66, 78
recover 69
recruitment agency 42
recycling bin 11
recycling industry 36
red 5
red card 61
red carpet 67
red hair 17
red tape 41
redcurrants 29
reduce your carbon footprint 53
reference (landlord) 13
references (employer) 42
reflector 49
reflexology 71
refrigerator 9
refund 73
rehearse 64
relationships 21
relax 71
relaxed 19
relaxing 6
reliable 18, 43
remarkable 6
remember 59
remote 66
removal van 13
renewable energy 53
rent 13
rent a cottage 47
renting 13
repair 59
repel 78
reply 7
reply all 7
reporter 66
Republic of Ireland 1
research 43
Research and Development / R & D 36
residential area 13
resit 23
respectable 6
responsible 43
responsible for 42
rest 69
restaurant 33, 72
results 78
resuscitate 69
retire 35
return ticket 47
review 23
review the minutes 40
revise 23
revolution 77
rhinoceros 55
rice 31
ride 44, 59
ride a bike 44
ride a horse 44, 58
right 46
ring 16
rip-off 73
355
river 52
road sign 45
road work / roadworks 75
roadmap 46
roar 55
roast 33
robbery 27
rock (music) 64
rock climbing 60
rocks 52
ROI 1
roll (action) 33
roll (bread) 31
roller (paint) 12
roller skates 62
roller-skating 60
rolling pin 10
romance 63
romantic comedy 65
romper suit 22
roof 9
room service 47
room with a view 47
roomer 13
roommate 13
rooms 9
round-trip ticket 47
router 76
row houses 13
rowing 60
rowing machine 71
rubber 37
rubber band 37
rubber gloves 11
rucksack 16, 49
rude 18
rug 9
rugby 60
ruler 37
run 59, 71
run in the family 21
run out of time 40
run-down 48
running 60
running a marathon 60
running track 62
runny nose 68
rush hour 75
Russia 1
Russian 1
rusty 25
Ssad 19
saddle 49
safe 47
safety goggles 78
safety pin 69
sailing 60
salad 28
salary 35
sale 74
Sales (department) 36
sales assistant 34
salmon 28, 57
salt 31, 70
salty 32
sand 50
sand dune 52
sandals 16
sandbox 22
sandcastle 50
sandpit 22
sandstorm 51
sandwich 28
sardines 28
satellite TV 66
satire 66
satnav 76
saturated fat 70
Saturday 3
saucepan 10
sauna 71
sausages 28
save 38
savory / savoury 32
saw 12
saxophone 64
scale (fish) 57
scales (measure) 46, 69
scallops 28
scanner 37
scared 19
scarf 16
school 4, 23
school of fish 57
science 23, 78
science fiction 63, 65
scientist 34, 78
scissors 10, 37, 69
score a goal 61
scouring pad 11
scrambled eggs 28
scratch 54
screen 65, 66, 76
screw 12
screwdriver 12
script 65
scrub the floor 11
scuba diving 60
sea 50, 52
sea creatures 57
sea lion 57
sea urchin 57
seafood platter 28
seagull 56
seahorse 57
seal 57
seasons 3, 66
seatbelt 45
second 2
second floor 74
secretive 18
security 61
security guard 34
see 59
see a play 58
see eye to eye with someone 21
see off somebody 48
see somebody off 48
seesaw 22
self-help 63
selfish 18
sell 73
semester 24
semi-detached houses 13
send 7
sensationalize 67
sensitive 18
sent off 61
sentence somebody to something 27
September 3
series 66
serious 18, 19
serious doubts 26
serious misgivings 26
serve a sentence 27
service charge 33
service the car 45
service-oriented 42
set menu 33
set of beliefs 26
set off 45
set the table 11
set your sights on something 39
sets 65
seven 2
seventeen 2
seventh 2
seventy 2
sew 58
shake 59
shake your head 14
shallow 5
shampoo 10
shape 12
shape of things to come 77
shark 57
sharp 5
shave 4, 17
356
shaving foam 10
shears 12
sheep 54
shell 28, 50, 57
shelves 74
shin 14
ship 44
shipping industry 36
shirt 15
shiver 14
shocked 19
shocking 6
shoe shop 73
shoe store 73
shoes 16
shop 11, 72
shop around 73
shoplifting 27
shopping 58, 73
shopping bag 74
shopping cart 74
shopping channel 66
shopping mall 72
shopping trolley 74
short 5, 17
short hair 17
shorts 15
shoulder (body) 14
shoulder (road) 46
shoulder-length hair 17
shout 59
show of hands 40
shower 4, 9
shower block 49
shower gel 10
shows 65, 66
shredder 37
shrimp 28, 57
shrug 14
shuttlecock 62
shy 18
sick 68
side 33
side order 33
sideburns 17
sidewalk 46
sieve 10
sigh 14
sightseeing 47
signal 45
signature 7
signpost 46
silk 5, 15
silly 18
silverware 10
simmer 33
sing 56, 59, 64
sing in a choir 58
Singapore 1
singer 64
single room 47
sink (action) 78
sink (household fixture) 9
sip 32
sister 20
sister-in-law 20
sit an exam 23
sit down 59
sit on the fence 8
sitcom 66
sit-up 71
six 2
sixteen 2
sixth 2
sixty 2
skateboard 62
skateboarding 60
skating 60
ski slope 62
skiing 60
skip 71
skipping rope 22, 71
skirt 15
skis 62
skydiving 60
skyscraper 72
slash prices 73
sleep well 71
sleeping bag 49
sleeve 15
slice 33
slide 22
slippers 16
sloth 55
Slovakia 1
slow down 45
small 5
smart 17
smartwatch 76
smell 59
smile 14
smog 51
smoothie 32
smuggling 27
snack 28, 33
snail 56
snake 55
sneakers 16
sneaking suspicion 26
sneeze 14, 68
sniff 54
snore 14
snorkel and mask 50
snorkeling / snorkelling 60
snort 54
snow 51
snowboard 62
snowboarding 60
snowdrift 51
snowed under 39
snowflake 51
snowstorm 51
snowsuit 22
snowy 51
soap 10
soap opera 66
soccer 60, 61
soccer cleats 62
social networking 7
socks 15
sofa 9
soft toy 22
solar panel 53
solar power 53
solid 78
solo 64
sometimes 3
son 20
sorbet 31
sore 68
sore throat 68
soul 64
soup 28
sour 32
south 46
South Africa 1
South Korea 1
southeast 46
southwest 46
soy sauce 31
spa 71
spaghetti 31
Spain 1
spam 7
Spanish 1
spanner 12
sparkling 32
spatula 10
speak 59
speak accurately 25
speaking 25
special 6
special effects 65
special offer 74
specials (menu) 33
speed camera 45
speed limit 45
speed up 45
speeding 27
spell 59
sperm whale 57
357
spices 31
spicy 32
spider 56
spinach 30
spine 63
spinning top 22
spirit level 12
splinter 68
split the bill 33
split the check 33
sponge 10, 11
spoon 10
sports 60, 62
sports center / centre 72
sports drink 32
sports programme 66
sports show 66
spotted 15
sprain 68
spread a rumor / rumour 26
spring 3
sprinkler 12
squash 60
squat 71
squeak 54
squid 28, 57
stadium 62
staff 35
stage 65
stair gate 22
stairs 9
stalls 65
stand up 59
standing ovation 65
stapler 37
staples 37
starfish 57
starfruit 29
start a rumor / rumour 26
start work 4
starter 33
state 7
state-of-the-art 77
static electricity 78
stationery 37
stay (at) home 58
stay in a hotel 47
steam 78
steam room 71
steering wheel 45
step down 39
stepbrother 20
stepmom 20
stepmother 20
stepmum 20
stepsister 20
stethoscope 69
steward 61
stick up for someone 21
sticky notes 37
stifling 51
still (drink) 32
sting 56, 68
stir 33
stitches 69
stock exchange 38
stomach 14
stomachache / stomach ache 68
stop at 46
stop off 48
stoppage time 61
stopwatch 62
storage 13
store 11, 72
stork 56
storm 51
stormy 51
stove 9
straight hair 17
straight on 46
strange 6
strategy 40
strawberries 29
stream 52
street address 7
street crime 27
street map 46, 72
street market 73
stress 68
stressed 19
stretch 71
striker 61
strikingly different 24
striped 15
stroke of luck 26
stroller 22
strong 32
stubble 17
student 23
study 9
study a subject 23
studying 23, 24
stuffed animal 22
stunning 6
stunt 65
style your hair 17
styles 15, 17
stylist 34
subject 7
substitutes 61
subtitles 66
subtract 59
suburb 75
suck 14
sugar 31, 70
suit (clothing) 15
suit (someone) 15
suitcase 47
sultana 29
sum up 40
summer 3
sun 51
sunbathing 50
sun cream 50
Sunday 3
sunglasses 16
sunny 51
sunscreen 50
superb 6
superfoods 70
supermarket 74
supervise 42
supportive 18
surf the internet 58
surfboard 62
surfing 50, 60
surgeon 34
surprised 19
sushi 28
swallow 32
swamp 52
swan 56
sweat 14
sweater 15
sweep the floor 11
sweet 32
sweet potatoes 30
sweetcorn 30
sweets 31
swimming 60
swimming cap 62
swimming gear 62
swimming pool 62, 72
swimming trunks 50, 62
swimsuit 50, 62
swing 55
swings 22
swollen 68
swoop 56
swordfish 57
symptoms 68
synagogue 72
syringe 69
Ttable 9
table tennis 60
tablet (gadget) 76
tablets (medicine) 69
tackle 61
358
tackle pollution 53
tackle something head-on 39
tail (airplane / aeroplane) 44
tail (animal) 54, 55
take a bath 4
take a flight 44
take a shower 4
take a test 24
take a year off 24
take a year out 24
take after someone 21
take an exam 24
take away 33
take minutes 40
take off 15, 39
take on someone 39
take out 33
take out the rubbish 4, 11
take out the trash 4, 11
take photos 58
take questions 40
take someone on 39
take something with a pinch of salt 8
take the bus 44
take the first left 46
take the second right 46
take the train 44
talent show 67
talented 18
talk 59
talk show 66
talkative 18
tall 17
tambourine 64
tan / tanned skin 17
tandem 49
tape measure 12
tapir 55
taste 32, 59
tasty 32
tattletale 26
taxi 44
taxi driver 34
taxi rank 44
taxi stand 44
tea 4, 32
teacher 23, 34
teacher’s pet 8
team player 43
teamwork 43
technology 23, 76, 77
technophile 77
technophobe 77
teddy bear 22
teenagers 20
teeth 14
telephone 37
telephone manner 43
television 9, 66 see also TV
tell a white lie 26
telltale 26
temperature 51, 68
temple 72
temporary 35
ten 2
tenancy agreement 13
tenant 13
tennis 60
tennis court 62
tennis racket 62
tent 49
tent peg 49
tent pole 49
tenth 2
term 24
terraced houses 13
terrarium 54
terrible 6
terrified 19
test 23
test results 69
test tubes 78
text message 7
textbook 23, 63
Thailand 1
theater / theatre 65, 72
there 46
thermometer 69
thesis 23
thick 5
thigh 14
thin 5
think 59
think outside the box 41
think the world of someone 21
third 2
thirst for adventure 48
thirteen 2
thirty 2
thousand 2
three 2
three times a week 3
thrilled 19
thriller 65, 66
thrilling 6
throw 59
throw money down the drain 41
throw-in 61
thumb 14
thumbtack 37
thunder 51
thundery 51
Thursday 3
ticket 44
tidy 11
tie (clothing) 15
tie (sports result) 61
tie your hair back 17
tiger 55
tight 5
tights 15
tile the bathroom 12
till 38, 74
time 3
time management 43
tin 32
tin opener 10
tip 33
tire 45, 49
tired 19
tiring 6
title 7
toast 31
toaster 10
toddler 20
toe 14
toilet 9
toilet block 49
toilet paper 10
toiletries 10
tomatoes 30
tonsillitis 68
tool box 12
tools 12
tooth 14
toothbrush 10
torch 49
tornado 51
tortoise 54
toucan 56
touch base 41
touch wood 26
tour guide 34
tourism 48
tourism industry 36
tourist attraction 75
tourist information 72
tourist office 72
tourist trap 48
towel 9, 50
town 72
town hall 72
town square 72
toy shop 73
toy store 73
toys 22
traffic jam 45, 75
traffic lights 45
tragedy 65
train 44, 71
train driver 34
359
train set 22
train station 44, 72
trained in 42
trainers 16
tram 44
transfer money 38
translation 25
transportation 44
transportation industry 36
trash 7
trash can 9, 37
travel 44, 47, 48
travel agent 34
travel writing 63
trays 37
treadmill 71
treatment 69
trial 27
trim a hedge 12
triplets 20
trombone 64
trousers 15
trout 57
trowel 12
truck 44
trumpet 64
trunk 45, 55
try on 73
t-shirt 15
Tuesday 3
tumble dryer 11
tuna 57
turkey 54
Turkey 1
Turkish 1
turn / turning 46
turn left 46
turn off 66, 76
turn on 66, 76
turn right 46
turn signal 45
turn up the volume 66
turtle 57
tusk 55
TV 9, 66
TV guide 63, 66
TV schedule 66
TV set 66
tweezers 69
twelfth 2
twelve 2
twentieth 2
twenty 2
twenty-first 2
twenty-one 2
twenty-two 2
twice a week 3
twin beds 47
twins 20
two 2
two hundred 2
two weeks 3
tyre 45, 49
UUAE 1
ugly 6
UK 1
umbrella 16
unanimous agreement 40
unapproachable 18
unblock the sink 12
uncle 20
unclog the sink 12
undergraduate 24
understand 59
undo 15
unenthusiastic 19
unfasten 15
unfriendly 18
unfurnished 13
unhappy 19
unicycle 49
uniform 15
unimpressed 19
United Arab Emirates 1
United Kingdom 1
United States of America 1
university 23
unkind 18
unload the dishwasher 11
unpack 13
unpleasant 6
unreasonable 18
unreliable 18
unsaturated fat 70
unshakable belief 26
unspoiled 48
up 15
up to your ears 39
up to your eyeballs 39
upload 76
upmarket 74
upset 19
upstairs 9
urban life 75
urban myth 26
US 1
USB drive 76
useful 6
useless 6
usher 65
usually 3
Vvacancies 47
vacation 47, 58
vacuum cleaner 11
vacuum the carpet 11
valley 52
van 44
vandalism 27, 75
vegan 70
vegetables 30
vegetarian 70
vet 34
veterinary medicine 23
vice / vise 12
video games 58
video on demand 66
view a house 13
villa 47
village 72
villain 65
vinegar 31
violin 64
virus 68
visit a gallery 58
visit a museum 58
vitamins 70
vocabulary 25
voicemail 7
volcano 52
volleyball 60
volunteer 42
vomit 68
vulture 56
Wwages 35
waist 14
waiter 33, 34
waiting room 69
waitress 33, 34
wake up 4
walk 44, 58
walk the dog 4
walking boots 49
walking holiday 47
walking vacation 47
wallet 16, 38
walnut 29
walrus 57
want 73
wardrobe 9
warm 51
warm up 71
wash the car 11
wash the dishes 4
360
The publisher would like to thank:
Sarah Edwards, Carrie Lewis, Daniel Mills, Aisvarya Misra, and Christine Stroyan for editorial assistance; Rabia Ahmad, Debjyoti
Mukherjee, and Sonakshi Singh for design assistance; Simon Mumford for national flags; Viola Wang for additional illustration;
Steph Lewis for proofreading; Elizabeth Wise for indexing; Christine Stroyan for audio recording management; and ID Audio for
audio recording and production.
wash your face 4
wash your hair 4
washing line 11
washing machine 11
washing up liquid 11
wasp 56
watch 16
watch a movie 58
watch television / TV 4, 58
watch your weight 70
water 32
water cooler 37
water the flowers 12
water the plants 11
waterfall 52
watermelon 29
waterproofs 49
wave (gesture) 14
wave (water) 50, 52
wavy hair 17
wear 15
weather 51, 66
weather forecast 66
website 7
Wednesday 3
weeding 12
week 3
weekend 3
weekly 3
weights 71
well-being 71
west 46
western 65
wet 51
wet suit 50
wet wipe 22
whales 57
what the future holds 77
wheel 45
wheel clamp 45
wheelbarrow 12
whisk (action) 33
whisk (equipment) 10
whiskers 54
whisper 59
white 5
white-collar crime 27
wide 5
wide range 74
widow 20
widower 20
wife 20
Wi-Fi 76
wild animals 55
wind 51
wind farm 53
wind power 53
windbreak 50
window 9
window seat 47
window shopping 73
windsurfing 50, 60
windy 51
wine 32
wing (airplane / aeroplane) 44
wing (bird) 28, 56
wink 14
winter 3
win-win situation 41
wipers 45
wire 76
wireless 76
withdraw money 38
witness 27
wok 10
wolf 55
women’s wear 74
wonderful 6
wood (landscape) 52
wood (material) 5
wooden spoon 10
woodpecker 56
wool 5
woolen / woollen 15
word of mouth 26
work 4, 59
work from home 35
work full-time 35
work opportunities 75
work out 71
work overtime 4
work part-time 35
work shifts 35
work well under pressure 43
working 39, 41
working environment 39
workplace 43
world of difference 24
worm 56
worried 19
wound 68
wrap (sandwich) 28
wrap up 40
wrench 12
wrinkles 17
write 58
writer 34
writing 25
written communication 43
XX-ray 69
Yyacht 44
yak 55
yard (garden) 9
yard (measurement) 46
yawn 14
year 3
yellow 5
yellow card 61
yoga 58, 71
yogurt 28
yolk 28
young 17
yo-yo 22
Zzebra 55
zip / zipper 15, 16
zip code 7
zucchini 30
Acknowledgments
LINUXSystem Programming
Robert Love
Beijing • Cambridge • Farnham • Köln • Paris • Sebastopol • Taipei • Tokyo
Linux System Programming
by Robert Love
Copyright © 2007 O’Reilly Media, Inc. All rights reserved.
Printed in the United States of America.
Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.
O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions
are also available for most titles (safari.oreilly.com). For more information, contact our
corporate/institutional sales department: (800) 998-9938 or corporate@oreilly.com.
Editor: Andy Oram
Production Editor: Sumita Mukherji
Copyeditor: Rachel Head
Proofreader: Sumita Mukherji
Indexer: John Bickelhaupt
Cover Designer: Karen Montgomery
Interior Designer: David Futato
Illustrator: Jessamyn Read
Printing History:
September 2007: First Edition.
Nutshell Handbook, the Nutshell Handbook logo, and the O’Reilly logo are registered trademarks of
O’Reilly Media, Inc. The Linux series designations, Linux System Programming, images of the man in
the flying machine, and related trade dress are trademarks of O’Reilly Media, Inc.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as
trademarks. Where those designations appear in this book, and O’Reilly Media, Inc. was aware of a
trademark claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of this book, the publisher and author assume
no responsibility for errors or omissions, or for damages resulting from the use of the information
contained herein.
This book uses RepKover™, a durable and flexible lay-flat binding.
ISBN-10: 0-596-00958-5
ISBN-13: 978-0-596-00958-8
[M]
v
Table of Contents
Foreword . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi
1. Introduction and Essential Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
System Programming 1
APIs and ABIs 4
Standards 6
Concepts of Linux Programming 9
Getting Started with System Programming 22
2. File I/O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
Opening Files 24
Reading via read( ) 29
Writing with write( ) 33
Synchronized I/O 37
Direct I/O 40
Closing Files 41
Seeking with lseek( ) 42
Positional Reads and Writes 44
Truncating Files 45
Multiplexed I/O 47
Kernel Internals 57
Conclusion 61
vi | Table of Contents
3. Buffered I/O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
User-Buffered I/O 62
Standard I/O 64
Opening Files 65
Opening a Stream via File Descriptor 66
Closing Streams 67
Reading from a Stream 67
Writing to a Stream 70
Sample Program Using Buffered I/O 72
Seeking a Stream 74
Flushing a Stream 75
Errors and End-of-File 76
Obtaining the Associated File Descriptor 77
Controlling the Buffering 77
Thread Safety 79
Critiques of Standard I/O 81
Conclusion 82
4. Advanced File I/O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Scatter/Gather I/O 84
The Event Poll Interface 89
Mapping Files into Memory 95
Advice for Normal File I/O 108
Synchronized, Synchronous, and Asynchronous Operations 111
I/O Schedulers and I/O Performance 114
Conclusion 125
5. Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
The Process ID 126
Running a New Process 129
Terminating a Process 136
Waiting for Terminated Child Processes 139
Users and Groups 149
Sessions and Process Groups 154
Daemons 159
Conclusion 161
Table of Contents | vii
6. Advanced Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
Process Scheduling 162
Yielding the Processor 166
Process Priorities 169
Processor Affinity 172
Real-Time Systems 176
Resource Limits 190
7. File and Directory Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
Files and Their Metadata 196
Directories 212
Links 223
Copying and Moving Files 228
Device Nodes 231
Out-of-Band Communication 233
Monitoring File Events 234
8. Memory Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
The Process Address Space 243
Allocating Dynamic Memory 245
Managing the Data Segment 255
Anonymous Memory Mappings 256
Advanced Memory Allocation 260
Debugging Memory Allocations 263
Stack-Based Allocations 264
Choosing a Memory Allocation Mechanism 268
Manipulating Memory 269
Locking Memory 273
Opportunistic Allocation 277
9. Signals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
Signal Concepts 280
Basic Signal Management 286
Sending a Signal 291
Reentrancy 293
Signal Sets 295
Blocking Signals 296
viii | Table of Contents
Advanced Signal Management 298
Sending a Signal with a Payload 305
Conclusion 306
10. Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
Time’s Data Structures 310
POSIX Clocks 313
Getting the Current Time of Day 315
Setting the Current Time of Day 318
Playing with Time 320
Tuning the System Clock 321
Sleeping and Waiting 324
Timers 330
Appendix. GCC Extensions to the C Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
ix
Foreword
There is an old line that Linux kernel developers like to throw out when they are feel-
ing grumpy: “User space is just a test load for the kernel.”
By muttering this line, the kernel developers aim to wash their hands of all responsi-
bility for any failure to run user-space code as well as possible. As far as they’re
concerned, user-space developers should just go away and fix their own code, as any
problems are definitely not the kernel’s fault.
To prove that it usually is not the kernel that is at fault, one leading Linux kernel
developer has been giving a “Why User Space Sucks” talk to packed conference
rooms for more than three years now, pointing out real examples of horrible user-
space code that everyone relies on every day. Other kernel developers have created
tools that show how badly user-space programs are abusing the hardware and drain-
ing the batteries of unsuspecting laptops.
But while user-space code might be just a “test load” for kernel developers to scoff
at, it turns out that all of these kernel developers also depend on that user-space code
every day. If it weren’t present, all the kernel would be good for would be to print
out alternating ABABAB patterns on the screen.
Right now, Linux is the most flexible and powerful operating system that has ever
been created, running everything from the tiniest cell phones and embedded devices
to more than 70 percent of the world’s top 500 supercomputers. No other operating
system has ever been able to scale so well and meet the challenges of all of these dif-
ferent hardware types and environments.
And along with the kernel, code running in user space on Linux can also operate on
all of those platforms, providing the world with real applications and utilities people
rely on.
In this book, Robert Love has taken on the unenviable task of teaching the reader
about almost every system call on a Linux system. In so doing, he has produced a
tome that will allow you to fully understand how the Linux kernel works from a
user-space perspective, and also how to harness the power of this system.
x | Foreword
The information in this book will show you how to create code that will run on all of
the different Linux distributions and hardware types. It will allow you to understand
how Linux works and how to take advantage of its flexibility.
In the end, this book teaches you how to write code that doesn't suck, which is the
best thing of all.
—Greg Kroah-Hartman
xi
Preface
This book is about system programming—specifically, system programming on
Linux. System programming is the practice of writing system software, which is code
that lives at a low level, talking directly to the kernel and core system libraries. Put
another way, the topic of the book is Linux system calls and other low-level func-
tions, such as those defined by the C library.
While many books cover system programming for Unix systems, few tackle the sub-
ject with a focus solely on Linux, and fewer still (if any) address the very latest Linux
releases and advanced Linux-only interfaces. Moreover, this book benefits from a
special touch: I have written a lot of code for Linux, both for the kernel and for sys-
tem software built thereon. In fact, I have implemented some of the system calls and
other features covered in this book. Consequently, this book carries a lot of insider
knowledge, covering not just how the system interfaces should work, but how they
actually work, and how you (the programmer) can use them most efficiently. This
book, therefore, combines in a single work a tutorial on Linux system programming,
a reference manual covering the Linux system calls, and an insider’s guide to writing
smarter, faster code. The text is fun and accessible, and regardless of whether you
code at the system level on a daily basis, this book will teach you tricks that will
enable you to write better code.
Audience and Assumptions
The following pages assume that the reader is familiar with C programming and the
Linux programming environment—not necessarily well-versed in the subjects, but at
least acquainted with them. If you have not yet read any books on the C program-
ming language, such as the classic Brian W. Kernighan and Dennis M. Ritchie work
The C Programming Language (Prentice Hall; the book is familiarly known as K&R),
I highly recommend you check one out. If you are not comfortable with a Unix text
editor—Emacs and vim being the most common and highly regarded—start playing
xii | Preface
with one. You’ll also want to be familiar with the basics of using gcc, gdb, make, and
so on. Plenty of other books on tools and practices for Linux programming are out
there; the bibliography at the end of this book lists several useful references.
I’ve made few assumptions about the reader’s knowledge of Unix or Linux system
programming. This book will start from the ground up, beginning with the basics,
and winding its way up to the most advanced interfaces and optimization tricks.
Readers of all levels, I hope, will find this work worthwhile and learn something
new. In the course of writing the book, I certainly did.
Nor do I make assumptions about the persuasion or motivation of the reader.
Engineers wishing to program (better) at a low level are obviously targeted, but
higher-level programmers looking for a stronger standing on the foundations on
which they rest will also find a lot to interest them. Simply curious hackers are also
welcome, for this book should satiate their hunger, too. Whatever readers want and
need, this book should cast a net wide enough—as least as far as Linux system pro-
gramming is concerned—to satisfy them.
Regardless of your motives, above all else, have fun.
Contents of This Book
This book is broken into 10 chapters, an appendix, and a bibliography.
Chapter 1, Introduction and Essential Concepts
This chapter serves as an introduction, providing an overview of Linux, system
programming, the kernel, the C library, and the C compiler. Even advanced
users should visit this chapter—trust me.
Chapter 2, File I/O
This chapter introduces files, the most important abstraction in the Unix envi-
ronment, and file I/O, the basis of the Linux programming mode. This chapter
covers reading from and writing to files, along with other basic file I/O operations.
The chapter culminates with a discussion on how the Linux kernel implements and
manages files.
Chapter 3, Buffered I/O
This chapter discusses an issue with the basic file I/O interfaces—buffer size
management—and introduces buffered I/O in general, and standard I/O in par-
ticular, as solutions.
Chapter 4, Advanced File I/O
This chapter completes the I/O troika with a treatment on advanced I/O inter-
faces, memory mappings, and optimization techniques. The chapter is capped with
a discussion on avoiding seeks, and the role of the Linux kernel’s I/O scheduler.
Preface | xiii
Chapter 5, Process Management
This chapter introduces Unix’s second most important abstraction, the process,
and the family of system calls for basic process management, including the ven-
erable fork.
Chapter 6, Advanced Process Management
This chapter continues the treatment with a discussion of advanced process
management, including real-time processes.
Chapter 7, File and Directory Management
This chapter discusses creating, moving, copying, deleting, and otherwise man-
aging files and directories.
Chapter 8, Memory Management
This chapter covers memory management. It begins by introducing Unix con-
cepts of memory, such as the process address space and the page, and continues
with a discussion of the interfaces for obtaining memory from and returning
memory to the kernel. The chapter concludes with a treatment on advanced
memory-related interfaces.
Chapter 9, Signals
This chapter covers signals. It begins with a discussion of signals and their role
on a Unix system. It then covers signal interfaces, starting with the basic, and
concluding with the advanced.
Chapter 10, Time
This chapter discusses time, sleeping, and clock management. It covers the basic
interfaces up through POSIX clocks and high-resolution timers.
Appendix, GCC Extensions to the C Language
The Appendix reviews many of the optimizations provided by gcc and GNUC,
such as attributes for marking a function constant, pure, and inline.
The book concludes with a bibliography of recommended reading, listing both use-
ful supplements to this work, and books that address prerequisite topics not covered
herein.
Versions Covered in This Book
The Linux system interface is definable as the application binary interface and appli-
cation programming interface provided by the triplet of the Linux kernel (the heart
of the operating system), the GNUC library (glibc ), and the GNUC Compiler (gcc —
now formally called the GNUCompiler Collection, but we are concerned only with
C). This book covers the system interface defined by Linux kernel version 2.6.22,
glibc version 2.5, and gcc version 4.2. Interfaces in this book should be backward
compatible with older versions (excluding new interfaces), and forward compatible
to newer versions.
xiv | Preface
If any evolving operating system is a moving target, Linux is a rabid cheetah.
Progress is measured in days, not years, and frequent releases of the kernel and other
components constantly morph the playing field. No book can hope to capture such a
dynamic beast in a timeless fashion.
Nonetheless, the programming environment defined by system programming is set in
stone. Kernel developers go to great pains not to break system calls, the glibc devel-
opers highly value forward and backward compatibility, and the Linux toolchain
generates compatible code across versions (particularly for the C language). Conse-
quently, while Linux may be constantly on the go, Linux system programming
remains stable, and a book based on a snapshot of the system, especially at this point
in Linux’s development, has immense staying power. What I am trying to say is sim-
ple: don’t worry about system interfaces changing, and buy this book!
Conventions Used in This Book
The following typographical conventions are used in this book:
Italic
Used for emphasis, new terms, URLs, foreign phrases, Unix commands and util-
ities, filenames, directory names, and pathnames.
Constant width
Indicates header files, variables, attributes, functions, types, parameters, objects,
macros, and other programming constructs.
Constant width italic
Indicates text (for example, a pathname component) to be replaced with a user-
supplied value.
This icon signifies a tip, suggestion, or general note.
Most of the code in this book is in the form of brief, but usable, code snippets. They
look like this:
while (1) {
int ret;
ret = fork ( );
if (ret == -1)
perror ("fork");
}
Great pains have been taken to provide code snippets that are concise but usable. No
special header files, full of crazy macros and illegible shortcuts, are required. Instead
of building a few gigantic programs, this book is filled with many simple examples.
Preface | xv
As the examples are descriptive and fully usable, yet small and clear, I hope they will
provide a useful tutorial on the first read, and remain a good reference on subse-
quent passes.
Nearly all of the examples in this book are self-contained. This means you can easily
copy them into your text editor, and put them to actual use. Unless otherwise men-
tioned, all of the code snippets should build without any special compiler flags. (In a
few cases, you need to link with a special library.) I recommend the following com-
mand to compile a source file:
$ gcc -Wall -Wextra -O2 -g -o snippet snippet.c
This compiles the source file snippet.c into the executable binary snippet, enabling
many warning checks, significant but sane optimizations, and debugging. The code
in this book should compile using this command without errors or warnings—
although of course, you might have to build a skeleton program around the snippet
first.
When a section introduces a new function, it is in the usual Unix manpage format
with a special emphasized font, which looks like this:
#include <fcntl.h>
int posix_fadvise (int fd, off_t pos, off_t len, int advice);
The required headers, and any needed definitions, are at the top, followed by a full
prototype of the call.
Safari® Books Online
When you see a Safari® Books Online icon on the cover of your
favorite technology book, that means the book is available online
through the O’Reilly Network Safari Bookshelf.
Safari offers a solution that’s better than e-books. It’s a virtual library that lets you
easily search thousands of top tech books, cut and paste code samples, download
chapters, and find quick answers when you need the most accurate, current informa-
tion. Try it for free at http://safari.oreilly.com.
Using Code Examples
This book is here to help you get your job done. In general, you may use the code in
this book in your programs and documentation. You do not need to contact us for
permission unless you are reproducing a significant portion of the code. For exam-
ple, writing a program that uses several chunks of code from this book does not
require permission. Selling or distributing a CD-ROM of examples from O’Reilly
books does require permission. Answering a question by citing this book and quoting
xvi | Preface
example code does not require permission. Incorporating a significant amount of
example code from this book into your product’s documentation does require
permission.
We appreciate attribution. An attribution usually includes the title, author, pub-
lisher, and ISBN. For example: “Linux System Programming by Robert Love. Copy-
right 2007 O’Reilly Media, Inc., 978-0-596-00958-8.”
If you believe that your use of code examples falls outside of fair use or the permis-
sion given above, feel free to contact us at permissions@oreilly.com.
How to Contact Us
Please address comments and questions concerning this book to the publisher:
O’Reilly Media, Inc.
1005 Gravenstein Highway North
Sebastopol, CA 95472
800-998-9938 (in the United States or Canada)
707-829-0515 (international or local)
707-829-0104 (fax)
We have a web page for this book, where we list errata, examples, and any addi-
tional information. You can access this page at this address:
http://www.oreilly.com/catalog/9780596009588/
To comment or ask technical questions about this book, you can send an email to
the following address:
bookquestions@oreilly.com
For more information about our books, conferences, Resource Centers, and the
O’Reilly Network, see our web site at this address:
http://www.oreilly.com
Acknowledgments
Many hearts and minds contributed to the completion of this manuscript. While no
list would be complete, it is my sincere pleasure to acknowledge the assistance and
friendship of individuals who provided encouragement, knowledge, and support
along the way.
Andy Oram is a phenomenal editor and human being. This effort would have been
impossible without his hard work. A rare breed, Andy couples deep technical knowl-
edge with a poetic command of the English language.
Preface | xvii
Brian Jepson served brilliantly as editor for a period, and his sterling efforts continue
to reverberate throughout this work as well.
This book was blessed with phenomenal technical reviewers, true masters of their
craft, without whom this work would pale in comparison to the final product you
now read. The technical reviewers were Robert Day, Jim Lieb, Chris Rivera, Joey
Shaw, and Alain Williams. Despite their toils, any errors remain my own.
Rachel Head performed flawlessly as copyeditor. In her aftermath, red ink decorated
my written word—readers will certainly appreciate her corrections.
For numerous reasons, thanks and respect to Paul Amici, Mikey Babbitt, Keith Bar-
bag, Jacob Berkman, Dave Camp, Chris DiBona, Larry Ewing, Nat Friedman, Albert
Gator, Dustin Hall, Joyce Hawkins, Miguel de Icaza, Jimmy Krehl, Greg Kroah-
Hartman, Doris Love, Jonathan Love, Linda Love, Tim O’Reilly, Aaron Matthews,
John McCain, Randy O’Dowd, Salvatore Ribaudo and family, Chris Rivera, Joey
Shaw, Sarah Stewart, Peter Teichman, Linus Torvalds, Jon Trowbridge, Jeremy Van-
Doren and family, Luis Villa, Steve Weisberg and family, and Helen Whisnant.
Final thanks to my parents, Bob and Elaine.
—Robert Love
Boston
1
Chapter 1 CHAPTER 1
Introduction and Essential
Concepts
This book is about system programming, which is the art of writing system software.
System software lives at a low level, interfacing directly with the kernel and core
system libraries. System software includes your shell and your text editor, your com-
piler and your debugger, your core utilities and system daemons. These components
are entirely system software, based on the kernel and the C library. Much other soft-
ware (such as high-level GUI applications) lives mostly in the higher levels, delving
into the low level only on occasion, if at all. Some programmers spend all day every
day writing system software; others spend only part of their time on this task. There
is no programmer, however, who does not benefit from some understanding of
system programming. Whether it is the programmer’s raison d’être, or merely a foun-
dation for higher-level concepts, system programming is at the heart of all software
that we write.
In particular, this book is about system programming on Linux. Linux is a modern
Unix-like system, written from scratch by Linus Torvalds, and a loose-knit commu-
nity of hackers around the globe. Although Linux shares the goals and ideology of
Unix, Linux is not Unix. Instead, Linux follows its own course, diverging where
desired, and converging only where practical. Generally, the core of Linux system
programming is the same as on any other Unix system. Beyond the basics, however,
Linux does well to differentiate itself—in comparison with traditional Unix systems,
Linux is rife with additional system calls, different behavior, and new features.
System Programming
Traditionally speaking, all Unix programming is system-level programming. Histori-
cally, Unix systems did not include many higher-level abstractions. Even programming
in a development environment such as the X Window System exposed in full view the
core Unix system API. Consequently, it can be said that this book is a book on Linux
2 | Chapter 1: Introduction and Essential Concepts
programming in general. But note that this book does not cover the Linux
programming environment—there is no tutorial on make in these pages. What is cov-
ered is the system programming API exposed on a modern Linux machine.
System programming is most commonly contrasted with application programming.
System-level and application-level programming differ in some aspects, but not in
others. System programming is distinct in that system programmers must have a
strong awareness of the hardware and operating system on which they are working.
Of course, there are also differences between the libraries used and calls made.
Depending on the “level” of the stack at which an application is written, the two may
not actually be very interchangeable, but, generally speaking, moving from applica-
tion programming to system programming (or vice versa) is not hard. Even when the
application lives very high up the stack, far from the lowest levels of the system,
knowledge of system programming is important. And the same good practices are
employed in all forms of programming.
The last several years have witnessed a trend in application programming away from
system-level programming and toward very high-level development, either through
web software (such as JavaScript or PHP), or through managed code (such as C# or
Java). This development, however, does not foretell the death of system program-
ming. Indeed, someone still has to write the JavaScript interpreter and the C#
runtime, which is itself system programming. Furthermore, the developers writing
PHP or Java can still benefit from knowledge of system programming, as an under-
standing of the core internals allows for better code no matter where in the stack the
code is written.
Despite this trend in application programming, the majority of Unix and Linux code
is still written at the system level. Much of it is C, and subsists primarily on interfaces
provided by the C library and the kernel. This is traditional system programming—
Apache, bash, cp, Emacs, init, gcc, gdb, glibc, ls, mv, vim, and X. These applications
are not going away anytime soon.
The umbrella of system programming often includes kernel development, or at least
device driver writing. But this book, like most texts on system programming, is
unconcerned with kernel development. Instead, it focuses on user-space system-level
programming; that is, everything above the kernel (although knowledge of kernel
internals is a useful adjunct to this text). Likewise, network programming—sockets
and such—is not covered in this book. Device driver writing and network program-
ming are large, expansive topics, best tackled in books dedicated to the subject.
What is the system-level interface, and how do I write system-level applications in
Linux? What exactly do the kernel and the C library provide? How do I write opti-
mal code, and what tricks does Linux provide? What neat system calls are provided
in Linux compared to other Unix variants? How does it all work? Those questions
are at the center of this book.
There are three cornerstones to system programming in Linux: system calls, the C
library, and the C compiler. Each deserves an introduction.
System Programming | 3
System Calls
System programming starts with system calls. System calls (often shorted to syscalls)
are function invocations made from user space—your text editor, favorite game, and so
on—into the kernel (the core internals of the system) in order to request some service
or resource from the operating system. System calls range from the familiar, such as
read( ) and write( ), to the exotic, such as get_thread_area( ) and set_tid_address( ).
Linux implements far fewer system calls than most other operating system kernels.
For example, a count of the i386 architecture’s system calls comes in at around 300,
compared with the allegedly thousands of system calls on Microsoft Windows. In the
Linux kernel, each machine architecture (such as Alpha, i386, or PowerPC) imple-
ments its own list of available system calls. Consequently, the system calls available
on one architecture may differ from those available on another. Nonetheless, a very
large subset of system calls—more than 90 percent—is implemented by all architec-
tures. It is this shared subset, these common interfaces, that I cover in this book.
Invoking system calls
It is not possible to directly link user-space applications with kernel space. For rea-
sons of security and reliability, user-space applications must not be allowed to
directly execute kernel code or manipulate kernel data. Instead, the kernel must pro-
vide a mechanism by which a user-space application can “signal” the kernel that it
wishes to invoke a system call. The application can then trap into the kernel through
this well-defined mechanism, and execute only code that the kernel allows it to exe-
cute. The exact mechanism varies from architecture to architecture. On i386, for
example, a user-space application executes a software interrupt instruction, int, with
a value of 0x80. This instruction causes a switch into kernel space, the protected
realm of the kernel, where the kernel executes a software interrupt handler—and
what is the handler for interrupt 0x80? None other than the system call handler!
The application tells the kernel which system call to execute and with what parame-
ters via machine registers. System calls are denoted by number, starting at 0. On the
i386 architecture, to request system call 5 (which happens to be open( )), the user-
space application stuffs 5 in register eax before issuing the int instruction.
Parameter passing is handled in a similar manner. On i386, for example, a register is
used for each possible parameter—registers ebx, ecx, edx, esi, and edi contain, in
order, the first five parameters. In the rare event of a system call with more than five
parameters, a single register is used to point to a buffer in user space where all of the
parameters are kept. Of course, most system calls have only a couple of parameters.
Other architectures handle system call invocation differently, although the spirit is
the same. As a system programmer, you usually do not need any knowledge of how
the kernel handles system call invocation. That knowledge is encoded into the stan-
dard calling conventions for the architecture, and handled automatically by the
compiler and the C library.
4 | Chapter 1: Introduction and Essential Concepts
The C Library
The C library (libc) is at the heart of Unix applications. Even when you’re programming
in another language, the C library is most likely in play, wrapped by the higher-level
libraries, providing core services, and facilitating system call invocation. On modern
Linux systems, the C library is provided by GNU libc, abbreviated glibc, and pro-
nounced gee-lib-see or, less commonly, glib-see.
The GNUC library provides more than its name suggests. In addition to implement-
ing the standard C library, glibc provides wrappers for system calls, threading
support, and basic application facilities.
The C Compiler
In Linux, the standard C compiler is provided by the GNU Compiler Collection (gcc).
Originally, gcc was GNU’s version of cc, the C Compiler. Thus, gcc stood for GNU C
Compiler. Over time, support was added for more and more languages. Conse-
quently, nowadays gcc is used as the generic name for the family of GNUcompilers.
However, gcc is also the binary used to invoke the C compiler. In this book, when I
talk of gcc, I typically mean the program gcc, unless context suggests otherwise.
The compiler used in a Unix system—Linux included—is highly relevant to system
programming, as the compiler helps implement the C standard (see “C Language
Standards”) and the system ABI (see “APIs and ABIs”), both later in this chapter.
APIs and ABIs
Programmers are naturally interested in ensuring their programs run on all of the sys-
tems that they have promised to support, now and in the future. They want to feel
secure that programs they write on their Linux distributions will run on other Linux
distributions, as well as on other supported Linux architectures and newer (or ear-
lier) Linux versions.
At the system level, there are two separate sets of definitions and descriptions that
impact portability. One is the application programming interface (API), and the other
is the application binary interface (ABI). Both define and describe the interfaces
between different pieces of computer software.
APIs
An API defines the interfaces by which one piece of software communicates with
another at the source level. It provides abstraction by providing a standard set of
interfaces—usually functions—that one piece of software (typically, although not
APIs and ABIs | 5
necessarily, a higher-level piece) can invoke from another piece of software (usually a
lower-level piece). For example, an API might abstract the concept of drawing text
on the screen through a family of functions that provide everything needed to draw
the text. The API merely defines the interface; the piece of software that actually pro-
vides the API is known as the implementation of the API.
It is common to call an API a “contract.” This is not correct, at least in the legal sense
of the term, as an API is not a two-way agreement. The API user (generally, the
higher-level software) has zero input into the API and its implementation. It may use
the API as-is, or not use it at all: take it or leave it! The API acts only to ensure that if
both pieces of software follow the API, they are source compatible; that is, that the
user of the API will successfully compile against the implementation of the API.
A real-world example is the API defined by the C standard and implemented by the
standard C library. This API defines a family of basic and essential functions, such as
string-manipulation routines.
Throughout this book, we will rely on the existence of various APIs, such as the stan-
dard I/O library discussed in Chapter 3. The most important APIs in Linux system
programming are discussed in the section “Standards” later in this chapter.
ABIs
Whereas an API defines a source interface, an ABI defines the low-level binary inter-
face between two or more pieces of software on a particular architecture. It defines
how an application interacts with itself, how an application interacts with the kernel,
and how an application interacts with libraries. An ABI ensures binary compatibility,
guaranteeing that a piece of object code will function on any system with the same
ABI, without requiring recompilation.
ABIs are concerned with issues such as calling conventions, byte ordering, register
use, system call invocation, linking, library behavior, and the binary object format.
The calling convention, for example, defines how functions are invoked, how argu-
ments are passed to functions, which registers are preserved and which are mangled,
and how the caller retrieves the return value.
Although several attempts have been made at defining a single ABI for a given archi-
tecture across multiple operating systems (particularly for i386 on Unix systems), the
efforts have not met with much success. Instead, operating systems—Linux
included—tend to define their own ABIs however they see fit. The ABI is intimately
tied to the architecture; the vast majority of an ABI speaks of machine-specific
concepts, such as particular registers or assembly instructions. Thus, each machine
architecture has its own ABI on Linux. In fact, we tend to call a particular ABI by its
machine name, such as alpha, or x86-64.
6 | Chapter 1: Introduction and Essential Concepts
System programmers ought to be aware of the ABI,but usually do not need to
memorize it. The ABI is enforced by the toolchain—the compiler, the linker, and so
on—and does not typically otherwise surface. Knowledge of the ABI, however, can
lead to more optimal programming, and is required if writing assembly code or hack-
ing on the toolchain itself (which is, after all, system programming).
The ABI for a given architecture on Linux is available on the Internet and imple-
mented by that architecture’s toolchain and kernel.
Standards
Unix system programming is an old art. The basics of Unix programming have
existed untouched for decades. Unix systems, however, are dynamic beasts. Behav-
ior changes and features are added. To help bring order to chaos, standards groups
codify system interfaces into official standards. Numerous such standards exist, but
technically speaking, Linux does not officially comply with any of them. Instead,
Linux aims toward compliance with two of the most important and prevalent stan-
dards: POSIX and the Single UNIX Specification (SUS).
POSIX and SUS document, among other things, the C API for a Unix-like operating
system interface. Effectively, they define system programming, or at least a common
subset thereof, for compliant Unix systems.
POSIX and SUS History
In the mid-1980s, the Institute of Electrical and Electronics Engineers (IEEE) spear-
headed an effort to standardize system-level interfaces on Unix systems. Richard
Stallman, founder of the Free Software movement, suggested the standard be named
POSIX (pronounced pahz-icks), which now stands for Portable Operating System
Interface.
The first result of this effort, issued in 1988, was IEEE Std 1003.1-1988 (POSIX 1988,
for short). In 1990, the IEEE revised the POSIX standard with IEEE Std 1003.1-1990
(POSIX 1990). Optional real-time and threading support were documented in, respec-
tively, IEEE Std 1003.1b-1993 (POSIX 1993 or POSIX.1b), and IEEE Std 1003.1c-1995
(POSIX 1995 or POSIX.1c). In 2001, the optional standards were rolled together with
the base POSIX 1990, creating a single standard: IEEE Std 1003.1-2001 (POSIX 2001).
The latest revision, released in April 2004, is IEEE Std 1003.1-2004. All of the core
POSIX standards are abbreviated POSIX.1, with the 2004 revision being the latest.
In the late 1980s and early 1990s, Unix system vendors were engaged in the “Unix
Wars,” with each struggling to define its Unix variant as the Unix operating system.
Several major Unix vendors rallied around The Open Group, an industry consortium
Standards | 7
formed from the merging of the Open Software Foundation (OSF) and X/Open. The
Open Group provides certification, white papers, and compliance testing. In the
early 1990s, with the Unix Wars raging, The Open Group released the Single UNIX
Specification. SUS rapidly grew in popularity, in large part due to its cost (free) ver-
sus the high cost of the POSIX standard. Today, SUS incorporates the latest POSIX
standard.
The first SUS was published in 1994. Systems compliant with SUSv1 are given the
mark UNIX 95. The second SUS was published in 1997, and compliant systems are
marked UNIX 98. The third and latest SUS, SUSv3, was published in 2002. Compli-
ant systems are given the mark UNIX 03. SUSv3 revises and combines IEEE Std
1003.1-2001 and several other standards. Throughout this book, I will mention
when system calls and other interfaces are standardized by POSIX. I mention POSIX
and not SUS because the latter subsumes the former.
C Language Standards
Dennis Ritchie and Brian Kernighan’s famed book, The C Programming Language
(Prentice Hall), acted as the informal C specification for many years following its
1978 publication. This version of C came to be known as K&R C. C was already
rapidly replacing BASIC and other languages as the lingua franca of microcomputer
programming. Therefore, to standardize the by then quite popular language, in 1983,
the American National Standards Institute (ANSI) formed a committee to develop an
official version of C, incorporating features and improvements from various vendors
and the new C++ language. The process was long and laborious, but ANSI C was
completed in 1989. In 1990, the International Organization for Standardization
(ISO) ratified ISO C90, based on ANSI C with a small handful of modifications.
In 1995, the ISO released an updated (although rarely implemented) version of the C
language, ISO C95. This was followed in 1999 with a large update to the language,
ISO C99, that introduced many new features, including inline functions, new data
types, variable-length arrays, C++-style comments, and new library functions.
Linux and the Standards
As stated earlier, Linux aims toward POSIX and SUS compliance. It provides the
interfaces documented in SUSv3 and POSIX.1, including the optional real-time
(POSIX.1b) and optional threading (POSIX.1c) support. More importantly, Linux
tries to provide behavior in line with POSIX and SUS requirements. In general, fail-
ing to agree with the standards is considered a bug. Linux is believed to comply with
POSIX.1 and SUSv3, but as no official POSIX or SUS certification has been per-
formed (particularly on each and every revision of Linux), I cannot say that Linux is
officially POSIX- or SUS-compliant.
8 | Chapter 1: Introduction and Essential Concepts
With respect to language standards, Linux fares well. The gcc C compiler supports
ISO C99. In addition, gcc provides many of its own extensions to the C language.
These extensions are collectively called GNU C, and are documented in the
Appendix.
Linux has not had a great history of forward compatibility,* although these days it
fares much better. Interfaces documented by standards, such as the standard C
library, will obviously always remain source compatible. Binary compatibility is
maintained across a given major version of glibc, at the very least. And as C is stan-
dardized, gcc will always compile legal C correctly, although gcc-specific extensions
may be deprecated and eventually removed with new gcc releases. Most importantly,
the Linux kernel guarantees the stability of system calls. Once a system call is imple-
mented in a stable version of the Linux kernel, it is set in stone.
Among the various Linux distributions, the Linux Standard Base (LSB) standardizes
much of the Linux system. The LSB is a joint project of several Linux vendors under
the auspices of the Linux Foundation (formerly the Free Standards Group). The LSB
extends POSIX and SUS, and adds several standards of its own; it attempts to provide
a binary standard, allowing object code to run unmodified on compliant systems.
Most Linux vendors comply with the LSB to some degree.
This Book and the Standards
This book deliberately avoids paying lip service to any of the standards. Far too
frequently, Unix system programming books must stop to elaborate on how an inter-
face behaves in one standard versus another, whether a given system call is
implemented on this system versus that, and similar page-filling bloat. This book,
however, is specifically about system programming on a modern Linux system, as
provided by the latest versions of the Linux kernel (2.6), gcc C compiler (4.2), and C
library (2.5).
As system interfaces are generally set in stone—the Linux kernel developers go to
great pains to never break the system call interfaces, for example—and provide some
level of both source and binary compatibility, this approach allows us to dive into
the details of Linux’s system interface unfettered by concerns of compatibility with
numerous other Unix systems and standards. This focus on Linux also enables this
book to offer in-depth treatment of cutting-edge Linux-specific interfaces that will
remain relevant and valid far into the future. The book draws upon an intimate
knowledge of Linux, and particularly of the implementation and behavior of compo-
nents such as gcc and the kernel, to provide an insider’s view, full of the best
practices and optimization tips of an experienced veteran.
* Experienced Linux users might remember the switch from a.out to ELF, the switch from libc5 to glibc, gcc
changes, and so on. Thankfully, those days are behind us.
Concepts of Linux Programming | 9
Concepts of Linux Programming
This section presents a concise overview of the services provided by a Linux system.
All Unix systems, Linux included, provide a mutual set of abstractions and inter-
faces. Indeed, this commonality defines Unix. Abstractions such as the file and the
process, interfaces to manage pipes and sockets, and so on, are at the core of what is
Unix.
This overview assumes that you are familiar with the Linux environment: I presume
that you can get around in a shell, use basic commands, and compile a simple C pro-
gram. This is not an overview of Linux, or its programming environment, but rather
of the “stuff” that forms the basis of Linux system programming.
Files and the Filesystem
The file is the most basic and fundamental abstraction in Linux. Linux follows the
everything-is-a-file philosophy (although not as strictly as some other systems, such
as Plan9* ). Consequently, much interaction transpires via reading of and writing to
files, even when the object in question is not what you would consider your every-
day file.
In order to be accessed, a file must first be opened. Files can be opened for reading,
writing, or both. An open file is referenced via a unique descriptor, a mapping from
the metadata associated with the open file back to the specific file itself. Inside the
Linux kernel, this descriptor is handled by an integer (of the C type int) called the
file descriptor, abbreviated fd. File descriptors are shared with user space, and are
used directly by user programs to access files. A large part of Linux system program-
ming consists of opening, manipulating, closing, and otherwise using file descriptors.
Regular files
What most of us call “files” are what Linux labels regular files. A regular file con-
tains bytes of data, organized into a linear array called a byte stream. In Linux, no
further organization or formatting is specified for a file. The bytes may have any val-
ues, and they may be organized within the file in any way. At the system level, Linux
does not enforce a structure upon files beyond the byte stream. Some operating sys-
tems, such as VMS, provide highly structured files, supporting concepts such as
records. Linux does not.
Any of the bytes within a file may be read from or written to. These operations start
at a specific byte, which is one’s conceptual “location” within the file. This location
is called the file position or file offset. The file position is an essential piece of the
* Plan9, an operating system born of Bell Labs, is often called the successor to Unix. It features several inno-
vative ideas, and is an adherent of the everything-is-a-file philosophy.
10 | Chapter 1: Introduction and Essential Concepts
metadata that the kernel associates with each open file. When a file is first opened, the
file position is zero. Usually, as bytes in the file are read from or written to, byte-by-byte,
the file position increases in kind. The file position may also be set manually to a given
value, even a value beyond the end of the file. Writing a byte to a file position beyond
the end of the file will cause the intervening bytes to be padded with zeros. While it
is possible to write bytes in this manner to a position beyond the end of the file, it is
not possible to write bytes to a position before the beginning of a file. Such a prac-
tice sounds nonsensical, and, indeed, would have little use. The file position starts at
zero; it cannot be negative. Writing a byte to the middle of a file overwrites the byte
previously located at that offset. Thus, it is not possible to expand a file by writing
into the middle of it. Most file writing occurs at the end of the file. The file posi-
tion’s maximum value is bounded only by the size of the C type used to store it,
which is 64-bits in contemporary Linux.
The size of a file is measured in bytes, and is called its length. The length, in other
words, is simply the number of bytes in the linear array that make up the file. A file’s
length can be changed via an operation called truncation. A file can be truncated to a
new size smaller than its original size, which results in bytes being removed from the
end of the file. Confusingly, given the operation’s name, a file can also be “trun-
cated” to a new size larger than its original size. In that case, the new bytes (which
are added to the end of the file) are filled with zeros. A file may be empty (have a
length of zero), and thus contain no valid bytes. The maximum file length, as with
the maximum file position, is bounded only by limits on the sizes of the C types that
the Linux kernel uses to manage files. Specific filesystems, however, may impose
their own restrictions, bringing the maximum length down to a smaller value.
A single file can be opened more than once, by a different or even the same process.
Each open instance of a file is given a unique file descriptor; processes can share their
file descriptors, allowing a single descriptor to be used by more than one process.
The kernel does not impose any restrictions on concurrent file access. Multiple pro-
cesses are free to read from and write to the same file at the same time. The results of
such concurrent accesses rely on the ordering of the individual operations, and are
generally unpredictable. User-space programs typically must coordinate amongst
themselves to ensure that concurrent file accesses are sufficiently synchronized.
Although files are usually accessed via filenames, they actually are not directly associ-
ated with such names. Instead, a file is referenced by an inode (originally information
node), which is assigned a unique numerical value. This value is called the inode
number, often abbreviated as i-number or ino. An inode stores metadata associated
with a file, such as its modification timestamp, owner, type, length, and the location
of the file’s data—but no filename! The inode is both a physical object, located on
disk in Unix-style filesystems, and a conceptual entity, represented by a data struc-
ture in the Linux kernel.
Concepts of Linux Programming | 11
Directories and links
Accessing a file via its inode number is cumbersome (and also a potential security
hole), so files are always opened from user space by a name, not an inode number.
Directories are used to provide the names with which to access files. A directory acts
as a mapping of human-readable names to inode numbers. A name and inode pair is
called a link. The physical on-disk form of this mapping—a simple table, a hash, or
whatever—is implemented and managed by the kernel code that supports a given
filesystem. Conceptually, a directory is viewed like any normal file, with the differ-
ence that it contains only a mapping of names to inodes. The kernel directly uses this
mapping to perform name-to-inode resolutions.
When a user-space application requests that a given filename be opened, the kernel
opens the directory containing the filename and searches for the given name. From
the filename, the kernel obtains the inode number. From the inode number, the
inode is found. The inode contains metadata associated with the file, including the
on-disk location of the file’s data.
Initially, there is only one directory on the disk, the root directory. This directory is
usually denoted by the path /. But, as we all know, there are typically many directo-
ries on a system. How does the kernel know which directory to look in to find a given
filename?
As mentioned previously, directories are much like regular files. Indeed, they even have
associated inodes. Consequently, the links inside of directories can point to the inodes
of other directories. This means directories can nest inside of other directories, form-
ing a hierarchy of directories. This, in turn, allows for the use of the pathnames with
which all Unix users are familiar—for example, /home/blackbeard/landscaping.txt.
When the kernel is asked to open a pathname like this, it walks each directory entry
(called a dentry inside of the kernel) in the pathname to find the inode of the next
entry. In the preceding example, the kernel starts at /, gets the inode for home, goes
there, gets the inode for blackbeard, runs there, and finally gets the inode for
landscaping.txt. This operation is called directory or pathname resolution. The Linux
kernel also employs a cache, called the dentry cache, to store the results of directory
resolutions, providing for speedier lookups in the future given temporal locality.*
A pathname that starts at the root directory is said to be fully qualified, and is called
an absolute pathname. Some pathnames are not fully qualified; instead, they are pro-
vided relative to some other directory (for example, todo/plunder). These paths are
called relative pathnames. When provided with a relative pathname, the kernel
begins the pathname resolution in the current working directory. From the current
working directory, the kernel looks up the directory todo. From there, the kernel gets
the inode for plunder.
* Temporal locality is the high likelihood of an access to a particular resource being followed by another access
to the same resource. Many resources on a computer exhibit temporal locality.
12 | Chapter 1: Introduction and Essential Concepts
Although directories are treated like normal files, the kernel does not allow them to
be opened and manipulated like regular files. Instead, they must be manipulated
using a special set of system calls. These system calls allow for the adding and remov-
ing of links, which are the only two sensible operations anyhow. If user space were
allowed to manipulate directories without the kernel’s mediation, it would be too
easy for a single simple error to wreck the filesystem.
Hard links
Conceptually, nothing covered thus far would prevent multiple names resolving to
the same inode. Indeed, this is allowed. When multiple links map different names to
the same inode, we call them hard links.
Hard links allow for complex filesystem structures with multiple pathnames point-
ing to the same data. The hard links can be in the same directory, or in two or more
different directories. In either case, the kernel simply resolves the pathname to the
correct inode. For example, a specific inode that points to a specific chunk of data
can be hard linked from /home/bluebeard/map.txt and /home/blackbeard/treasure.txt.
Deleting a file involves unlinking it from the directory structure, which is done sim-
ply by removing its name and inode pair from a directory. Because Linux supports
hard links, however, the filesystem cannot destroy the inode and its associated data
on every unlink operation. What if another hard link existed elsewhere in the filesys-
tem? To ensure that a file is not destroyed until all links to it are removed, each inode
contains a link count that keeps track of the number of links within the filesystem
that point to it. When a pathname is unlinked, the link count is decremented by one;
only when it reaches zero are the inode and its associated data actually removed from
the filesystem.
Symbolic links
Hard links cannot span filesystems because an inode number is meaningless outside
of the inode’s own filesystem. To allow links that can span filesystems, and that are a
bit simpler and less transparent, Unix systems also implement symbolic links (often
shortened to symlinks).
Symbolic links look like regular files. A symlink has its own inode and data chunk,
which contains the complete pathname of the linked-to file. This means symbolic
links can point anywhere, including to files and directories that reside on different
filesystems, and even to files and directories that do not exist. A symbolic link that
points to a nonexistent file is called a broken link.
Symbolic links incur more overhead than hard links because resolving a symbolic
link effectively involves resolving two files: the symbolic link, and then the linked-to
file. Hard links do not incur this additional overhead—there is no difference between
accessing a file linked into the filesystem more than once, and one linked only once.
The overhead of symbolic links is minimal, but it is still considered a negative.
Concepts of Linux Programming | 13
Symbolic links are also less transparent than hard links. Using hard links is entirely
transparent; in fact, it takes effort to find out that a file is linked more than once!
Manipulating symbolic links, on the other hand, requires special system calls. This
lack of transparency is often considered a positive, with symbolic links acting more
as shortcuts than as filesystem-internal links.
Special files
Special files are kernel objects that are represented as files. Over the years, Unix sys-
tems have supported a handful of different special files. Linux supports four: block
device files, character device files, named pipes, and Unix domain sockets. Special
files are a way to let certain abstractions fit into the filesystem, partaking in the every-
thing-is-a-file paradigm. Linux provides a system call to create a special file.
Device access in Unix systems is performed via device files, which act and look like
normal files residing on the filesystem. Device files may be opened, read from, and
written to, allowing user space to access and manipulate devices (both physical and
virtual) on the system. Unix devices are generally broken into two groups: character
devices and block devices. Each type of device has its own special device file.
A character device is accessed as a linear queue of bytes. The device driver places
bytes onto the queue, one by one, and user space reads the bytes in the order that
they were placed on the queue. A keyboard is an example of a character device. If the
user types “peg,” for example, an application would want to read from the keyboard
device the p, the e, and, finally, the g. When there are no more characters left to read,
the device returns end-of-file (EOF). Missing a character, or reading them in any
other order, would make little sense. Character devices are accessed via character
device files.
A block device, in contrast, is accessed as an array of bytes. The device driver maps
the bytes over a seekable device, and user space is free to access any valid bytes in the
array, in any order—it might read byte 12, then byte 7, and then byte 12 again. Block
devices are generally storage devices. Hard disks, floppy drives, CD-ROM drives, and
flash memory are all examples of block devices. They are accessed via block device
files.
Named pipes (often called FIFOs, short for “first in, first out”) are an interprocess
communication (IPC) mechanism that provides a communication channel over a file
descriptor, accessed via a special file. Regular pipes are the method used to “pipe”
the output of one program into the input of another; they are created in memory via
a system call, and do not exist on any filesystem. Named pipes act like regular pipes,
but are accessed via a file, called a FIFO special file. Unrelated processes can access
this file and communicate.
Sockets are the final type of special file. Sockets are an advanced form of IPC that
allow for communication between two different processes, not only on the same
machine, but on two different machines. In fact, sockets form the basis of network
14 | Chapter 1: Introduction and Essential Concepts
and Internet programming. They come in multiple varieties, including the Unix
domain socket, which is the form of socket used for communication within the local
machine. Whereas sockets communicating over the Internet might use a hostname
and port pair for identifying the target of communication, Unix domain sockets use a
special file residing on a filesystem, often simply called a socket file.
Filesystems and namespaces
Linux, like all Unix systems, provides a global and unified namespace of files and
directories. Some operating systems separate different disks and drives into sepa-
rate namespaces—for example, a file on a floppy disk might be accessible via the
pathname A:\plank.jpg, while the hard drive is located at C:\. In Unix, that same file
on a floppy might be accessible via the pathname /media/floppy/plank.jpg, or even
via /home/captain/stuff/plank.jpg, right alongside files from other media. That is, on
Unix, the namespace is unified.
A filesystem is a collection of files and directories in a formal and valid hierarchy.
Filesystems may be individually added to and removed from the global namespace of
files and directories. These operations are called mounting and unmounting. Each file-
system is mounted to a specific location in the namespace, known as a mount point.
The root directory of the filesystem is then accessible at this mount point. For exam-
ple, a CD might be mounted at /media/cdrom, making the root of the filesystem on
the CD accessible at that mount point. The first filesystem mounted is located in the
root of the namespace, /, and is called the root filesystem. Linux systems always have
a root filesystem. Mounting other filesystems at other mount points is optional.
Filesystems usually exist physically (i.e., are stored on disk), although Linux also
supports virtual filesystems that exist only in memory, and network filesystems that
exist on machines across the network. Physical filesystems reside on block storage
devices, such as CDs, floppy disks, compact flash cards, or hard drives. Some such
devices are partionable, which means that they can be divided up into multiple file-
systems, all of which can be manipulated individually. Linux supports a wide range
of filesystems—certainly anything that the average user might hope to come across—
including media-specific filesystems (for example, ISO9660), network filesystems
(NFS), native filesystems (ext3), filesystems from other Unix systems (XFS), and even
filesystems from non-Unix systems (FAT).
The smallest addressable unit on a block device is the sector. The sector is a physical
quality of the device. Sectors come in various powers of two, with 512 bytes being
quite common. A block device cannot transfer or access a unit of data smaller than a
sector; all I/O occurs in terms of one or more sectors.
Concepts of Linux Programming | 15
Likewise, the smallest logically addressable unit on a filesystem is the block. The
block is an abstraction of the filesystem, not of the physical media on which the file-
system resides. A block is usually a power-of-two multiple of the sector size. Blocks
are generally larger than the sector, but they must be smaller than the page size* (the
smallest unit addressable by the memory management unit, a hardware component).
Common block sizes are 512 bytes, 1 kilobyte, and 4 kilobytes.
Historically, Unix systems have only a single shared namespace, viewable by all users
and all processes on the system. Linux takes an innovative approach, and supports
per-process namespaces, allowing each process to optionally have a unique view of
the system’s file and directory hierarchy. † By default, each process inherits the
namespace of its parent, but a process may elect to create its own namespace with its
own set of mount points, and a unique root directory.
Processes
If files are the most fundamental abstraction in a Unix system, processes are the sec-
ond most fundamental. Processes are object code in execution: active, alive, running
programs. But they’re more than just object code—processes consist of data,
resources, state, and a virtualized computer.
Processes begin life as executable object code, which is machine-runnable code in an
executable format that the kernel understands (the format most common in Linux is
ELF). The executable format contains metadata, and multiple sections of code and
data. Sections are linear chunks of the object code that load into linear chunks of
memory. All bytes in a section are treated the same, given the same permissions, and
generally used for similar purposes.
The most important and common sections are the text section, the data section, and
the bss section. The text section contains executable code and read-only data, such as
constant variables, and is typically marked read-only and executable. The data
section contains initialized data, such as C variables with defined values, and is typi-
cally marked readable and writable. The bss section contains uninitialized global
data. Because the C standard dictates default values for C variables that are essen-
tially all zeros, there is no need to store the zeros in the object code on disk. Instead,
the object code can simply list the uninitialized variables in the bss section, and the
kernel can map the zero page (a page of all zeros) over the section when it is loaded
into memory. The bss section was conceived solely as an optimization for this pur-
pose. The name is a historic relic; it stands for block started by symbol, or block storage
segment. Other common sections in ELF executables are the absolute section (which
contains nonrelocatable symbols) and the undefined section (a catchall).
* This is an artificial kernel limitation, in the name of simplicity, that may go away in the future.
† This approach was first pioneered by Bell Labs’ Plan9.
16 | Chapter 1: Introduction and Essential Concepts
A process is also associated with various system resources, which are arbitrated and
managed by the kernel. Processes typically request and manipulate resources only
through system calls. Resources include timers, pending signals, open files, network
connections, hardware, and IPC mechanisms. A process’ resources, along with data
and statistics related to the process, are stored inside the kernel in the process’
process descriptor.
A process is a virtualization abstraction. The Linux kernel, supporting both preemp-
tive multitasking and virtual memory, provides a process both a virtualized processor,
and a virtualized view of memory. From the process’ perspective, the view of the sys-
tem is as though it alone were in control. That is, even though a given process may be
scheduled alongside many other processes, it runs as though it has sole control of the
system. The kernel seamlessly and transparently preempts and reschedules pro-
cesses, sharing the system’s processors among all running processes. Processes never
know the difference. Similarly, each process is afforded a single linear address space,
as if it alone were in control of all of the memory in the system. Through virtual
memory and paging, the kernel allows many processes to coexist on the system, each
operating in a different address space. The kernel manages this virtualization through
hardware support provided by modern processors, allowing the operating system to
concurrently manage the state of multiple independent processes.
Threads
Each process consists of one or more threads of execution (usually just called
threads). A thread is the unit of activity within a process, the abstraction responsible
for executing code, and maintaining the process’ running state.
Most processes consist of only a single thread; they are called single-threaded. Pro-
cesses that contain multiple threads are said to be multithreaded. Traditionally, Unix
programs have been single-threaded, owing to Unix’s historic simplicity, fast process
creation times, and robust IPC mechanisms, all of which mitigate the desire for
threads.
A thread consists of a stack (which stores its local variables, just as the process stack
does on nonthreaded systems), processor state, and a current location in the object
code (usually stored in the processor’s instruction pointer). The majority of the
remaining parts of a process are shared among all threads.
Internally, the Linux kernel implements a unique view of threads: they are simply
normal processes that happen to share some resources (most notably, an address
space). In user space, Linux implements threads in accordance with POSIX 1003.1c
(known as pthreads). The name of the current Linux thread implementation, which
is part of glibc, is the Native POSIX Threading Library (NPTL).
Process hierarchy
Each process is identified by a unique positive integer called the process ID (pid). The
pid of the first process is 1, and each subsequent process receives a new, unique pid.
Concepts of Linux Programming | 17
In Linux, processes form a strict hierarchy, known as the process tree. The process
tree is rooted at the first process, known as the init process, which is typically the
init(8) program. New processes are created via the fork( ) system call. This system
call creates a duplicate of the calling process. The original process is called the par-
ent; the new process is called the child. Every process except the first has a parent. If
a parent process terminates before its child, the kernel will reparent the child to the
init process.
When a process terminates, it is not immediately removed from the system. Instead,
the kernel keeps parts of the process resident in memory, to allow the process’ parent
to inquire about its status upon terminating. This is known as waiting on the termi-
nated process. Once the parent process has waited on its terminated child, the child
is fully destroyed. A process that has terminated, but not yet been waited upon, is
called a zombie. The init process routinely waits on all of its children, ensuring that
reparented processes do not remain zombies forever.
Users and Groups
Authorization in Linux is provided by users and groups. Each user is associated with
a unique positive integer called the user ID (uid). Each process is in turn associated
with exactly one uid, which identifies the user running the process, and is called the
process’ real uid. Inside the Linux kernel, the uid is the only concept of a user. Users
themselves, however, refer to themselves and other users through usernames, not
numerical values. Usernames and their corresponding uids are stored in /etc/passwd,
and library routines map user-supplied usernames to the corresponding uids.
During login, the user provides a username and password to the login(1) program. If
given a valid username and the correct password, the login(1) program spawns the
user’s login shell, which is also specified in /etc/passwd, and makes the shell’s uid
equal to that of the user. Child processes inherit the uids of their parents.
The uid 0 is associated with a special user known as root. The root user has special
privileges, and can do almost anything on the system. For example, only the root
user can change a process’ uid. Consequently, the login(1) program runs as root.
In addition to the real uid, each process also has an effective uid, a saved uid, and a
filesystem uid. While the real uid is always that of the user who started the process,
the effective uid may change under various rules to allow a process to execute with
the rights of different users. The saved uid stores the original effective uid; its value is
used in deciding what effective uid values the user may switch to. The filesystem uid,
which is usually equal to the effective uid, is used for verifying filesystem access.
Each user may belong to one or more groups, including a primary or login group, listed
in /etc/passwd, and possibly a number of supplemental groups, listed in /etc/group. Each
process is therefore also associated with a corresponding group ID (gid), and has a real
gid, an effective gid, a saved gid, and a filesystem gid. Processes are generally associated
with a user’s login group, not any of the supplemental groups.
18 | Chapter 1: Introduction and Essential Concepts
Certain security checks allow processes to perform certain operations only if they
meet specific criteria. Historically, Unix has made this decision very black-and-white:
processes with uid 0 had access, while no others did. Recently, Linux has replaced
this security system with a more general capabilities system. Instead of a simple
binary check, capabilities allow the kernel to base access on much more fine-grained
settings.
Permissions
The standard file permission and security mechanism in Linux is the same as that in
historic Unix.
Each file is associated with an owning user, an owning group, and a set of permis-
sion bits. The bits describe the ability of the owning user, the owning group, and
everybody else to read, write, and execute the file; there are three bits for each of the
three classes, making nine bits in total. The owners and the permissions are stored in
the file’s inode.
For regular files, the permissions are rather obvious: they specify the ability to open a
file for reading, open a file for writing, or execute a file. Read and write permissions
are the same for special files as for regular files, although what exactly is read or writ-
ten is up to the special file in question. Execute permissions are ignored on special
files. For directories, read permission allows the contents of the directory to be listed,
write permission allows new links to be added inside the directory, and execute per-
mission allows the directory to be entered and used in a pathname. Table 1-1 lists each
of the nine permission bits, their octal values (a popular way of representing the nine
bits), their text values (as ls might show them), and their corresponding meanings.
In addition to historic Unix permissions, Linux also supports access control lists
(ACLs). ACLs allow for much more detailed and exacting permission and security
controls, at the cost of increased complexity and on-disk storage.
Table 1-1. Permission bits and their values
Bit Octal value Text value Corresponding permission
8 400 r-------- Owner may read
7 200 -w------- Owner may write
6 100 --x------ Owner may execute
5 040 ---r----- Group may read
4 020 ----w---- Group may write
3 010 -----x--- Group may execute
2 004 ------r-- Everyone else may read
1 002 -------w- Everyone else may write
0 001 --------x Everyone else may execute
Concepts of Linux Programming | 19
Signals
Signals are a mechanism for one-way asynchronous notifications. A signal may be
sent from the kernel to a process, from a process to another process, or from a pro-
cess to itself. Signals typically alert a process to some event, such as a segmentation
fault, or the user pressing Ctrl-C.
The Linux kernel implements about 30 signals (the exact number is architecture-
dependent). Each signal is represented by a numeric constant and a textual name.
For example, SIGHUP, used to signal that a terminal hangup has occurred, has a value
of 1 on the i386 architecture.
With the exception of SIGKILL (which always terminates the process), and SIGSTOP
(which always stops the process), processes may control what happens when they
receive a signal. They can accept the default action, which may be to terminate the
process, terminate and coredump the process, stop the process, or do nothing,
depending on the signal. Alternatively, processes can elect to explicitly ignore or
handle signals. Ignored signals are silently dropped. Handled signals cause the execu-
tion of a user-supplied signal handler function. The program jumps to this function
as soon as the signal is received, and (when the signal handler returns) the control of
the program resumes at the previously interrupted instruction.
Interprocess Communication
Allowing processes to exchange information and notify each other of events is one of
an operating system’s most important jobs. The Linux kernel implements most of
the historic Unix IPC mechanisms—including those defined and standardized by
both System V and POSIX—as well as implementing a mechanism or two of its own.
IPC mechanisms supported by Linux include pipes, named pipes, semaphores, mes-
sage queues, shared memory, and futexes.
Headers
Linux system programming revolves around a handful of headers. Both the kernel
itself and glibc provide the headers used in system-level programming. These headers
include the standard C fare (for example, <string.h>), and the usual Unix offerings
(say, <unistd.h>).
Error Handling
It goes without saying that checking for and handling errors are of paramount impor-
tance. In system programming, an error is signified via a function’s return value, and
described via a special variable, errno. glibc transparently provides errno support for
both library and system calls. The vast majority of interfaces covered in this book
will use this mechanism to communicate errors.
20 | Chapter 1: Introduction and Essential Concepts
Functions notify the caller of errors via a special return value, which is usually -1
(the exact value used depends on the function). The error value alerts the caller to
the occurrence of an error, but provides no insight into why the error occurred. The
errno variable is used to find the cause of the error.
This variable is defined in <errno.h> as follows:
extern int errno;
Its value is valid only immediately after an errno-setting function indicates an error
(usually by returning -1), as it is legal for the variable to be modified during the suc-
cessful execution of a function.
The errno variable may be read or written directly; it is a modifiable lvalue. The
value of errno maps to the textual description of a specific error. A preprocessor
#define also maps to the numeric errno value. For example, the preprocessor define
EACCESS equals 1, and represents “permission denied.” See Table 1-2 for a listing of
the standard defines and the matching error descriptions.
Table 1-2. Errors and their descriptions
Preprocessor define Description
E2BIG Argument list too long
EACCESS Permission denied
EAGAIN Try again
EBADF Bad file number
EBUSY Device or resource busy
ECHILD No child processes
EDOM Math argument outside of domain of function
EEXIT File already exists
EFAULT Bad address
EFBIG File too large
EINTR System call was interrupted
EINVAL Invalid argument
EIO I/O error
EISDIR Is a directory
EMFILE Too many open files
EMLINK Too many links
ENFILE File table overflow
ENODEV No such device
ENOENT No such file or directory
ENOEXEC Exec format error
ENOMEM Out of memory
ENOSPC No space left on device
Concepts of Linux Programming | 21
The C library provides a handful of functions for translating an errno value to the
corresponding textual representation. This is needed only for error reporting, and the
like; checking and handling errors can be done using the preprocessor defines and
errno directly.
The first such function is perror( ):
#include <stdio.h>
void perror (const char *str);
This function prints to stderr (standard error) the string representation of the current
error described by errno, prefixed by the string pointed at by str, followed by a
colon. To be useful, the name of the function that failed should be included in the
string. For example:
if (close (fd) == -1)
perror ("close");
The C library also provides strerror( ) and strerror_r( ), prototyped as:
#include <string.h>
char * strerror (int errnum);
and:
#include <string.h>
int strerror_r (int errnum, char *buf, size_t len);
The former function returns a pointer to a string describing the error given by errnum.
The string may not be modified by the application, but can be modified by subse-
quent perror( ) and strerror( ) calls. In this manner, it is not thread-safe.
ENOTDIR Not a directory
ENOTTY Inappropriate I/O control operation
ENXIO No such device or address
EPERM Operation not permitted
EPIPE Broken pipe
ERANGE Result too large
EROFS Read-only filesystem
ESPIPE Invalid seek
ESRCH No such process
ETXTBSY Text file busy
EXDEV Improper link
Table 1-2. Errors and their descriptions (continued)
Preprocessor define Description
22 | Chapter 1: Introduction and Essential Concepts
The strerror_r( ) function is thread-safe. It fills the buffer of length len pointed at
by buf. A call to strerror_r( ) returns 0 on success, and -1 on failure. Humorously, it
sets errno on error.
For a few functions, the entire range of the return type is a legal return value. In
those cases, errno must be zeroed before invocation, and checked afterward (these
functions promise to only return a nonzero errno on actual error). For example:
errno = 0;
arg = strtoul (buf, NULL, 0);
if (errno)
perror ("strtoul");
A common mistake in checking errno is to forget that any library or system call can
modify it. For example, this code is buggy:
if (fsync (fd) == -1) {
fprintf (stderr, "fsync failed!\n");
if (errno == EIO)
fprintf (stderr, "I/O error on %d!\n", fd);
}
If you need to preserve the value of errno across function invocations, save it:
if (fsync (fd) == -1) {
int err = errno;
fprintf (stderr, "fsync failed: %s\n", strerror (errno));
if (err == EIO) {
/* if the error is I/O-related, jump ship */
fprintf (stderr, "I/O error on %d!\n", fd);
exit (EXIT_FAILURE);
}
}
In single-threaded programs, errno is a global variable, as shown earlier in this sec-
tion. In multithreaded programs, however, errno is stored per-thread, and is thus
thread-safe.
Getting Started with System Programming
This chapter looked at the fundamentals of Linux system programming and pro-
vided a programmer’s overview of the Linux system. The next chapter discusses
basic file I/O. This includes, of course, reading from and writing to files; however,
because Linux implements many interfaces as files, file I/O is crucial to a lot more
than just, well, files.
With the preliminaries behind us, growing smaller on the horizon, it’s time to dive
into actual system programming. Let’s go!
23
Chapter 2 CHAPTER 2
File I/O
This chapter covers the basics of reading to and writing from files. Such operations
form the core of a Unix system. The next chapter covers standard I/O from the stan-
dard C library, and Chapter 4 continues the coverage with a treatment of the more
advanced and specialized file I/O interfaces. Chapter 7 rounds out the discussion by
addressing the topic of file and directory manipulation.
Before a file can be read from or written to, it must be opened. The kernel maintains
a per-process list of open files, called the file table. This table is indexed via nonnega-
tive integers known as file descriptors (often abbreviated fds). Each entry in the list
contains information about an open file, including a pointer to an in-memory copy of
the file’s backing inode and associated metadata, such as the file position and access
modes. Both user space and kernel space use file descriptors as unique per-process
cookies. Opening a file returns a file descriptor, while subsequent operations (read-
ing, writing, and so on) take the file descriptor as their primary argument.
By default, a child process receives a copy of its parent’s file table. The list of open
files and their access modes, current file positions, and so on, are the same, but a
change in one process—say, the child closing a file—does not affect the other pro-
cess’ file table. However, as you’ll see in Chapter 5, it is possible for the child and
parent to share the parent’s file table (as threads do).
File descriptors are represented by the C int type. Not using a special type—an fd_t,
say—is often considered odd, but is, historically, the Unix way. Each Linux process
has a maximum number of files that it may open. File descriptors start at 0, and go
up to one less than this maximum value. By default, the maximum is 1,024, but it
can be configured as high as 1,048,576. Because negative values are not legal file
descriptors, –1 is often used to indicate an error from a function that would other-
wise return a valid file descriptor.
Unless the process explicitly closes them, every process by convention has at least
three file descriptors open: 0, 1, and 2. File descriptor 0 is standard in (stdin), file
descriptor 1 is standard out (stdout), and file descriptor 2 is standard error (stderr).
24 | Chapter 2: File I/O
Instead of referencing these integers directly, the C library provides the preprocessor
defines STDIN_FILENO, STDOUT_FILENO, and STDERR_FILENO.
Note that file descriptors can reference more than just regular files. They are used for
accessing device files and pipes, directories and futexes, FIFOs, and sockets—follow-
ing the everything-is-a-file philosophy, just about anything you can read or write is
accessible via a file descriptor.
Opening Files
The most basic method of accessing a file is via the read( ) and write( ) system calls.
Before a file can be accessed, however, it must be opened via an open( ) or creat( )
system call. Once done using the file, it should be closed using the system call close( ).
The open( ) System Call
A file is opened, and a file descriptor is obtained with the open( ) system call:
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
int open (const char *name, int flags);
int open (const char *name, int flags, mode_t mode);
The open( ) system call maps the file given by the pathname name to a file descriptor,
which it returns on success. The file position is set to zero, and the file is opened for
access according to the flags given by flags.
Flags for open( )
The flags argument must be one of O_RDONLY, O_WRONLY, or O_RDWR. Respectively,
these arguments request that the file be opened only for reading, only for writing, or
for both reading and writing.
For example, the following code opens /home/kidd/madagascar for reading:
int fd;
fd = open ("/home/kidd/madagascar", O_RDONLY);
if (fd == -1)
/* error */
A file opened only for writing cannot also be read, and vice versa. The process issu-
ing the open( ) system call must have sufficient permissions to obtain the access
requested.
The flags argument can be bitwise-ORed with one or more of the following values,
modifying the behavior of the open request:
Opening Files | 25
O_APPEND
The file will be opened in append mode. That is, before each write, the file posi-
tion will be updated to point to the end of the file. This occurs even if another
process has written to the file after the issuing process’ last write, thereby chang-
ing the file position. (See “Append Mode” later in this chapter).
O_ASYNC
A signal (SIGIO by default) will be generated when the specified file becomes
readable or writable. This flag is available only for terminals and sockets, not for
regular files.
O_CREAT
If the file denoted by name does not exist, the kernel will create it. If the file
already exists, this flag has no effect unless O_EXCL is also given.
O_DIRECT
The file will be opened for direct I/O (see “Direct I/O” later in this chapter).
O_DIRECTORY
If name is not a directory, the call to open( ) will fail. This flag is used internally by
the opendir( ) library call.
O_EXCL
When given with O_CREAT, this flag will cause the call to open( ) to fail if the file
given by name already exists. This is used to prevent race conditions on file
creation.
O_LARGEFILE
The given file will be opened using 64-bit offsets, allowing files larger than two
gigabytes to be opened. This is implied on 64-bit architectures.
O_NOCTTY
If the given name refers to a terminal device (say, /dev/tty), it will not become the
process’ controlling terminal, even if the process does not currently have a con-
trolling terminal. This flag is not frequently used.
O_NOFOLLOW
If name is a symbolic link, the call to open( ) will fail. Normally, the link is
resolved, and the target file is opened. If other components in the given path are
links, the call will still succeed. For example, if name is /etc/ship/plank.txt, the call
will fail if plank.txt is a symbolic link. It will succeed, however, if etc or ship is a
symbolic link, so long as plank.txt is not.
O_NONBLOCK
If possible, the file will be opened in nonblocking mode. Neither the open( ) call,
nor any other operation will cause the process to block (sleep) on the I/O. This
behavior may be defined only for FIFOs.
26 | Chapter 2: File I/O
O_SYNC
The file will be opened for synchronous I/O. No write operation will complete
until the data has been physically written to disk; normal read operations are
already synchronous, so this flag has no effect on reads. POSIX additionally
defines O_DSYNC and O_RSYNC; on Linux, these flags are synonymous with O_SYNC.
(See “The O_SYNC Flag,” later in this chapter.)
O_TRUNC
If the file exists, it is a regular file, and the given flags allow for writing, the file
will be truncated to zero length. Use of O_TRUNC on a FIFO or terminal device is
ignored. Use on other file types is undefined. Specifying O_TRUNC with O_RDONLY is
also undefined, as you need write access to the file in order to truncate it.
For example, the following code opens for writing the file /home/teach/pearl. If the
file already exists, it will be truncated to a length of zero. Because the O_CREAT flag is
not specified, if the file does not exist, the call will fail:
int fd;
fd = open ("/home/teach/pearl", O_WRONLY | O_TRUNC);
if (fd == -1)
/* error */
Owners of New Files
Determining which user owns a new file is straightforward: the uid of the file’s
owner is the effective uid of the process creating the file.
Determining the owning group is more complicated. The default behavior is to set
the file’s group to the effective gid of the process creating the file. This is the System
V behavior (the behavioral model for much of Linux), and the standard Linux modus
operandi.
To be difficult, however, BSD defined its own behavior: the file’s group is set to the
gid of the parent directory. This behavior is available on Linux via a mount-time
option*—it is also the behavior that will occur on Linux by default if the file’s parent
directory has the set group ID (setgid) bit set. Although most Linux systems will use
the System V behavior (where new files receive the gid of the creating process), the
possibility of the BSD behavior (where new files receive the gid of the parent direc-
tory) implies that code that truly cares needs to manually set the group via the chown( )
system call (see Chapter 7).
Thankfully, caring about the owning group of a file is uncommon.
* The mount options bsdgroups or sysvgroups.
Opening Files | 27
Permissions of New Files
Both of the previously given forms of the open( ) system call are valid. The mode argu-
ment is ignored unless a file is created; it is required if O_CREAT is given. If you forget
to provide the mode argument when using O_CREAT, the results are undefined, and
often quite ugly—so don’t forget!
When a file is created, the mode argument provides the permissions of the newly
created file. The mode is not checked on this particular open of the file, so you can
perform contradictory operations, such as opening the file for writing, but assigning
the file read-only permissions.
The mode argument is the familiar Unix permission bitset, such as octal 0644 (owner
can read and write, everyone else can only read). Technically speaking, POSIX
allowed the exact values to be implementation-specific, allowing different Unix sys-
tems to lay out the permission bits however they desired. To compensate for the
nonportability of bit positions in the mode, POSIX introduced the following set of
constants that may be binary-ORed together, and supplied for the mode argument:
S_IRWXU
Owner has read, write, and execute permission.
S_IRUSR
Owner has read permission.
S_IWUSR
Owner has write permission.
S_IXUSR
Owner has execute permission.
S_IRWXG
Group has read, write, and execute permission.
S_IRGRP
Group has read permission.
S_IWGRP
Group has write permission.
S_IXGRP
Group has execute permission.
S_IRWXO
Everyone else has read, write, and execute permission.
S_IROTH
Everyone else has read permission.
28 | Chapter 2: File I/O
S_IWOTH
Everyone else has write permission.
S_IXOTH
Everyone else has execute permission.
The actual permission bits that hit the disk are determined by binary-ANDing the
mode argument with the complement of the user’s file creation mask (umask). Infor-
mally, the bits in the umask are turned off in the mode argument given to open( ).
Thus, the usual umask of 022 would cause a mode argument of 0666 to become 0644
(0666 & ~022). As a system programmer, you normally do not take into consider-
ation the umask when setting permissions—the umask exists to allow the user to
limit the permissions that his programs set on new files.
As an example, the following code opens the file given by file for writing. If the file
does not exist, assuming a umask of 022, it is created with the permissions 0644
(even though the mode argument specifies 0664). If it does exist, it is truncated to zero
length:
int fd;
fd = open (file, O_WRONLY | O_CREAT | O_TRUNC,
S_IWUSR | S_IRUSR | S_IWGRP | S_IRGRP | S_IROTH);
if (fd == -1)
/* error */
The creat( ) Function
The combination of O_WRONLY | O_CREAT | O_TRUNC is so common that a system call
exists to provide just that behavior:
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
int creat (const char *name, mode_t mode);
Yes, this function’s name is missing an e. Ken Thompson, the creator
of Unix, once joked that the missing letter was his largest regret in the
design of Unix.
The following typical creat( ) call:
int fd;
fd = creat (file, 0644);
if (fd == -1)
/* error */
Reading via read( ) | 29
is identical to:
int fd;
fd = open (file, O_WRONLY | O_CREAT | O_TRUNC, 0644);
if (fd == -1)
/* error */
On most Linux architectures, * creat( ) is a system call, even though it can be imple-
mented in user space as simply:
int creat (const char *name, int mode)
{
return open (name, O_WRONLY | O_CREAT | O_TRUNC, mode);
}
This duplication is a historic relic from when open( ) had only two arguments.
Today, the creat( ) system call remains around for compatibility. New architectures
can implement creat( ) as shown in glibc.
Return Values and Error Codes
Both open( ) and creat( ) return a file descriptor on success. On error, both return -1,
and set errno to an appropriate error value (Chapter 1 discussed errno and listed the
potential error values). Handling an error on file open is not complicated, as gener-
ally there will have been few or no steps performed prior to the open that need to be
undone. A typical response would be prompting the user for a different filename or
simply terminating the program.
Reading via read( )
Now that you know how to open a file, let’s look at how to read it. In the following
section, we will examine writing.
The most basic—and common—mechanism used for reading is the read( ) system
call, defined in POSIX.1:
#include <unistd.h>
ssize_t read (int fd, void *buf, size_t len);
Each call reads up to len bytes into buf from the current file offset of the file refer-
enced by fd. On success, the number of bytes written into buf is returned. On error,
the call returns -1, and errno is set. The file position is advanced by the number of
bytes read from fd. If the object represented by fd is not capable of seeking (for
example, a character device file), the read always occurs from the “current” position.
* Recall that system calls are defined on a per-architecture basis. Thus, while i386 has a creat( ) system call,
Alpha does not. You can use creat( ) on any architecture, of course, but it may be a library function instead
of having its own system call.
30 | Chapter 2: File I/O
Basic usage is simple. This example reads from the file descriptor fd into word. The
number of bytes read is equal to the size of the unsigned long type, which is four
bytes on 32-bit Linux systems, and eight bytes on 64-bit systems. On return, nr con-
tains the number of bytes read, or -1 on error:
unsigned long word;
ssize_t nr;
/* read a couple bytes into 'word' from 'fd' */
nr = read (fd, &word, sizeof (unsigned long));
if (nr == -1)
/* error */
There are two problems with this naïve implementation: the call might return with-
out reading all len bytes, and it could produce certain errors that this code does not
check for and handle. Code such as this, unfortunately, is very common. Let’s see
how to improve it.
Return Values
It is legal for read( ) to return a positive nonzero value less than len. This can hap-
pen for a number of reasons: less than len bytes may have been available, the system
call may have been interrupted by a signal, the pipe may have broken (if fd is a pipe),
and so on.
The possibility of a return value of 0 is another consideration when using read( ).
The read( ) system call returns 0 to indicate end-of-file (EOF); in this case, of course,
no bytes were read. EOF is not considered an error (and hence is not accompanied
by a -1 return value); it simply indicates that the file position has advanced past the
last valid offset in the file, and thus there is nothing else to read. If, however, a call is
made for len bytes, but no bytes are available for reading, the call will block (sleep)
until the bytes become available (assuming the file descriptor was not opened in non-
blocking mode; see “Nonblocking Reads”). Note that this is different from returning
EOF. That is, there is a difference between “no data available” and “end of data.” In
the EOF case, the end of the file was reached. In the case of blocking, the read is
waiting for more data—say, in the case of reading from a socket or a device file.
Some errors are recoverable. For example, if a call to read( ) is interrupted by a sig-
nal before any bytes are read, it returns -1 (a 0 could be confused with EOF), and
errno is set to EINTR. In that case, you can resubmit the read.
Indeed, a call to read( ) can result in many possibilities:
• The call returns a value equal to len. All len read bytes are stored in buf. The
results are as intended.
• The call returns a value less than len, but greater than zero. The read bytes are
stored in buf. This can occur because a signal interrupted the read midway, an
error occurred in the middle of the read, more than zero, but less than len bytes’
Reading via read( ) | 31
worth of data was available, or EOF was reached before len bytes were read.
Reissuing the read (with correspondingly updated buf and len values) will read the
remaining bytes into the rest of the buffer, or indicate the cause of the problem.
• The call returns 0. This indicates EOF. There is nothing to read.
• The call blocks because no data is currently available. This won’t happen in non-
blocking mode.
• The call returns -1, and errno is set to EINTR. This indicates that a signal was
received before any bytes were read. The call can be reissued.
• The call returns -1, and errno is set to EAGAIN. This indicates that the read would
block because no data is currently available, and that the request should be reis-
sued later. This happens only in nonblocking mode.
• The call returns -1, and errno is set to a value other than EINTR or EAGAIN. This
indicates a more serious error.
Reading All the Bytes
These possibilities imply that the previous trivial, simplistic use of read( ) is not suit-
able if you want to handle all errors, and actually read all len bytes (at least up to an
EOF). To do that, you need a loop, and a handful of conditional statements:
ssize_t ret;
while (len != 0 && (ret = read (fd, buf, len)) != 0) {
if (ret == -1) {
if (errno == EINTR)
continue;
perror ("read");
break;
}
len -= ret;
buf += ret;
}
This snippet handles all five conditions. The loop reads len bytes from the current
file position of fd into buf. It continues reading until it reads all len bytes, or until
EOF is reached. If more than zero, but less than len bytes are read, len is reduced by
the amount read, buf is increased by the amount read, and the call is reissued. If the
call returns -1, and errno equals EINTR, the call is reissued without updating the
parameters. If the call returns -1, and errno is set to anything else, perror( ) is called
to print a description to standard error and the loop terminates.
Partial reads are not only legal, but also common. Innumerable bugs derive from pro-
grammers not properly checking for and handling short read requests. Do not add to
the list!
32 | Chapter 2: File I/O
Nonblocking Reads
Sometimes, programmers do not want a call to read( ) to block when there is no data
available. Instead, they prefer that the call return immediately, indicating that no data
is available. This is called nonblocking I/O; it allows applications to perform I/O,
potentially on multiple files, without ever blocking, and thus missing data available in
another file.
Consequently, an additional errno value is worth checking: EAGAIN. As discussed pre-
viously, if the given file descriptor was opened in nonblocking mode (if O_NONBLOCK
was given to open( ); see “Flags for open( )”) and there is no data to read, the read( )
call will return -1, and set errno to EAGAIN instead of blocking. When performing
nonblocking reads, you must check for EAGAIN, or risk confusing a serious error with
the mere lack of data. For example, you might use code like the following:
char buf[BUFSIZ];
ssize_t nr;
start:
nr = read (fd, buf, BUFSIZ);
if (nr == -1) {
if (errno == EINTR)
goto start; /* oh shush */
if (errno == EAGAIN)
/* resubmit later */
else
/* error */
}
Handling EAGAIN in this example with a goto start would actually
make little sense—you might as well not use nonblocking I/O. Using
it ends up saving no time, and instead introduces more overhead by
looping over and over.
Other Error Values
The other error codes refer to programming errors or (for EIO) low-level problems.
Possible errno values after a failure on read( ) include:
EBADF
The given file descriptor is invalid, or not open for reading.
EFAULT
The pointer provided by buf is not inside the calling process’ address space.
EINVAL
The file descriptor is mapped to an object that does not allow reading.
EIO
A low-level I/O error occurred.
Writing with write( ) | 33
Size Limits on read( )
The size_t and ssize_t types are mandated by POSIX. The size_t type is used for
storing values used to measure size in bytes. The ssize_t type is a signed version of
size_t (the negative values are used to connote errors). On 32-bit systems, the back-
ing C types are usually unsigned int and int, respectively. Because the two types are
often used together, the potentially smaller range of ssize_t places a limit on the
range of size_t.
The maximum value of a size_t is SIZE_MAX; the maximum value of an ssize_t is
SSIZE_MAX. If len is larger than SSIZE_MAX, the results of the call to read( ) are unde-
fined. On most Linux systems, SSIZE_MAX is LONG_MAX, which is 0x7fffffff on a 32-bit
machine. That is relatively large for a single read, but nonetheless something to keep
in mind. If you use the previous read loop as a generic super read, you might want to
do something like this:
if (len > SSIZE_MAX)
len = SSIZE_MAX;
A call to read( ) with a len of zero results in the call returning immediately with a
return value of 0.
Writing with write( )
The most basic and common system call used for writing is write( ). write( ) is the
counterpart of read( ) and is also defined in POSIX.1:
#include <unistd.h>
ssize_t write (int fd, const void *buf, size_t count);
A call to write( ) writes up to count bytes starting at buf to the current file position of
the file referenced by the file descriptor fd. Files backed by objects that do not sup-
port seeking (for example, character devices) always write starting at the “head.”
On success, the number of bytes written is returned, and the file position is updated
in kind. On error, -1 is returned, and errno is set appropriately. A call to write( ) can
return 0, but this return value does not have any special meaning; it simply implies
that zero bytes were written.
As with read( ), the most basic usage is simple:
const char *buf = "My ship is solid!";
ssize_t nr;
/* write the string in 'buf' to 'fd' */
nr = write (fd, buf, strlen (buf));
if (nr == -1)
/* error */
34 | Chapter 2: File I/O
But again, as with read( ), this usage is not quite right. Callers also need to check for
the possible occurrence of a partial write:
unsigned long word = 1720;
size_t count;
ssize_t nr;
count = sizeof (word);
nr = write (fd, &word, count);
if (nr == -1)
/* error, check errno */
else if (nr != count)
/* possible error, but 'errno' not set */
Partial Writes
A write( ) system call is less likely to return a partial write than a read( ) system call
is to return a partial read. Also, there is no EOF condition for a write( ) system call.
For regular files, write( ) is guaranteed to perform the entire requested write, unless
an error occurs.
Consequently, for regular files, you do not need to perform writes in a loop. How-
ever, for other file types—say, sockets—a loop may be required to guarantee that
you really write out all of the requested bytes. Another benefit of using a loop is that
a second call to write( ) may return an error revealing what caused the first call to
perform only a partial write (although, again, this situation is not very common).
Here’s an example:
ssize_t ret, nr;
while (len != 0 && (ret = write (fd, buf, len)) != 0) {
if (ret == -1) {
if (errno == EINTR)
continue;
perror ("write");
break;
}
len -= ret;
buf += ret;
}
Append Mode
When fd is opened in append mode (via O_APPEND), writes do not occur at the file
descriptor’s current file position. Instead, they occur at the current end of the file.
For example, assume that two processes are writing to the same file. Without append
mode, if the first process writes to the end of the file, and then the second process
does the same, the first process’ file position will no longer point to the end of the
Writing with write( ) | 35
file; it will point to the end of the file, minus the data that the second process just
wrote. This means that multiple processes can never append to the same file without
explicit synchronization because they will encounter race conditions.
Append mode avoids this problem. It ensures that the file position is always set to
the end of the file, so all writes always append, even when there are multiple writers.
You can think of it as an atomic update to the file position preceding each write
request. The file position is then updated to point at the end of the newly written
data. This will not matter to the next call to write( ), as it updates the file position
automatically, but it might matter if you next call read( ) for some odd reason.
Append mode makes a lot of sense for certain tasks, such as updating log files, but
little sense for much else.
Nonblocking Writes
When fd is opened in nonblocking mode (via O_NONBLOCK), and the write as issued
would normally block, the write( ) system call returns -1, and errno is set to EAGAIN.
The request should be reissued later. Generally, this does not occur with regular files.
Other Error Codes
Other notable errno values include:
EBADF
The given file descriptor is not valid, or is not open for writing.
EFAULT
The pointer provided by buf points outside of the process’ address space.
EFBIG
The write would have made the file larger than per-process maximum file limits,
or internal implementation limits.
EINVAL
The given file descriptor is mapped to an object that is not suitable for writing.
EIO
A low-level I/O error occurred.
ENOSPC
The filesystem backing the given file descriptor does not have sufficient space.
EPIPE
The given file descriptor is associated with a pipe or socket whose reading end is
closed. The process will also receive a SIGPIPE signal. The default action for the
SIGPIPE signal is to terminate the receiving process. Therefore, processes receive
this errno value only if they explicitly ask to ignore, block, or handle this signal.
36 | Chapter 2: File I/O
Size Limits on write( )
If count is larger than SSIZE_MAX, the results of the call to write( ) are undefined.
A call to write( ) with a count of zero results in the call returning immediately with a
return value of 0.
Behavior of write( )
When a call to write( ) returns, the kernel has copied the data from the supplied
buffer into a kernel buffer, but there is no guarantee that the data has been written
out to its intended destination. Indeed, write calls return much too fast for that to be
the case. The disparity in performance between processors and hard disks would
make such behavior painfully obvious.
Instead, when a user-space application issues a write( ) system call, the Linux kernel
performs a few checks, and then simply copies the data into a buffer. Later, in the
background, the kernel gathers up all of the “dirty” buffers, sorts them optimally,
and writes them out to disk (a process known as writeback). This allows write calls
to occur lightning fast, returning almost immediately. It also allows the kernel to
defer writes to more idle periods, and batch many writes together.
The delayed writes do not change POSIX semantics. For example, if a read is issued
for a piece of just-written data that lives in a buffer and is not yet on disk, the request
will be satisfied from the buffer, and not cause a read from the “stale” data on disk.
This behavior actually improves performance, as the read is satisfied from an in-
memory cache without having to go to disk. The read and write requests interleave
as intended, and the results are as expected—that is, if the system does not crash
before the data makes it to disk! Even though an application may believe that a write
has occurred successfully, in this event, the data will never make it to disk.
Another issue with delayed writes is the inability to enforce write ordering. Although
an application may take care to order its write requests in such a way that they hit
the disk in a specific order, the kernel will reorder the write requests as it sees fit, pri-
marily for performance. This is normally a problem only if the system crashes, as
eventually all of the buffers are written back and all is well. Even then, the vast
majority of applications are not actually concerned with write ordering.
A final problem with delayed writes has to do with the reporting of certain I/O
errors. Any I/O error that occurs during writeback—say, a physical drive failure—
cannot be reported back to the process that issued the write request. Indeed, buffers
are not associated with processes at all. Multiple processes may have dirtied the data
contained in a single buffer, and processes may exit after writing data to a buffer but
before that data is written back to disk. Besides, how would you communicate to a
process that a write failed ex post facto?
Synchronized I/O | 37
The kernel does attempt to minimize the risks of deferred writes. To ensure that data
is written out in a timely manner, the kernel institutes a maximum buffer age, and
writes out all dirty buffers before they mature past the given value. Users can config-
ure this value via /proc/sys/vm/dirty_expire_centiseconds. The value is specified in
centiseconds (one hundredths of a second).
It is also possible to force the writeback of a given file’s buffer, or even to make all
writes synchronous. These topics are discussed in the next section, “Synchronized
I/O.”
Later in this chapter, “Kernel Internals” will cover the Linux kernel’s buffer write-
back subsystem in depth.
Synchronized I/O
Although synchronizing I/O is an important topic, the issues associated with delayed
writes should not be feared. Buffering writes provides a huge performance improve-
ment, and consequently, any operating system even halfway deserving the mark
“modern” implements delayed writes via buffers. Nonetheless, there are times when
applications want to control when data hits the disk. For those uses, the Linux
kernel provides a handful of options that allow performance to be traded for syn-
chronized operations.
fsync( ) and fdatasync( )
The simplest method of ensuring that data has reached the disk is via the fsync( )
system call, defined by POSIX.1b:
#include <unistd.h>
int fsync (int fd);
A call to fsync( ) ensures that all dirty data associated with the file mapped by the
file descriptor fd is written back to disk. The file descriptor fd must be open for writ-
ing. The call writes back both data and metadata, such as creation timestamps, and
other attributes contained in the inode. It will not return until the hard drive says
that the data and metadata are on the disk.
In the case of write caches on hard disks, it is not possible for fsync( ) to know
whether the data is physically on the disk. The hard drive can report that the data
was written, but the data may in fact reside in the drive’s write cache. Fortunately,
data in a hard disk’s cache should be committed to the disk in short order.
Linux also provides the system call fdatasync( ):
#include <unistd.h>
int fdatasync (int fd);
38 | Chapter 2: File I/O
This system call does the same thing as fsync( ), except that it only flushes data. The
call does not guarantee that metadata is synchronized to disk, and is therefore poten-
tially faster. Often this is sufficient.
Both functions are used the same way, which is very simple:
int ret;
ret = fsync (fd);
if (ret == -1)
/* error */
Neither function guarantees that any updated directory entries containing the file are
synchronized to disk. This implies that if a file’s link has recently been updated, the
file’s data may successfully reach the disk, but not the associated directory entry, ren-
dering the file unreachable. To ensure that any updates to the directory entry are also
committed to disk, fsync( ) must be called on a file descriptor opened against the
directory itself.
Return values and error codes
On success, both calls return 0. On failure, both calls return -1, and set errno to one
of the following three values:
EBADF
The given file descriptor is not a valid file descriptor open for writing.
EINVAL
The given file descriptor is mapped to an object that does not support
synchronization.
EIO
A low-level I/O error occurred during synchronization. This represents a real I/O
error, and is often the place where such errors are caught.
Currently, a call to fsync( ) may fail because fsync( ) is not implemented by the
backing filesystem, even when fdatasync( ) is implemented. Paranoid applications
may want to try fdatasync( ) if fsync( ) returns EINVAL. For example:
if (fsync (fd) == -1) {
/*
* We prefer fsync(), but let's try fdatasync( )
* if fsync( ) fails, just in case.
*/
if (errno == EINVAL) {
if (fdatasync (fd) == -1)
perror ("fdatasync");
} else
perror ("fsync");
}
Synchronized I/O | 39
Because POSIX requires fsync( ), but labels fdatasync( ) as optional, the fsync( )
system call should always be implemented for regular files on any of the common
Linux filesystems. Odd file types (perhaps those in which there is no metadata to
synchronize) or strange filesystems may implement only fdatasync( ), however.
sync( )
Less optimal, but wider in scope, the old-school sync( ) system call is provided for
synchronizing all buffers to disk:
#include <unistd.h>
void sync (void);
The function has no parameters, and no return value. It always succeeds, and upon
return, all buffers—both data and metadata—are guaranteed to reside on disk.*
The standards do not require sync( ) to wait until all buffers are flushed to disk
before returning; they require only that the call initiates the process of committing all
buffers to disk. For this reason, it is often recommended to synchronize multiple
times to ensure that all data is safely on disk. Linux, however, does wait until all buff-
ers are committed. Therefore, a single sync( ) is sufficient.
The only real use for sync( ) is in implementing the sync(8) utility. Applications
should use fsync( ) and fdatasync( ) to commit to disk the data of just the requisite
file descriptors. Note that sync( ) may take several minutes to complete on a busy
system.
The O_SYNC Flag
The O_SYNC flag may be passed to open( ), indicating that all I/O on the file should be
synchronized:
int fd;
fd = open (file, O_WRONLY | O_SYNC);
if (fd == -1) {
perror ("open");
return -1;
}
Read requests are always synchronized. If they weren’t, the validity of the read data in
the supplied buffer would be unknown. However, as discussed previously, calls to
write( ) are normally not synchronized. There is no relation between the call returning
and the data being committed to disk. The O_SYNC flag forces the relationship, ensur-
ing that calls to write( ) perform synchronized I/O.
* Well, the same caveat applies as before: the hard drive may lie and inform the kernel that the buffers reside
on disk when they actually are still in the disk’s cache.
40 | Chapter 2: File I/O
One way of looking at O_SYNC is that it forces an implicit fsync( ) after each write( )
operation, before the call returns. These are indeed the semantics provided, although
the Linux kernel implements O_SYNC a bit more efficiently.
O_SYNC results in slightly worse user and kernel times (times spent in user and kernel
space, respectively) for write operations. Moreover, depending on the size of the file
being written, O_SYNC can cause an increase in total elapsed time of one or two orders
of magnitude because all I/O wait time (time spent waiting for I/O to complete) is
incurred by the process. The increase in cost is huge, so synchronized I/O should be
used only after exhausting all possible alternatives.
Normally, applications which need guarantees that write operations have hit the disk
use fsync( ) or fdatasync( ). These tend to incur less cost than O_SYNC, as they can be
called less often (i.e., only after certain critical operations have completed).
O_DSYNC and O_RSYNC
POSIX defines two other synchronized-I/O-related open( ) flags: O_DSYNC and O_RSYNC.
On Linux, these flags are defined to be synonymous with O_SYNC; they provide in the
same behavior.
The O_DSYNC flag specifies that only normal data be synchronized after each write
operation, not metadata. Think of it as causing an implicit fdatasync( ) after each
write request. Because O_SYNC provides stronger guarantees, there is no functionality
loss in not explicitly supporting O_DSYNC; there’s only a potential performance loss
from the stronger requirements provided by O_SYNC.
The O_RSYNC flag specifies the synchronization of read requests as well as write
requests. It must be used with one of O_SYNC or O_DSYNC. As mentioned earlier, reads
are already synchronized—they do not return until they have something to give the
user, after all. The O_RSYNC flag stipulates that any side effects of a read operation be
synchronized, too. This means that metadata updates resulting from a read must be
written to disk before the call returns. In practical terms, this requirement most likely
means only that the file access time must be updated in the on-disk copy of the inode
before the call to read( ) returns. Linux defines O_RSYNC to be the same as O_SYNC,
although this does not make much sense (the two are not as related as O_SYNC and
O_DSYNC). There is currently no way in Linux to obtain the behavior of O_RSYNC; the
closest a developer can come is invoking fdatasync( ) after each read( ) call. This
behavior is rarely needed, though.
Direct I/O
The Linux kernel, like any modern operating system kernel, implements a complex
layer of caching, buffering, and I/O management between devices and applications
(see “Kernel Internals” at the end of this chapter). A high-performance application
may wish to bypass this layer of complexity and perform its own I/O management.
Closing Files | 41
Rolling your own I/O system is usually not worth the effort, though, and in fact the
tools available at the operating-system level are likely to achieve much better perfor-
mance than those available at the application level. Still, database systems often
prefer to perform their own caching, and want to minimize the presence of the oper-
ating system as much as feasible.
Providing the O_DIRECT flag to open( ) instructs the kernel to minimize the presence of
I/O management. When this flag is provided, I/O will initiate directly from user-
space buffers to the device, bypassing the page cache. All I/O will be synchronous;
operations will not return until completed.
When performing direct I/O, the request length, buffer alignment, and file offsets
must all be integer multiples of the underlying device’s sector size—generally, this is
512 bytes. Before the 2.6 Linux kernel, this requirement was stricter: in 2.4, every-
thing must be aligned on the filesystem’s logical block size (often 4 KB). To remain
compatible, applications should align to the larger (and potentially less convenient)
logical block size.
Closing Files
After a program has finished working with a file descriptor, it can unmap the file
descriptor from the associated file via the close( ) system call:
#include <unistd.h>
int close (int fd);
A call to close( ) unmaps the open file descriptor fd, and disassociates the process
from the file. The given file descriptor is then no longer valid, and the kernel is free to
reuse it as the return value to a subsequent open( ) or creat( ) call. A call to close( )
returns 0 on success. On error, it returns -1, and sets errno appropriately. Usage is
simple:
if (close (fd) == -1)
perror ("close");
Note that closing a file has no bearing on when the file is flushed to disk. If an applica-
tion wants to ensure that the file is committed to disk before closing it, it needs to make
use of one of the synchronization options discussed earlier in “Synchronized I/O.”
Closing a file does have some side effects, though. When the last open file descriptor
referring to a file is closed, the data structure representing the file inside the kernel is
freed. When this data structure is freed, it unpins the in-memory copy of the inode
associated with the file. If nothing else is pinning the inode, it too may be freed from
memory (it may stick around because the kernel caches inodes for performance rea-
sons, but it need not). If a file has been unlinked from the disk, but was kept open
before it was unlinked, it is not physically removed until it is closed and its inode is
removed from memory. Therefore, calling close( ) may also result in an unlinked file
finally being physically removed from the disk.
42 | Chapter 2: File I/O
Error Values
It is a common mistake to not check the return value of close( ). This can result in
missing a crucial error condition because errors associated with deferred operations
may not manifest until later, and close( ) can report them.
There are a handful of possible errno values on failure. Other than EBADF (the given
file descriptor was invalid), the most important error value is EIO, indicating a low-
level I/O error probably unrelated to the actual close. Regardless of any reported
error, the file descriptor, if valid, is always closed, and the associated data structures
are freed.
Although POSIX allows it, close( ) will never return EINTR. The Linux kernel devel-
opers know better—such an implementation is not smart.
Seeking with lseek( )
Normally, I/O occurs linearly through a file, and the implicit updates to the file posi-
tion caused by reads and writes are all the seeking that is needed. Some applications,
however, need to jump around in the file. The lseek( ) system call is provided to set
the file position of a file descriptor to a given value. Other than updating the file
position, it performs no other action, and initiates no I/O whatsoever:
#include <sys/types.h>
#include <unistd.h>
off_t lseek (int fd, off_t pos, int origin);
The behavior of lseek( ) depends on the origin argument, which can be one of the
following:
SEEK_CUR
The current file position of fd is set to its current value plus pos, which can be
negative, zero, or positive. A pos of zero returns the current file position value.
SEEK_END
The current file position of fd is set to the current length of the file plus pos,
which can be negative, zero, or positive. A pos of zero sets the offset to the end of
the file.
SEEK_SET
The current file position of fd is set to pos. A pos of zero sets the offset to the
beginning of the file.
The call returns the new file position on success. On error, it returns -1 and errno is
set as appropriate.
Seeking with lseek( ) | 43
For example, to set the file position of fd to 1825:
off_t ret;
ret = lseek (fd, (off_t) 1825, SEEK_SET);
if (ret == (off_t) -1)
/* error */
Alternatively, to set the file position of fd to the end of the file:
off_t ret;
ret = lseek (fd, 0, SEEK_END);
if (ret == (off_t) -1)
/* error */
As lseek( ) returns the updated file position, it can be used to find the current file
position via a SEEK_CUR to zero:
int pos;
pos = lseek (fd, 0, SEEK_CUR);
if (pos == (off_t) -1)
/* error */
else
/* 'pos' is the current position of fd */
By far, the most common uses of lseek( ) are seeking to the beginning, seeking to the
end, or determining the current file position of a file descriptor.
Seeking Past the End of a File
It is possible to instruct lseek( ) to advance the file pointer past the end of a file. For
example, this code seeks to 1,688 bytes beyond the end of the file mapped by fd:
int ret;
ret = lseek (fd, (off_t) 1688, SEEK_END);
if (ret == (off_t) -1)
/* error */
On its own, seeking past the end of a file does nothing—a read request to the newly
created file position will return EOF. If a write request is subsequently made to this
position, however, new space will be created between the old length of the file and
the new length, and it will be padded with zeros.
This zero padding is called a hole. On Unix-style filesystems, holes do not occupy
any physical disk space. This implies that the total size of all files on a filesystem can
add up to more than the physical size of the disk. Files with holes are called sparse
files. Sparse files can save considerable space and enhance performance because
manipulating the holes does not initiate any physical I/O.
A read request to the part of a file in a hole will return the appropriate number of
binary zeros.
44 | Chapter 2: File I/O
Error Values
On error, lseek( ) returns -1, and errno is set to one of the following four values:
EBADF
The given file descriptor does not refer to an open file descriptor.
EINVAL
The value given for origin is not one of SEEK_SET, SEEK_CUR, or SEEK_END, or the
resulting file position would be negative. The fact that EINVAL represents both of
these errors is unfortunate. The former is almost assuredly a compile-time pro-
gramming error, whereas the latter can represent a more insidious runtime logic
error.
EOVERFLOW
The resulting file offset cannot be represented in an off_t. This can occur only
on 32-bit architectures. Currently, the file position is updated; this error indi-
cates just that it is impossible to return it.
ESPIPE
The given file descriptor is associated with an unseekable object, such as a pipe,
FIFO, or socket.
Limitations
The maximum file positions are limited by the size of the off_t type. Most machine
architectures define this to be the C long type, which on Linux is always the word
size (usually the size of the machine’s general-purpose registers). Internally, how-
ever, the kernel stores the offsets in the C long long type. This poses no problem on
64-bit machines, but it means that 32-bit machines can generate EOVERFLOW errors
when performing relative seeks.
Positional Reads and Writes
In lieu of using lseek( ), Linux provides two variants of the read( ) and write( ) sys-
tem calls that each take as a parameter the file position from which to read or write.
Upon completion, they do not update the file position.
The read form is called pread( ):
#define _XOPEN_SOURCE 500
#include <unistd.h>
ssize_t pread (int fd, void *buf, size_t count, off_t pos);
Truncating Files | 45
This call reads up to count bytes into buf from the file descriptor fd at file position pos.
The write form is called pwrite( ):
#define _XOPEN_SOURCE 500
#include <unistd.h>
ssize_t pwrite (int fd, const void *buf, size_t count, off_t pos);
This call writes up to count bytes from buf to the file descriptor fd at file position pos.
These calls are almost identical in behavior to their non-p brethren, except that they
completely ignore the current file position; instead of using the current position, they
use the value provided by pos. Also, when done, they do not update the file position.
In other words, any intermixed read( ) and write( ) calls could potentially corrupt
the work done by the positional calls.
Both positional calls can be used only on seekable file descriptors. They provide
semantics similar to preceding a read( ) or write( ) call with a call to lseek( ), with
three differences. First, these calls are easier to use, especially when doing a tricky
operation such as moving through a file backward or randomly. Second, they do not
update the file pointer upon completion. Finally, and most importantly, they avoid
any potential races that might occur when using lseek( ). As threads share file
descriptors, it would be possible for a different thread in the same program to update
the file position after the first thread’s call to lseek( ), but before its read or write
operation executed. Such race conditions can be avoided by using the pread( ) and
pwrite( ) system calls.
Error Values
On success, both calls return the number of bytes read or written. A return value of 0
from pread( ) indicates EOF; from pwrite( ), a return value of 0 indicates that the call
did not write anything. On error, both calls return -1 and set errno appropriately.
For pread( ), any valid read( ) or lseek( ) errno value is possible. For pwrite( ), any
valid write( ) or lseek( ) value is possible.
Truncating Files
Linux provides two system calls for truncating the length of a file, both of which are
defined and required (to varying degrees) by various POSIX standards. They are:
#include <unistd.h>
#include <sys/types.h>
int ftruncate (int fd, off_t len);
46 | Chapter 2: File I/O
and:
#include <unistd.h>
#include <sys/types.h>
int truncate (const char *path, off_t len);
Both system calls truncate the given file to the length given by len. The ftruncate( )
system call operates on the file descriptor given by fd, which must be open for writ-
ing. The truncate( ) system call operates on the filename given by path, which must
be writable. Both return 0 on success. On error, they return -1, and set errno as
appropriate.
The most common use of these system calls is to truncate a file to a size smaller than
its current length. Upon successful return, the file’s length is len. The data previ-
ously existing between len and the old length is discarded, and no longer accessible
via a read request.
The functions can also be used to “truncate” a file to a larger size, similar to the seek
plus write combination described earlier in “Seeking Past the End of a File.” The
extended bytes are filled with zeros.
Neither operation updates the current file position.
For example, consider the file pirate.txt of length 74 bytes with the following contents:
Edward Teach was a notorious English pirate.
He was nicknamed Blackbeard.
From the same directory, running the following program:
#include <unistd.h>
#include <stdio.h>
int main( )
{
int ret;
ret = truncate ("./pirate.txt", 45);
if (ret == -1) {
perror ("truncate");
return -1;
}
return 0;
}
results in a file of length 45 bytes with the contents:
Edward Teach was a notorious English pirate.
Multiplexed I/O | 47
Multiplexed I/O
Applications often need to block on more than one file descriptor, juggling I/O
between keyboard input (stdin), interprocess communication, and a handful of files.
Modern event-driven graphical user interface (GUI) applications may contend with
literally hundreds of pending events via their mainloops.*
Without the aid of threads—essentially servicing each file descriptor separately—a
single process cannot reasonably block on more than one file descriptor at the same
time. Working with multiple file descriptors is fine, so long as they are always ready
to be read from or written to. But as soon as one file descriptor that is not yet ready is
encountered—say, if a read( ) system call is issued, and there is not yet any data—
the process will block, no longer able to service the other file descriptors. It might
block for just a few seconds, making the application inefficient and annoying the user.
However, if no data becomes available on the file descriptor, it could block forever.
Because file descriptors’ I/O is often interrelated—think pipes—it is quite possible for
one file descriptor not to become ready until another is serviced. Particularly with net-
work applications, which may have many sockets open simultaneously, this is poten-
tially quite a problem.
Imagine blocking on a file descriptor related to interprocess communication while
stdin has data pending. The application won’t know that keyboard input is pending
until the blocked IPC file descriptor ultimately returns data—but what if the blocked
operation never returns?
Earlier in this chapter, we looked at nonblocking I/O as a solution to this problem.
With nonblocking I/O, applications can issue I/O requests that return a special error
condition instead of blocking. However, this solution is inefficient, for two reasons.
First, the process needs to continually issue I/O operations in some arbitrary order,
waiting for one of its open file descriptors to be ready for I/O. This is poor program
design. Second, it would be much more efficient if the program could sleep, freeing
the processor for other tasks, to be woken up only when one or more file descriptors
were ready to perform I/O.
Enter multiplexed I/O.
Multiplexed I/O allows an application to concurrently block on multiple file descrip-
tors, and receive notification when any one of them becomes ready to read or write
without blocking. Multiplexed I/O thus becomes the pivot point for the application,
designed similarly to the following:
1. Multiplexed I/O: Tell me when any of these file descriptors are ready for I/O.
2. Sleep until one or more file descriptors are ready.
* Mainloops should be familiar to anyone who has written GUI applications—for example, GNOME applica-
tions utilize a mainloop provided by GLib, their base library. A mainloop allows multiple events to be
watched for and responded to from a single blocking point.
48 | Chapter 2: File I/O
3. Woken up: What is ready?
4. Handle all file descriptors ready for I/O, without blocking.
5. Go back to step 1, and start over.
Linux provides three multiplexed I/O solutions: the select, poll, and epoll interfaces.
We will cover the first two here, and the last, which is an advanced Linux-specific
solution, in Chapter 4.
select( )
The select( ) system call provides a mechanism for implementing synchronous mul-
tiplexing I/O:
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>
int select (int n,
fd_set *readfds,
fd_set *writefds,
fd_set *exceptfds,
struct timeval *timeout);
FD_CLR(int fd, fd_set *set);
FD_ISSET(int fd, fd_set *set);
FD_SET(int fd, fd_set *set);
FD_ZERO(fd_set *set);
A call to select( ) will block until the given file descriptors are ready to perform I/O,
or until an optionally specified timeout has elapsed.
The watched file descriptors are broken into three sets, each waiting for a different
event. File descriptors listed in the readfds set are watched to see if data is available
for reading (that is, if a read operation will complete without blocking). File descrip-
tors listed in the writefds set are watched to see if a write operation will complete
without blocking. Finally, file descriptors in the exceptfds set are watched to see if an
exception has occurred, or if out-of-band data is available (these states apply only to
sockets). A given set may be NULL, in which case select( ) does not watch for that
event.
On successful return, each set is modified such that it contains only the file descrip-
tors that are ready for I/O of the type delineated by that set. For example, assume
two file descriptors, with the values 7 and 9, are placed in the readfds set. When the
call returns, if 7 is still in the set, that file descriptor is ready to read without block-
ing. If 9 is no longer in the set, it is probably not readable without blocking. (I say
Multiplexed I/O | 49
probably here because it is possible that data became available after the call com-
pleted. In that case, a subsequent call to select( ) will return the file descriptor as
ready to read.* )
The first parameter, n, is equal to the value of the highest-valued file descriptor in
any set, plus one. Consequently, a caller to select( ) is responsible for checking
which given file descriptor is the highest-valued, and passing in that value plus one
for the first parameter.
The timeout parameter is a pointer to a timeval structure, which is defined as follows:
#include <sys/time.h>
struct timeval {
long tv_sec; /* seconds */
long tv_usec; /* microseconds */
};
If this parameter is not NULL, the call to select( ) will return after tv_sec seconds, and
tv_usec microseconds, even if no file descriptors are ready for I/O. On return, the
state of this structure across various Unix systems is undefined, and thus it must be
reinitialized (along with the file descriptor sets) before every invocation. Indeed, cur-
rent versions of Linux modify this parameter automatically, setting the values to the
time remaining. Thus, if the timeout was set for 5 seconds, and 3 seconds elapsed
before a file descriptor became ready, tv.tv_sec would contain 2 upon the call’s
return.
If both values in the timeout are set to zero, the call will return immediately, reporting
any events that were pending at the time of the call, but not waiting for any subse-
quent events.
The sets of file descriptors are not manipulated directly, but are instead managed
through helper macros. This allows Unix systems to implement the sets however
they want. Most systems, however, implement the sets as simple bit arrays. FD_ZERO
removes all file descriptors from the specified set. It should be called before every
invocation of select( ):
fd_set writefds;
FD_ZERO(&writefds);
FD_SET adds a file descriptor to a given set, and FD_CLR removes a file descriptor from
a given set:
FD_SET(fd, &writefds); /* add 'fd' to the set */
FD_CLR(fd, &writefds); /* oops, remove 'fd' from the set */
* This is because select( ) and poll( ) are level-triggered and not edge-triggered. epoll( ), which we’ll discuss
in Chapter 4, can operate in either mode. Edge-triggered operation is simpler, but allows I/O events to be
missed if care is not taken.
50 | Chapter 2: File I/O
Well-designed code should never have to make use of FD_CLR, and it is rarely, if ever,
used.
FD_ISSET tests whether a file descriptor is part of a given set. It returns a nonzero inte-
ger if the file descriptor is in the set, and 0 if it is not. FD_ISSET is used after a call
from select( ) returns to test whether a given file descriptor is ready for action:
if (FD_ISSET(fd, &readfds))
/* 'fd' is readable without blocking! */
Because the file descriptor sets are statically created, they impose a limit on the maxi-
mum number of file descriptors and the largest-valued file descriptor that may be
placed inside them, both of which are given by FD_SETSIZE. On Linux, this value is
1,024. We will look at the ramifications of this limit later in this chapter.
Return values and error codes
On success, select( ) returns the number of file descriptors ready for I/O, among all
three sets. If a timeout was provided, the return value may be 0. On error, the call
returns -1, and errno is set to one of the following values:
EBADF
An invalid file descriptor was provided in one of the sets.
EINTR
A signal was caught while waiting, and the call can be reissued.
EINVAL
The parameter n is negative, or the given timeout is invalid.
ENOMEM
Insufficient memory was available to complete the request.
select( ) example
Let’s consider an example program, trivial but fully functional, to illustrate the use of
select( ). This example blocks waiting for input on stdin for up to 5 seconds.
Because it watches only a single file descriptor, it is not actually multiplexing I/O,
but the usage of the system call is made clear:
#include <stdio.h>
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>
#define TIMEOUT 5 /* select timeout in seconds */
#define BUF_LEN 1024 /* read buffer in bytes */
int main (void)
{
struct timeval tv;
fd_set readfds;
int ret;
Multiplexed I/O | 51
/* Wait on stdin for input. */
FD_ZERO(&readfds);
FD_SET(STDIN_FILENO, &readfds);
/* Wait up to five seconds. */
tv.tv_sec = TIMEOUT;
tv.tv_usec = 0;
/* All right, now block! */
ret = select (STDIN_FILENO + 1,
&readfds,
NULL,
NULL,
&tv);
if (ret == -1) {
perror ("select");
return 1;
} else if (!ret) {
printf ("%d seconds elapsed.\n", TIMEOUT);
return 0;
}
/*
* Is our file descriptor ready to read?
* (It must be, as it was the only fd that
* we provided and the call returned
* nonzero, but we will humor ourselves.)
*/
if (FD_ISSET(STDIN_FILENO, &readfds)) {
char buf[BUF_LEN+1];
int len;
/* guaranteed to not block */
len = read (STDIN_FILENO, buf, BUF_LEN);
if (len == -1) {
perror ("read");
return 1;
}
if (len) {
buf[len] = '\0';
printf ("read: %s\n", buf);
}
return 0;
}
fprintf (stderr, "This should not happen!\n");
return 1;
}
52 | Chapter 2: File I/O
Portable sleeping with select( )
Because select( ) has historically been more readily implemented on various Unix
systems than a mechanism for subsecond-resolution sleeping, it is often employed as
a portable way to sleep by providing a non-NULL timeout but NULL for all three sets:
struct timeval tv;
tv.tv_sec = 0;
tv.tv_usec = 500;
/* sleep for 500 microseconds */
select (0, NULL, NULL, NULL, &tv);
Linux, of course, provides interfaces for high-resolution sleeping. We will cover these
in Chapter 10.
pselect( )
The select( ) system call, first introduced IN 4.2BSD, is popular, but POSIX defined
its own solution, pselect( ), in POSIX 1003.1g-2000 and later in POSIX 1003.1-2001:
#define _XOPEN_SOURCE 600
#include <sys/select.h>
int pselect (int n,
fd_set *readfds,
fd_set *writefds,
fd_set *exceptfds,
const struct timespec *timeout,
const sigset_t *sigmask);
FD_CLR(int fd, fd_set *set);
FD_ISSET(int fd, fd_set *set);
FD_SET(int fd, fd_set *set);
FD_ZERO(fd_set *set);
There are three differences between pselect( ) and select( ):
1. pselect( ) uses the timespec structure, not the timeval structure, for its timeout
parameter. The timespec structure uses seconds and nanoseconds, not seconds
and microseconds, providing theoretically superior timeout resolution. In prac-
tice, however, neither call reliably provides even microsecond resolution.
2. A call to pselect( ) does not modify the timeout parameter. Consequently, this
parameter does not need to be reinitialized on subsequent invocations.
3. The select( ) system call does not have the sigmask parameter. With respect to
signals, when this parameter is set to NULL, pselect( ) behaves like select( ).
The timespec structure is defined as follows:
#include <sys/time.h>
struct timespec {
Multiplexed I/O | 53
long tv_sec; /* seconds */
long tv_nsec; /* nanoseconds */
};
The primary motivator behind the addition of pselect( ) to Unix’s toolbox was the
addition of the sigmask parameter, which attempts to solve a race condition between
waiting on file descriptors and signals (signals are covered in depth in Chapter 9).
Assume that a signal handler sets a global flag (as most do), and the process checks
this flag before a call to select( ). Now, assume that the signal arrives after the
check, but before the call. The application may block indefinitely, and never respond
to the set flag. The pselect( ) call solves this problem by allowing an application to
call pselect( ), providing a set of signals to block. Blocked signals are not handled
until they are unblocked. Once pselect( ) returns, the kernel restores the old signal
mask. Seriously, see Chapter 9.
Until the 2.6.16 kernel, the Linux implementation of pselect( ) was not a system
call, but a simple wrapper around select( ), provided by glibc. This wrapper mini-
mized—but did not totally eliminate—the risk of this race condition occurring. With
the introduction of a true system call, the race is gone.
Despite the (relatively minor) improvements in pselect( ), most applications con-
tinue to use select( ), either out of habit, or in the name of greater portability.
poll( )
The poll( ) system call is System V’s multiplexed I/O solution. It solves several defi-
ciencies in select( ), although select( ) is still often used (again, most likely out of
habit, or in the name of portability):
#include <sys/poll.h>
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
Unlike select( ), with its inefficient three bitmask-based sets of file descriptors,
poll( ) employs a single array of nfds pollfd structures, pointed to by fds. The struc-
ture is defined as follows:
#include <sys/poll.h>
struct pollfd {
int fd; /* file descriptor */
short events; /* requested events to watch */
short revents; /* returned events witnessed */
};
Each pollfd structure specifies a single file descriptor to watch. Multiple structures
may be passed, instructing poll( ) to watch multiple file descriptors. The events field
of each structure is a bitmask of events to watch for on that file descriptor. The user
54 | Chapter 2: File I/O
sets this field. The revents field is a bitmask of events that were witnessed on the file
descriptor. The kernel sets this field on return. All of the events requested in the
events field may be returned in the revents field. Valid events are as follows:
POLLIN
There is data to read.
POLLRDNORM
There is normal data to read.
POLLRDBAND
There is priority data to read.
POLLPRI
There is urgent data to read.
POLLOUT
Writing will not block.
POLLWRNORM
Writing normal data will not block.
POLLWRBAND
Writing priority data will not block.
POLLMSG
A SIGPOLL message is available.
In addition, the following events may be returned in the revents field:
POLLER
Error on the given file descriptor.
POLLHUP
Hung up event on the given file descriptor.
POLLNVAL
The given file descriptor is invalid.
These events have no meaning in the events field, as they are always returned if
applicable. With poll( ), unlike select( ), you need not explicitly ask for reporting of
exceptions.
POLLIN | POLLPRI is equivalent to select( )’s read event, and POLLOUT | POLLWRBAND is
equivalent to select( )’s write event. POLLIN is equivalent to POLLRDNORM | POLLRDBAND,
and POLLOUT is equivalent to POLLWRNORM.
For example, to watch a file descriptor for both readability and writability, we would
set events to POLLIN | POLLOUT. On return, we would check revents for these flags in
the structure corresponding to the file descriptor in question. If POLLIN were set, the
file descriptor would be readable without blocking. If POLLOUT were set, the file
descriptor would be writable without blocking. The flags are not mutually exclusive:
both may be set, signifying that both reads and writes will return instead of blocking
on that file descriptor.
Multiplexed I/O | 55
The timeout parameter specifies the length of time to wait, in milliseconds, before
returning regardless of any ready I/O. A negative value denotes an infinite timeout. A
value of 0 instructs the call to return immediately, listing any file descriptors with
pending ready I/O, but not waiting for any further events. In this manner, poll( ) is
true to its name, polling once, and immediately returning.
Return values and error codes
On success, poll( ) returns the number of file descriptors whose structures have non-
zero revents fields. It returns 0 if the timeout occurred before any events occurred.
On failure, -1 is returned, and errno is set to one of the following:
EBADF
An invalid file descriptor was given in one or more of the structures.
EFAULT
The pointer to fds pointed outside of the process’ address space.
EINTR
A signal occurred before any requested event. The call may be reissued.
EINVAL
The nfds parameter exceeded the RLIMIT_NOFILE value.
ENOMEM
Insufficient memory was available to complete the request.
poll( ) example
Let’s look at an example program that uses poll( ) to simultaneously check whether
a read from stdin and a write to stdout will block:
#include <stdio.h>
#include <unistd.h>
#include <sys/poll.h>
#define TIMEOUT 5 /* poll timeout, in seconds */
int main (void)
{
struct pollfd fds[2];
int ret;
/* watch stdin for input */
fds[0].fd = STDIN_FILENO;
fds[0].events = POLLIN;
/* watch stdout for ability to write (almost always true) */
fds[1].fd = STDOUT_FILENO;
fds[1].events = POLLOUT;
/* All set, block! */
ret = poll (fds, 2, TIMEOUT * 1000);
56 | Chapter 2: File I/O
if (ret == -1) {
perror ("poll");
return 1;
}
if (!ret) {
printf ("%d seconds elapsed.\n", TIMEOUT);
return 0;
}
if (fds[0].revents & POLLIN)
printf ("stdin is readable\n");
if (fds[1].revents & POLLOUT)
printf ("stdout is writable\n");
return 0;
}
Running this, we get the following, as expected:
$ ./poll
stdout is writable
Running it again, but this time redirecting a file into standard in, we see both events:
$ ./poll < ode_to_my_parrot.txt
stdin is readable
stdout is writable
If we were using poll( ) in a real application, we would not need to reconstruct the
pollfd structures on each invocation. The same structure may be passed in repeat-
edly; the kernel will handle zeroing the revents field as needed.
ppoll( )
Linux provides a ppoll( ) cousin to poll( ), in the same vein as pselect( ). Unlike
pselect( ), however, ppoll( ) is a Linux-specific interface:
#define _GNU_SOURCE
#include <sys/poll.h>
int ppoll (struct pollfd *fds,
nfds_t nfds,
const struct timespec *timeout,
const sigset_t *sigmask);
As with pselect( ), the timeout parameter specifies a timeout value in seconds and
nanoseconds, and the sigmask parameter provides a set of signals for which to wait.
Kernel Internals | 57
poll( ) Versus select( )
Although they perform the same basic job, the poll( ) system call is superior to
select( ) for a handful of reasons:
• poll( ) does not require that the user calculate and pass in as a parameter the
value of the highest-numbered file descriptor plus one.
• poll( ) is more efficient for large-valued file descriptors. Imagine watching a sin-
gle file descriptor with the value 900 via select( )—the kernel would have to
check each bit of each passed-in set, up to the 900th bit.
• select( )’s file descriptor sets are statically sized, introducing a tradeoff: they are
small, limiting the maximum file descriptor that select( ) can watch, or they are
inefficient. Operations on large bitmasks are not efficient, especially if it is not
known whether they are sparsely populated.* With poll( ), one can create an
array of exactly the right size. Only watching one item? Just pass in a single
structure.
• With select( ), the file descriptor sets are reconstructed on return, so each sub-
sequent call must reinitialize them. The poll( ) system call separates the input
(events field) from the output (revents field), allowing the array to be reused
without change.
• The timeout parameter to select( ) is undefined on return. Portable code needs
to reinitialize it. This is not an issue with pselect( ), however.
The select( ) system call does have a few things going for it, though:
• select( ) is more portable, as some Unix systems do not support poll( ).
• select( ) provides better timeout resolution: down to the microsecond. Both
ppoll( ) and pselect( ) theoretically provide nanosecond resolution, but in prac-
tice, none of these calls reliably provides even microsecond resolution.
Superior to both poll( ) and select( ) is the epoll interface, a Linux-specific multi-
plexing I/O solution that we’ll look at in Chapter 4.
Kernel Internals
This section looks at how the Linux kernel implements I/O, focusing on three pri-
mary subsystems of the kernel: the virtual filesystem (VFS), the page cache, and page
writeback. Together, these subsystems help make I/O seamless, efficient, and optimal.
* If a bitmask is generally sparsely populated, each word composing the mask can be checked against zero;
only if that operation returns false need each bit be checked. This work is wasted, however, if the bitmask is
densely populated.
58 | Chapter 2: File I/O
In Chapter 4, we will look at a fourth subsystem, the I/O scheduler.
The Virtual Filesystem
The virtual filesystem, occasionally also called a virtual file switch, is a mechanism of
abstraction that allows the Linux kernel to call filesystem functions and manipulate
filesystem data without knowing—or even caring about—the specific type of filesys-
tem being used.
The VFS accomplishes this abstraction by providing a common file model, which is
the basis for all filesystems in Linux. Via function pointers and various object-oriented
practices,* the common file model provides a framework to which filesystems in the
Linux kernel must adhere. This allows the VFS to generically make requests of the
filesystem. The framework provides hooks to support reading, creating links,
synchronizing, and so on. Each filesystem then registers functions to handle the
operations of which it is capable.
This approach forces a certain amount of commonality between filesystems. For
example, the VFS talks in terms of inodes, superblocks, and directory entries. A file-
system not of Unix origins, possibly devoid of Unix-like concepts such as inodes,
simply has to cope. Indeed, cope they do: Linux supports filesystems such as FAT
and NTFS without issue.
The benefits of the VFS are enormous. A single system call can read from any filesys-
tem on any medium; a single utility can copy from any one filesystem to any other.
All filesystems support the same concepts, the same interfaces, and the same calls.
Everything just works—and works well.
When an application issues a read( ) system call, it takes an interesting journey. The
C library provides definitions of the system call that are converted to the appropriate
trap statements at compile-time. Once a user-space process is trapped into the ker-
nel, passed through the system call handler, and handed to the read( ) system call,
the kernel figures out what object backs the given file descriptor. The kernel then
invokes the read function associated with the backing object. For filesystems, this
function is part of the filesystem code. The function then does its thing—for exam-
ple, physically reading the data from the filesystem—and returns the data to the
user-space read( ) call, which then returns to the system call handler, which copies
the data back to user space, where the read( ) system call returns and the process
continues to execute.
* Yes, in C.
Kernel Internals | 59
To system programmers, the ramifications of the VFS are important. Programmers
need not worry about the type of filesystem or media on which a file resides. Generic
system calls—read( ), write( ), and so on—can manipulate files on any supported
filesystem and on any supported media.
The Page Cache
The page cache is an in-memory store of recently accessed data from an on-disk file-
system. Disk access is painfully slow, particularly relative to today’s processor
speeds. Storing requested data in memory allows the kernel to fulfill subsequent
requests for the same data from memory, avoiding repeated disk access.
The page cache exploits the concept of temporal locality, a type of locality of refer-
ence, which says that a resource accessed at one point has a high probability of being
accessed again in the near future. The memory consumed to cache data on its first
access therefore pays off, as it prevents future expensive disk accesses.
The page cache is the first place that the kernel looks for filesystem data. The kernel
invokes the memory subsystem to read data from the disk only when it isn’t found in
the cache. Thus, the first time any item of data is read, it is transferred from the disk
into the page cache, and is returned to the application from the cache. If that data is
then read again, it is simply returned from the cache. All operations transparently
execute through the page cache, ensuring that its data is relevant and always valid.
The Linux page cache is dynamic in size. As I/O operations bring more and more
data into memory, the page cache grows larger and larger, consuming any free mem-
ory. If the page cache eventually does consume all free memory, and an allocation is
committed that requests additional memory, the page cache is pruned, releasing its
least-used pages, to make room for “real” memory usage. This pruning occurs seam-
lessly and automatically. A dynamically sized cache allows Linux to use all of the
memory in the system, and cache as much data as possible.
Often, however, it would make more sense to swap to disk a seldom-used chunk of
data than it would to prune an oft-used piece of the page cache that could well be
reread into memory on the next read request (swapping allows the kernel to store
data on the disk, to allow a larger memory footprint than the machine has RAM).
The Linux kernel implements heuristics to balance the swapping of data versus the
pruning of the page cache (and other in-memory reserves). These heuristics might
decide to swap data out to disk in lieu of pruning the page cache, particularly if the
data being swapped out is not in use.
The swap-versus-cache balance is tuned via /proc/sys/vm/swappiness. This virtual file
has a value from 0 to 100, with a default of 60. A higher value implies a stronger
preference toward keeping the page cache in memory, and swapping more readily. A
lower value implies a stronger preference toward pruning the page cache and not
swapping.
60 | Chapter 2: File I/O
Another form of locality of reference is sequential locality, which says that data is
often referenced sequentially. To take advantage of this principle, the kernel also
implements page cache readahead. Readahead is the act of reading extra data off the
disk and into the page cache following each read request—in effect, reading a little
bit ahead. When the kernel reads a chunk of data from the disk, it also reads the fol-
lowing chunk or two. Reading large sequential chunks of data at once is efficient, as
the disk usually need not seek. In addition, the kernel can fulfill the readahead
request while the process is manipulating the first chunk of read data. If, as often
happens, the process goes on to submit a new read request for the subsequent
chunk, the kernel can hand over the data from the initial readahead without having
to issue a disk I/O request.
As with the page cache, the kernel manages readahead dynamically. If it notices that
a process is consistently using the data that was read in via readahead, the kernel
grows the readahead window, thereby reading ahead more and more data. The
readahead window may be as small as 16 KB, and as large as 128 KB. Conversely, if
the kernel notices that readahead is not resulting in any useful hits—that is, that the
application is seeking around the file and not reading sequentially—it can disable
readahead entirely.
The presence of a page cache is meant to be transparent. System programmers gener-
ally cannot optimize their code to better take advantage of the fact that a page cache
exists—other than, perhaps, not implementing such a cache in user space them-
selves. Normally, efficient code is all that is needed to best utilize the page cache.
Utilizing readahead, on the other hand, is possible. Sequential file I/O is always pre-
ferred to random access, although it’s not always feasible.
Page Writeback
As discussed earlier in “Behavior of write( ),” the kernel defers writes via buffers.
When a process issues a write request, the data is copied into a buffer, and the buffer
is marked dirty, denoting that the in-memory copy is newer than the on-disk copy.
The write request then simply returns. If another write request is made to the same
chunk of a file, the buffer is updated with the new data. Write requests elsewhere in
the same file generate new buffers.
Eventually the dirty buffers need to be committed to disk, synchronizing the on-disk
files with the data in memory. This is known as writeback. It occurs in two situations:
• When free memory shrinks below a configurable threshold, dirty buffers are
written back to disk so that the now-clean buffers may be removed, freeing
memory.
• When a dirty buffer ages beyond a configurable threshold, the buffer is written
back to disk. This prevents data from remaining dirty indefinitely.
Conclusion | 61
Writebacks are carried out by a gang of kernel threads named pdflush threads
(presumably for page dirty flush, but who knows). When one of the previous two
conditions is met, the pdflush threads wake up, and begin committing dirty buffers
to disk until neither condition is true.
There may be multiple pdflush threads instantiating writebacks at the same time.
This is done to capitalize on the benefits of parallelism and to implement congestion
avoidance. Congestion avoidance attempts to keep writes from getting backed up
while waiting to be written to any one block device. If dirty buffers from different
block devices exist, the various pdflush threads will work to fully use each block
device. This fixes a deficiency in earlier kernels: the predecessor to pdflush threads
(bdflush, a single thread) could spend all of its time waiting on a single block device,
while other block devices sat idle. On a modern machine, the Linux kernel can now
keep a very large number of disks saturated.
Buffers are represented in the kernel by the buffer_head data structure. This data
structure tracks various metadata associated with the buffer, such as whether the
buffer is clean or dirty. It also contains a pointer to the actual data. This data resides in
the page cache. In this manner, the buffer subsystem and the page cache are unified.
In early versions of the Linux kernel—before 2.4—the buffer subsystem was sepa-
rate from the page cache, and thus there was both a page and a buffer cache. This
implied that data could exist in the buffer cache (as a dirty buffer) and the page cache
(as cached data) at the same time. Naturally, synchronizing these two separate
caches took some effort. The unified page cache introduced in the 2.4 Linux kernel
was a welcomed improvement.
Deferred writes and the buffer subsystem in Linux enable fast writes, at the expense
of the risk of data loss on power failure. To avoid this risk, paranoid and critical
applications can use synchronized I/O (discussed earlier in this chapter).
Conclusion
This chapter discussed the basics of Linux system programming: file I/O. On a sys-
tem such as Linux, which strives to represent as much as possible as a file, it’s very
important to know how to open, read, write, and close files. All of these operations
are classic Unix, and are represented in many standards.
The next chapter tackles buffered I/O, and the standard C library’s standard I/O
interfaces. The standard C library is not just a convenience; buffering I/O in user
space provides crucial performance improvements.
62
Chapter 3CHAPTER 3
Buffered I/O
Recall from Chapter 1 that the block, a filesystem abstraction, is the lingua franca of
I/O—all disk operations occur in terms of blocks. Consequently, I/O performance is
optimal when requests are issued on block-aligned boundaries in integer multiples of
the block size.
Performance degradation is exacerbated by the increased number of system calls
required to read, say, a single byte 1,024 times rather than 1,024 bytes all at once.
Even a series of operations performed in a size larger than a block can be suboptimal
if the size is not an integer multiple of the block size. For example, if the block size is
one kilobyte, operations in chunks of 1,130 bytes may still be slower than 1,024 byte
operations.
User-Buffered I/O
Programs that have to issue many small I/O requests to regular files often perform
user-buffered I/O. This refers to buffering done in user space, either manually by the
application, or transparently in a library, not to buffering done by the kernel. As dis-
cussed in Chapter 2, for reasons of performance, the kernel buffers data internally by
delaying writes, coalescing adjacent I/O requests, and reading ahead. Through differ-
ent means, user buffering also aims to improve performance.
Consider an example using the user-space program dd:
dd bs=1 count=2097152 if=/dev/zero of=pirate
Because of the bs=1 argument, this command will copy two megabytes from the
device /dev/zero (a virtual device providing an endless stream of zeros) to the file
pirate in 2,097,152 one byte chunks. That is, it will copy the data via about two mil-
lion read and write operations—one byte at a time.
Now consider the same two megabyte copy, but using 1,024 byte blocks:
dd bs=1024 count=2048 if=/dev/zero of=pirate
User-Buffered I/O | 63
This operation copies the same two megabytes to the same file, yet issues 1,024 times
fewer read and write operations. The performance improvement is huge, as you can
see in Table 3-1. Here, I’ve recorded the time taken (using three different measures)
by four dd commands that differed only in block size. Real time is the total elapsed
wall clock time, user time is the time spent executing the program’s code in user
space, and system time is the time spent executing system calls in kernel space on the
process’ behalf.
Using 1,024 byte chunks results in an enormous performance improvement com-
pared to the single byte chunk. However, the table also demonstrates that using a
larger block size—which implies even fewer system calls—can result in performance
degradation if the operations are not performed in multiples of the disk’s block size.
Despite requiring fewer calls, the 1,130 byte requests end up generating unaligned
requests, and are therefore less efficient than the 1,024 byte requests.
Taking advantage of this performance boon requires prior knowledge of the likely
physical block size. The results in the table show the block size is most likely 1,024,
an integer multiple of 1,024, or a divisor of 1,024. In the case of /dev/zero, the block
size is actually 4,096 bytes.
Block Size
In practice, blocks are usually 512, 1,024, 2,048, or 4,096 bytes in size.
As Table 3-1 demonstrates, a large performance gain is realized simply by perform-
ing operations in chunks that are integer multiples or divisors of the block size. This
is because the kernel and hardware speak in terms of blocks. So, using the block size
or a value that fits neatly inside of a block guarantees block-aligned I/O requests, and
prevents extraneous work inside the kernel.
Figuring out the block size for a given device is easy using the stat( ) system call
(covered in Chapter 7) or the stat(1) command. It turns out, however, that you don’t
usually need to know the actual block size.
The primary goal in picking a size for your I/O operations is to not pick an oddball
size such as 1,130. No block in the history of Unix has been 1,130 bytes, and choos-
ing such a size for your operations will result in unaligned I/O after the first request.
Using any integer multiple or divisor of the block size, however, prevents unaligned
requests. So long as your chosen size keeps everything block-aligned, performance
will be good. Larger multiples will simply result in fewer system calls.
Table 3-1. Effects of block size on performance
Block size Real time User time System time
1 byte 18.707 seconds 1.118 seconds 17.549 seconds
1,024 bytes 0.025 seconds 0.002 seconds 0.023 seconds
1,130 bytes 0.035 seconds 0.002 seconds 0.027 seconds
64 | Chapter 3: Buffered I/O
Therefore, the easiest choice is to perform I/O using a large buffer size that is a multi-
ple of the typical block sizes. Both 4,096 and 8,192 bytes work great.
The problem, of course, is that programs rarely deal in terms of blocks. Programs
work with fields, lines, and single characters, not abstractions such as blocks. As
described earlier, to remedy this situation, programs employ user-buffered I/O. As
data is written, it is stored in a buffer inside the program’s address space. When the
buffer reaches a specific size—the buffer size—the entire buffer is written out in a
single write operation. Likewise, data is read in using buffer-sized, block-aligned
chunks. As the application issues its odd-sized read requests, the chunks of the
buffer are handed out piece by piece. Ultimately, when the buffer is empty, another
large block-aligned chunk is read in. If this buffer is the right size, huge performance
benefits are realized.
It is possible to implement user buffering by hand in your own programs. Indeed,
many mission-critical applications do just this. The vast majority of programs, how-
ever, make use of the popular standard I/O library (part of the standard C library),
which provides a robust and capable user-buffering solution.
Standard I/O
The standard C library provides the standard I/O library (often simply called stdio),
which in turn provides a platform-independent, user-buffering solution. The stan-
dard I/O library is simple to use, yet powerful.
Unlike programming languages such as FORTRAN, the C language does not include
any built-in support or keywords providing any functionality more advanced than
flow control, arithmetic, and so on—there’s certainly no inherent support for I/O. As
the C programming language progressed, users developed standard sets of routines
to provide core functionality, such as string manipulation, mathematical routines,
time and date functionality, and I/O. Over time, these routines matured, and with the
ratification of the ANSI C standard in 1989 (C89) they were eventually formalized as
the standard C library. Although both C95 and C99 added several new interfaces, the
standard I/O library has remained relatively untouched since its creation in 1989.
The remainder of this chapter discusses user-buffered I/O as it pertains to file I/O,
and is implemented in the standard C library—that is, opening, closing, reading, and
writing files via the standard C library. Whether an application will use standard I/O,
a home-rolled user-buffering solution, or straight system calls is a decision that
developers must make carefully after weighing the application’s needs and behavior.
The C standards always leave some details up to each implementation, and imple-
mentations often add additional features. This chapter, just like the rest of the book,
documents the interfaces and behavior as they are implemented in glibc on a modern
Linux system. Where Linux deviates from the basic standard, this is noted.
Opening Files | 65
File Pointers
Standard I/O routines do not operate directly on file descriptors. Instead, they use
their own unique identifier, known as the file pointer. Inside the C library, the file
pointer maps to a file descriptor. The file pointer is represented by a pointer to the
FILE typedef, which is defined in <stdio.h>.
In standard I/O parlance, an open file is called a stream. Streams may be opened for
reading (input streams), writing (output streams), or both (input/output streams).
Opening Files
Files are opened for reading or writing via fopen( ):
#include <stdio.h>
FILE * fopen (const char *path, const char *mode);
This function opens the file path according to the given modes, and associates a new
stream with it.
Modes
The mode argument describes how to open the given file. It is one of the following
strings:
r
Open the file for reading. The stream is positioned at the start of the file.
r+
Open the file for both reading and writing. The stream is positioned at the start
of the file.
w
Open the file for writing. If the file exists, it is truncated to zero length. If the file
does not exist, it is created. The stream is positioned at the start of the file.
w+
Open the file for both reading and writing. If the file exists, it is truncated to zero
length. If the file does not exist, it is created. The stream is positioned at the start
of the file.
a
Open the file for writing in append mode. The file is created if it does not exist.
The stream is positioned at the end of the file. All writes will append to the file.
a+
Open the file for both reading and writing in append mode. The file is created if
it does not exist. The stream is positioned at the end of the file. All writes will
append to the file.
66 | Chapter 3: Buffered I/O
The given mode may also contain the character b, although this value
is always ignored on Linux. Some operating systems treat text and
binary files differently, and the b mode instructs the file to be opened
in binary mode. Linux, as with all POSIX-conforming systems, treats
text and binary files identically.
Upon success, fopen( ) returns a valid FILE pointer. On failure, it returns NULL, and
sets errno appropriately.
For example, the following code opens /etc/manifest for reading, and associates it
with stream:
FILE *stream;
stream = fopen ("/etc/manifest", "r");
if (!stream)
/* error */
Opening a Stream via File Descriptor
The function fdopen( ) converts an already open file descriptor (fd) to a stream:
#include <stdio.h>
FILE * fdopen (int fd, const char *mode);
The possible modes are the same as for fopen( ), and must be compatible with the
modes originally used to open the file descriptor. The modes w and w+ may be speci-
fied, but they will not cause truncation. The stream is positioned at the file position
associated with the file descriptor.
Once a file descriptor is converted to a stream, I/O should no longer be directly
performed on the file descriptor. It is, however, legal to do so. Note that the file
descriptor is not duplicated, but is merely associated with a new stream. Closing the
stream will close the file descriptor as well.
On success, fdopen( ) returns a valid file pointer; on failure, it returns NULL.
For example, the following code opens /home/kidd/map.txt via the open( ) system
call, and then uses the backing file descriptor to create an associated stream:
FILE *stream;
int fd;
fd = open ("/home/kidd/map.txt", O_RDONLY);
if (fd == &#8722;1)
/* error */
stream = fdopen (fd, "r");
if (!stream)
/* error */
Reading from a Stream | 67
Closing Streams
The fclose( ) function closes a given stream:
#include <stdio.h>
int fclose (FILE *stream);
Any buffered and not-yet-written data is first flushed. On success, fclose( ) returns
0. On failure, it returns EOF and sets errno appropriately.
Closing All Streams
The fcloseall( ) function closes all streams associated with the current process,
including standard in, standard out, and standard error:
#define _GNU_SOURCE
#include <stdio.h>
int fcloseall (void);
Before closing, all streams are flushed. The function always returns 0; it is Linux-
specific.
Reading from a Stream
The standard C library implements multiple functions for reading from an open
stream, ranging from the common to the esoteric. This section will look at three of
the most popular approaches to reading: reading one character at a time, reading an
entire line at a time, and reading binary data. To read from a stream, it must have
been opened as an input stream with the appropriate mode; that is, any valid mode
except w or a.
Reading a Character at a Time
Often, the ideal I/O pattern is simply reading one character at a time. The function
fgetc( ) is used to read a single character from a stream:
#include <stdio.h>
int fgetc (FILE *stream);
This function reads the next character from stream and returns it as an unsigned char
cast to an int. The casting is done to have a sufficient range for notification of end-
of-file or error: EOF is returned in such conditions. The return value of fgetc( ) must
be stored in an int. Storing it in a char is a common but dangerous mistake.
68 | Chapter 3: Buffered I/O
The following example reads a single character from stream, checks for error, and
then prints the result as a char:
int c;
c = fgetc (stream);
if (c == EOF)
/* error */
else
printf ("c=%c\n", (char) c);
The stream pointed at by stream must be open for reading.
Putting the character back
Standard I/O provides a function for pushing a character back onto a stream, allow-
ing you to “peek” at the stream, and return the character if it turns out that you
don’t want it:
#include <stdio.h>
int ungetc (int c, FILE *stream);
Each call pushes back c, cast to an unsigned char, onto stream. On success, c is
returned; on failure, EOF is returned. A subsequent read on stream will return c. If
multiple characters are pushed back, they are returned in the reverse order—that is,
the last pushed character is returned first. POSIX dictates that only one pushback is
guaranteed to succeed without intervening read requests. Some implementations, in
turn, allow only a single pushback; Linux allows an infinite number of pushbacks, so
long as memory is available. One pushback, of course, always succeeds.
If you make an intervening call to a seeking function (see “Seeking a Stream” later in
this chapter) after calling ungetc( ) but before issuing a read request, it will cause all
pushed-back characters to be discarded. This is true among threads in a single pro-
cess, as threads share the buffer.
Reading an Entire Line
The function fgets( ) reads a string from a given stream:
#include <stdio.h>
char * fgets (char *str, int size, FILE *stream);
This function reads up to one less than size bytes from stream, and stores the results
in str. A null character (\0) is stored in the buffer after the bytes read in. Reading
stops after an EOF or a newline character is reached. If a newline is read, the \n is
stored in str.
On success, str is returned; on failure, NULL is returned.
Reading from a Stream | 69
For example:
char buf[LINE_MAX];
if (!fgets (buf, LINE_MAX, stream))
/* error */
POSIX defines LINE_MAX in <limits.h>: it is the maximum size of input line that
POSIX line-manipulating interfaces can handle. Linux’s C library has no such limita-
tion—lines may be of any size—but there is no way to communicate that with the
LINE_MAX definition. Portable programs can use LINE_MAX to remain safe; it is set rela-
tively high on Linux. Linux-specific programs need not worry about limits on the
sizes of lines.
Reading arbitrary strings
Often, the line-based reading of fgets( ) is useful. Nearly as often, it’s annoying.
Sometimes, developers want to use a delimiter other than the newline. Other times,
developers do not want a delimiter at all—and rarely do developers want the delim-
iter stored in the buffer! In retrospect, the decision to store the newline in the
returned buffer rarely appears correct.
It is not hard to write an fgets( ) replacement that uses fgetc( ). For example, this
snippet reads the n – 1 bytes from stream into str, and then appends a \0 character:
char *s;
int c;
s = str;
while (--n > 0 && (c = fgetc (stream)) != EOF)
*s++ = c;
*s = '\0';
The snippet can be expanded to also stop reading at a delimiter, given by d (which
cannot be the null character in this example):
char *s;
int c = 0;
s = str;
while (--n > 0 && (c = fgetc (stream)) != EOF && (*s++ = c) != d)
;
if (c == d)
*--s = '\0';
else
*s = '\0';
Setting d to \n would provide behavior similar to fgets( ), minus storing the newline
in the buffer.
70 | Chapter 3: Buffered I/O
Depending on the implementation of fgets( ), this variant is probably slower, as it
issues repeated function calls to fgetc( ). This is not the same problem exhibited by
our original dd example, however! Although this snippet incurs additional function
call overhead, it does not incur the system call overhead and unaligned I/O penalty
burdened on dd with bs=1. The latter are much larger problems.
Reading Binary Data
For some applications, reading individual characters or lines is insufficient. Some-
times, developers want to read and write complex binary data, such as C structures.
For this, the standard I/O library provides fread( ):
#include <stdio.h>
size_t fread (void *buf, size_t size, size_t nr, FILE *stream);
A call to fread( ) will read up to nr elements of data, each of size bytes, from stream
into the buffer pointed at by buf. The file pointer is advanced by the number of bytes
read.
The number of elements read (not the number of bytes read!) is returned. The function
indicates failure or EOF via a return value less than nr. Unfortunately, it is impossible to
know which of the two conditions occurred without using ferror( ) and feof( ) (see
the later section “Errors and End-of-File”).
Because of differences in variable sizes, alignment, padding, and byte order, binary
data written with one application may not be readable by a different application, or
even by the same application on a different machine.
The simplest example of fread( ) is reading a single element of linear bytes from a
given stream:
char buf[64];
size_t nr;
nr = fread (buf, sizeof(buf), 1, stream);
if (nr == 0)
/* error */
We will look at examples that are more complicated when we study the write coun-
terpart to fread( ), fwrite( ).
Writing to a Stream
As with reading, the standard C library defines many functions for writing to an open
stream. This section will look at three of the most popular approaches to writing:
writing a single character, writing a string of characters, and writing binary data.
Such varied writing approaches are ideally suited to buffered I/O. To write to a
stream, it must have been opened as an output stream with the appropriate mode;
that is, any valid mode except r.
Writing to a Stream | 71
Writing a Single Character
The counterpart of fgetc( ) is fputc( ):
#include <stdio.h>
int fputc (int c, FILE *stream);
The fputc( ) function writes the byte specified by c (cast to an unsigned char) to the
stream pointed at by stream. Upon successful completion, the function returns c.
Otherwise, it returns EOF, and errno is set appropriately.
Use is simple:
if (fputc ('p', stream) == EOF)
/* error */
This example writes the character p to stream, which must be open for writing.
Issues of Alignment
All machine architectures have data alignment requirements. Programmers tend to
think of memory as simply an array of bytes. Our processors, however, do not read and
write from memory in byte-sized chunks. Instead, processors access memory with a
specific granularity, such as 2, 4, 8, or 16 bytes. Because each process’ address space
starts at address 0, processes must initiate access from an address that is an integer
multiple of the granularity.
Consequently, C variables must be stored at and accessed from aligned addresses. In
general, variables are naturally aligned, which refers to the alignment that corresponds
to the size of the C data type. For example, a 32-bit integer is aligned on a 4 byte bound-
ary. In other words, an int would be stored at a memory address that is evenly divisible
by four.
Accessing misaligned data has various penalties, which depend on the machine archi-
tecture. Some processors can access misaligned data, but with a large performance
penalty. Other processors cannot access misaligned data at all, and attempting to do
so causes a hardware exception. Worse, some processors silently drop the low-order
bits in order to force the address to be aligned, almost certainly resulting in unintended
behavior.
Normally, the compiler naturally aligns all data, and alignment is not a visible issue to
the programmer. Dealing with structures, performing memory management by hand,
saving binary data to disk, and communicating over a network may bring alignment
issues to the forefront. System programmers, therefore, ought to be well versed in these
issues!
Chapter 8 addresses alignment in greater depth.
72 | Chapter 3: Buffered I/O
Writing a String of Characters
The function fputs( ) is used to write an entire string to a given stream:
#include <stdio.h>
int fputs (const char *str, FILE *stream);
A call to fputs( ) writes all of the null-delimited string pointed at by str to the
stream pointed at by stream. On success, fputs( ) returns a nonnegative number. On
failure, it returns EOF.
The following example opens the file for writing in append mode, writes the given
string to the associated stream, and then closes the stream:
FILE *stream;
stream = fopen ("journal.txt", "a");
if (!stream)
/* error */
if (fputs ("The ship is made of wood.\n", stream) == EOF)
/* error */
if (fclose (stream) == EOF)
/* error */
Writing Binary Data
Individual characters and lines will not cut it when programs need to write complex
data. To directly store binary data such as C variables, standard I/O provides fwrite( ):
#include <stdio.h>
size_t fwrite (void *buf,
size_t size,
size_t nr,
FILE *stream);
A call to fwrite( ) will write to stream up to nr elements, each size bytes in length,
from the data pointed at by buf. The file pointer will be advanced by the total num-
ber of bytes written.
The number of elements (not the number of bytes!) successfully written will be
returned. A return value less than nr denotes error.
Sample Program Using Buffered I/O
Now let’s look at an example—a complete program, in fact—that integrates many of
the interfaces we have covered thus far in this chapter. This program first defines
struct pirate, and then declares two variables of that type. The program initializes
one of the variables and subsequently writes it out to disk via an output stream to the
Sample Program Using Buffered I/O | 73
file data. Via a different stream, the program reads the data back in from data directly
to the other instance of struct pirate. Finally, the program writes the contents of the
structure to standard out:
#include <stdio.h>
int main (void)
{
FILE *in, *out;
struct pirate {
char name[100]; /* real name */
unsigned long booty; /* in pounds sterling */
unsigned int beard_len; /* in inches */
} p, blackbeard = { "Edward Teach", 950, 48 };
out = fopen ("data", "w");
if (!out) {
perror ("fopen");
return 1;
}
if (!fwrite (&blackbeard, sizeof (struct pirate), 1, out)) {
perror ("fwrite");
return 1;
}
if (fclose (out)) {
perror ("fclose");
return 1;
}
in = fopen ("data", "r");
if (!in) {
perror ("fopen");
return 1;
}
if (!fread (&p, sizeof (struct pirate), 1, in)) {
perror ("fread");
return 1;
}
if (fclose (in)) {
perror ("fclose");
return 1;
}
printf ("name=\"%s\" booty=%lu beard_len=%u\n",
p.name, p.booty, p.beard_len);
return 0;
}
The output is, of course, the original values:
name="Edward Teach" booty=950 beard_len=48
74 | Chapter 3: Buffered I/O
Again, it’s important to bear in mind that because of differences in variable sizes,
alignment, and so on, binary data written with one application may not be readable
by other applications. That is, a different application—or even the same application
on a different machine—may not be able to correctly read back the data written with
fwrite( ). In our example, consider the ramifications if the size of unsigned long
changed, or if the amount of padding varied. These things are guaranteed to remain
constant only on a particular machine type with a particular ABI.
Seeking a Stream
Often, it is useful to manipulate the current stream position. Perhaps the application
is reading a complex record-based file, and needs to jump around. Alternatively, per-
haps the stream needs to be reset to file position zero. Whatever the case, standard I/O
provides a family of interfaces equivalent in functionality to the system call lseek( )
(discussed in Chapter 2). The fseek( ) function, the most common of the standard I/O
seeking interfaces, manipulates the file position of stream in accordance with offset
and whence:
#include <stdio.h>
int fseek (FILE *stream, long offset, int whence);
If whence is set to SEEK_SET, the file position is set to offset. If whence is set to SEEK_CUR,
the file position is set to the current position plus offset. If whence is set to SEEK_END,
the file position is set to the end of the file plus offset.
Upon successful completion, fseek( ) returns 0, clears the EOF indicator, and undoes the
effects (if any) of ungetc( ). On error, it returns -1, and errno is set appropriately. The
most common errors are invalid stream (EBADF) and invalid whence argument (EINVAL).
Alternatively, standard I/O provides fsetpos( ):
#include <stdio.h>
int fsetpos (FILE *stream, fpos_t *pos);
This function sets the stream position of stream to pos. It works the same as fseek( )
with a whence argument of SEEK_SET. On success, it returns 0. Otherwise, it returns -1,
and errno is set as appropriate. This function (along with its counterpart fgetpos( ),
which we will cover shortly) is provided solely for other (non-Unix) platforms that
have complex types representing the stream position. On those platforms, this func-
tion is the only way to set the stream position to an arbitrary value, as the C long
type is presumably insufficient. Linux-specific applications need not use this inter-
face, although they may, if they want to be portable to all possible platforms.
Standard I/O also provides rewind( ), as a shortcut:
#include <stdio.h>
void rewind (FILE *stream);
Flushing a Stream | 75
This invocation:
rewind (stream);
resets the position back to the start of the stream. It is equivalent to:
fseek (stream, 0, SEEK_SET);
except that it also clears the error indicator.
Note that rewind( ) has no return value, and thus cannot directly communicate error
conditions. Callers wishing to ascertain the existence of an error should clear errno
before invocation, and check to see whether the variable is nonzero afterward. For
example:
errno = 0;
rewind (stream);
if (errno)
/* error */
Obtaining the Current Stream Position
Unlike lseek( ), fseek( ) does not return the updated position. A separate interface is
provided for this purpose. The ftell( ) function returns the current stream position
of stream:
#include <stdio.h>
long ftell (FILE *stream);
On error, it returns -1 and errno is set appropriately.
Alternatively, standard I/O provides fgetpos( ):
#include <stdioh.h>
int fgetpos (FILE *stream, fpos_t *pos);
Upon success, fgetpos( ) returns 0, and places the current stream position of stream in
pos. On failure, it returns -1, and sets errno appropriately. Like fsetpos( ), fgetpos( )
is provided solely for non-Linux platforms with complex file position types.
Flushing a Stream
The standard I/O library provides an interface for writing out the user buffer to the
kernel, ensuring that all data written to a stream is flushed via write( ). The fflush( )
function provides this functionality:
#include <stdio.h>
int fflush (FILE *stream);
76 | Chapter 3: Buffered I/O
On invocation, any unwritten data in the stream pointed to by stream is flushed to
the kernel. If stream is NULL, all open input streams in the process are flushed. On
success, fflush( ) returns 0. On failure, it returns EOF, and errno is set appropriately.
To understand the effect of fflush( ), you have to understand the difference between
the buffer maintained by the C library, and the kernel’s own buffering. All of the calls
described in this chapter work with a buffer that is maintained by the C library,
which resides in user space, not kernel space. That is where the performance
improvement comes in—you are staying in user space, and therefore running user
code, not issuing system calls. A system call is issued only when the disk or some
other medium has to be accessed.
fflush( ) merely writes the user-buffered data out to the kernel buffer. The effect is
the same as if user buffering was not employed, and write( ) was used directly. It
does not guarantee that the data is physically committed to any medium—for that
need, use something like fsync( ) (see “Synchronized I/O” in Chapter 2). Most
likely, you will want to call fflush( ), followed immediately by fsync( ): that is, first
ensure that the user buffer is written out to the kernel, and then ensure that the ker-
nel’s buffer is written out to disk.
Errors and End-of-File
Some of the standard I/O interfaces, such as fread( ), communicate failures back to
the caller poorly, as they provide no mechanism for differentiating between error and
EOF. With these calls, and on other occasions, it can be useful to check the status of
a given stream to determine whether it has encountered an error, or reached the end
of a file. Standard I/O provides two interfaces to this end. The function ferror( )
tests whether the error indicator is set on stream:
include <stdio.h>
int ferror (FILE *stream);
The error indicator is set by other standard I/O interfaces in response to an error con-
dition. The function returns a nonzero value if the indicator is set, and 0 otherwise.
The function feof( ) tests whether the EOF indicator is set on stream:
include <stdio.h>
int feof (FILE *stream);
The EOF indicator is set by other standard I/O interfaces when the end of a file is
reached. This function returns a nonzero value if the indicator is set, and 0 otherwise.
The clearerr( ) function clears the error and the EOF indicators for stream:
#include <stdio.h>
void clearerr (FILE *stream);
Controlling the Buffering | 77
It has no return value, and cannot fail (there is no way to know whether an invalid
stream was provided). You should make a call to clearerr( ) only after checking the
error and EOF indicators, as they will be discarded irretrievably afterward. For example:
/* 'f' is a valid stream */
if (ferror (f))
printf ("Error on f!\n");
if (feof (f))
printf ("EOF on f!\n");
clearerr (f);
Obtaining the Associated File Descriptor
Sometimes, it is advantageous to obtain the file descriptor backing a given stream.
For example, it might be useful to perform a system call on a stream, via its file
descriptor, when an associated standard I/O function does not exist. To obtain the
file descriptor backing a stream, use fileno( ):
#include <stdio.h>
int fileno (FILE *stream);
Upon success, fileno( ) returns the file descriptor associated with stream. On fail-
ure, it returns -1. This can only happen when the given stream is invalid, in which
case, the function sets errno to EBADF.
Intermixing standard I/O calls with system calls is not normally advised. Program-
mers must exercise caution when using fileno( ) to ensure proper behavior. Particu-
larly, it is probably wise to flush the stream before manipulating the backing file
descriptor. You should almost never intermix actual I/O operations.
Controlling the Buffering
Standard I/O implements three types of user buffering, and provides developers with
an interface for controlling the type and size of the buffer. The different types of user
buffering serve different purposes, and are ideal for different situations. Here are the
options:
Unbuffered
No user buffering is performed. Data is submitted directly to the kernel. As this
is the antithesis of user buffering, this option is not commonly used. Standard
error, by default, is unbuffered.
78 | Chapter 3: Buffered I/O
Line-buffered
Buffering is performed on a per-line basis. With each newline character, the
buffer is submitted to the kernel. Line buffering makes sense for streams being
output to the screen. Consequently, this is the default buffering used for termi-
nals (standard out is line-buffered by default).
Block-buffered
Buffering is performed on a per-block basis. This is the type of buffering dis-
cussed at the beginning of this chapter, and it is ideal for files. By default, all
streams associated with files are block-buffered. Standard I/O uses the term full
buffering for block buffering.
Most of the time, the default buffering type is correct and optimal. However, stan-
dard I/O does provide an interface for controlling the type of buffering employed:
#include <stdio.h>
int setvbuf (FILE *stream, char *buf, int mode, size_t size);
The setvbuf( ) function sets the buffering type of stream to mode, which must be one
of the following:
_IONBF
Unbuffered
_IOLBF
Line-buffered
_IOFBF
Block-buffered
Except with _IONBF, in which case buf and size are ignored, buf may point to a buffer
of size bytes that standard I/O will use as the buffer for the given stream. If buf is
NULL, a buffer is allocated automatically by glibc.
The setvbuf( ) function must be called after opening the stream, but before any
other operations have been performed on it. It returns 0 on success, and a nonzero
value otherwise.
The supplied buffer, if any, must exist when the stream is closed. A common mis-
take is to declare the buffer as an automatic variable in a scope that ends before the
stream is closed. Particularly, be careful not to provide a buffer local to main( ), and
then fail to explicitly close the streams. For example, the following is a bug:
#include <stdio.h>
int main (void)
{
char buf[BUFSIZ];
/* set stdin to block-buffered with a BUFSIZ buffer */
setvbuf (stdout, buf, _IOFBF, BUFSIZ);
Thread Safety | 79
printf ("Arrr!\n");
return 0;
}
The bug can be fixed by explicitly closing the stream before falling out of scope, or
by making buf a global variable.
Generally, developers need not mess with the buffering on a stream. With the excep-
tion of standard error, terminals are line-buffered, and that makes sense. Files are
block-buffered, and that, too, makes sense. The default buffer size for block buffering
is BUFSIZ, defined in <stdio.h>, and it is usually an optimal choice (a large multiple of
a typical block size).
Thread Safety
Threads are multiple strains of execution within a single process. One way to concep-
tualize them is as multiple processes that share an address space. Threads can run at
any time, and can overwrite shared data unless care is taken to synchronize access to
the data or make it thread-local. Operating systems that support threads provide
locking mechanisms (programming constructs that ensure mutual exclusion) to
ensure that threads do not trample on each other’s feet. Standard I/O uses these
mechanisms. Still, they are not always adequate. For example, sometimes you want
to lock a group of calls, enlarging the critical region (the chunk of code that runs
without interference from another thread) from one I/O operation to several. In
other situations, you may want to eliminate locking altogether to improve efficiency.*
In this section, we will discuss how to do both.
The standard I/O functions are inherently thread-safe. Internally, they associate a
lock, a lock count, and an owning thread with each open stream. Any given thread
must acquire the lock and become the owning thread before issuing any I/O
requests. Two or more threads operating on the same stream cannot interleave stan-
dard I/O operations, and thus, within the context of single function calls, standard I/O
operations are atomic.
Of course, in practice, many applications require greater atomicity than at the level
of individual function calls. For example, if multiple threads were issuing write
requests, although the individual writes would not interleave and result in garbled
output, the application might wish to have all of the write requests complete with-
out interruption. To allow for this, standard I/O provides a family of functions for
individually manipulating the lock associated with a stream.
* Normally, eliminating locking will lead to an assortment of problems. But some programs might explicitly
implement their thread usage to delegate all I/O to a single thread. In that case, there is no need for the over-
head of locking.
80 | Chapter 3: Buffered I/O
Manual File Locking
The function flockfile( ) waits until stream is no longer locked, and then acquires
the lock, bumps the lock count, becomes the owning thread of the stream, and
returns:
#include <stdio.h>
void flockfile (FILE *stream);
The function funlockfile( ) decrements the lock count associated with stream:
#include <stdio.h>
void funlockfile (FILE *stream);
If the lock count reaches zero, the current thread relinquishes ownership of the
stream. Another thread is now able to acquire the lock.
These calls can nest. That is, a single thread can issue multiple flockfile( ) calls, and
the stream will not unlock until the process issues a corresponding number of
funlockfile( ) calls.
The ftrylockfile( ) function is a nonblocking version of flockfile( ):
#include <stdio.h>
int ftrylockfile (FILE *stream);
If stream is currently locked, ftrylockfile( ) does nothing, and immediately returns
a nonzero value. If stream is not currently locked, it acquires the lock, bumps the
lock count, becomes the owning thread of stream, and returns 0.
Let’s consider an example:
flockfile (stream);
fputs ("List of treasure:\n", stream);
fputs (" (1) 500 gold coins\n", stream);
fputs (" (2) Wonderfully ornate dishware\n", stream);
funlockfile (stream);
Although the individual fputs( ) operations could never race—for example, we
would never end up with anything interleaving with “List of treasure”—another
standard I/O operation from another thread to this same stream could interleave
between two fputs( ) calls. Ideally, an application is designed such that multiple
threads are not submitting I/O to the same stream. If your application does need to
do so, however, and you need an atomic region greater than a single function,
flockfile( ) and friends can save the day.
Critiques of Standard I/O | 81
Unlocked Stream Operations
There is a second reason for performing manual locking on streams. With the finer-
grained and more precise control of locking that only the application programmer
can provide, it might be possible to minimize the overhead of locking, and to
improve performance. To this end, Linux provides a family of functions, cousins to
the usual standard I/O interfaces, that do not perform any locking whatsoever. They
are, in effect, the unlocked counterparts to standard I/O:
#define _GNU_SOURCE
#include <stdio.h>
int fgetc_unlocked (FILE *stream);
char *fgets_unlocked (char *str, int size, FILE *stream);
size_t fread_unlocked (void *buf, size_t size, size_t nr,
FILE *stream);
int fputc_unlocked (int c, FILE *stream);
int fputs_unlocked (const char *str, FILE *stream);
size_t fwrite_unlocked (void *buf, size_t size, size_t nr,
FILE *stream);
int fflush_unlocked (FILE *stream);
int feof_unlocked (FILE *stream);
int ferror_unlocked (FILE *stream);
int fileno_unlocked (FILE *stream);
void clearerr_unlocked (FILE *stream);
These functions all behave identically to their locked cousins, except that they do not
check for or acquire the lock associated with the given stream. If locking is required,
it is the responsibility of the programmer to ensure that the lock is manually acquired
and released.
Although POSIX does define some unlocked variants of the standard I/O functions,
none of the above functions are defined by POSIX. They are all Linux-specific,
although various other Unix systems support a subset.
Critiques of Standard I/O
As widely used as standard I/O is, some experts point to flaws in it. Some of the
functions, such as fgets( ), are occasionally inadequate. Other functions, such as
gets( ), are so horrendous that they have been all but evicted from the standards.
The biggest complaint with standard I/O is the performance impact from the double
copy. When reading data, standard I/O issues a read( ) system call to the kernel,
copying the data from the kernel to the standard I/O buffer. When an application
then issues a read request via standard I/O—say, using fgetc( )—the data is copied
again, this time from the standard I/O buffer to the supplied buffer. Write requests
work in the opposite fashion: the data is copied once from the supplied buffer to the
standard I/O buffer, and then later from the standard I/O buffer to the kernel via
write( ).
82 | Chapter 3: Buffered I/O
An alternative implementation could avoid the double copy by having each read
request return a pointer into the standard I/O buffer. The data could then be read
directly, inside of the standard I/O buffer, without ever needing an extraneous copy.
In the event that the application did want the data in its own local buffer—perhaps
to write to it—it could always perform the copy manually. This implementation
would provide a “free” interface, allowing applications to signal when they are done
with a given chunk of the read buffer.
Writes would be a bit more complicated, but the double copy could still be avoided.
When issuing a write request, the implementation would record the pointer. Ulti-
mately, when ready to flush the data to the kernel, the implementation could walk its
list of stored pointers, writing out the data. This could be done using scatter-gather I/O,
via writev( ), and thus only a single system call. (We will discuss scatter-gather I/O in
the next chapter.)
Highly optimal user-buffering libraries exist, solving the double copy problem with
implementations similar to what we’ve just discussed. Alternatively, some developers
choose to implement their own user-buffering solutions. But despite these alterna-
tives, standard I/O remains popular.
Conclusion
Standard I/O is a user-buffering library provided as part of the standard C library.
Modulo a few flaws, it is a powerful and very popular solution. Many C program-
mers, in fact, know nothing but standard I/O. Certainly, for terminal I/O, where
line-based buffering is ideal, standard I/O is the only game in town. Who has ever
directly used write( ) to print to standard out?
Standard I/O—and user buffering in general, for that matter—makes sense when
any of the following are true:
• You could conceivably issue many system calls, and you want to minimize the
overhead by combining many calls into few.
• Performance is crucial, and you want to ensure that all I/O occurs in block-sized
chunks on block-aligned boundaries.
• Your access patterns are character- or line-based, and you want interfaces to
make such access easy without issuing extraneous system calls.
• You prefer a higher-level interface to the low-level Linux system calls.
The most flexibility, however, exists when you work directly with the Linux system
calls. In the next chapter, we will look at advanced forms of I/O and the associated
system calls.
83
Chapter 4 CHAPTER 4
Advanced File I/O
In Chapter 2, we looked at the basic I/O system calls in Linux. These calls form not
only the basis of file I/O, but also the foundation of virtually all communication on
Linux. In Chapter 3, we looked at how user-space buffering is often needed on top of
the basic I/O system calls, and we studied a specific user-space buffering solution,
C’s standard I/O library. In this chapter, we’ll look at the more advanced I/O system
calls that Linux provides:
Scatter/gather I/O
Allows a single call to read or write data to and from many buffers at once; use-
ful for bunching together fields of different data structures to form one I/O
transaction.
Epoll
Improves on the poll( ) and select( ) system calls described in Chapter 2; use-
ful when hundreds of file descriptors have to be polled in a single program.
Memory-mapped I/O
Maps a file into memory, allowing file I/O to occur via simple memory manipu-
lation; useful for certain patterns of I/O.
File advice
Allows a process to provide hints to the kernel on its usage scenarios; can result
in improved I/O performance.
Asynchronous I/O
Allows a process to issue I/O requests without waiting for them to complete;
useful for juggling heavy I/O workloads without the use of threads.
The chapter will conclude with a discussion of performance considerations and the
kernel’s I/O subsystems.
84 | Chapter 4: Advanced File I/O
Scatter/Gather I/O
Scatter/gather I/O is a method of input and output where a single system call writes
to a vector of buffers from a single data stream, or, alternatively, reads into a vector
of buffers from a single data stream. This type of I/O is so named because the data is
scattered into or gathered from the given vector of buffers. An alternative name for
this approach to input and output is vectored I/O. In comparison, the standard read
and write system calls that we covered in Chapter 2 provide linear I/O.
Scatter/gather I/O provides several advantages over linear I/O methods:
More natural handling
If your data is naturally segmented—say, the fields of a predefined header file—
vectored I/O allows for intuitive manipulation.
Efficiency
A single vectored I/O operation can replace multiple linear I/O operations.
Performance
In addition to a reduction in the number of issued system calls, a vectored I/O
implementation can provide improved performance over a linear I/O implemen-
tation via internal optimizations.
Atomicity
Unlike with multiple linear I/O operations, a process can execute a single vec-
tored I/O operation with no risk of interleaving of an operation from another
process.
Both a more natural I/O method and atomicity are achievable without a scatter/
gather I/O mechanism. A process can concatenate the disjoint vectors into a single
buffer before writing, and decompose the returned buffer into multiple vectors after
reading—that is, a user-space application can perform the scattering and the gather-
ing manually. Such a solution, however, is neither efficient nor fun to implement.
readv( ) and writev( )
POSIX 1003.1-2001 defines, and Linux implements, a pair of system calls that imple-
ment scatter/gather I/O. The Linux implementation satisfies all of the goals listed in
the previous section.
The readv( ) function reads count segments from the file descriptor fd into the buffers
described by iov:
#include <sys/uio.h>
ssize_t readv (int fd,
const struct iovec *iov,
int count);
Scatter/Gather I/O | 85
The writev( ) function writes at most count segments from the buffers described by
iov into the file descriptor fd:
#include <sys/uio.h>
ssize_t writev (int fd,
const struct iovec *iov,
int count);
The readv( ) and writev( ) functions behave the same as read( ) and write( ), respec-
tively, except that multiple buffers are read from or written to.
Each iovec structure describes an independent disjoint buffer, which is called a segment:
#include <sys/uio.h>
struct iovec {
void *iov_base; /* pointer to start of buffer */
size_t iov_len; /* size of buffer in bytes */
};
A set of segments is called a vector. Each segment in the vector describes the address
and length of a buffer in memory to or from which data should be written or read.
The readv( ) function fills each buffer of iov_len bytes completely before proceeding
to the next buffer. The writev( ) function always writes out all full iov_len bytes
before proceeding to the next buffer. Both functions always operate on the segments
in order, starting with iov[0], then iov[1], and so on, through iov[count–1].
Return values
On success, readv( ) and writev( ) return the number of bytes read or written,
respectively. This number should be the sum of all count iov_len values. On error, the
system calls return -1, and set errno as appropriate. These system calls can experience
any of the errors of the read( ) and write( ) system calls, and will, upon receiving such
errors, set the same errno codes. In addition, the standards define two other error
situations.
First, because the return type is an ssize_t, if the sum of all count iov_len values is
greater than SSIZE_MAX, no data will be transferred, -1 will be returned, and errno will
be set to EINVAL.
Second, POSIX dictates that count must be larger than zero, and less than or equal to
IOV_MAX, which is defined in <limits.h>. In Linux, IOV_MAX is currently 1024. If count
is 0, the system calls return 0. * If count is greater than IOV_MAX, no data is transferred,
the calls return -1, and errno is set to EINVAL.
* Note that other Unix systems may set errno to EINVAL if count is 0. This is explicitly allowed by the standards,
which say that EINVAL may be set if that value is 0, or that the system can handle the zero case in some other
(nonerror) way.
86 | Chapter 4: Advanced File I/O
writev( ) example
Let’s consider a simple example that writes out a vector of three segments, each con-
taining a string of a different size. This self-contained program is complete enough to
demonstrate writev( ), yet simple enough to serve as a useful code snippet:
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <string.h>
#include <sys/uio.h>
int main ( )
{
struct iovec iov[3];
ssize_t nr;
int fd, i;
char *buf[] = {
"The term buccaneer comes from the word boucan.\n",
"A boucan is a wooden frame used for cooking meat.\n",
"Buccaneer is the West Indies name for a pirate.\n" };
fd = open ("buccaneer.txt", O_WRONLY | O_CREAT | O_TRUNC);
if (fd == -1) {
perror ("open");
return 1;
}
/* fill out three iovec structures */
for (i = 0; i < 3; i++) {
iov[i].iov_base = buf[i];
iov[i].iov_len = strlen (buf[i]);
}
Optimizing the Count
During a vectored I/O operation, the Linux kernel must allocate internal data struc-
tures to represent each segment. Normally, this allocation would occur dynamically,
based on the size of count. As an optimization, however, the Linux kernel creates a
small array of segments on the stack that it uses if count is sufficiently small, negating
the need to dynamically allocate the segments, and thereby providing a small boost in
performance. This threshold is currently eight, so if count is less than or equal to 8, the
vectored I/O operation occurs in a very memory-efficient manner off of the process’
kernel stack.
Most likely, you won’t have a choice about how many segments you need to transfer
at once in a given vectored I/O operation. If you are flexible, however, and are debating
over a small value, choosing a value of eight or less definitely improves efficiency.
Scatter/Gather I/O | 87
/* with a single call, write them all out */
nr = writev (fd, iov, 3);
if (nr == -1) {
perror ("writev");
return 1;
}
printf ("wrote %d bytes\n", nr);
if (close (fd)) {
perror ("close");
return 1;
}
return 0;
}
Running the program produces the desired result:
$ ./writev
wrote 148 bytes
As does reading the file:
$ cat buccaneer.txt
The term buccaneer comes from the word boucan.
A boucan is a wooden frame used for cooking meat.
Buccaneer is the West Indies name for a pirate.
readv( ) example
Now, let’s consider an example program that uses the readv( ) system call to read
from the previously generated text file using vectored I/O. This self-contained exam-
ple is likewise simple yet complete:
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <sys/uio.h>
int main ( )
{
char foo[48], bar[51], baz[49];
struct iovec iov[3];
ssize_t nr;
int fd, i;
fd = open ("buccaneer.txt", O_RDONLY);
if (fd == -1) {
perror ("open");
return 1;
}
/* set up our iovec structures */
88 | Chapter 4: Advanced File I/O
iov[0].iov_base = foo;
iov[0].iov_len = sizeof (foo);
iov[1].iov_base = bar;
iov[1].iov_len = sizeof (bar);
iov[2].iov_base = baz;
iov[2].iov_len = sizeof (baz);
/* read into the structures with a single call */
nr = readv (fd, iov, 3);
if (nr == -1) {
perror ("readv");
return 1;
}
for (i = 0; i < 3; i++)
printf ("%d: %s", i, (char *) iov[i].iov_base);
if (close (fd)) {
perror ("close");
return 1;
}
return 0;
}
Running this program after running the previous program produces the following
results:
$ ./readv
0: The term buccaneer comes from the word boucan.
1: A boucan is a wooden frame used for cooking meat.
2: Buccaneer is the West Indies name for a pirate.
Implementation
A naïve implementation of readv( ) and writev( ) could be done in user space as a
simple loop, something similar to the following:
#include <unistd.h>
#include <sys/uio.h>
ssize_t naive_writev (int fd, const struct iovec *iov, int count)
{
ssize_t ret = 0;
int i;
for (i = 0; i < count; i++) {
ssize_t nr;
nr = write (fd, iov[i].iov_base, iov[i].iov_len);
if (nr == -1) {
ret = -1;
break;
}
ret += nr;
The Event Poll Interface | 89
}
return ret;
}
Thankfully, this is not the Linux implementation: Linux implements readv( ) and
writev( ) as system calls, and internally performs scatter/gather I/O. In fact, all I/O
inside the Linux kernel is vectored; read( ) and write( ) are implemented as vectored
I/O with a vector of only one segment.
The Event Poll Interface
Recognizing the limitations of both poll( ) and select( ), the 2.6 Linux kernel* intro-
duced the event poll (epoll) facility. While more complex than the two earlier interfaces,
epoll solves the fundamental performance problem shared by both of them, and adds
several new features.
Both poll( ) and select( ) (discussed in Chapter 2) require the full list of file descrip-
tors to watch on each invocation. The kernel must then walk the list of each file
descriptor to be monitored. When this list grows large—it may contain hundreds or
even thousands of file descriptors—walking the list on each invocation becomes a
scalability bottleneck.
Epoll circumvents this problem by decoupling the monitor registration from the
actual monitoring. One system call initializes an epoll context, another adds moni-
tored file descriptors to or removes them from the context, and a third performs the
actual event wait.
Creating a New Epoll Instance
An epoll context is created via epoll_create( ):
#include <sys/epoll.h>
int epoll_create (int size)
A successful call to epoll_create( ) instantiates a new epoll instance, and returns a
file descriptor associated with the instance. This file descriptor has no relationship to
a real file; it is just a handle to be used with subsequent calls using the epoll facility.
The size parameter is a hint to the kernel about the number of file descriptors that
are going to be monitored; it is not the maximum number. Passing in a good approx-
imation will result in better performance, but the exact number is not required. On
error, the call returns -1, and sets errno to one of the following:
EINVAL
The size parameter is not a positive number.
* Epoll was introduced in the 2.5.44 development kernel, and the interface was finalized as of 2.5.66.
90 | Chapter 4: Advanced File I/O
ENFILE
The system has reached the limit on the total number of open files.
ENOMEM
Insufficient memory was available to complete the operation.
A typical call is:
int epfd;
epfd = epoll_create (100); /* plan to watch ~100 fds */
if (epfd < 0)
perror ("epoll_create");
The file descriptor returned from epoll_create( ) should be destroyed via a call to
close( ) after polling is finished.
Controlling Epoll
The epoll_ctl( ) system call can be used to add file descriptors to and remove file
descriptors from a given epoll context:
#include <sys/epoll.h>
int epoll_ctl (int epfd,
int op,
int fd,
struct epoll_event *event);
The header <sys/epoll.h> defines the epoll_event structure as:
struct epoll_event {
_ _u32 events; /* events */
union {
void *ptr;
int fd;
_ _u32 u32;
_ _u64 u64;
} data;
};
A successful call to epoll_ctl( ) controls the epoll instance associated with the file
descriptor epfd. The parameter op specifies the operation to be taken against the file
associated with fd. The event parameter further describes the behavior of the operation.
Here are valid values for the op parameter:
EPOLL_CTL_ADD
Add a monitor on the file associated with the file descriptor fd to the epoll
instance associated with epfd, per the events defined in event.
The Event Poll Interface | 91
EPOLL_CTL_DEL
Remove a monitor on the file associated with the file descriptor fd from the epoll
instance associated with epfd.
EPOLL_CTL_MOD
Modify an existing monitor of fd with the updated events specified by event.
The events field in the epoll_event structure lists which events to monitor on the given
file descriptor. Multiple events can be bitwise-ORed together. Here are valid values:
EPOLLERR
An error condition occurred on the file. This event is always monitored, even if
it’s not specified.
EPOLLET
Enables edge-triggered behavior for the monitor of the file (see the upcoming
section “Edge- Versus Level-Triggered Events”). The default behavior is level-
triggered.
EPOLLHUP
A hangup occurred on the file. This event is always monitored, even if it’s not
specified.
EPOLLIN
The file is available to be read from without blocking.
EPOLLONESHOT
After an event is generated and read, the file is automatically no longer monitored.
A new event mask must be specified via EPOLL_CTL_MOD to reenable the watch.
EPOLLOUT
The file is available to be written to without blocking.
EPOLLPRI
There is urgent out-of-band data available to read.
The data field inside the event_poll structure is for the user’s private use. The
contents are returned to the user upon receipt of the requested event. The common
practice is to set event.data.fd to fd, which makes it easy to look up which file
descriptor caused the event.
Upon success, epoll_ctl( ) returns 0. On failure, the call returns -1, and sets errno to
one of the following values:
EBADF
epfd is not a valid epoll instance, or fd is not a valid file descriptor.
EEXIST
op was EPOLL_CTL_ADD, but fd is already associated with epfd.
92 | Chapter 4: Advanced File I/O
EINVAL
epfd is not an epoll instance, epfd is the same as fd, or op is invalid.
ENOENT
op was EPOLL_CTL_MOD, or EPOLL_CTL_DEL, but fd is not associated with epfd.
ENOMEM
There was insufficient memory to process the request.
EPERM
fd does not support epoll.
As an example, to add a new watch on the file associated with fd to the epoll
instance epfd, you would write:
struct epoll_event event;
int ret;
event.data.fd = fd; /* return the fd to us later */
event.events = EPOLLIN | EPOLLOUT;
ret = epoll_ctl (epfd, EPOLL_CTL_ADD, fd, &event);
if (ret)
perror ("epoll_ctl");
To modify an existing event on the file associated with fd on the epoll instance epfd,
you would write:
struct epoll_event event;
int ret;
event.data.fd = fd; /* return the fd to us later */
event.events = EPOLLIN;
ret = epoll_ctl (epfd, EPOLL_CTL_MOD, fd, &event);
if (ret)
perror ("epoll_ctl");
Conversely, to remove an existing event on the file associated with fd from the epoll
instance epfd, you would write:
struct epoll_event event;
int ret;
ret = epoll_ctl (epfd, EPOLL_CTL_DEL, fd, &event);
if (ret)
perror ("epoll_ctl");
Note that the event parameter can be NULL when op is EPOLL_CTL_DEL, as there is no
event mask to provide. Kernel versions before 2.6.9, however, erroneously check for
this parameter to be non-NULL. For portability to these older kernels, you should pass
in a valid non-NULL pointer; it will not be touched. Kernel 2.6.9 fixed this bug.
The Event Poll Interface | 93
Waiting for Events with Epoll
The system call epoll_wait( ) waits for events on the file descriptors associated with
the given epoll instance:
#include <sys/epoll.h>
int epoll_wait (int epfd,
struct epoll_event *events,
int maxevents,
int timeout);
A call to epoll_wait( ) waits up to timeout milliseconds for events on the files associ-
ated with the epoll instance epfd. Upon success, events points to memory containing
epoll_event structures describing each event, up to a maximum of maxevents events.
The return value is the number of events, or -1 on error, in which case errno is set to
one of the following:
EBADF
epfd is not a valid file descriptor.
EFAULT
The process does not have write access to the memory pointed at by events.
EINTR
The system call was interrupted by a signal before it could complete.
EINVAL
epfd is not a valid epoll instance, or maxevents is equal to or less than 0.
If timeout is 0, the call returns immediately, even if no events are available, in which
case the call will return 0. If the timeout is -1, the call will not return until an event is
available.
When the call returns, the events field of the epoll_event structure describes the
events that occurred. The data field contains whatever the user set it to before invo-
cation of epoll_ctl( ).
A full epoll_wait( ) example looks like this:
#define MAX_EVENTS 64
struct epoll_event *events;
int nr_events, i, epfd;
events = malloc (sizeof (struct epoll_event) * MAX_EVENTS);
if (!events) {
perror ("malloc");
return 1;
}
nr_events = epoll_wait (epfd, events, MAX_EVENTS, -1);
if (nr_events < 0) {
perror ("epoll_wait");
94 | Chapter 4: Advanced File I/O
free (events);
return 1;
}
for (i = 0; i < nr_events; i++) {
printf ("event=%ld on fd=%d\n",
events[i].events,
events[i].data.fd);
/*
* We now can, per events[i].events, operate on
* events[i].data.fd without blocking.
*/
}
free (events);
We will cover the functions malloc( ) and free( ) in Chapter 8.
Edge- Versus Level-Triggered Events
If the EPOLLET value is set in the events field of the event parameter passed to
epoll_ctl( ), the watch on fd is edge-triggered, as opposed to level-triggered.
Consider the following events between a producer and a consumer communicating
over a Unix pipe:
1. The producer writes 1 KB of data onto a pipe.
2. The consumer performs an epoll_wait( ) on the pipe, waiting for the pipe to
contain data, and thus be readable.
With a level-triggered watch, the call to epoll_wait( ) in step 2 will return immedi-
ately, showing that the pipe is ready to read. With an edge-triggered watch, this call
will not return until after step 1 occurs. That is, even if the pipe is readable at the
invocation of epoll_wait( ), the call will not return until the data is written onto the
pipe.
Level-triggered is the default behavior. It is how poll( ) and select( ) behave, and it is
what most developers expect. Edge-triggered behavior requires a different approach to
programming, commonly utilizing nonblocking I/O, and careful checking for EAGAIN.
The terminology comes from electrical engineering. A level-triggered
interrupt is issued whenever a line is asserted. An edge-triggered inter-
rupt is caused only during the rising or falling edge of the change in
assertion. Level-triggered interrupts are useful when the state of the
event (the asserted line) is of interest. Edge-triggered interrupts are
useful when the event itself (the line being asserted) is of interest.
Mapping Files into Memory | 95
Mapping Files into Memory
As an alternative to standard file I/O, the kernel provides an interface that allows an
application to map a file into memory, meaning that there is a one-to-one correspon-
dence between a memory address and a word in the file. The programmer can then
access the file directly through memory, identically to any other chunk of memory-
resident data—it is even possible to allow writes to the memory region to transparently
map back to the file on disk.
POSIX.1 standardizes—and Linux implements—the mmap( ) system call for mapping
objects into memory. This section will discuss mmap( ) as it pertains to mapping files
into memory to perform I/O; in Chapter 8, we will visit other applications of mmap( ).
mmap( )
A call to mmap( ) asks the kernel to map len bytes of the object represented by the file
descriptor fd, starting at offset bytes into the file, into memory. If addr is included, it
indicates a preference to use that starting address in memory. The access permis-
sions are dictated by prot, and additional behavior can be given by flags:
#include <sys/mman.h>
void * mmap (void *addr,
size_t len,
int prot,
int flags,
int fd,
off_t offset);
The addr parameter offers a suggestion to the kernel of where best to map the file. It
is only a hint; most users pass 0. The call returns the actual address in memory where
the mapping begins.
The prot parameter describes the desired memory protection of the mapping. It may
be either PROT_NONE, in which case the pages in this mapping may not be accessed
(making little sense!), or a bitwise OR of one or more of the following flags:
PROT_READ
The pages may be read.
PROT_WRITE
The pages may be written.
PROT_EXEC
The pages may be executed.
The desired memory protection must not conflict with the open mode of the file. For
example, if the program opens the file read-only, prot must not specify PROT_WRITE.
96 | Chapter 4: Advanced File I/O
The flags argument describes the type of mapping, and some elements of its behav-
ior. It is a bitwise OR of the following values:
MAP_FIXED
Instructs mmap( ) to treat addr as a requirement, not a hint. If the kernel is unable
to place the mapping at the given address, the call fails. If the address and length
parameters overlap an existing mapping, the overlapped pages are discarded and
replaced by the new mapping. As this option requires intimate knowledge of the
process address space, it is nonportable, and its use is discouraged.
MAP_PRIVATE
States that the mapping is not shared. The file is mapped copy-on-write, and any
changes made in memory by this process are not reflected in the actual file, or in
the mappings of other processes.
MAP_SHARED
Shares the mapping with all other processes that map this same file. Writing into
the mapping is equivalent to writing to the file. Reads from the mapping will
reflect the writes of other processes.
Either MAP_SHARED or MAP_PRIVATE must be specified, but not both. Other, more
advanced flags are discussed in Chapter 8.
When you map a file descriptor, the file’s reference count is incremented. Therefore,
you can close the file descriptor after mapping the file, and your process will still
have access to it. The corresponding decrement of the file’s reference count will
occur when you unmap the file, or when the process terminates.
Protection Flags, Architectures, and Security
While POSIX defines four protection bits (read, write, execute, and stay the heck
away), some architectures support only a subset of these. It is common, for example,
for a processor to not differentiate between the actions of reading and executing. In that
case, the processor may have only a single “read” flag. On those systems, PROT_READ
implies PROT_EXEC. Until recently, the x86 architecture was one such system.
Of course, relying on such behavior is not portable. Portable programs should always
set PROT_EXEC if they intend to execute code in the mapping.
The reverse situation is one reason for the prevalence of buffer overflow attacks: even
if a given mapping does not specify execution permission, the processor may allow exe-
cution anyway.
Recent x86 processors have introduced the NX (no-execute) bit, which allows for read-
able, but not executable, mappings. On these newer systems, PROT_READ no longer
implies PROT_EXEC.
Mapping Files into Memory | 97
As an example, the following snippet maps the file backed by fd, beginning with its
first byte, and extending for len bytes, into a read-only mapping:
void *p;
p = mmap (0, len, PROT_READ, MAP_SHARED, fd, 0);
if (p == MAP_FAILED)
perror ("mmap");
Figure 4-1 shows the effects of paramaters supplied with mmap( ) on the mapping
between a file and a process’ address space.
The page size
The page is the smallest unit of memory that can have distinct permissions and
behavior. Consequently, the page is the building block of memory mappings, which
in turn are the building blocks of the process address space.
The mmap( ) system call operates on pages. Both the addr and offset parameters must
be aligned on a page-sized boundary. That is, they must be integer multiples of the
page size.
Mappings are, therefore, integer multiples of pages. If the len parameter provided by
the caller is not aligned on a page boundary—perhaps because the underlying file’s
size is not a multiple of the page size—the mapping is rounded up to the next full
page. The bytes inside this added memory, between the last valid byte and the end of
the mapping, are zero-filled. Any read from that region will return zeros. Any writes
to that memory will not affect the backing file, even if it is mapped as MAP_SHARED.
Only the original len bytes are ever written back to the file.
Figure 4-1. Mapping a file into a process’ address space
Process Address Space
Stack
Mapped file
Heap
bss
Text
File Mapped region
of file
Off len
98 | Chapter 4: Advanced File I/O
sysconf( ). The standard POSIX method of obtaining the page size is with sysconf( ),
which can retrieve a variety of system-specific information:
#include <unistd.h>
long sysconf (int name);
A call to sysconf( ) returns the value of the configuration item name, or -1 if name is
invalid. On error, the call sets errno to EINVAL. Because -1 may be a valid value for
some items (e.g., limits, where -1 means no limit), it may be wise to clear errno
before invocation, and check its value after.
POSIX defines _SC_PAGESIZE (and a synonym, _SC_PAGE_SIZE) to be the size of a page,
in bytes. Therefore, getting the page size is simple:
long page_size = sysconf (_SC_PAGESIZE);
getpagesize( ). Linux also provides the getpagesize( ) function:
#include <unistd.h>
int getpagesize (void);
A call to getpagesize( ) will likewise return the size of a page, in bytes. Usage is even
simpler than sysconf( ):
int page_size = getpagesize ( );
Not all Unix systems support this function; it’s been dropped from the 1003.1-2001
revision of the POSIX standard. It is included here for completeness.
PAGE_SIZE. The page size is also stored statically in the macro PAGE_SIZE, which is
defined in <asm/page.h>. Thus, a third possible way to retrieve the page size is:
int page_size = PAGE_SIZE;
Unlike the first two options, however, this approach retrieves the system page size at
compile-time, and not runtime. Some architectures support multiple machine types
with different page sizes, and some machine types even support multiple page sizes
themselves! A single binary should be able to run on all machine types in a given
architecture—that is, you should be able to build it once and run it everywhere.
Hard-coding the page size would nullify that possibility. Consequently, you should
determine the page size at runtime. Because addr and offset are usually 0, this
requirement is not overly difficult to meet.
Moreover, future kernel versions will likely not export this macro to user space. We
cover it in this chapter due to its frequent presence in Unix code, but you should not
use it in your own programs. The sysconf( ) approach is your best bet.
Mapping Files into Memory | 99
Return values and error codes
On success, a call to mmap( ) returns the location of the mapping. On failure, the call
returns MAP_FAILED, and sets errno appropriately. A call to mmap( ) never returns 0.
Possible errno values include:
EACCESS
The given file descriptor is not a regular file, or the mode with which it was
opened conflicts with prot or flags.
EAGAIN
The file has been locked via a file lock.
EBADF
The given file descriptor is not valid.
EINVAL
One or more of the parameters addr, len, or off are invalid.
ENFILE
The system-wide limit on open files has been reached.
ENODEV
The filesystem on which the file to map resides does not support memory mapping.
ENOMEM
The process does not have enough memory.
EOVERFLOW
The result of addr+len exceeds the size of the address space.
EPERM
PROT_EXEC was given, but the filesystem is mounted noexec.
Associated signals
Two signals are associated with mapped regions:
SIGBUS
This signal is generated when a process attempts to access a region of a mapping
that is no longer valid—for example, because the file was truncated after it was
mapped.
SIGSEGV
This signal is generated when a process attempts to write to a region that is
mapped read-only.
munmap( )
Linux provides the munmap( ) system call for removing a mapping created with mmap( ):
#include <sys/mman.h>
int munmap (void *addr, size_t len);
100 | Chapter 4: Advanced File I/O
A call to munmap( ) removes any mappings that contain pages located anywhere in the
process address space starting at addr, which must be page-aligned, and continuing
for len bytes. Once the mapping has been removed, the previously associated mem-
ory region is no longer valid, and further access attempts result in a SIGSEGV signal.
Normally, munmap( ) is passed the return value and the len parameter from a previ-
ous invocation of mmap( ).
On success, munmap( ) returns 0; on failure, it returns -1, and errno is set appropri-
ately. The only standard errno value is EINVAL, which specifies that one or more
parameters were invalid.
As an example, the following snippet unmaps any memory regions with pages con-
tained in the interval [addr,addr+len]:
if (munmap (addr, len) == -1)
perror ("munmap");
Mapping Example
Let’s consider a simple example program that uses mmap( ) to print a file chosen by
the user to standard out:
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/mman.h>
int main (int argc, char *argv[])
{
struct stat sb;
off_t len;
char *p;
int fd;
if (argc < 2) {
fprintf (stderr, "usage: %s <file>\n", argv[0]);
return 1;
}
fd = open (argv[1], O_RDONLY);
if (fd == -1) {
perror ("open");
return 1;
}
if (fstat (fd, &sb) == -1) {
perror ("fstat");
return 1;
}
Mapping Files into Memory | 101
if (!S_ISREG (sb.st_mode)) {
fprintf (stderr, "%s is not a file\n", argv[1]);
return 1;
}
p = mmap (0, sb.st_size, PROT_READ, MAP_SHARED, fd, 0);
if (p == MAP_FAILED) {
perror ("mmap");
return 1;
}
if (close (fd) == -1) {
perror ("close");
return 1;
}
for (len = 0; len < sb.st_size; len++)
putchar (p[len]);
if (munmap (p, sb.st_size) == -1) {
perror ("munmap");
return 1;
}
return 0;
}
The only unfamiliar system call in this example should be fstat( ), which we will
cover in Chapter 7. All you need to know at this point is that fstat( ) returns infor-
mation about a given file. The S_ISREG( ) macro can check some of this information,
so that we can ensure that the given file is a regular file (as opposed to a device file or
a directory) before we map it. The behavior of nonregular files when mapped
depends on the backing device. Some device files are mmap-able; other nonregular
files are not mmap-able, and will set errno to EACCESS.
The rest of the example should be straightforward. The program is passed a file-
name as an argument. It opens the file, ensures it is a regular file, maps it, closes it,
prints the file byte-by-byte to standard out, and then unmaps the file from memory.
Advantages of mmap( )
Manipulating files via mmap( ) has a handful of advantages over the standard read( )
and write( ) system calls. Among them are:
• Reading from and writing to a memory-mapped file avoids the extraneous copy
that occurs when using the read( ) or write( ) system calls, where the data must
be copied to and from a user-space buffer.
• Aside from any potential page faults, reading from and writing to a memory-
mapped file does not incur any system call or context switch overhead. It is as
simple as accessing memory.
102 | Chapter 4: Advanced File I/O
• When multiple processes map the same object into memory, the data is shared
among all the processes. Read-only and shared writable mappings are shared in
their entirety; private writable mappings have their not-yet-COW (copy-on-write)
pages shared.
• Seeking around the mapping involves trivial pointer manipulations. There is no
need for the lseek( ) system call.
For these reasons, mmap( ) is a smart choice for many applications.
Disadvantages of mmap( )
There are a few points to keep in mind when using mmap( ):
• Memory mappings are always an integer number of pages in size. Thus, the dif-
ference between the size of the backing file and an integer number of pages is
“wasted” as slack space. For small files, a significant percentage of the mapping
may be wasted. For example, with 4 KB pages, a 7 byte mapping wastes 4,089
bytes.
• The memory mappings must fit into the process’ address space. With a 32-bit
address space, a very large number of various-sized mappings can result in frag-
mentation of the address space, making it hard to find large free contiguous
regions. This problem, of course, is much less apparent with a 64-bit address
space.
• There is overhead in creating and maintaining the memory mappings and associ-
ated data structures inside the kernel. This overhead is generally obviated by the
elimination of the double copy mentioned in the previous section, particularly
for larger and frequently accessed files.
For these reasons, the benefits of mmap( ) are most greatly realized when the mapped
file is large (and thus any wasted space is a small percentage of the total mapping), or
when the total size of the mapped file is evenly divisible by the page size (and thus
there is no wasted space).
Resizing a Mapping
Linux provides the mremap( ) system call for expanding or shrinking the size of a
given mapping. This function is Linux-specific:
#define _GNU_SOURCE
#include <unistd.h>
#include <sys/mman.h>
void * mremap (void *addr, size_t old_size,
size_t new_size, unsigned long flags);
Mapping Files into Memory | 103
A call to mremap( ) expands or shrinks mapping in the region [addr,addr+old_size) to
the new size new_size. The kernel can potentially move the mapping at the same
time, depending on the availability of space in the process’ address space and the
value of flags.
The opening [ in [addr,addr+old_size) indicates that the region starts
with (and includes) the low address, whereas the closing ) indicates
that the region stops just before (does not include) the high address.
This convention is known as interval notation.
The flags parameter can be either 0 or MREMAP_MAYMOVE, which specifies that the kernel
is free to move the mapping, if required, in order to perform the requested resizing. A
large resizing is more likely to succeed if the kernel can move the mapping.
Return values and error codes
On success, mremap( ) returns a pointer to the newly resized memory mapping. On
failure, it returns MAP_FAILED, and sets errno to one of the following:
EAGAIN
The memory region is locked, and cannot be resized.
EFAULT
Some pages in the given range are not valid pages in the process’ address space,
or there was a problem remapping the given pages.
EINVAL
An argument was invalid.
ENOMEM
The given range cannot be expanded without moving (and MREMAP_MAYMOVE was
not given), or there is not enough free space in the process’ address space.
Libraries such as glibc often use mremap( ) to implement an efficient realloc( ), which
is an interface for resizing a block of memory originally obtained via malloc( ). For
example:
void * realloc (void *addr, size_t len)
{
size_t old_size = look_up_mapping_size (addr);
void *p;
p = mremap (addr, old_size, len, MREMAP_MAYMOVE);
if (p == MAP_FAILED)
return NULL;
return p;
}
This would only work if all malloc( ) allocations were unique anonymous mappings;
nonetheless, it stands as a useful example of the performance gains to be had. The
example assumes the programmer has written a look_up_mapping_size( ) function.
104 | Chapter 4: Advanced File I/O
The GNUC library does use mmap( ) and family for performing some memory alloca-
tions. We will look that topic in depth in Chapter 8.
Changing the Protection of a Mapping
POSIX defines the mprotect( ) interface to allow programs to change the permissions
of existing regions of memory:
#include <sys/mman.h>
int mprotect (const void *addr,
size_t len,
int prot);
A call to mprotect( ) will change the protection mode for the memory pages con-
tained in [addr,addr+len), where addr is page-aligned. The prot parameter accepts
the same values as the prot given to mmap( ): PROT_NONE, PROT_READ, PROT_WRITE, and
PROT_EXEC. These values are not additive; if a region of memory is readable, and prot
is set to only PROT_WRITE, the call will make the region only writable.
On some systems, mprotect( ) may operate only on memory mappings previously
created via mmap( ). On Linux, mprotect( ) can operate on any region of memory.
Return values and error codes
On success, mprotect( ) returns 0. On failure, it returns -1, and sets errno to one of
the following:
EACCESS
The memory cannot be given the permissions requested by prot. This can hap-
pen, for example, if you attempt to set the mapping of a file opened read-only to
writable.
EINVAL
The parameter addr is invalid or not page-aligned.
ENOMEM
Insufficient kernel memory is available to satisfy the request, or one or more
pages in the given memory region are not a valid part of the process’ address
space.
Synchronizing a File with a Mapping
POSIX provides a memory-mapped equivalent of the fsync( ) system call that we dis-
cussed in Chapter 2:
#include <sys/mman.h>
int msync (void *addr, size_t len, int flags);
Mapping Files into Memory | 105
A call to msync( ) flushes back to disk any changes made to a file mapped via mmap( ),
synchronizing the mapped file with the mapping. Specifically, the file or subset of a
file associated with the mapping starting at memory address addr and continuing for
len bytes is synchronized to disk. The addr argument must be page-aligned; it is gen-
erally the return value from a previous mmap( ) invocation.
Without invocation of msync( ), there is no guarantee that a dirty mapping will be
written back to disk until the file is unmapped. This is different from the behavior of
write( ), where a buffer is dirtied as part of the writing process, and queued for
writeback to disk. When writing into a memory mapping, the process directly modi-
fies the file’s pages in the kernel’s page cache, without kernel involvement. The
kernel may not synchronize the page cache and the disk anytime soon.
The flags parameter controls the behavior of the synchronizing operation. It is a bit-
wise OR of the following values:
MS_ASYNC
Specifies that synchronization should occur asynchronously. The update is
scheduled, but the msync( ) call returns immediately without waiting for the
writes to take place.
MS_INVALIDATE
Specifies that all other cached copies of the mapping be invalidated. Any future
access to any mappings of this file will reflect the newly synchronized on-disk
contents.
MS_SYNC
Specifies that synchronization should occur synchronously. The msync( ) call will
not return until all pages are written back to disk.
Either MS_ASYNC or MS_SYNC must be specified, but not both.
Usage is simple:
if (msync (addr, len, MS_ASYNC) == -1)
perror ("msync");
This example asynchronously synchronizes (say that 10 times fast) to disk the file
mapped in the region [addr,addr+len).
Return values and error codes
On success, msync( ) returns 0. On failure, the call returns -1, and sets errno appro-
priately. The following are valid errno values:
EINVAL
The flags parameter has both MS_SYNC and MS_ASYNC set, a bit other than one of
the three valid flags is set, or addr is not page-aligned.
106 | Chapter 4: Advanced File I/O
ENOMEM
The given memory region (or part of it) is not mapped. Note that Linux will
return ENOMEM, as POSIX dictates, when asked to synchronize a region that is only
partly unmapped, but it will still synchronize any valid mappings in the region.
Before version 2.4.19 of the Linux kernel, msync( ) returned EFAULT in place of ENOMEM.
Giving Advice on a Mapping
Linux provides a system call named madvise( ) to let processes give the kernel advice
and hints on how they intend to use a mapping. The kernel can then optimize its
behavior to take advantage of the mapping’s intended use. While the Linux kernel
dynamically tunes its behavior, and generally provides optimal performance without
explicit advice, providing such advice can ensure the desired caching and readahead
behavior for some workloads.
A call to madvise( ) advises the kernel on how to behave with respect to the pages in
the memory map starting at addr, and extending for len bytes:
#include <sys/mman.h>
int madvise (void *addr,
size_t len,
int advice);
If len is 0, the kernel will apply the advice to the entire mapping that starts at addr.
The parameter advice delineates the advice, which can be one of:
MADV_NORMAL
The application has no specific advice to give on this range of memory. It should
be treated as normal.
MADV_RANDOM
The application intends to access the pages in the specified range in a random
(nonsequential) order.
MADV_SEQUENTIAL
The application intends to access the pages in the specified range sequentially,
from lower to higher addresses.
MADV_WILLNEED
The application intends to access the pages in the specified range in the near
future.
MADV_DONTNEED
The application does not intend to access the pages in the specified range in the
near future.
The actual behavior modifications that the kernel takes in response to this advice are
implementation-specific: POSIX dictates only the meaning of the advice, not any
potential consequences. The current 2.6 kernel behaves as follows in response to the
advice values:
Mapping Files into Memory | 107
MADV_NORMAL
The kernel behaves as usual, performing a moderate amount of readahead.
MADV_RANDOM
The kernel disables readahead, reading only the minimal amount of data on each
physical read operation.
MADV_SEQUENTIAL
The kernel performs aggressive readahead.
MADV_WILLNEED
The kernel initiates readahead, reading the given pages into memory.
MADV_DONTNEED
The kernel frees any resources associated with the given pages, and discards any
dirty and not-yet-synchronized pages. Subsequent accesses to the mapped data
will cause the data to be paged in from the backing file.
Typical usage is:
int ret;
ret = madvise (addr, len, MADV_SEQUENTIAL);
if (ret < 0)
perror ("madvise");
This call instructs the kernel that the process intends to access the memory region
[addr,addr+len) sequentially.
Readahead
When the Linux kernel reads files off the disk, it performs an optimization known as
readahead. That is, when a request is made for a given chunk of a file, the kernel also
reads the following chunk of the file. If a request is subsequently made for that
chunk—as is the case when reading a file sequentially—the kernel can return the
requested data immediately. Because disks have track buffers (basically, hard disks
perform their own readahead internally), and because files are generally laid out
sequentially on disk, this optimization is low-cost.
Some readahead is usually advantageous, but optimal results depend on the question
of how much readahead to perform. A sequentially accessed file may benefit from a
larger readahead window, while a randomly accessed file may find readahead to be
worthless overhead.
As discussed in “Kernel Internals” in Chapter 2, the kernel dynamically tunes the size
of the readahead window in response to the hit rate inside that window. More hits
imply that a larger window would be advantageous; fewer hits suggest a smaller win-
dow. The madvise( ) system call allows applications to influence the window size right
off the bat.
108 | Chapter 4: Advanced File I/O
Return values and error codes
On success, madvise( ) returns 0. On failure, it returns -1, and errno is set appropri-
ately. The following are valid errors:
EAGAIN
An internal kernel resource (probably memory) was unavailable. The process
can try again.
EBADF
The region exists, but does not map a file.
EINVAL
The parameter len is negative, addr is not page-aligned, the advice parameter is
invalid, or the pages were locked or shared with MADV_DONTNEED.
EIO
An internal I/O error occurred with MADV_WILLNEED.
ENOMEM
The given region is not a valid mapping in this process’ address space, or
MADV_WILLNEED was given, but there is insufficient memory to page in the given
regions.
Advice for Normal File I/O
In the previous subsection, we looked at providing advice on memory mappings. In
this section, we will look at providing advice to the kernel on normal file I/O. Linux
provides two interfaces for such advice-giving: posix_fadvise( ) and readahead( ).
The posix_fadvise( ) System Call
The first advice interface, as its name alludes, is standardized by POSIX 1003.1-2003:
#include <fcntl.h>
int posix_fadvise (int fd,
off_t offset,
off_t len,
int advice);
A call to posix_fadvise( ) provides the kernel with the hint advice on the file descrip-
tor fd in the interval [offset,offset+len). If len is 0, the advice will apply to the
range [offset,length of file]. Common usage is to specify 0 for len and offset,
applying the advice to the entire file.
The available advice options are similar to those for madvise( ). Exactly one of the
following should be provided for advice:
Advice for Normal File I/O | 109
POSIX_FADV_NORMAL
The application has no specific advice to give on this range of the file. It should
be treated as normal.
POSIX_FADV_RANDOM
The application intends to access the data in the specified range in a random
(nonsequential) order.
POSIX_FADV_SEQUENTIAL
The application intends to access the data in the specified range sequentially,
from lower to higher addresses.
POSIX_FADV_WILLNEED
The application intends to access the data in the specified range in the near
future.
POSIX_FADV_NOREUSE
The application intends to access the data in the specified range in the near
future, but only once.
POSIX_FADV_DONTNEED
The application does not intend to access the pages in the specified range in the
near future.
As with madvise( ), the actual response to the given advice is implementation-
specific—even different versions of the Linux kernel may react dissimilarly. The
following are the current responses:
POSIX_FADV_NORMAL
The kernel behaves as usual, performing a moderate amount of readahead.
POSIX_FADV_RANDOM
The kernel disables readahead, reading only the minimal amount of data on each
physical read operation.
POSIX_FADV_SEQUENTIAL
The kernel performs aggressive readahead, doubling the size of the readahead
window.
POSIX_FADV_WILLNEED
The kernel initiates readahead to begin reading into memory the given pages.
POSIX_FADV_NOREUSE
Currently, the behavior is the same as for POSIX_FADV_WILLNEED; future kernels
may perform an additional optimization to exploit the “use once” behavior. This
hint does not have an madvise( ) complement.
POSIX_FADV_DONTNEED
The kernel evicts any cached data in the given range from the page cache. Note that
this hint, unlike the others, is different in behavior from its madvise( ) counterpart.
110 | Chapter 4: Advanced File I/O
As an example, the following snippet instructs the kernel that the entire file repre-
sented by the file descriptor fd will be accessed in a random, nonsequential manner:
int ret;
ret = posix_fadvise (fd, 0, 0, POSIX_FADV_RANDOM);
if (ret == -1)
perror ("posix_fadvise");
Return values and error codes
On success, posix_fadvise( ) returns 0. On failure, -1 is returned, and errno is set to
one of the following values:
EBADF
The given file descriptor is invalid.
EINVAL
The given advice is invalid, the given file descriptor refers to a pipe, or the speci-
fied advice cannot be applied to the given file.
The readahead( ) System Call
The posix_fadvise( ) system call is new to the 2.6 Linux kernel. Before, the readahead( )
system call was available to provide behavior identical to the POSIX_FADV_WILLNEED hint.
Unlike posix_fadvise( ), readahead( ) is a Linux-specific interface:
#include <fcntl.h>
ssize_t readahead (int fd,
off64_t offset,
size_t count);
A call to readahead( ) populates the page cache with the region [offset,offset+count)
from the file descriptor fd.
Return values and error codes
On success, readahead( ) returns 0. On failure, it returns -1, and errno is set to one of
the following values:
EBADF
The given file descriptor is invalid.
EINVAL
The given file descriptor does not map to a file that supports readahead.
Advice Is Cheap
A handful of common application workloads can readily benefit from a little well-
intentioned advice to the kernel. Such advice can go a long way toward mitigating
Synchronized, Synchronous, and Asynchronous Operations | 111
the burden of I/O. With hard disks being so slow, and modern processors being so
fast, every little bit helps, and good advice can go a long way.
Before reading a chunk of a file, a process can provide the POSIX_FADV_WILLNEED hint
to instruct the kernel to read the file into the page cache. The I/O will occur asyn-
chronously, in the background. When the application ultimately accesses the file, the
operation can complete without generating blocking I/O.
Conversely, after reading or writing a lot of data—say, while continuously streaming
video to disk—a process can provide the POSIX_FADV_DONTNEED hint to instruct the
kernel to evict the given chunk of the file from the page cache. A large streaming
operation can continually fill the page cache. If the application never intends to
access the data again, this means the page cache will be filled with superfluous data,
at the expense of potentially more useful data. Thus, it makes sense for a streaming
video application to periodically request that streamed data be evicted from the
cache.
A process that intends to read in an entire file can provide the POSIX_FADV_SEQUENTIAL
hint, instructing the kernel to perform aggressive readahead. Conversely, a process
that knows it is going to access a file randomly, seeking to and fro, can provide the
POSIX_FADV_RANDOM hint, instructing the kernel that readahead will be nothing but
worthless overhead.
Synchronized, Synchronous, and Asynchronous
Operations
Unix systems use the terms synchronized, nonsynchronized, synchronous, and asyn-
chronous freely, without much regard to the fact that they are confusing—in English,
the differences between “synchronous” and “synchronized” do not amount to much!
A synchronous write operation does not return until the written data is—at least—
stored in the kernel’s buffer cache. A synchronous read operation does not return
until the read data is stored in the user-space buffer provided by the application. On
the other side of the coin, an asynchronous write operation may return before the
data even leaves user space; an asynchronous read operation may return before the
read data is available. That is, the operations may only be queued for later. Of
course, in this case, some mechanism must exist for determining when the operation
has actually completed, and with what level of success.
A synchronized operation is more restrictive and safer than a merely synchronous
operation. A synchronized write operation flushes the data to disk, ensuring that the
on-disk data is always synchronized vis-à-vis the corresponding kernel buffers. A
synchronized read operation always returns the most up-to-date copy of the data,
presumably from the disk.
112 | Chapter 4: Advanced File I/O
In sum, the terms synchronous and asynchronous refer to whether I/O operations
wait for some event (e.g., storage of the data) before returning. The terms synchro-
nized and nonsynchronized, meanwhile, specify exactly what event must occur (e.g.,
writing the data to disk).
Normally, Unix write operations are synchronous and nonsynchronized; read opera-
tions are synchronous and synchronized.* For write operations, every combination of
these characteristics is possible, as Table 4-1 illustrates.
Read operations are always synchronized, as reading stale data makes little sense.
Such operations can be either synchronous or asynchronous, however, as illustrated
in Table 4-2.
In Chapter 2, we discussed how to make writes synchronized (via the O_SYNC flag),
and how to ensure that all I/O is synchronized as of a given point (via fsync( ) and
friends). Now, let’s look at what it takes to make reads and writes asynchronous.
Asynchronous I/O
Performing asynchronous I/O requires kernel support at the very lowest layers.
POSIX 1003.1-2003 defines the aio interfaces, which Linux fortunately implements.
The aio library provides a family of functions for submitting asynchronous I/O and
receiving notification upon its completion:
* Read operations are technically also nonsynchronized, like write operations, but the kernel ensures that the
page cache contains up-to-date data. That is, the page cache’s data is always identical to or newer than the
data on disk. In this manner, the behavior in practice is always synchronized. There is little argument for
behaving any other way.
Table 4-1. Synchronicity of write operations
Synchronized Nonsynchronized
Synchronous Write operations do not return until the data is flushed to disk.
This is the behavior if O_SYNC is specified during file open.
Write operations do not return until
the data is stored in kernel buffers. This
is the usual behavior.
Asynchronous Write operations return as soon as the request is queued. Once
the write operation ultimately executes, the data is guaranteed
to be on disk.
Write operations return as soon as the
request is queued. Once the write oper-
ation ultimately executes, the data is
guaranteed to at least be stored in
kernel buffers.
Table 4-2. Synchronicity of read operations
Synchronized
Synchronous Read operations do not return until the data, which is up-to-date, is stored in the provided buffer (this is the
usual behavior).
Asynchronous Read operations return as soon as the request is queued, but when the read operation ultimately executes,
the data returned is up-to-date.
Synchronized, Synchronous, and Asynchronous Operations | 113
#include <aio.h>
/* asynchronous I/O control block */
struct aiocb {
int aio_filedes; /* file descriptor */
int aio_lio_opcode; /* operation to perform */
int aio_reqprio; /* request priority offset */
volatile void *aio_buf; /* pointer to buffer */
size_t aio_nbytes; /* length of operation */
struct sigevent aio_sigevent; /* signal number and value */
/* internal, private members follow... */
};
int aio_read (struct aiocb *aiocbp);
int aio_write (struct aiocb *aiocbp);
int aio_error (const struct aiocb *aiocbp);
int aio_return (struct aiocb *aiocbp);
int aio_cancel (int fd, struct aiocb *aiocbp);
int aio_fsync (int op, struct aiocb *aiocbp);
int aio_suspend (const struct aiocb * const cblist[],
int n,
const struct timespec *timeout);
Thread-based asynchronous I/O
Linux only supports aio on files opened with the O_DIRECT flag. To perform asynchro-
nous I/O on regular files opened without O_DIRECT, we have to look inward, toward a
solution of our own. Without kernel support, we can only hope to approximate
asynchronous I/O, giving results similar to the real thing.
First, let’s look at why an application developer would want asynchronous I/O:
• To perform I/O without blocking
• To separate the acts of queuing I/O, submitting I/O to the kernel, and receiving
notification of operation completion
The first point is a matter of performance. If I/O operations never block, the over-
head of I/O reaches zero, and a process need not be I/O-bound. The second point is
a matter of procedure, simply a different method of handling I/O.
The most common way to reach these goals is with threads (scheduling matters are
discussed thoroughly in Chapters 5 and 6). This approach involves the following
programming tasks:
1. Create a pool of “worker threads” to handle all I/O.
2. Implement a set of interfaces for placing I/O operations onto a work queue.
3. Have each of these interfaces return an I/O descriptor uniquely identifying the
associated I/O operation. In each worker thread, grab I/O requests from the
head of the queue and submit them, waiting for their completion.
114 | Chapter 4: Advanced File I/O
4. Upon completion, place the results of the operation (return values, error codes,
any read data) onto a results queue.
5. Implement a set of interfaces for retrieving status information from the results
queue, using the originally returned I/O descriptors to identify each operation.
This provides similar behavior to POSIX’s aio interfaces, albeit with the greater over-
head of thread management.
I/O Schedulers and I/O Performance
In a modern system, the relative performance gap between disks and the rest of the
system is quite large—and widening. The worst component of disk performance is
the process of moving the read/write head from one part of the disk to another, an
operation known as a seek. In a world where many operations are measured in a
handful of processor cycles (which might take all of a third of a nanosecond each), a
single disk seek can average over eight milliseconds—still a small number, to be sure,
but 25 million times longer than a single processor cycle!
Given the disparity in performance between disk drives and the rest of the system, it
would be incredibly crude and inefficient to send I/O requests to the disk in the
order in which they are issued. Therefore, modern operating system kernels imple-
ment I/O schedulers, which work to minimize the number and size of disk seeks by
manipulating the order in which I/O requests are serviced, and the times at which
they are serviced. I/O schedulers work hard to lessen the performance penalties asso-
ciated with disk access.
Disk Addressing
To understand the role of an I/O scheduler, some background information is neces-
sary. Hard disks address their data using the familiar geometry-based addressing of
cylinders, heads, and sectors, or CHS addressing. A hard drive is composed of multi-
ple platters, each consisting of a single disk, spindle, and read/write head. You can
think of each platter as a CD (or record), and the set of platters in a disk as a stack of
CDs. Each platter is divided into circular ring-like tracks, like on a CD. Each track is
then divided up into of an integer number of sectors.
To locate a specific unit of data on a disk, the drive’s logic requires three pieces of
information: the cylinder, head, and sector values. The cylinder value specifies the
track on which the data resides. If you lay the platters on top of one another, a given
track forms a cylinder through each platter. In other words, a cylinder is represented
by a track at the same distance from the center on each disk. The head value identi-
fies the exact read/write head (and thus the exact platter) in question. The search is
now narrowed down to a single track on a single platter. The disk then uses the sec-
tor value to identify an exact sector on the track. The search is now complete: the
I/O Schedulers and I/O Performance | 115
hard disk knows what platter, what track, and what sector to look in for the data. It
can position the read/write head of the correct platter over the correct track, and
read from or write to the requisite sector.
Thankfully, modern hard disks do not force computers to communicate with their
disks in terms of cylinders, heads, and sectors. Instead, contemporary hard drives
map a unique block number (also called physical blocks or device blocks) over each
cylinder/head/sector triplet—effectively, a block maps to a specific sector. Modern
operating systems can then address hard drives using these block numbers—a
process known as logical block addressing (LBA)—and the hard drive internally trans-
lates the block number into the correct CHS address. * Although nothing guarantees
it, the block-to-CHS mapping tends to be sequential: physical block n tends to be
physically adjacent on disk to logical block n + 1. This sequential mapping is impor-
tant, as we shall soon see.
Filesystems, meanwhile, exist only in software. They operate on their own units,
known as logical blocks (sometimes called filesystem blocks, or, confusingly, just
blocks). The logical block size must be an integer multiple of the physical block size.
In other words, a filesystem’s logical blocks map to one or more of a disk’s physical
blocks.
The Life of an I/O Scheduler
I/O schedulers perform two basic operations: merging and sorting. Merging is the
process of taking two or more adjacent I/O requests, and combining them into a sin-
gle request. Consider two requests, one to read from disk block 5, and another to
read from disk blocks 6 through 7. These requests can be merged into a single
request to read from disk blocks 5 through 7. The total amount of I/O might be the
same, but the number of I/O operations is reduced by half.
Sorting, the more important of the two operations, is the process of arranging pend-
ing I/O requests in ascending block order. For example, given I/O operations to
blocks 52, 109, and 7, the I/O scheduler would sort these requests into the ordering
7, 52, and 109. If a request was then issued to block 81, it would be inserted between
the requests to blocks 52 and 109. The I/O scheduler would then dispatch the
requests to the disk in the order that they exist in the queue: 7, then 52, then 81, and
finally 109.
In this manner, the disk head’s movements are minimized. Instead of potentially
haphazard movements—here to there and back, seeking all over the disk—the disk
head moves in a smooth, linear fashion. Because seeks are the most expensive part of
disk I/O, performance is improved.
* Limits on the absolute size of this block number are largely responsible for the various limits on total drive
sizes over the years.
116 | Chapter 4: Advanced File I/O
Helping Out Reads
Each read request must return up-to-date data. Thus, if the requested data is not in
the page cache, the reading process must block until the data can be read from
disk—a potentially lengthy operation. We call this performance impact read latency.
A typical application might initiate several read I/O requests in a short period.
Because each request is individually synchronized, the later requests are dependent on
the earlier ones’ completion. Consider reading every file in a directory. The applica-
tion opens the first file, reads a chunk of it, waits for data, reads another chunk, and
so on, until the entire file is read. Then the application starts again, on the next file.
The requests become serialized: a subsequent request cannot be issued until the cur-
rent request completes.
This is in stark contrast to write requests, which (in their default, nonsynchronized
state) need not initiate any disk I/O until some time in the future. Thus, from the
perspective of a user-space application, write requests stream, unencumbered by the
performance of the disk. This streaming behavior only compounds the problem for
reads: as writes stream, they can hog the kernel and disk’s attention. This phenome-
non is known as the writes-starving-reads problem.
If an I/O scheduler always sorted new requests by the order of insertion, it would be
possible to starve requests to far-off blocks indefinitely. Consider our previous exam-
ple. If new requests were continually issued to blocks in, say, the 50s, the request to
block 109 would never be serviced. Because read latency is critical, this behavior
would greatly hurt system performance. Thus, I/O schedulers employ a mechanism
to prevent starvation.
A simple approach—such as the one taken by the 2.4 Linux kernel’s I/O scheduler,
the Linus Elevator* —is to simply stop insertion-sorting if there is a sufficiently old
request in the queue. This trades overall performance for per-request fairness and, in
the case of reads, improves latency. The problem is that this heuristic is a bit too
simplistic. Recognizing this, the 2.6 Linux kernel witnessed the demise of the Linus
Elevator, and unveiled several new I/O schedulers in its place.
The Deadline I/O Scheduler
The Deadline I/O Scheduler was introduced to solve the problems with the 2.4 I/O
scheduler, and traditional elevator algorithms in general. The Linus Elevator main-
tains a sorted list of pending I/O requests. The I/O request at the head of the queue is
the next one to be serviced. The Deadline I/O Scheduler keeps this queue, but kicks
things up a notch by introducing two additional queues: the read FIFO queue, and the
write FIFO queue. The items in each of these queues are sorted by submission time
* Yes, the man has an I/O scheduler named after him. I/O schedulers are sometimes called elevator algorithms,
because they solve a problem similar to that of keeping an elevator running smoothly.
I/O Schedulers and I/O Performance | 117
(effectively, the first in is the first out). The read FIFO queue, as its name suggests,
contains only read requests. The write FIFO queue, likewise, contains only write
requests. Each request in the FIFO queues is assigned an expiration value. The read
FIFO queue has an expiration time of 500 milliseconds. The write FIFO queue has
an expiration time of five seconds.
When a new I/O request is submitted, it is insertion-sorted into the standard queue,
and placed at the tail of its respective (read or write) FIFO queue. Normally, the hard
drive is sent I/O requests from the head of the standard sorted queue. This maxi-
mizes global throughput by minimizing seeks, as the normal queue is sorted by block
number (as with the Linus Elevator).
When the item at the head of one of the FIFO queues grows older than the expiration
value associated with its queue, however, the I/O scheduler stops dispatching I/O
requests from the standard queue, and begins servicing requests from that queue—the
request at the head of the FIFO queue is serviced, plus a couple of extras for good
measure. The I/O scheduler needs to check and handle only the requests at the head
of the queue, as those are the oldest requests.
In this manner, the Deadline I/O Scheduler can enforce a soft deadline on I/O
requests. Although it makes no promise that an I/O request will be serviced before
its expiration time, the I/O scheduler generally services requests near their expira-
tion times. Thus, the Deadline I/O Scheduler continues to provide good global
throughput without starving any one request for an unacceptably long time. Because
read requests are given shorter expiration times, the writes-starving-reads problem is
minimized.
The Anticipatory I/O Scheduler
The Deadline I/O Scheduler’s behavior is good, but not perfect. Recall our discus-
sion on read dependency. With the Deadline I/O Scheduler, the first read request in a
series of reads is serviced in short order, at or before its expiration time, and the I/O
scheduler then returns to servicing I/O requests from the sorted queue—so far, so
good. But suppose the application then swoops in and hits us with another read
request? Eventually its expiration time will also approach, and the I/O scheduler will
submit it to the disk, which will seek over to promptly handle the request, then seek
back to continue handling requests from the sorted queue. This seeking back and
forth can continue for some time because many applications exhibit this behavior.
While latency is kept to a minimum, global throughput is not very good because the
read requests keep coming in, and the disk has to keep seeking back and forth to
handle them. Performance would be improved if the disk just took a break to wait
for another read, and did not move away to service the sorted queue again. But,
unfortunately, by the time the application is scheduled and submits its next depen-
dent read request, the I/O scheduler has already shifted gears.
118 | Chapter 4: Advanced File I/O
The problem again stems from those darn dependent reads—each new read request
is issued only when the previous one is returned, but by the time the application
receives the read data, is scheduled to run, and submits its next read request, the I/O
scheduler has moved on, and begun servicing other requests. This results in a wasted
pair of seeks for each read: the disk seeks to the read, services it, and then seeks
back. If only there was some way for the I/O scheduler to know—to anticipate—that
another read would soon be submitted to the same part of the disk, instead of seek-
ing back and forth, it could wait in anticipation of the next read. Saving those awful
seeks certainly would be worth a few milliseconds of waiting.
This is exactly how the Anticipatory I/O Scheduler operates. It began life as the
Deadline I/O Scheduler, but was gifted with the addition of an anticipation mecha-
nism. When a read request is submitted, the Anticipatory I/O Scheduler services it
within its deadline, as usual. Unlike the Deadline I/O Scheduler, however, the Antici-
patory I/O Scheduler then sits and waits, doing nothing, for up to six milliseconds.
Chances are good that the application will issue another read to the same part of the
filesystem during those six milliseconds. If so, that request is serviced immediately,
and the Anticipatory I/O Scheduler waits some more. If six milliseconds go by with-
out a read request, the Anticipatory I/O Scheduler decides it has guessed wrong, and
returns to whatever it was doing before (i.e., servicing the standard sorted queue). If
even a moderate number of requests are anticipated correctly, a great deal of time—
two expensive seeks’ worth at each go—is saved. Because most reads are dependent,
the anticipation pays off much of the time.
The CFQ I/O Scheduler
The Complete Fair Queuing (CFQ) I/O Scheduler works to achieve similar goals,
albeit via a different approach. * With CFQ, each process is assigned its own queue,
and each queue is assigned a timeslice. The I/O scheduler visits each queue in a
round-robin fashion, servicing requests from the queue until the queue’s timeslice is
exhausted, or until no more requests remain. In the latter case, the CFQ I/O Sched-
uler will then sit idle for a brief period—by default, 10 ms—waiting for a new
request on the queue. If the anticipation pays off, the I/O scheduler avoids seeking. If
not, the waiting was in vain, and the scheduler moves on to the next process’ queue.
Within each process’ queue, synchronized requests (such as reads) are given priority
over nonsynchronized requests. In this manner, CFQ favors reads and prevents the
writes-starving-reads problem. Because of the per-process queue setup, the CFQ I/O
Scheduler is fair to all processes, while still providing good global performance.
The CFQ I/O Scheduler is well suited to most workloads, and makes an excellent
first choice.
* The following text discusses the CFQ I/O Scheduler as it is currently implemented. Previous incarnations
did not use timeslices or the anticipation heuristic, but operated in a similar fashion.
I/O Schedulers and I/O Performance | 119
The Noop I/O Scheduler
The Noop I/O Scheduler is the most basic of the available schedulers. It performs no
sorting whatsoever, only basic merging. It is used for specialized devices that do not
require (or that perform) their own request sorting.
Selecting and Configuring Your I/O Scheduler
The default I/O scheduler is selectable at boot time via the iosched kernel command-
line parameter. Valid options are as, cfq, deadline, and noop. The I/O scheduler is also
runtime-selectable on a per-device basis via /sys/block/device/queue/scheduler, where
device is the block device in question. Reading this file returns the current I/O sched-
uler; writing one of the valid options to this file sets the I/O scheduler. For example,
to set the device hda to the CFQ I/O Scheduler, one would do the following:
# echo cfq > /sys/block/hda/queue/scheduler
The directory /sys/block/device/queue/iosched contains files that allow the adminis-
trator to retrieve and set tunable values related to the I/O scheduler. The exact
options depend on the current I/O scheduler. Changing any of these settings requires
root privileges.
A good programmer writes programs that are agnostic to the underlying I/O sub-
system. Nonetheless, knowledge of this subsystem can surely help one write optimal
code.
Optimizing I/O Performance
Because disk I/O is so slow relative to the performance of other components in the
system, yet I/O is such an important aspect of modern computing, maximizing I/O
performance is crucial.
Minimizing I/O operations (by coalescing many smaller operations into fewer larger
operations), performing block-size-aligned I/O, or using user buffering (see
Chapter 3), and taking advantage of advanced I/O techniques, such as vectored I/O,
positional I/O (see Chapter 2), and asynchronous I/O, are important steps to always
consider when system programming.
The most demanding mission-critical and I/O-intense applications, however, can
employ additional tricks to maximize performance. Although the Linux kernel, as
discussed previously, utilizes advanced I/O schedulers to minimize dreaded disk
seeks, user-space applications can work toward the same end, in a similar fashion, to
further improve performance.
120 | Chapter 4: Advanced File I/O
Scheduling I/O in user space
I/O-intensive applications that issue a large number of I/O requests and need to
extract every ounce of performance can sort and merge their pending I/O requests,
performing the same duties as the Linux I/O scheduler. *
Why perform the same work twice, if you know the I/O scheduler will sort requests
block-wise, minimizing seeks, and allowing the disk head to move in a smooth, lin-
ear fashion? Consider an application that submits a large number of unsorted I/O
requests. These requests arrive in the I/O scheduler’s queue in a generally random
order. The I/O scheduler does its job, sorting and merging the requests before send-
ing them out to the disk—but the requests start hitting the disk while the application
is still generating I/O and submitting requests. The I/O scheduler is able to sort only a
small set of requests—say, a handful from this application, and whatever other
requests are pending—at a time. Each batch of the application’s requests is neatly
sorted, but the full queue, and any future requests are not part of the equation.
Therefore, if an application is generating many requests—particularly if they are for
data all over the disk—it can benefit from sorting the requests before submitting
them, ensuring they reach the I/O scheduler in the desired order.
A user-space application is not bestowed with access to the same information as the
kernel, however. At the lowest levels inside the I/O scheduler, requests are already
specified in terms of physical disk blocks. Sorting them is trivial. But, in user space,
requests are specified in terms of files and offsets. User-space applications must
probe for information, and make educated guesses about the layout of the filesystem.
Given the goal of determining the most seek-friendly ordering given a list of I/O
requests to specific files, user-space applications have a couple of options. They can
sort based on:
• The full path
• The inode number
• The physical disk block of the file
Each of these options involves a tradeoff. Let’s look at each briefly.
Sorting by path. Sorting by the pathname is the easiest, yet least effective, way of approx-
imating a block-wise sort. Due to the layout algorithms used by most filesystems, the
files in each directory—and thus the directories sharing a parent directory—tend to be
adjacent on disk. The probability that files in the same directory were created around
the same time only amplifies this characteristic.
* One should apply the techniques discussed here only to I/O-intensive, mission-critical applications. Sorting
the I/O requests—assuming there is even anything to sort—of applications that do not issue many such
requests is silly and unneeded.
I/O Schedulers and I/O Performance | 121
Sorting by path, therefore, roughly approximates the physical locations of files on the
disk. It is definitely true that two files in the same directory have a better chance of
being located near each other than two files in radically different parts of the filesys-
tem. The downside of this approach is that it fails to take into account fragmentation:
the more fragmented the filesystem, the less useful is sorting by path. Even ignoring
fragmentation, a path-wise sort only approximates the actual block-wise ordering. On
the upside, a path-wise sort is at least somewhat applicable to all filesystems. No mat-
ter the approach to file layout, temporal locality suggests a path-wise sort will be at
least mildly accurate. It is also an easy sort to perform.
Sorting by inode. Inodes are Unix constructs that contain the metadata associated
with individual files. While a file’s data may consume multiple physical disk blocks,
each file has exactly one inode, which contains information such as the file’s size,
permissions, owner, and so on. We will discuss inodes in depth in Chapter 7. For
now, you need to know two facts: that every file has an inode associated with it, and
that the inodes are assigned unique numbers.
Sorting by inode is better than sorting by path, assuming that this relation:
file i's inode number < file j's inode number
implies, in general, that:
physical blocks of file i < physical blocks of file j
This is certainly true for Unix-style filesystems such as ext2 and ext3. Anything is
possible for filesystems that do not employ actual inodes, but the inode number
(whatever it may map to) is still a good first-order approximation.
Obtaining the inode number is done via the stat( ) system call, also discussed in
Chapter 7. Given the inode associated with the file involved in each I/O request, the
requests can be sorted in ascending order by inode number.
Here is a simple program that prints out the inode number of a given file:
#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
/*
* get_inode - returns the inode of the file associated
* with the given file descriptor, or -1 on failure
*/
int get_inode (int fd)
{
struct stat buf;
int ret;
ret = fstat (fd, &buf);
122 | Chapter 4: Advanced File I/O
if (ret < 0) {
perror ("fstat");
return -1;
}
return buf.st_ino;
}
int main (int argc, char *argv[])
{
int fd, inode;
if (argc < 2) {
fprintf (stderr, "usage: %s <file>\n", argv[0]);
return 1;
}
fd = open (argv[1], O_RDONLY);
if (fd < 0) {
perror ("open");
return 1;
}
inode = get_inode (fd);
printf ("%d\n", inode);
return 0;
}
The get_inode( ) function is easily adaptable for use in your programs.
Sorting by inode number has a few upsides: the inode number is easy to obtain, is
easy to sort on, and is a good approximation of the physical file layout. The major
downsides are that fragmentation degrades the approximation, that the approximation
is just a guess, and that the approximation is less accurate for non-Unix filesystems.
Nonetheless, this is the most commonly used method for scheduling I/O requests in
user space.
Sorting by physical block. The best approach to designing your own elevator algorithm,
of course, is to sort by physical disk block. As discussed earlier, each file is broken up
into logical blocks, which are the smallest allocation units of a filesystem. The size of
a logical block is filesystem-dependent; each logical block maps to a single physical
block. We can thus find the number of logical blocks in a file, determine what physi-
cal blocks they map to, and sort based on that.
The kernel provides a method for obtaining the physical disk block from the logical
block number of a file. This is done via the ioctl( ) system call, discussed in
Chapter 7, with the FIBMAP command:
ret = ioctl (fd, FIBMAP, &block);
if (ret < 0)
perror ("ioctl");
I/O Schedulers and I/O Performance | 123
Here, fd is the file descriptor of the file in question, and block is the logical block
whose physical block we want to determine. On successful return, block is replaced
with the physical block number. The logical blocks passed in are zero-indexed and
file-relative. That is, if a file is made up of eight logical blocks, valid values are 0
through 7.
Finding the logical-to-physical-block mapping is thus a two-step process. First, we
must determine the number of blocks in a given file. This is done via the stat( ) sys-
tem call. Second, for each logical block, we must issue an ioctl( ) request to find the
corresponding physical block.
Here is a sample program to do just that for a file passed in on the command line:
#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/ioctl.h>
#include <linux/fs.h>
/*
* get_block - for the file associated with the given fd, returns
* the physical block mapping to logical_block
*/
int get_block (int fd, int logical_block)
{
int ret;
ret = ioctl (fd, FIBMAP, &logical_block);
if (ret < 0) {
perror ("ioctl");
return -1;
}
return logical_block;
}
/*
* get_nr_blocks - returns the number of logical blocks
* consumed by the file associated with fd
*/
int get_nr_blocks (int fd)
{
struct stat buf;
int ret;
ret = fstat (fd, &buf);
if (ret < 0) {
perror ("fstat");
return -1;
}
124 | Chapter 4: Advanced File I/O
return buf.st_blocks;
}
/*
* print_blocks - for each logical block consumed by the file
* associated with fd, prints to standard out the tuple
* "(logical block, physical block)"
*/
void print_blocks (int fd)
{
int nr_blocks, i;
nr_blocks = get_nr_blocks (fd);
if (nr_blocks < 0) {
fprintf (stderr, "get_nr_blocks failed!\n");
return;
}
if (nr_blocks == 0) {
printf ("no allocated blocks\n");
return;
} else if (nr_blocks == 1)
printf ("1 block\n\n");
else
printf ("%d blocks\n\n", nr_blocks);
for (i = 0; i < nr_blocks; i++) {
int phys_block;
phys_block = get_block (fd, i);
if (phys_block < 0) {
fprintf (stderr, "get_block failed!\n");
return;
}
if (!phys_block)
continue;
printf ("(%u, %u) ", i, phys_block);
}
putchar ('\n');
}
int main (int argc, char *argv[])
{
int fd;
if (argc < 2) {
fprintf (stderr, "usage: %s <file>\n", argv[0]);
return 1;
}
fd = open (argv[1], O_RDONLY);
if (fd < 0) {
Conclusion | 125
perror ("open");
return 1;
}
print_blocks (fd);
return 0;
}
Because files tend to be contiguous, and it would be difficult (at best) to sort our I/O
requests on a per-logical-block basis, it makes sense to sort based on the location of
just the first logical block of a given file. Consequently, get_nr_blocks( ) is not
needed, and our applications can sort based on the return value from:
get_block (fd, 0);
The downside of FIBMAP is that it requires the CAP_SYS_RAWIO capability—effectively,
root privileges. Consequently, nonroot applications cannot make use of this
approach. Further, while the FIBMAP command is standardized, its actual implemen-
tation is left up to the filesystems. While common systems such as ext2 and ext3
support it, a more esoteric beast may not. The ioctl( ) call will return EINVAL if
FIBMAP is not supported.
Among the pros of this approach, however, is that it returns the actual physical disk
block at which a file resides, which is exactly what you want to sort on. Even if you
sort all I/O to a single file based on the location of just one block (the kernel’s I/O
scheduler sorts each individual request on a block-wise basis), this approach comes
very close to the optimal ordering. The root requirement, however, is a bit of a non-
starter for many.
Conclusion
Over the course of the last three chapters, we have touched on all aspects of file I/O
in Linux. In Chapter 2, we looked at the basics of Linux file I/O—really, the basis of
Unix programming—with system calls such as read( ), write( ), open( ), and close( ).
In Chapter 3, we discussed user-space buffering and the standard C library’s imple-
mentation thereof. In this chapter, we discussed various facets of advanced I/O, from
the more-powerful-but-more-complex I/O system calls to optimization techniques
and the dreaded performance-sucking disk seek.
In the next two chapters, we will look at process management: creating, destroying,
and managing processes. Onward!
126
Chapter 5CHAPTER 5
Process Management
As mentioned in Chapter 1, processes are the most fundamental abstraction in a
Unix system, after files. As object code in execution—active, alive, running pro-
grams—processes are more than just assembly language; they consist of data,
resources, state, and a virtualized computer.
In this chapter, we will look at the fundamentals of the process, from creation to ter-
mination. The basics have remained relatively unchanged since the earliest days of
Unix. It is here, in the subject of process management, that the longevity and for-
ward thinking of Unix’s original design shines brightest. Unix took an interesting
path, one seldom traveled, and separated the act of creating a new process from the
act of loading a new binary image. Although the two tasks are performed in tandem
most of the time, the division has allowed a great deal of freedom for experimenta-
tion and evolution for each of the tasks. This road less traveled has survived to this
day, and while most operating systems offer a single system call to start up a new
program, Unix requires two: a fork and an exec. But before we cover those system
calls, let’s look more closely at the process itself.
The Process ID
Each process is represented by a unique identifier, the process ID (frequently short-
ened to pid). The pid is guaranteed to be unique at any single point in time. That is,
while at time t0 there can be only one process with the pid 770 (if any process at all
exists with such a value), there is no guarantee that at time t1 a different process
won’t exist with pid 770. Essentially, however, most code presumes that the kernel
does not readily reissue process identifiers—an assumption that, as you will see
shortly, is fairly safe.
The idle process—the process that the kernel “runs” when there are no other runna-
ble processes—has the pid 0. The first process that the kernel executes after booting
the system, called the init process, has the pid 1. Normally, the init process on Linux
is the init program. We use the term “init” to refer to both the initial process that the
kernel runs, and the specific program used for that purpose.
The Process ID | 127
Unless the user explicitly tells the kernel what process to run (through the init kernel
command-line parameter), the kernel has to identify a suitable init process on its
own—a rare example where the kernel dictates policy. The Linux kernel tries four
executables, in the following order:
1. /sbin/init: The preferred and most likely location for the init process.
2. /etc/init: Another likely location for the init process.
3. /bin/init: A possible location for the init process.
4. /bin/sh: The location of the Bourne shell, which the kernel tries to run if it fails to
find an init process.
The first of these processes that exists is executed as the init process. If all four pro-
cesses fail to execute, the Linux kernel halts the system with a panic.
After the handoff from the kernel, the init process handles the remainder of the boot
process. Typically, this includes initializing the system, starting various services, and
launching a login program.
Process ID Allocation
By default, the kernel imposes a maximum process ID value of 32768. This is for
compatibility with older Unix systems, which used smaller 16-bit types for process
IDs. System administrators can set the value higher via /proc/sys/kernel/pid_max,
trading a larger pid space for reduced compatibility.
The kernel allocates process IDs to processes in a strictly linear fashion. If pid 17 is
the highest number currently allocated, pid 18 will be allocated next, even if the
process last assigned pid 17 is no longer running when the new process starts. The
kernel does not reuse process ID values until it wraps around from the top—that is,
earlier values will not be reused until the value in /proc/sys/kernel/pid_max is allo-
cated. Therefore, while Linux makes no guarantee of the uniqueness of process IDs
over a long period, its allocation behavior does provide at least short-term comfort in
the stability and uniqueness of pid values.
The Process Hierarchy
The process that spawns a new process is known as the parent; the new process is
known as the child. Every process is spawned from another process (except, of
course, the init process). Therefore, every child has a parent. This relationship is
recorded in each process’ parent process ID (ppid), which is the pid of the child’s
parent.
Each process is owned by a user and a group. This ownership is used to control
access rights to resources. To the kernel, users and groups are mere integer values.
Through the files /etc/passwd and /etc/group, these integers are mapped to the
human-readable names with which Unix users are familiar, such as the user root or the
128 | Chapter 5: Process Management
group wheel (generally speaking, the Linux kernel has no interest in human-readable
strings, and prefers to identify objects with integers). Each child process inherits its
parent’s user and group ownership.
Each process is also part of a process group, which simply expresses its relationship
to other processes, and must not be confused with the aforementioned user/group
concept. Children normally belong to the same process groups as their parents. In
addition, when a shell starts up a pipeline (e.g., when a user enters ls | less), all the
commands in the pipeline go into the same process group. The notion of a process
group makes it easy to send signals to or get information on an entire pipeline, as
well as all children of the processes in the pipeline. From the perspective of a user, a
process group is closely related to a job.
pid_t
Programmatically, the process ID is represented by the pid_t type, which is defined
in the header file <sys/types.h>. The exact backing C type is architecture-specific,
and not defined by any C standard. On Linux, however, pid_t is generally a typedef
to the C int type.
Obtaining the Process ID and Parent Process ID
The getpid( ) system call returns the process ID of the invoking process:
#include <sys/types.h>
#include <unistd.h>
pid_t getpid (void);
The getppid( ) system call returns the process ID of the invoking process’ parent:
#include <sys/types.h>
#include <unistd.h>
pid_t getppid (void);
Neither call will return an error. Consequently, usage is trivial:
printf ("My pid=%d\n", getpid ( ));
printf ("Parent's pid=%d\n", getppid ( ));
How do we know that a pid_t is a signed integer? Good question! The answer, sim-
ply, is that we do not know. Even though we can safely assume that pid_t is an int
on Linux, such a guess still defeats the intention of the abstract type, and hurts port-
ability. Unfortunately, as with all typedefs in C, there is no easy way to print pid_t
values—this is part of the abstraction, and technically we need a pid_to_int( ) func-
tion, which we lack. Treating these values as integers, however, at least for the
purposes of printf( ), is common.
Running a New Process | 129
Running a New Process
In Unix, the act of loading into memory and executing a program image is separate
from the act of creating a new process. One system call (actually, one call from a
family of calls) loads a binary program into memory, replacing the previous contents
of the address space, and begins execution of the new program. This is called execut-
ing a new program, and the functionality is provided by the exec family of calls.
A different system call is used to create a new process, which initially is a near dupli-
cate of its parent process. Often, the new process immediately executes a new
program. The act of creating a new process is called forking, and this functionality is
provided by the fork( ) system call. Two acts—first a fork, to create a new process,
and then an exec, to load a new image into that process—are thus required to exe-
cute a new program image in a new process. We will cover the exec calls first, then
fork( ).
The Exec Family of Calls
There is no single exec function; instead, there is a family of exec functions built on a
single system call. Let’s first look at the simplest of these calls, execl( ):
#include <unistd.h>
int execl (const char *path,
const char *arg,
...);
A call to execl( ) replaces the current process image with a new one by loading into
memory the program pointed at by path. The parameter arg is the first argument to
this program. The ellipsis signifies a variable number of arguments—the execl( )
function is variadic, which means that additional arguments may optionally follow,
one by one. The list of arguments must be NULL-terminated.
For example, the following code replaces the currently executing program with /bin/vi:
int ret;
ret = execl ("/bin/vi", "vi", NULL);
if (ret == -1)
perror ("execl");
Note that we follow the Unix convention and pass “vi” as the program’s first argu-
ment. The shell puts the last component of the path, the “vi,” into the first argument
when it forks/execs processes, so a program can examine its first argument, argv[0],
to discover the name of its binary image. In many cases, several system utilities that
appear as different names to the user are in fact a single program with hard links for
their multiple names. The program uses the first argument to determine its behavior.
130 | Chapter 5: Process Management
As another example, if you wanted to edit the file /home/kidd/hooks.txt, you could
execute the following code:
int ret;
ret = execl ("/bin/vi", "vi", "/home/kidd/hooks.txt", NULL);
if (ret == -1)
perror ("execl");
Normally, execl( ) does not return. A successful invocation ends by jumping to the
entry point of the new program, and the just-executed code no longer exists in the
process’ address space. On error, however, execl( ) returns -1, and sets errno to indi-
cate the problem. We will look at the possible errno values later in this section.
A successful exec1( ) call changes not only the address space and process image, but
certain other attributes of the process:
• Any pending signals are lost.
• Any signals that the process is catching (see Chapter 9) are returned to their
default behavior, as the signal handlers no longer exist in the process’ address
space.
• Any memory locks (see Chapter 8) are dropped.
• Most thread attributes are returned to the default values.
• Most process statistics are reset.
• Anything related to the process’ memory, including any mapped files, is
dropped.
• Anything that exists solely in user space, including features of the C library, such
as atexit( ) behavior, is dropped.
Many properties of the process, however, do not change. For example, the pid, par-
ent pid, priority, and owning user and group all remain the same.
Normally, open files are inherited across an exec. This means the newly executed
program has full access to all of the files open in the original process, assuming it
knows the file descriptor values. However, this is often not the desired behavior. The
usual practice is to close files before the exec, although it is also possible to instruct
the kernel to do so automatically via fcntl( ).
The rest of the family
In addition to execl( ), there are five other members of the exec family:
#include <unistd.h>
int execlp (const char *file,
const char *arg,
...);
Running a New Process | 131
int execle (const char *path,
const char *arg,
...,
char * const envp[]);
int execv (const char *path, char *const argv[]);
int execvp (const char *file, char *const argv[]);
int execve (const char *filename,
char *const argv[],
char *const envp[]);
The mnemonics are simple. The l and v delineate whether the arguments are provided
via a list or an array (vector). The p denotes that the user’s full path is searched for the
given file. Commands using the p variants can specify just a filename, so long as it is
located in the user’s path. Finally, the e notes that a new environment is also supplied
for the new process. Curiously, although there is no technical reason for the omission,
the exec family contains no member that both searches the path and takes a new envi-
ronment. This is probably because the p variants were implemented for use by shells,
and shell-executed processes generally inherit their environments from the shell.
The members of the exec family that accept an array work about the same, except
that an array is constructed and passed in instead of a list. The use of an array allows
the arguments to be determined at runtime. Like the variadic list of arguments, the
array must be NULL-terminated.
The following snippet uses execvp( ) to execute vi, as we did previously:
const char *args[] = { "vi", "/home/kidd/hooks.txt", NULL };
int ret;
ret = execvp ("vi", args);
if (ret == -1)
perror ("execvp");
Assuming /bin is in the user’s path, this works similarly to the last example.
In Linux, only one member of the exec family is a system call. The rest are wrappers
in the C library around the system call. Because variadic system calls would be diffi-
cult to implement, at best, and because the concept of the user’s path exists solely in
user space, the only option for the lone system call is execve( ). The system call pro-
totype is identical to the user call.
Error values
On success, the exec system calls do not return. On failure, the calls return -1, and
set errno to one of the following values:
E2BIG
The total number of bytes in the provided arguments list (arg) or environment
(envp) is too large.
132 | Chapter 5: Process Management
EACCESS
The process lacks search permission for a component in path; path is not a regu-
lar file; the target file is not marked executable; or the filesystem on which path
or file resides is mounted noexec.
EFAULT
A given pointer is invalid.
EIO
A low-level I/O error occurred (this is bad).
EISDIR
The final component in path, or the interpreter, is a directory.
ELOOP
The system encountered too many symbolic links in resolving path.
EMFILE
The invoking process has reached its limit on open files.
ENFILE
The system-wide limit on open files has been reached.
ENOENT
The target of path or file does not exist, or a needed shared library does not
exist.
ENOEXEC
The target of path or file is an invalid binary, or is intended for a different
machine architecture.
ENOMEM
There is insufficient kernel memory available to execute a new program.
ENOTDIR
A nonfinal component in path is not a directory.
EPERM
The filesystem on which path or file resides is mounted nosuid, the user is not
root, and path or file has the suid or sgid bit set.
ETXTBSY
The target of path or file is open for writing by another process.
The fork( ) System Call
A new process running the same image as the current one can be created via the
fork( ) system call:
#include <sys/types.h>
#include <unistd.h>
pid_t fork (void);
Running a New Process | 133
A successful call to fork( ) creates a new process, identical in almost all aspects to
the invoking process. Both processes continue to run, returning from fork( ) as if
nothing special had happened.
The new process is called the “child” of the original process, which in turn is called
the “parent.” In the child, a successful invocation of fork( ) returns 0. In the parent,
fork( ) returns the pid of the child. The child and the parent process are identical in
nearly every facet, except for a few necessary differences:
• The pid of the child is, of course, newly allocated, and different from that of the
parent.
• The child’s parent pid is set to the pid of its parent process.
• Resource statistics are reset to zero in the child.
• Any pending signals are cleared, and not inherited by the child (see Chapter 9).
• Any acquired file locks are not inherited by the child.
On error, a child process is not created, fork( ) returns -1, and errno is set appropri-
ately. There are two possible errno values, with three possible meanings:
EAGAIN
The kernel failed to allocate certain resources, such as a new pid, or the
RLIMIT_NPROC resource limit (rlimit) has been reached (see Chapter 6).
ENOMEM
Insufficient kernel memory was available to complete the request.
Use is simple:
pid_t pid;
pid = fork ( );
if (pid > 0)
printf ("I am the parent of pid=%d!\n", pid);
else if (!pid)
printf ("I am the baby!\n");
else if (pid == -1)
perror ("fork");
The most common usage of fork( ) is to create a new process in which a new binary
image is then loaded—think a shell running a new program for the user or a process
spawning a helper program. First the process forks a new process, and then the child
executes a new binary image. This “fork plus exec” combination is frequent and sim-
ple. The following example spawns a new process running the binary /bin/windlass:
pid_t pid;
pid = fork ( );
if (pid == -1)
perror ("fork");
/* the child ... */
134 | Chapter 5: Process Management
if (!pid) {
const char *args[] = { "windlass", NULL };
int ret;
ret = execv ("/bin/windlass", args);
if (ret == -1) {
perror ("execv");
exit (EXIT_FAILURE);
}
}
The parent process continues running with no change, other than that it now has a
new child. The call to execv( ) changes the child to running the /bin/windlass program.
Copy-on-write
In early Unix systems, forking was simple, if not naïve. Upon invocation, the kernel
created copies of all internal data structures, duplicated the process’ page table
entries, and then performed a page-by-page copy of the parent’s address space into
the child’s new address space. But this page-by-page copy was, at least from the
standpoint of the kernel, time-consuming.
Modern Unix systems behave more optimally. Instead of a wholesale copy of the par-
ent’s address space, modern Unix systems such as Linux employ copy-on-write
(COW) pages.
Copy-on-write is a lazy optimization strategy designed to mitigate the overhead of
duplicating resources. The premise is simple: if multiple consumers request read
access to their own copies of a resource, duplicate copies of the resource need not be
made. Instead, each consumer can be handed a pointer to the same resource. So long
as no consumer attempts to modify its “copy” of the resource, the illusion of exclu-
sive access to the resource remains, and the overhead of a copy is avoided. If a
consumer does attempt to modify its copy of the resource, at that point, the resource
is transparently duplicated, and the copy is given to the modifying consumer. The
consumer, never the wiser, can then modify its copy of the resource while the other
consumers continue to share the original, unchanged version. Hence the name: the
copy occurs only on write.
The primary benefit is that if a consumer never modifies its copy of the resource, a
copy is never needed. The general advantage of lazy algorithms—that they defer
expensive actions until the last possible moment—also applies.
In the specific example of virtual memory, copy-on-write is implemented on a per-
page basis. Thus, so long as a process does not modify all of its address space, a copy
of the entire address space is not required. At the completion of a fork, the parent
and child believe that they each have a unique address space, while in fact they are
sharing the parent’s original pages—which in turn may be shared with other parent
or child processes, and so on!
Running a New Process | 135
The kernel implementation is simple. The pages are marked as read-only and as
copy-on-write in the kernel’s page-related data structures. If either process attempts
to modify a page, a page fault occurs. The kernel then handles the page fault by
transparently making a copy of the page; at this point, the page’s copy-on-write
attribute is cleared, and it is no longer shared.
Because modern machine architectures provide hardware-level support for copy-
on-write in their memory management units (MMUs), the charade is simple and
easy to implement.
Copy-on-write has yet a bigger benefit in the case of forking. Because a large percent-
age of forks are followed by an exec, copying the parent’s address space into the
child’s address space is often a complete waste of time: if the child summarily exe-
cutes a new binary image, its previous address space is wiped out. Copy-on-write
optimizes for this case.
vfork( )
Before the arrival of copy-on-write pages, Unix designers were concerned with the
wasteful address-space copy during a fork that is immediately followed by an exec.
BSD developers therefore unveiled the vfork( ) system call in 3.0BSD:
#include <sys/types.h>
#include <unistd.h>
pid_t vfork (void);
A successful invocation of vfork( ) has the same behavior as fork( ), except that the
child process must immediately issue a successful call to one of the exec functions, or
exit by calling _exit( ) (discussed in the next section). The vfork( ) system call
avoids the address space and page table copies by suspending the parent process
until the child terminates or executes a new binary image. In the interim, the parent
and the child share—without copy-on-write semantics—their address space and
page table entries. In fact, the only work done during a vfork( ) is the duplication of
internal kernel data structures. Consequently, the child must not modify any mem-
ory in the address space.
The vfork( ) system call is a relic, and should never have been implemented on
Linux, although it should be noted that even with copy-on-write, vfork( ) is faster
than fork( ) because the page table entries need not be copied.* Nonetheless, the
advent of copy-on-write pages weakens any argument for an alternative to fork( ).
Indeed, until the 2.2.0 Linux kernel, vfork( ) was simply a wrapper around fork( ).
As the requirements for vfork( ) are weaker than the requirements for fork( ), such a
vfork( ) implementation is feasible.
* Although not currently part of the 2.6 Linux kernel, a patch implementing copy-on-write shared page table
entries has been floated on the Linux Kernel Mailing List (lkml). Should it be merged, there would be abso-
lutely no benefit to using vfork( ).
136 | Chapter 5: Process Management
Strictly speaking, no vfork( ) implementation is bug-free: consider the situation if the
exec call were to fail! The parent would be suspended indefinitely while the child fig-
ured out what to do or until it exited.
Terminating a Process
POSIX and C89 both define a standard function for terminating the current process:
#include <stdlib.h>
void exit (int status);
A call to exit( ) performs some basic shutdown steps, and then instructs the kernel
to terminate the process. This function has no way of returning an error—in fact, it
never returns at all. Therefore, it does not make sense for any instructions to follow
the exit( ) call.
The status parameter is used to denote the process’ exit status. Other programs—as
well as the user at the shell—can check this value. Specifically, status & 0377 is
returned to the parent. We will look at retrieving the return value later in this chapter.
EXIT_SUCCESS and EXIT_FAILURE are defined as portable ways to represent success and
failure. On Linux, 0 typically represents success; a nonzero value, such as 1 or -1,
corresponds to failure.
Consequently, a successful exit is as simple as this one-liner:
exit (EXIT_SUCCESS);
Before terminating the process, the C library performs the following shutdown steps,
in order:
1. Call any functions registered with atexit( ) or on_exit( ), in the reverse order of
their registration. (We will discuss these functions later in this chapter.)
2. Flush all open standard I/O streams (see Chapter 3).
3. Remove any temporary files created with the tmpfile( ) function.
These steps finish all the work the process needs to do in user space, so exit( )
invokes the system call _exit( ) to let the kernel handle the rest of the termination
process:
#include <unistd.h>
void _exit (int status);
When a process exits, the kernel cleans up all of the resources that it created on the
process’ behalf that are no longer in use. This includes, but is not limited to, allo-
cated memory, open files, and System V semaphores. After cleanup, the kernel
destroys the process and notifies the parent of its child’s demise.
Terminating a Process | 137
Applications can call _exit( ) directly, but such a move seldom makes sense: most
applications need to do some of the cleanup provided by a full exit, such as flushing
the stdout stream. Note, however, that vfork( ) users should call _exit( ), and not
exit( ), after a fork.
In a brilliant stroke of redundancy, the ISO C99 standard added the
_Exit( ) function, which has identical behavior to _exit( ):
#include <stdlib.h>
void _Exit (int status);
Other Ways to Terminate
The classic way to end a program is not via an explicit system call, but by simply
“falling off the end” of the program. In the case of C, this happens when the main( )
function returns. The “falling off the end” approach, however, still invokes a system
call: the compiler simply inserts an implicit _exit( ) after its own shutdown code. It
is good coding practice to explicitly return an exit status, either via exit( ), or by
returning a value from main( ). The shell uses the exit value for evaluating the suc-
cess or failure of commands. Note that a successful return is exit(0), or a return
from main( ) of 0.
A process can also terminate if it is sent a signal whose default action is to terminate
the process. Such signals include SIGTERM and SIGKILL (see Chapter 9).
A final way to end a program’s execution is by incurring the wrath of the kernel. The
kernel can kill a process for executing an illegal instruction, causing a segmentation
violation, running out of memory, and so on.
atexit( )
POSIX 1003.1-2001 defines, and Linux implements, the atexit( ) library call, used
to register functions to be invoked on process termination:
#include <stdlib.h>
int atexit (void (*function)(void));
A successful invocation of atexit( ) registers the given function to run during nor-
mal process termination; i.e., when a process is terminated via either exit( ) or a
return from main( ). If a process invokes an exec function, the list of registered func-
tions is cleared (as the functions no longer exist in the new process’ address space). If
a process terminates via a signal, the registered functions are not called.
The given function takes no parameters, and returns no value. A prototype has the
form:
void my_function (void);
138 | Chapter 5: Process Management
Functions are invoked in the reverse order that they are registered. That is, the func-
tions are stored in a stack, and the last in is the first out (LIFO). Registered functions
must not call exit( ), lest they begin an endless recursion. If a function needs to end
the termination process early, it should call _exit( ). Such behavior is not recom-
mended, however, as a possibly important function may then not run.
The POSIX standard requires that atexit( ) support at least ATEXIT_MAX registered
functions, and that this value has to be at least 32. The exact maximum may be
obtained via sysconf( ) and the value of _SC_ATEXIT_MAX:
long atexit_max;
atexit_max = sysconf (_SC_ATEXIT_MAX);
printf ("atexit_max=%ld\n", atexit_max);
On success, atexit( ) returns 0. On error, it returns -1.
Here’s a simple example:
#include <stdio.h>
#include <stdlib.h>
void out (void)
{
printf ("atexit( ) succeeded!\n");
}
int main (void)
{
if (atexit (out))
fprintf(stderr, "atexit( ) failed!\n");
return 0;
}
on_exit( )
SunOS 4 defined its own equivalent to atexit( ), and Linux’s glibc supports it:
#include <stdlib.h>
int on_exit (void (*function)(int , void *), void *arg);
This function works the same as atexit( ), but the registered function’s prototype is
different:
void my_function (int status, void *arg);
The status argument is the value passed to exit( ) or returned from main( ). The arg
argument is the second parameter passed to on_exit( ). Care must be taken to ensure
that the memory pointed at by arg is valid when the function is ultimately invoked.
The latest version of Solaris no longer supports this function. You should use the
standards-compliant atexit( ) instead.
Waiting for Terminated Child Processes | 139
SIGCHLD
When a process terminates, the kernel sends the signal SIGCHLD to the parent. By
default, this signal is ignored, and no action is taken by the parent. Processes can
elect to handle this signal, however, via the signal( ) or sigaction( ) system calls.
These calls, and the rest of the wonderful world of signals, are covered in Chapter 9.
The SIGCHLD signal may be generated and dispatched at any time, as a child’s termi-
nation is asynchronous with respect to its parent. But often, the parent wants to
learn more about its child’s termination, or even explicitly wait for the event’s occur-
rence. This is possible with the system calls discussed next.
Waiting for Terminated Child Processes
Receiving notification via a signal is nice, but many parents want to obtain more
information when one of their child processes terminates—for example, the child’s
return value.
If a child process were to entirely disappear when terminated, as one might expect,
no remnants would remain for the parent to investigate. Consequently, the original
designers of Unix decided that when a child dies before its parent, the kernel should
put the child into a special process state. A process in this state is known as a zom-
bie. Only a minimal skeleton of what was once the process—some basic kernel data
structures containing potentially useful data—is retained. A process in this state
waits for its parent to inquire about its status (a procedure known as waiting on the
zombie process). Only after the parent obtains the information preserved about the
terminated child does the process formally exit and cease to exist even as a zombie.
The Linux kernel provides several interfaces for obtaining information about termi-
nated children. The simplest such interface, defined by POSIX, is wait( ):
#include <sys/types.h>
#include <sys/wait.h>
pid_t wait (int *status);
A call to wait( ) returns the pid of a terminated child, or -1 on error. If no child has
terminated, the call blocks until a child terminates. If a child has already terminated,
the call returns immediately. Consequently, a call to wait( ) in response to news of a
child’s demise—say, upon receipt of a SIGCHLD—will always return without blocking.
On error, there are two possible errno values:
ECHILD
The calling process does not have any children.
EINTR
A signal was received while waiting, and the call returned early.
140 | Chapter 5: Process Management
If not NULL, the status pointer contains additional information about the child.
Because POSIX allows implementations to define the bits in status as they see fit, the
standard provides a family of macros for interpreting the parameter:
#include <sys/wait.h>
int WIFEXITED (status);
int WIFSIGNALED (status);
int WIFSTOPPED (status);
int WIFCONTINUED (status);
int WEXITSTATUS (status);
int WTERMSIG (status);
int WSTOPSIG (status);
int WCOREDUMP (status);
Either of the first two macros may return true (a nonzero value), depending on how
the process terminated. The first, WIFEXITED, returns true if the process terminated
normally—that is, if the process called _exit( ). In this case, the macro WEXITSTATUS
provides the low-order eight bits that were passed to _exit( ).
WIFSIGNALED returns true if a signal caused the process’ termination (see Chapter 9 for
further discussion on signals). In this case, WTERMSIG returns the number of the signal
that caused the termination, and WCOREDUMP returns true if the process dumped core
in response to receipt of the signal. WCOREDUMP is not defined by POSIX, although
many Unix systems, Linux included, support it.
WIFSTOPPED and WIFCONTINUED return true if the process was stopped or continued,
respectively, and is currently being traced via the ptrace( ) system call. These condi-
tions are generally applicable only when implementing a debugger, although when
used with waitpid( ) (see the following subsection), they are used to implement job
control, too. Normally, wait( ) is used only to communicate information about a
process’ termination. If WIFSTOPPED is true, WSTOPSIG provides the number of the sig-
nal that stopped the process. WIFCONTINUED is not defined by POSIX, although future
standards define it for waitpid( ). As of the 2.6.10 Linux kernel, Linux provides this
macro for wait( ), too.
Let’s look at an example program that uses wait( ) to figure out what happened to its
child:
#include <unistd.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/wait.h>
int main (void)
{
int status;
pid_t pid;
if (!fork ( ))
return 1;
Waiting for Terminated Child Processes | 141
pid = wait (&status);
if (pid == -1)
perror ("wait");
printf ("pid=%d\n", pid);
if (WIFEXITED (status))
printf ("Normal termination with exit status=%d\n",
WEXITSTATUS (status));
if (WIFSIGNALED (status))
printf ("Killed by signal=%d%s\n",
WTERMSIG (status),
WCOREDUMP (status) ? " (dumped core)" : "");
if (WIFSTOPPED (status))
printf ("Stopped by signal=%d\n",
WSTOPSIG (status));
if (WIFCONTINUED (status))
printf ("Continued\n");
return 0;
}
This program forks a child, which immediately exits. The parent process then exe-
cutes the wait( ) system call to determine the status of its child. The process prints
the child’s pid, and how it died. Because in this case the child terminated by return-
ing from main( ), we know that we will see output similar to the following:
$ ./wait
pid=8529
Normal termination with exit status=1
If, instead of having the child return, we have it call abort( ), * which sends itself the
SIGABRT signal, we will instead see something resembling the following:
$ ./wait
pid=8678
Killed by signal=6
Waiting for a Specific Process
Observing the behavior of child processes is important. Often, however, a process
has multiple children, and does not wish to wait for all of them, but rather for a spe-
cific child process. One solution would be to make multiple invocations of wait( ),
each time noting the return value. This is cumbersome, though—what if you later
wanted to check the status of a different terminated process? The parent would have
to save all of the wait( ) output, in case it needed it later.
* Defined in the header <stdlib.h>.
142 | Chapter 5: Process Management
If you know the pid of the process you want to wait for, you can use the waitpid( )
system call:
#include <sys/types.h>
#include <sys/wait.h>
pid_t waitpid (pid_t pid, int *status, int options);
The waitpid( ) call is a more powerful version of wait( ). Its additional parameters
allow for fine-tuning.
The pid parameter specifies exactly which process or processes to wait for. Its values
fall into four camps:
< -1
Wait for any child process whose process group ID is equal to the absolute value of
this value. For example, passing -500 waits for any process in process group 500.
-1
Wait for any child process. This is the same behavior as wait( ).
0
Wait for any child process that belongs to the same process group as the calling
process.
> 0
Wait for any child process whose pid is exactly the value provided. For exam-
ple, passing 500 waits for the child process with pid 500.
The status parameter works identically to the sole parameter to wait( ), and can be
operated on using the macros discussed previously.
The options parameter is a binary OR of zero or more of the following options:
WNOHANG
Do not block, but return immediately if no matching child process has already
terminated (or stopped or continued).
WUNTRACED
If set, WIFSTOPPED is set, even if the calling process is not tracing the child pro-
cess. This flag allows for the implementation of more general job control, as in a
shell.
WCONTINUED
If set, WIFCONTINUED is set even if the calling process is not tracing the child pro-
cess. As with WUNTRACED, this flag is useful for implementing a shell.
On success, waitpid( ) returns the pid of the process whose state has changed. If
WNOHANG is specified, and the specified child or children have not yet changed state,
waitpid( ) returns 0. On error, the call returns -1, and errno is set to one of three values:
Waiting for Terminated Child Processes | 143
ECHILD
The process or processes specified by the pid argument do not exist, or are not
children of the calling process.
EINTR
The WNOHANG option was not specified, and a signal was received while waiting.
EINVAL
The options argument is invalid.
As an example, assume your program wants to grab the return value of the specific
child with pid 1742 but return immediately if the child has not yet terminated. You
might code up something similar to the following:
int status;
pid_t pid;
pid = waitpid (1742, &status, WNOHANG);
if (pid == -1)
perror ("waitpid");
else {
printf ("pid=%d\n", pid);
if (WIFEXITED (status))
printf ("Normal termination with exit status=%d\n",
WEXITSTATUS (status));
if (WIFSIGNALED (status))
printf ("Killed by signal=%d%s\n",
WTERMSIG (status),
WCOREDUMP (status) ? " (dumped core)" : "");
}
As a final example, note that the following usage of wait( ):
wait (&status);
is identical to the following usage of waitpid( ):
waitpid (-1, &status, 0);
Even More Waiting Versatility
For applications that require even greater versatility in their waiting-for-children
functionality, the XSI extension to POSIX defines, and Linux provides, waitid( ):
#include <sys/wait.h>
int waitid (idtype_t idtype,
id_t id,
siginfo_t *infop,
int options);
144 | Chapter 5: Process Management
As with wait( ) and waitpid( ), waitid( ) is used to wait for and obtain information
about the status change (termination, stopping, continuing) of a child process. It pro-
vides even more options, but it offers them with the tradeoff of greater complexity.
Like waitpid( ), waitid( ) allows the developer to specify what to wait for. However,
waitid( ) accomplishes this task with not one, but two parameters. The idtype and
id arguments specify which children to wait for, accomplishing the same goal as the
sole pid argument in waitpid( ). idtype may be one of the following values:
P_PID
Wait for a child whose pid matches id.
P_GID
Wait for a child whose process group ID matches id.
P_ALL
Wait for any child; id is ignored.
The id argument is the rarely seen id_t type, which is a type representing a generic
identification number. It is employed in case future implementations add a new
idtype value, and supposedly offers greater insurance that the predefined type will be
able to hold the newly created identifier. The type is guaranteed to be sufficiently
large to hold any pid_t. On Linux, developers may use it as if it were a pid_t—for
example, by directly passing pid_t values, or numeric constants. Pedantic program-
mers, however, are free to typecast.
The options parameter is a binary OR of one or more of the following values:
WEXITED
The call will wait for children (as determined by id and idtype) that have
terminated.
WSTOPPED
The call will wait for children that have stopped execution in response to receipt
of a signal.
WCONTINUED
The call will wait for children that have continued execution in response to
receipt of a signal.
WNOHANG
The call will never block, but will return immediately if no matching child pro-
cess has already terminated (or stopped, or continued).
WNOWAIT
The call will not remove the matching process from the zombie state. The pro-
cess may be waited upon in the future.
Upon successfully waiting for a child, waitid( ) fills in the infop parameter, which
must point to a valid siginfo_t type. The exact layout of the siginfo_t structure is
Waiting for Terminated Child Processes | 145
implementation-specific, * but a handful of fields are valid after a call to waitid( ).
That is, a successful invocation will ensure that the following fields are filled in:
si_pid
The child’s pid.
si_uid
The child’s uid.
si_code
Set to one of CLD_EXITED, CLD_KILLED, CLD_STOPPED, or CLD_CONTINUED in response
to the child terminating, dying via signal, stopping via signal, or continuing via
signal, respectively.
si_signo
Set to SIGCHLD.
si_status
If si_code is CLD_EXITED, this field is the exit code of the child process. Other-
wise, this field is the number of the signal delivered to the child that caused the
state change.
On success, waitid( ) returns 0. On error, waitid( ) returns -1, and errno is set to one
of the following values:
ECHLD
The process or processes delineated by id and idtype do not exist.
EINTR
WNOHANG was not set in options, and a signal interrupted execution.
EINVAL
The options argument or the combination of the id and idtype arguments is
invalid.
The waitid( ) function provides additional, useful semantics not found in wait( ) and
waitpid( ). In particular, the information retrievable from the siginfo_t structure
may prove quite valuable. If such information is not needed, however, it may make
more sense to stick to the simpler functions, which are supported on a wider range of
systems, and thus are portable to more non-Linux systems.
BSD Wants to Play: wait3( ) and wait4( )
While waitpid( ) derives from AT&T’s System V Release 4, BSD takes its own route,
and provides two other functions used to wait for a child to change state:
#include <sys/types.h>
#include <sys/time.h>
* Indeed, the siginfo_t structure is very complicated on Linux. For its definition, see /usr/include/bits/siginfo.h.
We will study this structure in more detail in Chapter 9.
146 | Chapter 5: Process Management
#include <sys/resource.h>
#include <sys/wait.h>
pid_t wait3 (int *status,
int options,
struct rusage *rusage);
pid_t wait4 (pid_t pid,
int *status,
int options,
struct rusage *rusage);
The 3 and 4 come from the fact that these two functions are three- and four-parameter
versions, respectively, of wait( ).
The functions work similarly to waitpid( ), with the exception of the rusage argu-
ment. The following wait3( ) invocation:
pid = wait3 (status, options, NULL);
is equivalent to the following waitpid( ) call:
pid = waitpid (-1, status, options);
And the following wait4( ) invocation:
pid = wait4 (pid, status, options, NULL);
is equivalent to this waitpid( ) call:
pid = waitpid (pid, status, options);
That is, wait3( ) waits for any child to change state, and wait4( ) waits for the spe-
cific child identified by the pid parameter to change state. The options argument
behaves the same as with waitpid( ).
As mentioned earlier, the big difference between these calls and waitpid( ) is the
rusage parameter. If it is non-NULL, the function fills out the pointer at rusage with
information about the child. This structure provides information about the child’s
resource usage:
#include <sys/resource.h>
struct rusage {
struct timeval ru_utime; /* user time consumed */
struct timeval ru_stime; /* system time consumed */
long ru_maxrss; /* maximum resident set size */
long ru_ixrss; /* shared memory size */
long ru_idrss; /* unshared data size */
long ru_isrss; /* unshared stack size */
long ru_minflt; /* page reclaims */
long ru_majflt; /* page faults */
long ru_nswap; /* swap operations */
long ru_inblock; /* block input operations */
long ru_oublock; /* block output operations */
long ru_msgsnd; /* messages sent */
Waiting for Terminated Child Processes | 147
long ru_msgrcv; /* messages received */
long ru_nsignals; /* signals received */
long ru_nvcsw; /* voluntary context switches */
long ru_nivcsw; /* involuntary context switches */
};
I will address resource usage further in the next chapter.
On success, these functions return the pid of the process that changed state. On fail-
ure, they return -1, and set errno to one of the same error values returned by
waitpid( ).
Because wait3( ) and wait4( ) are not POSIX-defined, * it is advisable to use them only
when resource-usage information is critical. Despite the lack of POSIX standardiza-
tion, however, nearly every Unix system supports these two calls.
Launching and Waiting for a New Process
Both ANSI C and POSIX define an interface that couples spawning a new process
and waiting for its termination—think of it as synchronous process creation. If a pro-
cess is spawning a child only to immediately wait for its termination, it makes sense
to use this interface:
#define _XOPEN_SOURCE /* if we want WEXITSTATUS, etc. */
#include <stdlib.h>
int system (const char *command);
The system( ) function is so named because the synchronous process invocation is
called shelling out to the system. It is common to use system( ) to run a simple utility
or shell script, often with the explicit goal of simply obtaining its return value.
A call to system( ) invokes the command provided by the command parameter, including
any additional arguments. The command parameter is suffixed to the arguments /bin/sh -c.
In this sense, the parameter is passed wholesale to the shell.
On success, the return value is the return status of the command as provided by
wait( ). Consequently, the exit code of the executed command is obtained via
WEXITSTATUS. If invoking /bin/sh itself failed, the value given by WEXITSTATUS is the
same as that returned by exit(127). Because it is also possible for the invoked com-
mand to return 127, there is no surefire method to check whether the shell itself
returned that error. On error, the call returns -1.
If command is NULL, system( ) returns a nonzero value if the shell /bin/sh is available,
and 0 otherwise.
* wait3( ) was included in the original Single UNIX Specification, but it has since been removed.
148 | Chapter 5: Process Management
During execution of the command, SIGCHLD is blocked, and SIGINT and SIGQUIT are
ignored. Ignoring SIGINT and SIGQUIT has several implications, particularly if system( )
is invoked inside a loop. If calling system( ) from within a loop, you should ensure
that the program properly checks the exit status of the child. For example:
do {
int ret;
ret = system ("pidof rudderd");
if (WIFSIGNALED (ret) &&
(WTERMSIG (ret) == SIGINT ||
WTERMSIG (ret) == SIGQUIT))
break; /* or otherwise handle */
} while (1);
Implementing system( ) using fork( ), a function from the exec family, and waitpid( )
is a useful exercise. You should attempt this yourself, as it ties together many of the
concepts of this chapter. In the spirit of completeness, however, here is a sample
implementation:
/*
* my_system - synchronously spawns and waits for the command
* "/bin/sh -c <cmd>".
*
* Returns -1 on error of any sort, or the exit code from the
* launched process. Does not block or ignore any signals.
*/
int my_system (const char *cmd)
{
int status;
pid_t pid;
pid = fork ( );
if (pid == -1)
return -1;
else if (pid == 0) {
const char *argv[4];
argv[0] = "sh";
argv[1] = "-c";
argv[2] = cmd;
argv[3] = NULL;
execv ("/bin/sh", argv);
exit (-1);
}
if (waitpid (pid, &status, 0) == -1)
return -1;
else if (WIFEXITED (status))
return WEXITSTATUS (status);
return -1;
}
Users and Groups | 149
Note that this example does not block or disable any signals, unlike the official
system( ). This behavior may be better or worse, depending on your program’s situa-
tion, but leaving at least SIGINT unblocked is often smart because it allows the
invoked command to be interrupted in the way a user normally expects. A better
implementation could add additional pointers as parameters that, when non-NULL,
signify errors currently differentiable from each other. For example, one might add
fork_failed and shell_failed.
Zombies
As discussed earlier, a process that has terminated, but that has not yet been waited
upon by its parent is called a “zombie.” Zombie processes continue to consume
system resources, although only a small percentage—enough to maintain a mere
skeleton of what they once were. These resources remain so that parent processes
that want to check up on the status of their children can obtain information relating
to the life and termination of those processes. Once the parent does so, the kernel
cleans up the process for good and the zombie ceases to exist.
However, anyone who has used Unix for a good while is sure to have seen zombie
processes sitting around. These processes, often called ghosts, have irresponsible par-
ents. If your application forks a child process, it is your application’s responsibility
(unless it is short-lived, as you will see shortly) to wait on the child, even if it will
merely discard the information gleaned. Otherwise, all of your process’ children will
become ghosts and live on, crowding the system’s process listing, and generating dis-
gust at your application’s sloppy implementation.
What happens, however, if the parent process dies before the child, or if it dies
before it has a chance to wait on its zombie children? Whenever a process termi-
nates, the Linux kernel walks a list of its children, and reparents all of them to the
init process (the process with a pid value of 1). This guarantees that no process is
ever without an immediate parent. The init process, in turn, periodically waits on all
of its children, ensuring that none remain zombies for too long—no ghosts! Thus, if
a parent dies before its children or does not wait on its children before exiting, the
child processes are eventually reparented to init and waited upon, allowing them to
fully exit. Although doing so is still considered good practice, this safeguard means
that short-lived processes need not worry excessively about waiting on all of their
children.
Users and Groups
As mentioned earlier in this chapter, and discussed in Chapter 1, processes are asso-
ciated with users and groups. The user and group identifiers are numeric values
represented by the C types uid_t and gid_t, respectively. The mapping between
150 | Chapter 5: Process Management
numeric values and human-readable names—as in the root user having the uid 0—is
performed in user space using the files /etc/passwd and /etc/group. The kernel deals
only with the numeric values.
In a Linux system, a process’ user and group IDs dictate the operations that the pro-
cess may undertake. Processes must therefore run under the appropriate users and
groups. Many processes run as the root user. However, best practices in software
development encourage the doctrine of least-privileged rights, meaning that a pro-
cess should execute with the minimum level of rights possible. This requirement is
dynamic: if a process requires root privileges to perform an operation early in its life,
but does not require these extensive privileges thereafter, it should drop root privileges
as soon as possible. To this end, many processes—particularly those that need root
privileges to carry out certain operations—often manipulate their user or group IDs.
Before we can look at how this is accomplished, we need to cover the complexities of
user and group IDs.
Real, Effective, and Saved User and Group IDs
The following discussion focuses on user IDs, but the situation is iden-
tical for group IDs.
There are, in fact, not one, but four user IDs associated with a process: the real,
effective, saved, and filesystem user IDs. The real user ID is the uid of the user who
originally ran the process. It is set to the real user ID of the process’ parent, and does
not change during an exec call. Normally, the login process sets the real user ID of
the user’s login shell to that of the user, and all of the user’s processes continue to
carry this user ID. The superuser (root) may change the real user ID to any value, but
no other user can change this value.
The effective user ID is the user ID that the process is currently wielding. Permission
verifications normally check against this value. Initially, this ID is equal to the real
user ID, because when a process forks, the effective user ID of the parent is inherited
by the child. Furthermore, when the process issues an exec call, the effective user is
usually unchanged. But, it is during the exec call that the key difference between real
and effective IDs emerges: by executing a setuid (suid) binary, the process can change
its effective user ID. To be exact, the effective user ID is set to the user ID of the
owner of the program file. For instance, because the /usr/bin/passwd file is a setuid
file, and root is its owner, when a normal user’s shell spawns a process to exec this
file, the process takes on the effective user ID of root regardless of who the executing
user is.
Nonprivileged users may set the effective user ID to the real or the saved user ID, as
you’ll see momentarily. The superuser may set the effective user ID to any value.
Users and Groups | 151
The saved user ID is the process’ original effective user ID. When a process forks, the
child inherits the saved user ID of its parent. Upon an exec call, however, the kernel
sets the saved user ID to the effective user ID, thereby making a record of the effec-
tive user ID at the time of the exec. Nonprivileged users may not change the saved
user ID; the superuser can change it to the same value as the real user ID.
What is the point of all these values? The effective user ID is the value that matters:
it’s the user ID that is checked in the course of validating a process’ credentials. The
real user ID and saved user ID act as surrogates, or potential user ID values that non-
root processes are allowed to switch to and from. The real user ID is the effective
user ID belonging to the user actually running the program, and the saved user ID is
the effective user ID before a suid binary caused a change during exec.
Changing the Real or Saved User or Group ID
The user and group IDs are set via two system calls:
#include <sys/types.h>
#include <unistd.h>
int setuid (uid_t uid);
int setgid (gid_t gid);
A call to setuid( ) sets the effective user ID of the current process. If the current
effective user ID of the process is 0 (root), the real and saved user IDs are also set.
The root user may provide any value for uid, thereby setting all three of the user ID
values to uid. A nonroot user is allowed only to provide the real or saved user ID for
uid. In other words, a nonroot user can only set the effective user ID to one of those
values.
On success, setuid( ) returns 0. On error, the call returns -1, and errno is set to one
of the following values:
EAGAIN
uid is different from the real user ID, and setting the real user ID to uid will put
the user over its NPROC rlimit (which specifies the number of processes that a user
may own).
EPERM
The user is not root, and uid is neither the effective nor the saved user ID.
The preceding discussion also applies to groups—simply replace setuid( ) with
setgid( ), and uid with gid.
Changing the Effective User or Group ID
Linux provides two POSIX-mandated functions for setting the effective user and
group IDs of the currently executing process:
#include <sys/types.h>
#include <unistd.h>
152 | Chapter 5: Process Management
int seteuid (uid_t euid);
int setegid (gid_t egid);
A call to seteuid( ) sets the effective user ID to euid. Root may provide any value for
euid. Nonroot users may set the effective user ID only to the real or saved user ID.
On success, seteuid( ) returns 0. On failure, it returns -1, and sets errno to EPERM,
which signifies that the current process is not owned by root, and that euid is equal
to neither the real nor the saved user ID.
Note that in the nonroot case, seteuid( ) and setuid( ) behave the same. It is thus
standard practice and a good idea to always use seteuid( ), unless your process tends
to run as root, in which case setuid( ) makes more sense.
The preceding discussion also applies to groups—simply replace seteuid( ) with
setegid( ), and euid with egid.
Changing the User and Group IDs, BSD Style
BSD settled on its own interfaces for setting the user and group IDs. Linux provides
these interfaces for compatibility:
#include <sys/types.h>
#include <unistd.h>
int setreuid (uid_t ruid, uid_t euid);
int setregid (gid_t rgid, gid_t egid);
A call to setreuid( ) sets the real and effective user IDs of a process to ruid and euid,
respectively. Specifying a value of -1 for either parameter leaves the associated user
ID unchanged. Nonroot processes are only allowed to set the effective user ID to the
real or saved user ID, and the real user ID to the effective user ID. If the real user ID
is changed, or if the effective user ID is changed to a value not equal to the previous
real user ID value, the saved user ID is changed to the new effective user ID. At least,
that’s how Linux and most other Unix systems react to such changes; the behavior is
left undefined by POSIX.
On success, setreuid( ) returns 0. On failure, it returns -1, and sets errno to EPERM,
which signifies that the current process is not owned by root, and that euid is equal to
neither the real nor the saved user ID, or that ruid is not equal to the effective user ID.
The preceding discussion also applies to groups—simply replace setreuid( ) with
setregid( ), ruid with rgid, and euid with egid.
Changing the User and Group IDs, HP-UX Style
You may feel the situation is growing insane, but HP-UX, Hewlett-Packard’s Unix
system, has also introduced its own mechanisms for setting a process’ user and
group IDs. Linux follows along and provides these interfaces:
Users and Groups | 153
#define _GNU_SOURCE
#include <unistd.h>
int setresuid (uid_t ruid, uid_t euid, uid_t suid);
int setresgid (gid_t rgid, gid_t egid, gid_t sgid);
A call to setresuid( ) sets the real, effective, and saved user IDs to ruid, euid, and
suid, respectively. Specifying a value of -1 for any of the parameters leaves its value
unchanged.
The root user may set any user ID to any value. Nonroot users may set any user ID to
the current real, effective, or saved user ID. On success, setuid( ) returns 0. On error,
the call returns -1, and errno is set to one of the following values:
EAGAIN
uid does not match the real user ID, and setting the real user ID to uid will put
the user over its NPROC rlimit (which specifies the number of processes that a user
may own).
EPERM
The user is not root and attempted to set new values for the real, effective, or
saved user ID that did not match one of the current real, effective, or saved user
IDs.
The preceding discussion also applies to groups—simply replace setresuid( ) with
setresgid( ), ruid with rgid, euid with egid, and suid with sgid.
Preferred User/Group ID Manipulations
Nonroot processes should use seteuid( ) to change their effective user IDs. Root pro-
cesses should use setuid( ) if they wish to change all three user IDs, and seteuid( ) if
they wish to temporarily change just the effective user ID. These functions are sim-
ple, and behave in accordance with POSIX, properly taking into account saved user
IDs.
Despite providing additional functionality, the BSD and HP-UX style functions do
not allow for any useful changes that setuid( ) and seteuid( ) do not.
Support for Saved User IDs
The existence of the saved user and group IDs is mandated by IEEE Std 1003.1-2001
(POSIX 2001), and Linux has supported these IDs since the early days of the 1.1.38
kernel. Programs written only for Linux may rest assured of the existence of the
saved user IDs. Programs written for older Unix systems should check for the macro
_POSIX_SAVED_IDS before making any references to a saved user or group ID.
In the absence of saved user and group IDs, the preceding discussions are still valid;
just ignore any parts of the rules that mention the saved user or group ID.
154 | Chapter 5: Process Management
Obtaining the User and Group IDs
These two system calls return the real user and group IDs, respectively:
#include <unistd.h>
#include <sys/types.h>
uid_t getuid (void);
gid_t getgid (void);
They cannot fail. Likewise, these two system calls return the effective user and group
IDs, respectively:
#include <unistd.h>
#include <sys/types.h>
uid_t geteuid (void);
gid_t getegid (void);
These two system calls cannot fail, either.
Sessions and Process Groups
Each process is a member of a process group, which is a collection of one or more pro-
cesses generally associated with each other for the purposes of job control. The primary
attribute of a process group is that signals may be sent to all processes in the group: a
single action can terminate, stop, or continue all processes in the same process group.
Each process group is identified by a process group ID (pgid), and has a process group
leader. The process group ID is equal to the pid of the process group leader. Process
groups exist so long as they have one remaining member. Even if the process group
leader terminates, the process group continues to exist.
When a new user first logs into a machine, the login process creates a new session
that consists of a single process, the user’s login shell. The login shell functions as the
session leader. The pid of the session leader is used as the session ID. A session is a
collection of one or more process groups. Sessions arrange a logged-in user’s activi-
ties, and associate that user with a controlling terminal, which is a specific tty device
that handles the user’s terminal I/O. Consequently, sessions are largely the business
of shells. In fact, nothing else really cares about them.
While process groups provide a mechanism to address signals to all of their mem-
bers, making job control and other shell functions easy, sessions exist to consolidate
logins around controlling terminals. Process groups in a session are divided into a
single foreground process group, and zero or more background process groups. When
a user exits a terminal, a SIGQUIT is sent to all processes in the foreground process
group. When a network disconnect is detected by a terminal, a SIGHUP is sent to all
processes in the foreground process group. When the user enters the interrupt key
(generally Ctrl-C), a SIGINT is sent to all processes in the foreground process group.
Thus, sessions make managing terminals and logins easier for shells.
Sessions and Process Groups | 155
As a review, say a user logs into the system and her login shell, bash, has the pid
1700. The user’s bash instance is now the sole member and leader of a new process
group, with the process group ID 1700. This process group is inside a new session
with the session ID 1700, and bash is the sole member and the leader of this session.
New commands that the user runs in the shell run in new process groups within ses-
sion 1700. One of these process groups—the one connected directly to the user and
in control of the terminal—is the foreground process group. All the other process
groups are background process groups.
On a given system, there are many sessions: one for each user login session, and oth-
ers for processes not tied to user login sessions, such as daemons. Daemons tend to
create their own sessions to avoid the issues of association with other sessions that
may exit.
Each of these sessions contains one or more process groups, and each process group
contains at least one process. Process groups that contain more than one process are
generally implementing job control.
A command on the shell such as this one:
$ cat ship-inventory.txt | grep booty | sort
results in one process group containing three processes. This way, the shell can sig-
nal all three processes in one fell swoop. Because the user has typed this command
on the console without a trailing ampersand, we can also say that this process group
is in the foreground. Figure 5-1 illustrates the relationship between sessions, process
groups, processes, and controlling terminals.
Linux provides several interfaces for setting and retrieving the session and process
group associated with a given process. These are primarily of use for shells, but can
also be useful to processes such as daemons that want to get out of the business of
sessions and process groups altogether.
Figure 5-1. Relationship between sessions, process groups, processes, and controlling terminals
Session
Process group
Process
Controlling terminal
156 | Chapter 5: Process Management
Session System Calls
Shells create new sessions on login. They do so via a special system call, which makes
creating a new session easy:
#include <unistd.h>
pid_t setsid (void);
A call to setsid( ) creates a new session, assuming that the process is not already a
process group leader. The calling process is made the session leader and sole member
of the new session, which has no controlling tty. The call also creates a new process
group inside the session, and makes the calling process the process group leader and
sole member. The new session’s and process group’s IDs are set to the calling pro-
cess’ pid.
In other words, setsid( ) creates a new process group inside of a new session, and
makes the invoking process the leader of both. This is useful for daemons, which do
not want to be members of existing sessions, or to have controlling terminals, and for
shells, which want to create a new session for each user upon login.
On success, setsid( ) returns the session ID of the newly created session. On error,
the call returns -1. The only possible errno code is EPERM, which indicates that the
process is currently a process group leader. The easiest way to ensure that any given
process is not a process group leader is to fork, have the parent terminate, and have
the child perform the setsid( ). For example:
pid_t pid;
pid = fork ( );
if (pid == -1) {
perror ("fork");
return -1;
} else if (pid != 0)
exit (EXIT_SUCCESS);
if (setsid ( ) == -1) {
perror ("setsid");
return -1;
}
Obtaining the current session ID, while less useful, is also possible:
#define _XOPEN_SOURCE 500
#include <unistd.h>
pid_t getsid (pid_t pid);
A call to getsid( ) returns the session ID of the process identified by pid. If the pid argu-
ment is 0, the call returns the session ID of the calling process. On error, the call returns
-1. The only possible errno value is ESRCH, indicating that pid does not correspond to a
Sessions and Process Groups | 157
valid process. Note that other Unix systems may also set errno to EPERM, indicating that
pid and the invoking process do not belong to the same session; Linux does not return
this error, and happily returns the session ID of any process.
Usage is rare and primarily for diagnostic purposes:
pid_t sid;
sid = getsid (0);
if (sid == -1)
perror ("getsid"); /* should not be possible */
else
printf ("My session id=%d\n", sid);
Process Group System Calls
A call to setpgid( ) sets the process group ID of the process identified by pid to pgid:
#define _XOPEN_SOURCE 500
#include <unistd.h>
int setpgid (pid_t pid, pid_t pgid);
The current process is used if the pid argument is 0. If pgid is 0, the process ID of the
process identified by pid is used as the process group ID.
On success, setpgid( ) returns 0. Success is contingent on several conditions:
• The process identified by pid must be the calling process, or a child of the call-
ing process, that has not issued an exec call, and is in the same session as the
calling process.
• The process identified by pid must not be a session leader.
• If pgid already exists, it must be in the same session as the calling process.
• pgid must be nonnegative.
On error, the call returns -1, and sets errno to one of the following error codes:
EACCESS
The process identified by pid is a child of the calling process that has already
invoked exec.
EINVAL
pgid is less than 0.
EPERM
The process identified by pid is a session leader, or is in a different session from
the calling process. Alternatively, an attempt was made to move a process into a
process group inside a different session.
ESRCH
pid is not the current process, 0, or a child of the current process.
158 | Chapter 5: Process Management
As with sessions, obtaining a process’ process group ID is possible, although less
useful:
#define _XOPEN_SOURCE 500
#include <unistd.h>
pid_t getpgid (pid_t pid);
A call to getpgid( ) returns the process group ID of the process identified by pid. If
pid is 0, the process group ID of the current process is used. On error, it returns -1,
and sets errno to ESRCH, the only possible value, indicating that pid is an invalid pro-
cess identifier.
As with getsid( ), usage is largely for diagnostic purposes:
pid_t pgid;
pgid = getpgid (0);
if (pgid == -1)
perror ("getpgid"); /* should not be possible */
else
printf ("My process group id=%d\n", pgid);
Obsolete Process Group Functions
Linux supports two older interfaces from BSD for manipulating or obtaining the pro-
cess group ID. As they are less useful than the previously discussed system calls, new
programs should use them only when portability is stringently required. setpgrp( )
can be used to set the process group ID:
#include <unistd.h>
int setpgrp (void);
This invocation:
if (setpgrp ( ) == -1)
perror ("setpgrp");
is identical to the following invocation:
if (setpgid (0,0) == -1)
perror ("setpgid");
Both attempt to assign the current process to the process group with the same num-
ber as the current process’ pid, returning 0 on success, and -1 on failure. All of the
errno values of setpgid( ) are applicable to setpgrp( ), except ERSCH.
Similarly, a call to getpgrp( ) can be used to retrieve the process group ID:
#include <unistd.h>
pid_t getpgrp (void);
Daemons | 159
This invocation:
pid_t pgid = getpgrp ( );
is identical to:
pid_t pgid = getpgid (0);
Both return the process group ID of the calling process. The function getpgid( ) can-
not fail.
Daemons
A daemon is a process that runs in the background, not connecting to any control-
ling terminal. Daemons are normally started at boot time, are run as root or some
other special user (such as apache or postfix), and handle system-level tasks. As a
convention, the name of a daemon often ends in d (as in crond and sshd), but this is
not required, or even universal.
The name derives from Maxwell’s demon, an 1867 thought experiment by the physi-
cist James Maxwell. Daemons are also supernatural beings in Greek mythology,
existing somewhere between humans and the gods and gifted with powers and divine
knowledge. Unlike the demons of Judeo-Christian lore, the Greek daemon need not
be evil. Indeed, the daemons of mythology tended to be aides to the gods, performing
tasks that the denizens of Mount Olympus found themselves unwilling to do—much
as Unix daemons perform tasks that foreground users would rather avoid.
A daemon has two general requirements: it must run as a child of init, and it must
not be connected to a terminal.
In general, a program performs the following steps to become a daemon:
1. Call fork( ). This creates a new process, which will become the daemon.
2. In the parent, call exit( ). This ensures that the original parent (the daemon’s
grandparent) is satisfied that its child terminated, that the daemon’s parent is no
longer running, and that the daemon is not a process group leader. This last
point is a requirement for the successful completion of the next step.
3. Call setsid( ), giving the daemon a new process group and session, both of
which have it as leader. This also ensures that the process has no associated con-
trolling terminal (as the process just created a new session, and will not assign
one).
4. Change the working directory to the root directory via chdir( ). This is done
because the inherited working directory can be anywhere on the filesystem. Dae-
mons tend to run for the duration of the system’s uptime, and you don’t want to
keep some random directory open, and thus prevent an administrator from
unmounting the filesystem containing that directory.
160 | Chapter 5: Process Management
5. Close all file descriptors. You do not want to inherit open file descriptors, and,
unaware, hold them open.
6. Open file descriptors 0, 1, and 2 (standard in, standard out, and standard error)
and redirect them to /dev/null.
Following these rules, here is a program that daemonizes itself:
#include <sys/types.h>
#include <sys/stat.h>
#include <stdlib.h>
#include <stdio.h>
#include <fcntl.h>
#include <unistd.h>
#include <linux/fs.h>
int main (void)
{
pid_t pid;
int i;
/* create new process */
pid = fork ( );
if (pid == -1)
return -1;
else if (pid != 0)
exit (EXIT_SUCCESS);
/* create new session and process group */
if (setsid ( ) == -1)
return -1;
/* set the working directory to the root directory */
if (chdir ("/") == -1)
return -1;
/* close all open files--NR_OPEN is overkill, but works */
for (i = 0; i < NR_OPEN; i++)
close (i);
/* redirect fd's 0,1,2 to /dev/null */
open ("/dev/null", O_RDWR); /* stdin */
dup (0); /* stdout */
dup (0); /* stderror */
/* do its daemon thing... */
return 0;
}
Most Unix systems provide a daemon( ) function in their C library that automates
these steps, turning the cumbersome into the simple:
#include <unistd.h>
int daemon (int nochdir, int noclose);
Conclusion | 161
If nochdir is nonzero, the daemon will not change its working directory to the root
directory. If noclose is nonzero, the daemon will not close all open file descriptors.
These options are useful if the parent process already set up these aspects of the dae-
monizing procedure. Normally, though, one passes 0 for both of these parameters.
On success, the call returns 0. On failure, the call returns -1, and errno is set to a
valid error code from fork( ) or setsid( ).
Conclusion
We covered the fundamentals of Unix process management, from process creation to
process termination, in this chapter. In the next chapter, we will cover more
advanced process management interfaces, as well as interfaces for changing the
scheduling behavior of processes.
162
Chapter 6CHAPTER 6
Advanced Process
Management
Chapter 5 introduced the abstraction of the process, and discussed the kernel inter-
faces used to create, control, and destroy it. This chapter builds on those ideas,
beginning with a discussion of the Linux process scheduler and its scheduling algo-
rithm, and then presenting advanced process management interfaces. These system
calls manipulate the scheduling behavior and semantics of a process, influencing the
scheduler’s behavior in pursuit of an application or user-dictated goal.
Process Scheduling
The process scheduler is the component of a kernel that selects which process to run
next. In other words, the process scheduler—or simply the scheduler—is the
subsystem of the kernel that divides the finite resource of processor time among a
system’s processes. In deciding which processes can run and when, the scheduler is
responsible for maximizing processor usage while simultaneously providing the
impression that multiple processes are executing concurrently and seamlessly.
In this chapter, we will talk a lot about runnable processes. A runnable process is one
that, first of all, is not blocked. Processes that interact with users, read and write files
heavily, or respond to I/O or network events, tend to spend a lot of time blocked
while they wait for resources to become available, and they are not runnable during
those long periods (long, that is, compared to the time it takes to execute machine
instructions). A runnable process must also have at least part of its timeslice—the
amount of time the scheduler has decided to let it run—remaining. The kernel places
all runnable processes on a run list. Once a process has exhausted its timeslice, it is
removed from this list, and not considered runnable again until all other runnable
processes have also exhausted their timeslices.
Given only one runnable process (or none at all), the job of a process scheduler is
trivial. A scheduler proves its worth, however, when there are more runnable pro-
cesses than processors. In such a situation, some processes must obviously run while
others wait. Deciding which processes to run, when, and for how long is the process
scheduler’s fundamental responsibility.
Process Scheduling | 163
An operating system on a single-processor machine is multitasking if it can interleave
the execution of more than one process, giving the illusion of there being more than
one process running at the same time. On multiprocessor machines, a multitasking
operating system allows processes to actually run in parallel, on different processors.
A nonmultitasking operating system, such as DOS, can run only one application at a
time.
Multitasking operating systems come in two variants: cooperative and preemptive.
Linux implements the latter form of multitasking, where the scheduler decides when
one process is to stop running, and a different process is to resume running. We call
the act of suspending a running process in lieu of another preemption. Again, the
length of time a process runs before the scheduler preempts it is known as the pro-
cess’ timeslice (so called because the scheduler allocates each runnable process a
“slice” of the processor’s time).
In cooperative multitasking, conversely, a process does not stop running until it vol-
untarily decides to do so. We call the act of a process voluntarily suspending itself
yielding. Ideally, processes yield often, but the operating system is unable to enforce
this behavior. A rude or broken program can run for a longer than optimal time, or
even bring down the entire system. Due to the shortcomings of this approach, mod-
ern operating systems are almost universally preemptively multitasked; Linux is no
exception.
The O(1) process scheduler, introduced during the 2.5 kernel series, is the heart of
Linux scheduling.* The Linux scheduling algorithm provides preemptive multitask-
ing along with support for multiple processors, processor affinity, nonuniform
memory access (NUMA) configurations, multithreading, real-time processes, and
user-provided priorities.
Big-Oh Notation
O(1)—read “big oh of one”—is an example of big-oh notation, which is used to rep-
resent an algorithm’s complexity and scalability. Formally,
In English, the value of some algorithm, f, is always less than or equal to the value of
g multiplied by some arbitrary constant, so long as the input x is larger than some
initial value x’. That is, g is as big as or bigger than f; g bounds f from above.
* For the curious reader, the process scheduler is self-contained, and defined in kernel/sched.c in the kernel
source tree.
If f x( ) is O g x( )( ),
then
c x' such that f x( ) c g x( ) x x'>∀,⋅≤,∃
164 | Chapter 6: Advanced Process Management
O(1), therefore, implies that the algorithm in question is valued at less than some
constant, c. All this pomp and circumstance boils down to one important promise:
the Linux process scheduler will always perform the same, regardless of the number
of processes on the system. This is important because the act of picking a new pro-
cess to run would seemingly involve at least one, if not multiple, iterations over lists
of processes. With more naïve schedulers (including those used by earlier versions of
Linux), as the number of processes on a system grows, such iterations quickly grow
to become a potential bottleneck. At best, such loops introduce uncertainty—a lack
of determinism—into the scheduling process.
The Linux scheduler, operating in constant time regardless of any factor, has no such
bottleneck.
Timeslices
The timeslice that Linux allots to each process is an important variable in the overall
behavior and performance of a system. If timeslices are too large, processes must
wait a long time in between executions, minimizing the appearance of concurrent
execution. The user may become frustrated at the perceptible delay. Conversely, if
the timeslices are too small, a significant amount of the system’s time is spent switch-
ing from one application to another, and benefits such as temporal locality are lost.
Consequently, determining an ideal timeslice is not easy. Some operating systems
give processes large timeslices, hoping to maximize system throughput and overall
performance. Other operating systems give processes very small timeslices, hoping to
provide a system with excellent interactive performance. As we will see, Linux aims
for the best of both worlds by dynamically allocating process timeslices.
Note that a process need not consume all of its timeslice in one go. A process
assigned a 100 ms timeslice might run for 20 ms, and then block on some resource,
such as keyboard input. The scheduler will temporarily remove this process from the
list of runnable processes. When the blocked resource becomes available—in this
case, when the keyboard buffer becomes nonempty—the scheduler wakes up the
process. The process can then continue running until it exhausts its remaining 80 ms
of timeslice, or until it again blocks on a resource.
I/O- Versus Processor-Bound Processes
Processes that continually consume all of their available timeslices are considered
processor-bound. Such processes are hungry for CPUtime, and will consume all that
the scheduler gives them. The simplest trivial example is an infinite loop. Other
examples include scientific computations, mathematical calculations, and image
processing.
On the other hand, processes that spend more time blocked waiting for some
resource than executing are considered I/O-bound. I/O-bound processes are often
issuing and waiting for file I/O, blocking on keyboard input, or waiting for the user
Process Scheduling | 165
to move the mouse. Examples of I/O-bound applications include file utilities that do
very little except issue system calls asking the kernel to perform I/O, such as cp or
mv, and many GUI applications, which spend a great deal of time waiting for user
input.
Processor- and I/O-bound applications differ in the type of scheduler behavior that
benefits them most. Processor-bound applications crave the largest timeslices possi-
ble, allowing them to maximize cache hit rates (via temporal locality), and get their
jobs done as quickly as possible. In contrast, I/O-bound processes do not necessarily
need large timeslices, because they typically run for only very short periods before
issuing I/O requests and blocking on some kernel resource. I/O-bound processes,
however, do benefit from constant attention from the scheduler. The quicker such an
application can restart after blocking and dispatch more I/O requests, the better it
can utilize the system’s hardware. Further, if the application was waiting for user
input, the faster it is scheduled, the greater the user’s perception of seamless execu-
tion will be.
Juggling the needs of processor- and I/O-bound processes is not easy. The Linux
scheduler attempts to identify and provide preferential treatment to I/O-bound
applications: heavily I/O-bound applications are given a priority boost, while heavily
processor-bound applications are served a priority penalty.
In reality, most applications are some mix of I/O- and processor-bound. Audio/video
encoding/decoding is a good example of a type of application that defies categoriza-
tion. Many games are also quite mixed. It is not always possible to identify the
proclivity of a given application, and, at any point in time, a given process may
behave in one way or the other.
Preemptive Scheduling
When a process exhausts its timeslice, the kernel suspends it, and begins running a
new process. If there are no runnable processes on the system, the kernel takes the
set of processes with exhausted timeslices, replenishes their timeslices, and begins
running them again. In this fashion, all processes eventually get to run, even if there
are higher-priority processes on the system—the lower-priority processes just have to
wait for the higher-priority processes to exhaust their timeslices or block. This
behavior formulates an important but tacit rule of Unix scheduling: all processes
must progress.
If there are no runnable processes left on the system, the kernel “runs” the idle pro-
cess. The idle process is actually not a process at all; nor does it actually run (to the
relief of batteries everywhere). Instead, the idle process is a special routine that the
kernel executes to simplify the scheduler algorithm, and to make accounting easy.
Idle time is simply the time spent running the idle process.
166 | Chapter 6: Advanced Process Management
If a process is running, and a process with a higher priority becomes runnable (per-
haps because it was blocked waiting for keyboard input, and the user just typed a
word), the currently running process is immediately suspended, and the kernel switches
to the higher-priority process. Thus, there are never runnable-but-not-running pro-
cesses with a higher priority than the currently running process. The running process is
always the highest-priority runnable process on the system.
Threading
Threads are units of execution within a single process. All processes have at least one
thread. Each thread has its own virtualization of the processor: its own set of regis-
ters, instruction pointer, and processor state. While most processes have but one
thread, processes can have large numbers of threads, all performing different tasks,
but sharing the same address space (and thus the same dynamic memory, mapped
files, object code, and so on), list of open files, and other kernel resources.
The Linux kernel has an interesting and unique view of threads. Essentially, the ker-
nel has no such concept. To the Linux kernel, all threads are unique processes. At a
broad level, there is no difference between two unrelated processes and two threads
inside of a single process. The kernel simply views threads as processes that share
resources. That is, the kernel considers a process consisting of two threads as two
distinct processes that share a set of kernel resources (address space, list of open files,
and so on).
Multithreaded programming is the art of programming with threads. The most com-
mon API on Linux for programming with threads is the API standardized by IEEE
Std 1003.1c-1995 (POSIX 1995 or POSIX.1c). Developers often call the library that
implements this API pthreads. Programming with threads is a complicated subject,
and the pthreads API is large and complex. Consequently, pthreads are outside the
scope of this book. Instead, this book focuses on the interfaces on which the
pthreads library is built.
Yielding the Processor
Although Linux is a preemptively multitasked operating system, it also provides a
system call that allows processes to explicitly yield execution and instruct the sched-
uler to select a new process for execution:
#include <sched.h>
int sched_yield (void);
A call to sched_yield( ) results in suspension of the currently running process, after
which the process scheduler selects a new process to run, in the same manner as if
the kernel had itself preempted the currently running process in favor of executing a
new process. Note that if no other runnable process exists, which is often the case,
Yielding the Processor | 167
the yielding process will immediately resume execution. Because of this uncertainty,
coupled with the general belief that there are generally better choices, use of this sys-
tem call is not common.
On success, the call returns 0; on failure, it returns -1, and sets errno to the appropriate
error code. On Linux—and, more than likely, most other Unix systems—sched_yield( )
cannot fail, and thus always returns 0. A thorough programmer may still check the
return value, however:
if (sched_yield ( ))
perror ("sched_yield");
Legitimate Uses
In practice, there are few (if any) legitimate uses of sched_yield( ) on a proper pre-
emptive multitasking system such as Linux. The kernel is fully capable of making the
optimal and most efficient scheduling decisions—certainly, the kernel is better
equipped than an individual application to decide what to preempt and when. This
is precisely why operating systems ditched cooperative multitasking in favor of pre-
emptive multitasking.
Why, then, do we have a “reschedule me” system call at all? The answer lies in applica-
tions having to wait for external events, which may be caused by the user, a hardware
component, or another process. For instance, if one process needs to wait for another,
“just yield the processor until the other process is done” is a first-pass solution. As an
example, the implementation of a naïve consumer in a consumer/producer pair might
be similar to the following:
/* the consumer... */
do {
while (producer_not_ready ( ))
sched_yield ( );
process_data ( );
} while (!time_to_quit ( ));
Thankfully, Unix programmers do not tend to write code such as this. Unix
programs are normally event-driven and tend to utilize some sort of blockable
mechanism (such as a pipe) between the consumer and the producer, in lieu of
sched_yield( ). In this case, the consumer reads from the pipe, blocking as necessary
until data is available. The producer, in turn, writes to the pipe as fresh data becomes
available. This removes the responsibility for coordination from the user-space pro-
cess, which just busy-loops, to the kernel, which can optimally manage the situation
by putting the processes to sleep, and waking them up only as needed. In general,
Unix programs should aim toward event-driven solutions that rely on blockable file
descriptors.
Until recently, one situation vexingly required sched_yield( ): user-space thread
locking. When a thread attempted to acquire a lock that another thread already held,
the new thread would yield the processor until the lock became available. Without
168 | Chapter 6: Advanced Process Management
kernel support for user-space locks, this approach was the simplest, and most effi-
cient. Thankfully, the modern Linux thread implementation (the New POSIX
Threading Library, or NPTL) ushered in an optimal solution using futexes, which
provide kernel support for user-space locks.
One other use for sched_yield( ) is “playing nicely”: a processor-intensive program
can call sched_yield( ) periodically, attempting to minimize its impact on the sys-
tem. While noble in pursuit, this strategy has two flaws. First, the kernel is able to
make global scheduling decisions much better than an individual process, and, con-
sequently, the responsibility for ensuring smooth system operation should lie on the
process scheduler, not the processes. Toward this end, the scheduler’s interactivity
bonus aims to reward I/O-intensive applications, and punish processor-intensive
ones. Second, mitigating the overhead of a processor-intensive application with
respect to other applications is the responsibility of the user, not of individual appli-
cations. The user can convey her relative preferences for application performance via
the nice shell command, which we will discuss later in this chapter.
Yielding, Past and Present
Before the introduction of the 2.6 Linux kernel, a call to sched_yield( ) had only a
minor effect. If another runnable process was available, the kernel would switch to it
and place the invoking process at the tail of the list of runnable processes. In short
order, the kernel would reschedule the invoking process. In the likely case of no
other runnable process being available, the invoking process would simply continue
executing.
The 2.6 kernel changed this behavior. The current algorithm is as follows:
1. Is this process a real-time process? If so, stick it at the tail of the runnable pro-
cess list, and return (this is the old behavior). If not, continue to the next step.
(For more on real-time processes, see “Real-Time Systems” later in this chapter.)
2. Remove this process from the list of runnable processes altogether, and place it
on the list of expired processes. This implies that all runnable processes must
execute and exhaust their timeslices before the invoking process, along with the
other expired processes, is able to resume execution.
3. Schedule the next runnable process in the list for execution.
The net effect of a call to sched_yield( ), therefore, is the same as if the process had
exhausted its timeslice. This behavior differs from earlier kernels, where the effect of
sched_yield( ) was milder (tantamount to “if another process is ready and waiting,
run it for a bit, but come right back to me”).
One reason for this change was to prevent the so-called “ping-pong” pathological
case. Imagine two processes, A and B, both calling sched_yield( ). Presume these are
the only runnable processes (there might be other processes able to run, but none
Process Priorities | 169
with nonzero timeslices). With the old sched_yield( ) behavior, the result of this sit-
uation is that the kernel schedules both processes in rotation, with each saying in
turn, “No, schedule someone else!” This persists until both processes exhaust their
timeslices. If we were to draw a diagram of the process selections made by the pro-
cess scheduler, it would resemble “A, B, A, B, A, B” and so on—hence the “ping
pong” moniker.
The new behavior prevents this case. As soon as process A asks to yield the proces-
sor, the scheduler removes it from the list of runnable processes. Likewise, as soon as
process B makes the same request, the scheduler removes it from the list of runnable
processes. The scheduler will not consider running process A or process B until there
are no other runnable processes left, preventing the ping-pong effect, and allowing
other processes to receive their fair share of the processor time.
Consequently, when asking to yield the processor, a process should truly intend to
yield it!
Process Priorities
The discussion in this section pertains to normal, nonreal-time pro-
cesses. Real-time processes require different scheduling criteria, and a
separate priority system. We will discuss real-time computing later in
this chapter.
Linux does not schedule processes willy-nilly. Instead, applications are assigned pri-
orities that affect when their processes run, and for how long. Unix has historically
called these priorities nice values, because the idea behind them was to “be nice” to
other processes on the system by lowering a process’ priority, allowing other pro-
cesses to consume more of the system’s processor time.
The nice value dictates when a process runs. Linux schedules runnable processes in
order of highest to lowest priority: a process with a higher priority runs before a pro-
cess with a lower priority. The nice value also dictates the size of a process’ timeslice.
Legal nice values range from –20 to 19 inclusive, with a default value of 0. Some-
what confusingly, the lower a process’ nice value, the higher its priority, and the
larger its timeslice; conversely, the higher the value, the lower the process’ priority,
and the smaller its timeslice. Increasing a process’ nice value is therefore “nice” to
the rest of the system. The numerical inversion is rather confusing. When we say a
process has a “high priority” we mean that it is chosen more quickly to run, and can
run for longer than lower-priority processes, but such a process will have a lower
nice value.
170 | Chapter 6: Advanced Process Management
nice( )
Linux provides several system calls for retrieving and setting a process’ nice value.
The simplest is nice( ):
#include <unistd.h>
int nice (int inc);
A successful call to nice( ) increments a process’ nice value by inc, and returns the
newly updated value. Only a process with the CAP_SYS_NICE capability (effectively,
processes owned by root) may provide a negative value for inc, decreasing its nice
value, and thereby increasing its priority. Consequently, nonroot processes may only
lower their priorities (by increasing their nice values).
On error, nice( ) returns -1. However, because nice( ) returns the new nice value, -1
is also a successful return value. To differentiate between success and failure, you can
zero out errno before invocation, and subsequently check its value. For example:
int ret;
errno = 0;
ret = nice (10); /* increase our nice by 10 */
if (ret == -1 && errno != 0)
perror ("nice");
else
printf ("nice value is now %d\n", ret);
Linux returns only a single error code: EPERM, signifying that the invoking process
attempted to increase its priority (via a negative inc value), but it does not possess
the CAP_SYS_NICE capability. Other systems also return EINVAL when inc would place
the nice value out of the range of valid values, but Linux does not. Instead, Linux
silently rounds invalid inc values up or down to the value at the limit of the allow-
able range, as needed.
Passing 0 for inc is an easy way to obtain the current nice value:
printf ("nice value is currently %d\n", nice (0));
Often, a process wants to set an absolute nice value rather than a relative increment.
This can be done with code like the following:
int ret, val;
/* get current nice value */
val = nice (0);
/* we want a nice value of 10 */
val = 10 – val;
errno = 0;
ret = nice (val);
if (ret == -1 && errno != 0)
perror ("nice");
else
printf ("nice value is now %d\n", ret);
Process Priorities | 171
getpriority( ) and setpriority( )
A preferable solution is to use the getpriority( ) and setpriority( ) system calls,
which allow more control, but are more complex in operation:
#include <sys/time.h>
#include <sys/resource.h>
int getpriority (int which, int who);
int setpriority (int which, int who, int prio);
These calls operate on the process, process group, or user, as specified by which and
who. The value of which must be one of PRIO_PROCESS, PRIO_PGRP, or PRIO_USER, in
which case who specifies a process ID, process group ID, or user ID, respectively. If
who is 0, the call operates on the current process ID, process group ID, or user ID,
respectively.
A call to getpriority( ) returns the highest priority (lowest numerical nice value) of
any of the specified processes. A call to setpriority( ) sets the priority of all speci-
fied processes to prio. As with nice( ), only a process possessing CAP_SYS_NICE may
raise a process’ priority (lower the numerical nice value). Further, only a process with
this capability can raise or lower the priority of a process not owned by the invoking
user.
Like nice( ), getpriority( ) returns -1 on error. As this is also a successful return
value, programmers should clear errno before invocation if they want to handle error
conditions. Calls to setpriority( ) have no such problem; setpriority( ) always
returns 0 on success, and -1 on error.
The following code returns the current process’ priority:
int ret;
ret = getpriority (PRIO_PROCESS, 0);
printf ("nice value is %d\n", ret);
The following code sets the priority of all processes in the current process group to 10:
int ret;
ret = setpriority (PRIO_PGRP, 0, 10);
if (ret == -1)
perror ("setpriority");
On error, both functions set errno to one of the following values:
EACCESS
The process attempted to raise the specified process’ priority, but does not pos-
sess CAP_SYS_NICE (setpriority( ) only).
EINVAL
The value specified by which was not one of PRIO_PROCESS, PRIO_PGRP, or PRIO_USER.
172 | Chapter 6: Advanced Process Management
EPERM
The effective user ID of the matched process does not match the effective user ID
of the running process, and the running process does not possess CAP_SYS_NICE
(setpriority( ) only).
ESRCH
No process was found matching the criteria provided by which and who.
I/O Priorities
In addition to a scheduling priority, Linux allows processes to specify an I/O prior-
ity. This value affects the relative priority of the processes’ I/O requests. The kernel’s
I/O scheduler (discussed in Chapter 4) services requests originating from processes
with higher I/O priorities before requests from processes with lower I/O priorities.
By default, I/O schedulers use a process’ nice value to determine the I/O priority.
Ergo, setting the nice value automatically changes the I/O priority. However, the
Linux kernel additionally provides two system calls for explicitly setting and retriev-
ing the I/O priority independently of the nice value:
int ioprio_get (int which, int who)
int ioprio_set (int which, int who, int ioprio)
Unfortunately, the kernel does not yet export these system calls, and glibc does not
provide any user-space access. Without glibc support, usage is cumbersome at best.
Further, when and if glibc support arrives, the interfaces may differ from the system
calls. Until such support is available, there are two portable ways to manipulate a
process’ I/O priority: via the nice value, or a utility such as ionice, part of the util-
linux package. *
Not all I/O schedulers support I/O priorities. Specifically, the Complete Fair Queu-
ing (CFQ) I/O Scheduler supports them; currently, the other standard schedulers do
not. If the current I/O scheduler does not support I/O priorities, they are silently
ignored.
Processor Affinity
Linux supports multiple processors in a single system. Aside from the boot process,
the bulk of the work of supporting multiple processors rests on the process sched-
uler. On a symmetric multiprocessing (SMP) machine, the process scheduler must
decide which processes run on each CPU. Two challenges derive from this responsi-
bility: the scheduler must work toward fully utilizing all of the system’s processors,
because it is inefficient for one CPU to sit idle while a process is waiting to run.
* The util-linux package is located at http://www.kernel.org/pub/linux/utils/util-linux. It is licensed under the
GNU General Public License v2.
Processor Affinity | 173
However, once a process has been scheduled on one CPU, the process scheduler
should aim to schedule it on the same CPUin the future. This is beneficial because
migrating a process from one processor to another has costs.
The largest of these costs are related to the cache effects of migration. Due to the
design of modern SMP systems, the caches associated with each processor are
separate and distinct. That is, the data in one processor’s cache is not in another’s.
Therefore, if a process moves to a new CPU, and writes new data into memory, the
data in the old CPU’s cache can become stale. Relying on that cache would now
cause corruption. To prevent this, caches invalidate each other’s data whenever they
cache a new chunk of memory. Consequently, a given piece of data is strictly in only
one processor’s cache at any given moment (assuming the data is cached at all).
When a process moves from one processor to another, there are thus two associated
costs: cached data is no longer accessible to the process that moved, and data in the
original processor’s cache must be invalidated. Because of these costs, process sched-
ulers attempt to keep a process on a specific CPU for as long as possible.
The process scheduler’s two goals, of course, are potentially conflicting. If one
processor has a significantly larger process load than another—or, worse, if one pro-
cessor is busy while another is idle—it makes sense to reschedule some processes on
the less-busy CPU. Deciding when to move processes in response to such imbal-
ances, called load balancing, is of great importance to the performance of SMP
machines.
Processor affinity refers to the likelihood of a process to be scheduled consistently on
the same processor. The term soft affinity refers to the scheduler’s natural propensity
to continue scheduling a process on the same processor. As we’ve discussed, this is a
worthwhile trait. The Linux scheduler attempts to schedule the same processes on
the same processors for as long as possible, migrating a process from one CPUto
another only in situations of extreme load imbalance. This allows the scheduler to
minimize the cache effects of migration, but still ensure that all processors in a sys-
tem are evenly loaded.
Sometimes, however, the user or an application wants to enforce a process-to-processor
bond. This is often because the process is strongly cache-sensitive, and desires to remain
on the same processor. Bonding a process to a particular processor and having the ker-
nel enforce the relationship is called setting a hard affinity.
sched_getaffinity() and sched_setaffinity( )
Processes inherit the CPUaffinities of their parents and, by default, processes may
run on any CPU. Linux provides two system calls for retrieving and setting a pro-
cess’ hard affinity:
#define _GNU_SOURCE
#include <sched.h>
174 | Chapter 6: Advanced Process Management
typedef struct cpu_set_t;
size_t CPU_SETSIZE;
void CPU_SET (unsigned long cpu, cpu_set_t *set);
void CPU_CLR (unsigned long cpu, cpu_set_t *set);
int CPU_ISSET (unsigned long cpu, cpu_set_t *set);
void CPU_ZERO (cpu_set_t *set);
int sched_setaffinity (pid_t pid, size_t setsize,
const cpu_set_t *set);
int sched_getaffinity (pid_t pid, size_t setsize,
cpu_set_t *set);
A call to sched_getaffinity( ) retrieves the CPUaffinity of the process pid, and
stores it in the special cpu_set_t type, which is accessed via special macros. If pid is
0, the call retrieves the current process’ affinity. The setsize parameter is the size of
the cpu_set_t type, which may be used by glibc for compatibility with future changes
in the size of this type. On success, sched_getaffinity( ) returns 0; on failure, it
returns -1, and errno is set. Here’s an example:
cpu_set_t set;
int ret, i;
CPU_ZERO (&set);
ret = sched_getaffinity (0, sizeof (cpu_set_t), &set);
if (ret == -1)
perror ("sched_getaffinity");
for (i = 0; i < CPU_SETSIZE; i++) {
int cpu;
cpu = CPU_ISSET (i, &set);
printf ("cpu=%i is %s\n", i,
cpu ? "set" : "unset");
}
Before invocation, we use CPU_ZERO to “zero out” all of the bits in the set. We then iter-
ate from 0 to CPU_SETSIZE over the set. Note that CPU_SETSIZE is, confusingly, not the
size of the set—you should never pass it for setsize—but rather the number of proces-
sors that could potentially be represented by a set. Because the current implementation
represents each processor with a single bit, CPU_SETSIZE is much larger than
sizeof(cpu_set_t). We use CPU_ISSET to check whether a given processor in the sys-
tem, i, is bound or unbound to this process. It returns 0 if unbound, and a nonzero
value if bound.
Only processors physically on the system are set. Thus, running this snippet on a sys-
tem with two processors will yield:
cpu=0 is set
cpu=1 is set
Processor Affinity | 175
cpu=2 is unset
cpu=3 is unset
...
cpu=1023 is unset
As the output shows, CPU_SETSIZE (which is zero-based) is currently 1,024.
We are concerned only with CPUs #0 and #1 because they are the only physical
processors on this system. Perhaps we want to ensure that our process runs only on
CPU #0, and never on #1. This code does just that:
cpu_set_t set;
int ret, i;
CPU_ZERO (&set); /* clear all CPUs */
CPU_SET (0, &set); /* allow CPU #0 */
CPU_CLR (1, &set); /* forbid CPU #1 */
ret = sched_setaffinity (0, sizeof (cpu_set_t), &set);
if (ret == -1)
perror ("sched_setaffinity");
for (i = 0; i < CPU_SETSIZE; i++) {
int cpu;
cpu = CPU_ISSET (i, &set);
printf ("cpu=%i is %s\n", i,
cpu ? "set" : "unset");
}
We start, as always, by zeroing out the set with CPU_ZERO. We then set CPU#0 with
CPU_SET and unset (clear) CPU#1 with CPU_CLR. The CPU_CLR operation is redundant
as we just zeroed out the whole set, but it is provided for completeness.
Running this on the same two-processor system will result in slightly different out-
put than before:
cpu=0 is set
cpu=1 is unset
cpu=2 is unset
...
cpu=1023 is unset
Now, CPU #1 is unset. This process will run only on CPU #0, no matter what!
Four errno values are possible:
EFAULT
The provided pointer was outside of the process’ address space or otherwise
invalid.
EINVAL
In this case, there were no processors physically on the system enabled in set
(sched_setaffinity( ) only), or setsize is smaller than the size of the kernel’s
internal data structure that represents sets of processors.
176 | Chapter 6: Advanced Process Management
EPERM
The process associated with pid is not owned by the current effective user ID of
the calling process, and the process does not possess CAP_SYS_NICE.
ESRCH
No process associated with pid was found.
Real-Time Systems
In computing, the term real-time is often the source of some confusion and misunder-
standing. A system is “real-time” if it is subject to operational deadlines: minimum and
mandatory times between stimuli and responses. A familiar real-time system is the anti-
lock braking system (ABS) found on nearly all modern automobiles. In this system,
when the brake is pressed, a computer regulates the brake pressure, often applying and
releasing maximum brake pressure many times a second. This prevents the wheels from
“locking up,” which can reduce stopping performance, or even send the car into an
uncontrolled skid. In such a system, the operational deadlines are how fast the system
must respond to a “locked” wheel condition and how quickly the system can apply
brake pressure.
Most modern operating systems, Linux included, provide some level of real-time
support.
Hard Versus Soft Real-Time Systems
Real-time systems come in two varieties: hard and soft. A hard real-time system
requires absolute adherence to operational deadlines. Exceeding the deadlines con-
stitutes failure, and is a major bug. A soft real-time system, on the other hand, does
not consider overrunning a deadline to be a critical failure.
Hard real-time applications are easy to identify: some examples are anti-lock brak-
ing systems, military weapons systems, medical devices, and signal processing. Soft
real-time applications are not always so easy to identify. One obvious member of that
group is video-processing applications: users notice a drop in quality if their dead-
lines are missed, but a few lost frames can be tolerated.
Many other applications have timing constraints that, if not met, result in a detri-
ment to the user experience. Multimedia applications, games, and networking
programs come to mind. What about a text editor, however? If the program cannot
respond quickly enough to keypresses, the experience is poor, and the user may grow
angry or frustrated. Is this a soft real-time application? Certainly, when the developers
were writing the application, they realized that they needed to respond to keypresses in
a timely manner. But does this count as an operational deadline? The line defining soft
real-time applications is anything but clear.
Real-Time Systems | 177
Contrary to common belief, a real-time system is not necessarily fast. Indeed, given
comparable hardware, a real-time system is probably slower than a nonreal-time sys-
tem—due to, if nothing else, the increase in overhead required to support real-time
processes. Likewise, the division between hard and soft real-time systems is indepen-
dent of the size of the operational deadlines. A nuclear reactor will overheat if the
SCRAM system does not lower the control rods within several seconds of detecting
excessive neutron flux. This is a hard real-time system with a lengthy (as far as com-
puters are concerned) operational deadline. Conversely, a video player might skip a
frame or stutter the sound if the application cannot refill the playback buffer within
100 ms. This is a soft real-time system with a demanding operational deadline.
Latency, Jitter, and Deadlines
Latency refers to the period from the occurrence of the stimulus until the execution
of the response. If latency is less than or equal to the operational deadline, the sys-
tem is operating correctly. In many hard real-time systems, the operational deadline
and the latency are equal—the system handles stimuli in fixed intervals, at exact
times. In soft real-time systems, the required response is less exact, and latency
exhibits some amount of variance—the aim is simply for the response to occur
within the deadline.
It is often hard to measure latency, because its calculation requires knowing the time
when the stimulus occurred. The ability to timestamp the stimulus, however, often
begs the ability to respond to it. Therefore, many attempts at instrumenting latency
do no such thing; instead, they measure the variation in timing between responses.
The variation in timing between successive events is jitter, not latency.
For example, consider a stimulus that occurs every 10 milliseconds. To measure the
performance of our system, we might timestamp our responses to ensure that they
occur every 10 milliseconds. The deviation from this target is not latency, however—
it is jitter. What we are measuring is the variance in successive responses. Without
knowing when the stimulus occurred, we do not know the actual difference in time
between stimulus and response. Even knowing that the stimulus occurs every 10 ms,
we do not know when the first occurrence was. Perhaps surprisingly, many attempts
at measuring latency make this mistake and report jitter, not latency. To be sure,
jitter is a useful metric, and such instrumentation is probably quite useful. Neverthe-
less, we must call a duck a duck!
Hard real-time systems often exhibit very low jitter because they respond to stimuli
after—not within—an exact amount of time. Such systems aim for a jitter of zero,
and a latency equal to the operational delay. If the latency exceeds the delay, the sys-
tem fails.
178 | Chapter 6: Advanced Process Management
Soft real-time systems are more susceptible to jitter. In these systems, the response
time is ideally within the operational delay—often much sooner, sometimes not. Jit-
ter, therefore, is often an excellent surrogate for latency as a performance metric.
Linux’s Real-Time Support
Linux provides applications with soft real-time support via a family of system calls
defined by IEEE Std 1003.1b-1993 (often shortened to POSIX 1993 or POSIX.1b).
Technically speaking, the POSIX standard does not dictate whether the provided
real-time support is soft or hard. In fact, all the POSIX standard really does is
describe several scheduling policies that respect priorities. What sorts of timing con-
straints the operating system enforces on these policies is up to the OS designers.
Over the years, the Linux kernel has gained better and better real-time support, pro-
viding lower and lower latency, and more consistent jitter, without compromising
system performance. Much of this is because improving latency helps many classes
of application, such as desktop and I/O-bound processes, and not just real-time
applications. The improvements are also attributable to the success of Linux in
embedded and real-time systems.
Unfortunately, many of the embedded and real-time modifications that have been
made to the Linux kernel exist only in custom Linux solutions, outside of the main-
stream official kernel. Some of these modifications provide further reductions in
latency, and even hard real-time behavior. The following sections discuss only the
official kernel interfaces and the behavior of the mainstream kernel. Luckily, most
real-time modifications continue to utilize the POSIX interfaces. Ergo, the subse-
quent discussion is also relevant on modified systems.
Linux Scheduling Policies and Priorities
The behavior of the Linux scheduler with respect to a process depends on the pro-
cess’ scheduling policy, also called the scheduling class. In addition to the normal
default policy, Linux provides two real-time scheduling policies. A preprocessor
macro from the header <sched.h> represents each policy: the macros are SCHED_FIFO,
SCHED_RR, and SCHED_OTHER.
Every process possesses a static priority, unrelated to the nice value. For normal
applications, this priority is always 0. For the real-time processes, it ranges from 1 to
99, inclusive. The Linux scheduler always selects the highest-priority process to run
(i.e., the one with the largest numerical static priority value). If a process is running
with a static priority of 50, and a process with a priority of 51 becomes runnable, the
scheduler will immediately preempt the running process, and switch to the newly
runnable process. Conversely, if a process is running with a priority of 50, and a pro-
cess with a priority of 49 becomes runnable, the scheduler will not run it until the
Real-Time Systems | 179
priority-50 process blocks, becoming unrunnable. Because normal processes have a
priority of 0, any real-time process that is runnable will always preempt a normal
process and run.
The first in, first out policy
The first in, first out (FIFO) class is a very simple real-time policy without timeslices.
A FIFO-classed process will continue running so long as no higher-priority process
becomes runnable. The FIFO class is represented by the macro SCHED_FIFO.
As the policy lacks timeslices, its rules of operation are rather simple:
• A runnable FIFO-classed process will always run if it is the highest-priority pro-
cess on the system. Particularly, once a FIFO-classed process becomes runnable,
it will immediately preempt a normal process.
• A FIFO-classed process will continue running until it blocks or calls sched_yield( ),
or until a higher-priority process becomes runnable.
• When a FIFO-classed process blocks, the scheduler removes it from the list of
runnable processes. When it again becomes runnable, it is inserted at the end of
the list of processes at its priority. Thus, it will not run until any other processes
of higher or equal priority cease execution.
• When a FIFO-classed process calls sched_yield( ), the scheduler moves it to the
end of the list of processes at its priority. Thus, it will not run until any other
equal-priority processes cease execution. If the invoking process is the only pro-
cess at its priority, sched_yield( ) will have no effect.
• When a higher-priority process preempts a FIFO-classed process, the FIFO-
classed process remains at the same location in the list of processes for its given
priority. Thus, once the higher-priority process ceases execution, the preempted
FIFO-classed process will continue executing.
• When a process joins the FIFO class, or when a process’ static priority changes,
it is put at the head of the list of processes for its given priority. Consequently, a
newly prioritized FIFO-classed process can preempt an executing process of the
same priority.
Essentially, we can say that FIFO-classed processes always run for as long as they
want, so long as they are the highest-priority processes on the system. The interest-
ing rules pertain to what happens among FIFO-classed processes with the same
priority.
The round-robin policy
The round-robin (RR) class is identical to the FIFO class, except that it imposes addi-
tional rules in the case of processes with the same priority. The macro SCHED_RR
represents this class.
180 | Chapter 6: Advanced Process Management
The scheduler assigns each RR-classed process a timeslice. When an RR-classed pro-
cess exhausts its timeslice, the scheduler moves it to the end of the list of processes at
its priority. In this manner, RR-classed processes of a given priority are scheduled
round-robin amongst themselves. If there is only one process at a given priority, the
RR class is identical to the FIFO class. In such a case, when its timeslice expires, the
process simply resumes execution.
We can think of an RR-classed process as identical to a FIFO-classed process, except
that it additionally ceases execution when it exhausts its timeslice, at which time it
moves to the end of the list of runnable processes at its priority.
Deciding whether to use SCHED_FIFO or SCHED_RR is entirely a question of intra-priority
behavior. The RR class’ timeslices are relevant only among processes of the same pri-
ority. FIFO-classed processes will continue running unabated; RR-classed processes
will schedule amongst themselves at a given priority. In neither case will a lower-
priority process ever run if a higher-priority process exists.
The normal policy
SCHED_OTHER represents the standard scheduling policy, the default nonreal-time
class. All normal-classed processes have a static priority of 0. Consequently, any run-
nable FIFO- or RR-classed process will preempt a running normal-classed process.
The scheduler uses the nice value, discussed earlier, to prioritize processes within the
normal class. The nice value has no bearing on the static priority, which remains 0.
The batch scheduling policy
SCHED_BATCH is the batch or idle scheduling policy. Its behavior is somewhat the antith-
esis of the real-time policies: processes in this class run only when there are no other
runnable processes on the system, even if the other processes have exhausted their
timeslices. This is different from the behavior of processes with the largest nice val-
ues (i.e., the lowest-priority processes) in that eventually such processes will run, as
the higher-priority processes exhaust their timeslices.
Setting the Linux scheduling policy
Processes can manipulate the Linux scheduling policy via sched_getscheduler( ) and
sched_setscheduler( ):
#include <sched.h>
struct sched_param {
/* ... */
int sched_priority;
/* ... */
};
int sched_getscheduler (pid_t pid);
Real-Time Systems | 181
int sched_setscheduler (pid_t pid,
int policy,
const struct sched_param *sp);
A successful call to sched_getscheduler( ) returns the scheduling policy of the pro-
cess represented by pid. If pid is 0, the call returns the invoking process’ scheduling
policy. An integer defined in <sched.h> represents the scheduling policy: the first in,
first out policy is SCHED_FIFO; the round-robin policy is SCHED_RR; and the normal pol-
icy is SCHED_OTHER. On error, the call returns -1 (which is never a valid scheduling
policy), and errno is set as appropriate.
Usage is simple:
int policy;
/* get our scheduling policy */
policy = sched_getscheduler (0);
switch (policy) {
case SCHED_OTHER:
printf ("Policy is normal\n");
break;
case SCHED_RR:
printf ("Policy is round-robin\n");
break;
case SCHED_FIFO:
printf ("Policy is first-in, first-out\n");
break;
case -1:
perror ("sched_getscheduler");
break;
default:
fprintf (stderr, "Unknown policy!\n");
}
A call to sched_setscheduler( ) sets the scheduling policy of the process represented
by pid to policy. Any parameters associated with the policy are set via sp. If pid is 0,
the invoking process’ policy and parameters are set. On success, the call returns 0.
On failure, the call returns -1, and errno is set as appropriate.
The valid fields inside the sched_param structure depend on the scheduling policies
supported by the operating system. The SCHED_RR and SCHED_FIFO policies require one
field, sched_priority, which represents the static priority. SCHED_OTHER does not use
any field, while scheduling policies supported in the future may use new fields.
Portable and legal programs must therefore not make assumptions about the layout
of the structure.
Setting a process’ scheduling policy and parameters is easy:
struct sched_param sp = { .sched_priority = 1 };
int ret;
ret = sched_setscheduler (0, SCHED_RR, &sp);
182 | Chapter 6: Advanced Process Management
if (ret == -1) {
perror ("sched_setscheduler");
return 1;
}
This snippet sets the invoking process’ scheduling policy to round-robin with a static
priority of 1. We presume that 1 is a valid priority—technically, it need not be. We
will discuss how to find the valid priority range for a given policy in an upcoming
section.
Setting a scheduling policy other than SCHED_OTHER requires the CAP_SYS_NICE capabil-
ity. Consequently, the root user typically runs real-time processes. Since the 2.6.12
kernel, the RLIMIT_RTPRIO resource limit allows nonroot users to set real-time poli-
cies up to a certain priority ceiling.
Error codes. On error, four errno values are possible:
EFAULT
The pointer sp points to an invalid or inaccessible region of memory.
EINVAL
The scheduling policy denoted by policy is invalid, or a value set in sp does not
make sense for the given policy (sched_setscheduler( ) only).
EPERM
The invoking process does not have the necessary capabilities.
ESRCH
The value pid does not denote a running process.
Setting Scheduling Parameters
The POSIX-defined sched_getparam( ) and sched_setparam( ) interfaces retrieve and
set the parameters associated with a scheduling policy that has already been set:
#include <sched.h>
struct sched_param {
/* ... */
int sched_priority;
/* ... */
};
int sched_getparam (pid_t pid, struct sched_param *sp);
int sched_setparam (pid_t pid, const struct sched_param *sp);
The sched_getscheduler( ) interface returns only the scheduling policy, not any asso-
ciated parameters. A call to sched_getparam( ) returns via sp the scheduling parame-
ters associated with pid:
Real-Time Systems | 183
struct sched_param sp;
int ret;
ret = sched_getparam (0, &sp);
if (ret == -1) {
perror ("sched_getparam");
return 1;
}
printf ("Our priority is %d\n", sp.sched_priority);
If pid is 0, the call returns the parameters of the invoking process. On success, the
call returns 0. On failure, it returns -1, and sets errno as appropriate.
Because sched_setscheduler( ) also sets any associated scheduling parameters,
sched_setparam( ) is useful only to later modify the parameters:
struct sched_param sp;
int ret;
sp.sched_priority = 1;
ret = sched_setparam (0, &sp);
if (ret == -1) {
perror ("sched_setparam");
return 1;
}
On success, the scheduling parameters of pid are set according to sp, and the call
returns 0. On failure, the call returns -1, and errno is set as appropriate.
If we ran the two preceding snippets in order, we would see the following output:
Our priority is 1
This example again assumes that 1 is a valid priority. It is, but portable applications
should make sure. We’ll look at how to check the range of valid priorities momentarily.
Error codes
On error, four errno values are possible:
EFAULT
The pointer sp points to an invalid or inaccessible region of memory.
EINVAL
A value set in sp does not make sense for the given policy (sched_getparam( )
only).
EPERM
The invoking process does not have the necessary capabilities.
ESRCH
The value pid does not denote a running process.
184 | Chapter 6: Advanced Process Management
Determining the range of valid priorities
Our previous examples have passed hardcoded priority values into the scheduling
system calls. POSIX makes no guarantees about what scheduling priorities exist on a
given system, except to say that there must be at least 32 priorities between the mini-
mum and maximum values. As mentioned earlier in “Linux Scheduling Policies and
Priorities,” Linux implements a range of 1 to 99 inclusive for the two real-time sched-
uling policies. A clean, portable program normally implements its own range of
priority values, and maps them onto the operating system’s range. For instance, if
you want to run processes at four different real-time priority levels, you dynamically
determine the range of priorities and choose four values.
Linux provides two system calls for retrieving the range of valid priority values. One
returns the minimum value and the other returns the maximum:
#include <sched.h>
int sched_get_priority_min (int policy);
int sched_get_priority_max (int policy);
On success, the call sched_get_priority_min( ) returns the minimum, and the call
sched_get_priority_max( ) returns the maximum valid priority associated with the
scheduling policy denoted by policy. Both calls then return 0. Upon failure, the calls
both return -1. The only possible error is if policy is invalid, in which case errno is
set to EINVAL.
Usage is simple:
int min, max;
min = sched_get_priority_min (SCHED_RR);
if (min == -1) {
perror ("sched_get_priority_min");
return 1;
}
max = sched_get_priority_max (SCHED_RR);
if (max == -1) {
perror ("sched_get_priority_max");
return 1;
}
printf ("SCHED_RR priority range is %d - %d\n", min, max);
On a standard Linux system, this snippet yields the following:
SCHED_RR priority range is 1 - 99
As discussed previously, numerically larger priority values denote higher priorities.
To set a process to the highest priority for its scheduling policy, you can do the
following:
Real-Time Systems | 185
/*
* set_highest_priority – set the associated pid's scheduling
* priority to the highest value allowed by its current
* scheduling policy. If pid is zero, sets the current
* process's priority.
*
* Returns zero on success.
*/
int set_highest_priority (pid_t pid)
{
struct sched_param sp;
int policy, max, ret;
policy = sched_getscheduler (pid);
if (policy == -1)
return -1;
max = sched_get_priority_max (policy);
if (max == -1)
return -1;
memset (&sp, 0, sizeof (struct sched_param));
sp.sched_priority = max;
ret = sched_setparam (pid, &sp);
return ret;
}
Programs typically retrieve the system’s minimum or maximum value, and then use
increments of 1 (such as max-1, max-2, etc.) to assign priorities as desired.
sched_rr_get_interval( )
As discussed earlier, SCHED_RR processes behave the same as SCHED_FIFO processes,
except that the scheduler assigns these processes timeslices. When a SCHED_RR pro-
cess exhausts its timeslice, the scheduler moves the process to the end of the run list
for its current priority. In this manner, all SCHED_RR processes of the same priority are
executed in a round-robin rotation. Higher-priority processes (and SCHED_FIFO
processes of the same or higher priority) will always preempt a running SCHED_RR pro-
cess, regardless of whether it has any of its timeslice remaining.
POSIX defines an interface for retrieving the length of a given process’ timeslice:
#include <sched.h>
struct timespec {
time_t tv_sec; /* seconds */
long tv_nsec; /* nanoseconds */
};
int sched_rr_get_interval (pid_t pid, struct timespec *tp);
186 | Chapter 6: Advanced Process Management
A successful call to the awfully named sched_rr_get_interval( ) saves in the
timespec structure pointed at by tp the duration of the timeslice allotted to pid and
returns 0. On failure, the call returns -1, and errno is set as appropriate.
According to POSIX, this function is required to work only with SCHED_RR processes.
On Linux, however, it can retrieve the length of any process’ timeslice. Portable
applications should assume that the function works only with round-robin pro-
cesses; Linux-specific programs may exploit the call as needed. Here’s an example:
struct timespec tp;
int ret;
/* get the current task's timeslice length */
ret = sched_rr_get_interval (0, &tp);
if (ret == -1) {
perror ("sched_rr_get_interval");
return 1;
}
/* convert the seconds and nanoseconds to milliseconds */
printf ("Our time quantum is %.2lf milliseconds\n",
(tp.tv_sec * 1000.0f) + (tp.tv_nsec / 1000000.0f));
If the process is running in the FIFO class, tv_sec and tv_nsec are both 0, denoting
infinity.
Error codes
On error, three errno values are possible:
EFAULT
The memory pointed at by the pointer tp is invalid or inaccessible.
EINVAL
The value pid is invalid (for example, it is negative).
ESRCH
The value pid is valid, but refers to a nonexistent process.
Precautions with Real-Time Processes
Because of the nature of real-time processes, developers should exercise caution
when developing and debugging such programs. If a real-time program goes off the
deep end, the system can become unresponsive. Any CPU-bound loop in a real-time
program—that is, any chunk of code that does not block—will continue running ad
infinitum, so long as no higher-priority real-time processes become runnable.
Consequently, designing real-time programs requires care and attention. Such pro-
grams reign supreme, and can easily bring down the entire system. Here are some
tips and precautions:
Real-Time Systems | 187
• Keep in mind that any CPU-bound loop will run until completion, without inter-
ruption, if there is no higher-priority real-time process on the system. If the loop
is infinite, the system will become unresponsive.
• Because real-time processes run at the expense of everything else on the system,
special attention must be paid to their design. Take care not to starve the rest of
the system of processor time.
• Be very careful with busy waiting. If a real-time process busy-waits for a resource
held by a lower-priority process, the real-time process will busy-wait forever.
• While developing a real-time process, keep a terminal open, running as a real-time
process with a higher priority than the process in development. In an emergency,
the terminal will remain responsive, and allow you to kill the runaway real-time
process. (As the terminal remains idle, waiting for keyboard input, it will not inter-
fere with the other real-time process.)
• The chrt utility, part of the util-linux package of tools, makes it easy to retrieve
and set the real-time attributes of other processes. This tool makes it easy to
launch arbitrary programs in a real-time scheduling class, such as the aforemen-
tioned terminal, or change the real-time priorities of existing applications.
Determinism
Real-time processes are big on determinism. In real-time computing, an action is
deterministic if, given the same input, it always produces the same result in the same
amount of time. Modern computers are the very definition of something that is not
deterministic: multiple levels of caches (which incur hits or misses without predict-
ability), multiple processors, paging, swapping, and multitasking wreak havoc on
any estimate of how long a given action will take. Sure, we have reached a point
where just about every action (modulo hard drive access) is “incredibly fast,” but
simultaneously, modern systems have also made it hard to pinpoint exactly how long
a given operation will take.
Real-time applications often try to limit unpredictability in general, and worst-case
delays specifically. The following sections discuss two methods that are used to this
end.
Prefaulting data and locking memory
Picture this: the hardware interrupt from the custom incoming ICBM monitor hits,
and the device’s driver quickly copies data from the hardware into the kernel. The
driver notes that a process is asleep, blocked on the hardware’s device node, waiting
for data. The driver tells the kernel to wake up the process. The kernel, noting that
this process is running with a real-time scheduling policy and a high priority, imme-
diately preempts the currently running process and shifts into overdrive, determined
to schedule the real-time process immediately. The scheduler switches to running the
188 | Chapter 6: Advanced Process Management
real-time process, and context-switches into its address space. The process is now
running. The whole ordeal took 0.3 ms, well within the 1 ms worst-case acceptable
latency period.
Now, in user space, the real-time process notes the incoming ICBM, and begins pro-
cessing its trajectory. With the ballistics calculated, the real-time process initiates the
deployment of an anti-ballistic missile system. Only another 0.1 ms have passed—
quick enough to deploy the ABM response and save lives. But—oh no!—the ABM
code has been swapped to disk. A page fault occurs, the processor switches back to
kernel mode, and the kernel initiates hard disk I/O to retrieve the swapped-out data.
The scheduler puts the process to sleep until the page fault is serviced. Several sec-
onds elapse. It is too late.
Clearly, paging and swapping introduce quite undeterministic behavior that can
wreak havoc on a real-time process. To prevent this catastrophe, a real-time applica-
tion will often “lock” or “hardwire” all of the pages in its address space into physical
memory, prefaulting them into memory, and preventing them from being swapped
out. Once the pages are locked into memory, the kernel will never swap them out to
disk. Any accesses of the pages will not cause page faults. Most real-time applica-
tions lock some or all of their pages into physical memory.
Linux provides interfaces for both prefaulting and locking data. Chapter 4 discussed
interfaces for prefaulting data into physical memory. Chapter 8 will discuss inter-
faces for locking data into physical memory.
CPU affinity and real-time processes
A second concern of real-time applications is multitasking. Although the Linux
kernel is preemptive, its scheduler is not always able to immediately reschedule one
process in favor of another. Sometimes, the currently running process is executing
inside of a critical region in the kernel, and the scheduler cannot preempt it until it
exits that region. If the process that is waiting to run is real-time, this delay may be
unacceptable, quickly overrunning the operational deadline.
Ergo, multitasking introduces indeterminism similar in nature to the unpredictabil-
ity associated with paging. The solution with respect to multitasking is the same:
eliminate it. Of course, chances are you cannot simply abolish all other processes. If
that were possible in your environment, you probably would not need Linux to begin
with—a simple custom operating system would suffice. If, however, your system has
multiple processors, you can dedicate one or more of those processors to your real-
time process or processes. In effect, you can shield the real-time processes from
multitasking.
Real-Time Systems | 189
We discussed system calls for manipulating a process’ CPUaffinity earlier in this
chapter. A potential optimization for real-time applications is to reserve one proces-
sor for each real-time process, and let all other processes time-share on the remaining
processor.
The simplest way to achieve this is to modify Linux’s init program, SysVinit,* to do
something similar to the following before it begins the boot process:
cpu_set_t set;
int ret;
CPU_ZERO (&set); /* clear all CPUs */
ret = sched_getaffinity (0, sizeof (cpu_set_t), &set);
if (ret == -1) {
perror ("sched_getaffinity");
return 1;
}
CPU_CLR (1, &set); /* forbid CPU #1 */
ret = sched_setaffinity (0, sizeof (cpu_set_t), &set);
if (ret == -1) {
perror ("sched_setaffinity");
return 1;
}
This snippet grabs init’s current set of allowed processors, which we expect is all of
them. It then removes one processor, CPU#1, from the set and updates the list of
allowed processors.
Because the set of allowed processors is inherited from parent to child, and init is the
super-parent of all processes, all of the system’s processes will run with this set of
allowed processors. Consequently, no processes will ever run on CPU #1.
Next, modify your real-time process to run only on CPU #1:
cpu_set_t set;
int ret;
CPU_ZERO (&set); /* clear all CPUs */
CPU_CLR (1, &set); /* forbid CPU #1 */
ret = sched_setaffinity (0, sizeof (cpu_set_t), &set);
if (ret == -1) {
perror ("sched_setaffinity");
return 1;
}
The result is that your real-time process runs only on CPU#1 and all other pro-
cesses run on the other processors.
* The SysVinit source is located at ftp://ftp.cistron.nl/pub/people/miquels/sysvinit/. It is licensed under the GNU
General Public License v2.
190 | Chapter 6: Advanced Process Management
Resource Limits
The Linux kernel imposes several resource limits on processes. These resource limits
place hard ceilings on the amount of kernel resources that a process can consume—
that is, the number of open files, pages of memory, pending signals, and so on. The
limits are strictly enforced; the kernel will not allow an action that places a process’
resource consumption over a hard limit. For example, if opening a file would cause a
process to have more open files than allowed by the applicable resource limit, the
open( ) invocation will fail.*
Linux provides two system calls for manipulating resource limits. POSIX standard-
ized both interfaces, but Linux supports several limits in addition to those dictated
by the standard. Limits can be checked with getrlimit( ) and set with setrlimit( ):
#include <sys/time.h>
#include <sys/resource.h>
struct rlimit {
rlim_t rlim_cur; /* soft limit */
rlim_t rlim_max; /* hard limit */
};
int getrlimit (int resource, struct rlimit *rlim);
int setrlimit (int resource, const struct rlimit *rlim);
Integer constants, such as RLIMIT_CPU, represent the resources. The rlimit structure
represents the actual limits. The structure defines two ceilings: a soft limit, and a hard
limit. The kernel enforces soft resource limits on processes, but a process may freely
change its soft limit to any value from 0 up to and including the hard limit. A pro-
cess without the CAP_SYS_RESOURCE capability (i.e., any nonroot process) can only
lower its hard limit. An unprivileged process can never raise its hard limit, not even
to a previously higher value; lowering the hard limit is irreversible. A privileged pro-
cess can set the hard limit to any valid value.
What the limits actually represent depends on the resource in question. If resource is
RLIMIT_FSIZE, for example, the limit represents the maximum size of a file that a pro-
cess can create, in bytes. In this case, if rlim_cur is 1,024, a process cannot create or
extend a file to a size greater than one kilobyte.
All of the resource limits have two special values: 0 and infinity. The former disables
use of the resource altogether. For example, if RLIMIT_CORE is 0, the kernel will never
create a core file. Conversely, the latter removes any limit on the resource. The ker-
nel denotes infinity by the special value RLIM_INFINITY, which happens to be -1 (this can
cause some confusion, as -1 is also the return value indicating error). If RLIMIT_CORE is
infinity, the kernel will create core files of any size.
* In which case the call will set errno to EMFILE, indicating that the process hit the resource limit on the maxi-
mum number of open files. Chapter 2 discusses the open( ) system call.
Resource Limits | 191
The function getrlimit( ) places the current hard and soft limits on the resource
denoted by resource in the structure pointed at by rlim. On success, the call returns
0. On failure, the call returns -1, and sets errno as appropriate.
Correspondingly, the function setrlimit( ) sets the hard and soft limits associated
with resource to the values pointed at by rlim. On success, the call returns 0, and the
kernel updates the resource limits as requested. On failure, the call returns -1, and
sets errno as appropriate.
The Limits
Linux currently provides 15 resource limits:
RLIMIT_AS
Limits the maximum size of a process’ address space, in bytes. Attempts to
increase the size of the address space past this limit—via calls such as mmap( )
and brk( )—will fail, and return ENOMEM. If the process’ stack, which automati-
cally grows as needed, expands beyond this limit, the kernel sends the process
the SIGSEGV signal. This limit is usually RLIM_INFINITY.
RLIMIT_CORE
Dictates the maximum size of core files, in bytes. If nonzero, core files larger
than this limit are truncated to the maximum size. If 0, core files are never
created.
RLIMIT_CPU
Dictates the maximum CPUtime that a process can consume, in seconds. If a
process runs for longer than this limit, the kernel sends it a SIGXCPU signal, which
processes may catch and handle. Portable programs should terminate on receipt
of this signal, as POSIX leaves undefined what action the kernel may take next.
Some systems may terminate the process if it continues to run. Linux, however,
allows the process to continue executing, and continues sending SIGXCPU signals
at one second intervals. Once the process reaches the hard limit, it is sent a
SIGKILL and terminated.
RLIMIT_DATA
Controls the maximum size of a process’ data segment and heap, in bytes.
Attempts to enlarge the data segment beyond this limit via brk( ) will fail and
return ENOMEM.
RLIMIT_FSIZE
Specifies the maximum file size that a process may create, in bytes. If a process
expands a file beyond this size, the kernel sends the process a SIGXFSZ signal. By
default, this signal terminates the process. A process may, however, elect to
catch and handle this signal, in which case, the offending system call fails, and
returns EFBIG.
192 | Chapter 6: Advanced Process Management
RLIMIT_LOCKS
Controls the maximum number of file locks that a process may hold (see
Chapter 7 for a discussion of file locks). Once this limit is reached, further
attempts to acquire additional file locks should fail, and return ENOLCK. Linux
kernel 2.4.25, however, removed this functionality. In current kernels, this limit
is settable, but has no effect.
RLIMIT_MEMLOCK
Specifies the maximum number of bytes of memory that a process without the
CAP_SYS_IPC capability (effectively, a nonroot process) can lock into memory via
mlock( ), mlockall( ), or shmctl( ). If this limit is exceeded, these calls fail, and
return EPERM. In practice, the effective limit is rounded down to an integer multi-
ple of pages. Processes possessing CAP_SYS_IPC can lock any number of pages
into memory, and this limit has no effect. Before kernel 2.6.9, this limit was the
maximum that a process with CAP_SYS_IPC could lock into memory, and unprivi-
leged processes could not lock any pages whatsoever. This limit is not part of
POSIX; BSD introduced it.
RLIMIT_MSGQUEUE
Specifies the maximum number of bytes that a user may allocate for POSIX mes-
sage queues. If a newly created message queue would exceed this limit, mq_open( )
fails, and returns ENOMEM. This limit is not part of POSIX; it was added in kernel
2.6.8 and is Linux-specific.
RLIMIT_NICE
Specifies the maximum value to which a process can lower its nice value (raise
its priority). As discussed earlier in this chapter, normally processes can only
raise their nice values (lower their priorities). This limit allows the administrator
to impose a maximum level (nice value floor) to which processes may legally
raise their priorities. Because nice values may be negative, the kernel interprets
the value as 20 - rlim_cur. Thus, if this limit is set to 40, a process can lower its
nice value to the minimum value of –20 (the highest priority). Kernel 2.6.12
introduced this limit.
RLIMIT_NOFILE
Specifies one greater than the maximum number of file descriptors that a process
may hold open. Attempts to surpass this limit result in failure and the applicable
system call returning EMFILE. This limit is also specifiable as RLIMIT_OFILE, which
is BSD’s name for it.
RLIMIT_NPROC
Specifies the maximum number of processes that the user may have running on
the system at any given moment. Attempts to surpass this limit result in failure,
and fork( ), returning EAGAIN. This limit is not part of POSIX; BSD introduced it.
RLIMIT_RSS
Specifies the maximum number of pages that a process may have resident in
memory (known as the resident set size, or RSS). Only early 2.4 kernels enforced
Resource Limits | 193
this limit. Current kernels allow the setting of this limit, but it is not enforced.
This limit is not part of POSIX; BSD introduced it.
RLIMIT_RTPRIO
Specifies the maximum real-time priority level a process without the CAP_SYS_NICE
capability (effectively, nonroot processes) may request. Normally, unprivileged
processes may not request any real-time scheduling class. This limit is not part of
POSIX; it was added in kernel 2.6.12, and is Linux-specific.
RLIMIT_SIGPENDING
Specifies the maximum number of signals (standard and real-time) that may be
queued for this user. Attempts to queue additional signals fail, and system calls
such as sigqueue( ) return EAGAIN. Note that it is always possible, regardless of
this limit, to queue one instance of a not-yet-queued signal. Therefore, it is
always possible to deliver to the process a SIGKILL or SIGTERM. This limit is not
part of POSIX; it is Linux-specific.
RLIMIT_STACK
Denotes the maximum size of a process’ stack, in bytes. Surpassing this limit
results in the delivery of a SIGSEGV.
The kernel stores the limits on a per-user basis. In other words, all processes run by
the same user will have the same soft and hard limits for any given resource. The lim-
its themselves, however, may describe per-process (not per-user) caps. For example,
the kernel maintains the value of RLIMIT_NOFILE on a per-user basis; by default, it is
1024. This limit, however, dictates the maximum number of files that each process
can open, not the number the user can have open overall. Note that this does not
mean that the limit can be configured individually for each of the user’s processes—
if one process changes RLIMIT_NOFILE’s soft limit, the change will apply to all
processes owned by that user.
Default limits
The default limits available to your process depend on three variables: the initial soft
limit, the initial hard limit, and your system administrator. The kernel dictates the
initial hard and soft limits; Table 6-1 lists them. The kernel sets these limits on the
init process, and because children inherit the limits of their parents, all subsequent
processes inherit the soft and hard limits of init.
Table 6-1. Default soft and hard resource limits
Resource limit Soft limit Hard limit
RLIMIT_AS RLIM_INFINITY RLIM_INFINITY
RLIMIT_CORE 0 RLIM_INFINITY
RLIMIT_CPU RLIM_INFINITY RLIM_INFINITY
RLIMIT_DATA RLIM_INFINITY RLIM_INFINITY
RLIMIT_FSIZE RLIM_INFINITY RLIM_INFINITY
194 | Chapter 6: Advanced Process Management
Two things can change these default limits:
• Any process is free to increase a soft limit to any value from 0 to the hard limit,
or to decrease a hard limit. Children will inherit these updated limits during a
fork.
• A privileged process is free to set a hard limit to any value. Children will inherit
these updated limits during a fork.
It is unlikely that a root process in a regular process’ lineage will change any hard
limits. Consequently, the first item is a much more likely source of limit changes
than the second. Indeed, the actual limits presented to a process are generally set by
the user’s shell, which the system administrator can set up to provide various limits.
In the Bourne-again shell (bash), for example, the administrator accomplishes this
via the ulimit command. Note that the administrator need not lower values; he can
also raise soft limits to the hard limits, providing users with saner defaults. This is
often done with RLIMIT_STACK, which is set to RLIM_INFINITY on many systems.
Setting and Retrieving Limits
With the explanations of the various resource limits behind us, let’s look at retriev-
ing and setting limits. Retrieving a resource limit is quite simple:
struct rlimit rlim;
int ret;
/* get the limit on core sizes */
ret = getrlimit (RLIMIT_CORE, &rlim);
if (ret == -1) {
perror ("getrlimit");
return 1;
}
printf ("RLIMIT_CORE limits: soft=%ld hard=%ld\n",
rlim.rlim_cur, rlim.rlim_max);
RLIMIT_LOCKS RLIM_INFINITY RLIM_INFINITY
RLIMIT_MEMLOCK 8 pages 8 pages
RLIMIT_MSGQUEUE 800 KB 800 KB
RLIMIT_NICE 0 0
RLIMIT_NOFILE 1024 1024
RLIMIT_NPROC 0 (implies no limit) 0 (implies no limit)
RLIMIT_RSS RLIM_INFINITY RLIM_INFINITY
RLIMIT_RTPRIO0 0
RLIMIT_SIGPENDING 0 0
RLIMIT_STACK 8 MB RLIM_INFINITY
Table 6-1. Default soft and hard resource limits (continued)
Resource limit Soft limit Hard limit
Resource Limits | 195
Compiling this snippet in a larger program and running it yields the following:
RLIMIT_CORE limits: soft=0 hard=-1
We have a soft limit of 0, and a hard limit of infinity (-1 denotes RLIM_INFINITY).
Therefore, we can set a new soft limit of any size. This example sets the maximum
core size to 32 MB:
struct rlimit rlim;
int ret;
rlim.rlim_cur = 32 * 1024 * 1024; /* 32 MB */
rlim.rlim_max = RLIM_INFINITY; /* leave it alone */
ret = setrlimit (RLIMIT_CORE, &rlim);
if (ret == -1) {
perror ("setrlimit");
return 1;
}
Error codes
On error, three errno codes are possible:
EFAULT
The memory pointed at by rlim is invalid or inaccessible.
EINVAL
The value denoted by resource is invalid, or rlim.rlim_cur is greater than
rlim.rlim_max (setrlimit( ) only).
EPERM
The caller did not possess CAP_SYS_RESOURCE, but tried to raise the hard limit.
196
Chapter 7CHAPTER 7
File and Directory
Management
In Chapters 2, 3, and 4, we covered an abundance of approaches to file I/O. In this
chapter, we’ll revisit files, this time focusing not on reading from or writing to them,
but rather on manipulating and managing them and their metadata.
Files and Their Metadata
As discussed in Chapter 1, each file is referenced by an inode, which is addressed by a
filesystem-unique numerical value known as an inode number. An inode is both a
physical object located on the disk of a Unix-style filesystem, and a conceptual entity
represented by a data structure in the Linux kernel. The inode stores the metadata
associated with a file, such as the file’s access permissions, last access timestamp,
owner, group, and size, as well as the location of the file’s data.
You can obtain the inode number for a file using the -i flag to the ls command:
$ ls -i
1689459 Kconfig 1689461 main.c 1680144 process.c 1689464 swsusp.c
1680137 Makefile 1680141 pm.c 1680145 smp.c 1680149 user.c
1680138 console.c 1689462 power.h 1689463 snapshot.c
1689460 disk.c 1680143 poweroff.c 1680147 swap.c
This output shows that, for example, disk.c has an inode number of 1689460. On
this particular filesystem, no other file will have this inode number. On a different
filesystem, however, we can make no such guarantees.
The Stat Family
Unix provides a family of functions for obtaining the metadata of a file:
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
int stat (const char *path, struct stat *buf);
int fstat (int fd, struct stat *buf);
int lstat (const char *path, struct stat *buf);
Files and Their Metadata | 197
Each of these functions returns information about a file. stat( ) returns information
about the file denoted by the path, path, while fstat( ) returns information about
the file represented by the file descriptor fd. lstat( ) is identical to stat( ), except
that in the case of a symbolic link, lstat( ) returns information about the link itself
and not the target file.
Each of these functions stores information in a stat structure, which is provided by
the user. The stat structure is defined in <bits/stat.h>, which is included from
<sys/stat.h>:
struct stat {
dev_t st_dev; /* ID of device containing file */
ino_t st_ino; /* inode number */
mode_t st_mode; /* permissions */
nlink_t st_nlink; /* number of hard links */
uid_t st_uid; /* user ID of owner */
gid_t st_gid; /* group ID of owner */
dev_t st_rdev; /* device ID (if special file) */
off_t st_size; /* total size in bytes */
blksize_t st_blksize; /* blocksize for filesystem I/O */
blkcnt_t st_blocks; /* number of blocks allocated */
time_t st_atime; /* last access time */
time_t st_mtime; /* last modification time */
time_t st_ctime; /* last status change time */
};
In more detail, the fields are as follows:
• The st_dev field describes the device node on which the file resides (we will
cover device nodes later in this chapter). If the file is not backed by a device—for
example, if it resides on an NFS mount—this value is 0.
• The st_ino field provides the file’s inode number.
• The st_mode field provides the file’s mode bytes. Chapters 1 and 2 covered mode
bytes and permissions.
• The st_nlink field provides the number of hard links pointing at the file. Every
file has at least one hard link.
• The st_uid field provides the user ID of the user who owns the file.
• The st_gid field provides the group ID of the group who owns the file.
• If the file is a device node, the st_rdev field describes the device that this file
represents.
• The st_size field provides the size of the file, in bytes.
• The st_blksize field describes the preferred block size for efficient file I/O. This
value (or an integer multiple) is the optimal block size for user-buffered I/O (see
Chapter 3).
• The st_blocks field provides the number of filesystem blocks allocated to the
file. This value will be smaller than the value provided by st_size if the file has
holes (that is, if the file is a sparse file).
198 | Chapter 7: File and Directory Management
• The st_atime field contains the last file access time. This is the most recent time
at which the file was accessed (for example, by read( ) or execle( )).
• The st_mtime field contains the last file modification time—that is, the last time
the file was written to.
• The st_ctime field contains the last file change time. This is often misunderstood
to be the file creation time, which is not preserved on Linux, or other Unix-style
systems. The field actually describes the last time that the file’s metadata (for
example, its owner or permissions) was changed.
On success, all three calls return 0, and store the file’s metadata in the provided stat
structure. On error, they return -1, and set errno to one of the following:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path (stat( ) and lstat( ) only).
EBADF
fd is invalid (fstat( ) only).
EFAULT
path or buf is an invalid pointer.
ELOOP
path contains too many symbolic links (stat( ) and lstat( ) only).
ENAMETOOLONG
path is too long (stat( ) and lstat( ) only).
ENOENT
A component in path does not exist (stat( ) and lstat( ) only).
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in path is not a directory (stat( ) and lstat( ) only).
The following program uses stat( ) to retrieve the size of a file provided on the com-
mand line:
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
#include <stdio.h>
int main (int argc, char *argv[])
{
struct stat sb;
int ret;
if (argc < 2) {
fprintf (stderr,
"usage: %s <file>\n", argv[0]);
Files and Their Metadata | 199
return 1;
}
ret = stat (argv[1], &sb);
if (ret) {
perror ("stat");
return 1;
}
printf ("%s is %ld bytes\n",
argv[1], sb.st_size);
return 0;
}
Here is the result of running the program on its own source file:
$ ./stat stat.c
stat.c is 392 bytes
This snippet, in turn, uses fstat( ) to check whether an already opened file is on a
physical (as opposed to a network) device:
/*
* is_on_physical_device – returns a positive
* integer if 'fd' resides on a physical device,
* 0 if the file resides on a nonphysical or
* virtual device (e.g., on an NFS mount), and
* -1 on error.
*/
int is_on_physical_device (int fd)
{
struct stat sb;
int ret;
ret = fstat (fd, &sb);
if (ret) {
perror ("fstat");
return -1;
}
return gnu_dev_major (sb.st_dev);
}
Permissions
While the stat calls can be used to obtain the permission values for a given file, two
other system calls set those values:
#include <sys/types.h>
#include <sys/stat.h>
int chmod (const char *path, mode_t mode);
int fchmod (int fd, mode_t mode);
200 | Chapter 7: File and Directory Management
Both chmod( ) and fchmod( ) set a file’s permissions to mode. With chmod( ), path
denotes the relative or absolute pathname of the file to modify. For fchmod( ), the file
is given by the file descriptor fd.
The legal values for mode, represented by the opaque mode_t integer type, are the same as
those returned by the st_mode field in the stat structure. Although the values are simple
integers, their meanings are specific to each Unix implementation. Consequently,
POSIX defines a set of constants that represent the various permissions (see “Permis-
sions of New Files” in Chapter 2 for full details). These constants can be binary-ORed
together to form the legal values for mode. For example, (S_IRUSR | S_IRGRP) sets the
file’s permissions as both owner- and group-readable.
To change a file’s permissions, the effective ID of the process calling chmod( ) or
fchmod( ) must match the owner of the file, or the process must have the CAP_FOWNER
capability.
On success, both calls return 0. On failure, both calls return -1, and set errno to one
of the following error values:
EACCESS
The invoking process lacked search permission for a component in path (chmod( )
only).
EBADF
The file descriptor fd is invalid (fchmod( ) only).
EFAULT
path is an invalid pointer (chmod( ) only).
EIO
An internal I/O error occurred on the filesystem. This is a very bad error to
encounter; it could indicate a corrupt disk or filesystem.
ELOOP
The kernel encountered too many symbolic links while resolving path (chmod( )
only).
ENAMETOOLONG
path is too long (chmod( ) only).
ENOENT
path does not exist (chmod( ) only).
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in path is not a directory (chmod( ) only).
Files and Their Metadata | 201
EPERM
The effective ID of the invoking process does not match the owner of the file,
and the process lacks the CAP_FOWNER capability.
EROFS
The file resides on a read-only filesystem.
This code snippet sets the file map.png to owner-readable and -writable:
int ret;
/*
* Set 'map.png' in the current directory to
* owner-readable and -writable. This is the
* same as 'chmod 600 ./map.png'.
*/
ret = chmod ("./map.png", S_IRUSR | S_IWUSR);
if (ret)
perror ("chmod");
This code snippet does the same thing, assuming that fd represents the open file
map.png:
int ret;
/*
* Set the file behind 'fd' to owner-readable
* and -writable.
*/
ret = fchmod (fd, S_IRUSR | S_IWUSR);
if (ret)
perror ("fchmod");
Both chmod( ) and fchmod( ) are available on all modern Unix systems. POSIX
requires the former, and makes the latter optional.
Ownership
In the stat structure, the st_uid and st_gid fields provide the file’s owner and group,
respectively. Three system calls allow a user to change those two values:
#include <sys/types.h>
#include <unistd.h>
int chown (const char *path, uid_t owner, gid_t group);
int lchown (const char *path, uid_t owner, gid_t group);
int fchown (int fd, uid_t owner, gid_t group);
chown( ) and lchown( ) set the ownership of the file specified by the path path. They
have the same effect, unless the file is a symbolic link: the former follows symbolic
links and changes the ownership of the link target rather than the link itself, while
202 | Chapter 7: File and Directory Management
lchown( ) does not follow symbolic links and therefore changes the ownership of the
symbolic link file instead. fchown( ) sets the ownership of the file represented by the
file descriptor fd.
On success, all three calls set the file’s owner to owner, set the file’s group to group,
and return 0. If either the owner or the group field is -1, that value is not set. Only a
process with the CAP_CHOWN capability (usually a root process) may change the owner
of a file. The owner of a file can change the file’s group to any group to which the
user is a member; processes with CAP_CHOWN can change the file’s group to any value.
On failure, the calls return -1, and set errno to one of the following values:
EACCESS
The invoking process lacks search permission for a component in path (chown( )
and lchown( ) only).
EBADF
fd is invalid (fchown( ) only).
EFAULT
path is invalid (chown( ) and lchown( ) only).
EIO
There was an internal I/O error (this is bad).
ELOOP
The kernel encountered too many symbolic links in resolving path (chown( ) and
lchown( ) only).
ENAMETOOLONG
path is too long (chown( ) and lchown( ) only).
ENOENT
The file does not exist.
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in path is not a directory (chown( ) and lchown( ) only).
EPERM
The invoking process lacked the necessary rights to change the owner or the
group as requested.
EROFS
The filesystem is read-only.
This code snippet changes the group of the file manifest.txt in the current working
directory to officers. For this to succeed, the invoking user either must possess the
CAP_CHOWN capability or must be kidd and in the officers group:
struct group *gr;
int ret;
Files and Their Metadata | 203
/*
* getgrnam( ) returns information on a group
* given its name.
*/
gr = getgrnam ("officers");
if (!gr) {
/* likely an invalid group */
perror ("getgrnam");
return 1;
}
/* set manifest.txt's group to 'officers' */
ret = chmod ("manifest.txt", -1, gr->gr_gid);
if (ret)
perror ("chmod");
Before invocation, the file’s group is crew:
$ ls –l
-rw-r--r-- 1 kidd crew 13274 May 23 09:20 manifest.txt
After invocation, the file is for the sole privilege of the officers:
$ ls –l
-rw-r--r-- 1 kidd officers 13274 May 23 09:20 manifest.txt
The file’s owner, kidd, is not changed because the code snippet passed -1 for uid.
This function sets the file represented by fd to root ownership and group:
/*
* make_root_owner - changes the owner and group of the file
* given by 'fd' to root. Returns 0 on success and -1 on
* failure.
*/
int make_root_owner (int fd)
{
int ret;
/* 0 is both the gid and the uid for root */
ret = fchown (fd, 0, 0);
if (ret)
perror ("fchown");
return ret;
}
The invoking process must have the CAP_CHOWN capability. As is par for the course
with capabilities, this generally means that it must be owned by root.
Extended Attributes
Extended attributes, also called xattrs, provide a mechanism for permanently associ-
ating key/value pairs with files. In this chapter, we have already discussed all sorts of
key/value metadata associated with files: the file’s size, owner, last modification
204 | Chapter 7: File and Directory Management
timestamp, and so on. Extended attributes allow existing filesystems to support new
features that weren’t anticipated in their original designs, such as mandatory access
controls for security. What makes extended attributes interesting is that user-space
applications may arbitrarily create, read from, and write to the key/value pairs.
Extended attributes are filesystem-agnostic, in the sense that applications use a stan-
dard interface for manipulating them; the interface is not specific to any filesystem.
Applications can thus use extended attributes without concern for what filesystem
the files reside on, or how the filesystem internally stores the keys and values. Still,
the implementation of extended attributes is very filesystem-specific. Different file-
systems store extended attributes in quite different ways, but the kernel hides these
differences, abstracting them away behind the extended attribute interface.
The ext3 filesystem, for example, stores a file’s extended attributes in empty space in
the file’s inode. * This feature makes reading extended attributes very fast. Because
the filesystem block containing the inode is read off the disk and into memory when-
ever an application accesses a file, the extended attributes are “automatically” read
into memory, and can be accessed without any additional overhead.
Other filesystems, such as FAT and minixfs, do not support extended attributes at
all. These filesystems return ENOTSUP when extended attribute operations are invoked
on their files.
Keys and values
A unique key identifies each extended attribute. Keys must be valid UTF-8. They
take the form namespace.attribute. Every key must be fully qualified; that is, it must
begin with a valid namespace, followed by a period. An example of a valid key name is
user.mime_type; this key is in the user namespace with the attribute name mime_type.
A key may be defined or undefined. If a key is defined, its value may be empty or non-
empty. That is, there is a difference between an undefined key, and a defined key
with no assigned value. As we shall see, this means a special interface is required for
removing keys (assigning them an empty value is not sufficient).
The value associated with a key, if nonempty, may be any arbitrary array of bytes.
Because the value is not necessarily a string, it need not be null-terminated, although
null-termination certainly makes sense if you choose to store a C string as a key’s
value. Since the values are not guaranteed to be null-terminated, all operations on
extended attributes require the size of the value. When reading an attribute, the ker-
nel provides the size; when writing an attribute, you must provide the size.
* Until the inode runs out of space, of course. Then ext3 stores extended attributes in additional filesystem
blocks. Older versions of ext3 lacked this in-inode extended attribute feature.
Files and Their Metadata | 205
Linux does not enforce any limits on the number of keys, the length of a key, the size
of a value, or the total space that can be consumed by all of the keys and values asso-
ciated with a file. Filesystems, however, have practical limits. These limits are usually
manifested as constraints on the total size of all of the keys, and values associated
with a given file.
With ext3, for example, all extended attributes for a given file must fit within the
slack space in the file’s inode, and up to one additional filesystem block. (Older ver-
sions of ext3 were limited to the one filesystem block, without the in-inode storage.)
This equates to a practical limit of about 1 KB to 8 KB per file, depending on the size
of the filesystem’s blocks. XFS, in contrast, has no practical limits. Even with ext3,
however, these limits are usually not an issue, as most keys and values are short text
strings. Nonetheless, keep them in mind—think twice before storing the entire revi-
sion control history of a project in a file’s extended attributes!
Extended attribute namespaces
The namespaces associated with extended attributes are more than just organiza-
tional tools. The kernel enforces different access policies depending on the
namespace.
Linux currently defines four extended attribute namespaces, and may define more in
the future. The current four are as follows:
system
The system namespace is used to implement kernel features that utilize extended
attributes, such as access control lists (ACLs). An example of an extended
A Better Way to Store MIME Types
GUI file managers, such as GNOME’s Nautilus, behave differently for files of varying
types: they offer unique icons, different default click behavior, special lists of opera-
tions to perform, and so on. To accomplish this, the file manager has to know the
format of each file. To determine the format, filesystems such as Windows simply look
at the file’s extension. For reasons of both tradition and security, however, Unix sys-
tems tend to inspect the file and interpret its type. This process is called MIME type
sniffing.
Some file managers generate this information on the fly; others generate the informa-
tion once and then cache it. Those that cache the information tend to put it in a custom
database. The file manager must work to keep this database in sync with the files,
which can change without the file manager’s knowledge. A better approach is to jetti-
son the custom database and store such metadata in extended attributes: these are
easier to maintain, faster to access, and readily accessible by any application.
206 | Chapter 7: File and Directory Management
attribute in this namespace is system.posix_acl_access. Whether users can read
from or write to these attributes depends on the security module in place.
Assume at worst that no user (including root) can even read these attributes.
security
The security namespace is used to implement security modules, such as SELinux.
Whether user-space applications can access these attributes depends, again, on
the security module in place. By default, all processes can read these attributes,
but only processes with the CAP_SYS_ADMIN capability can write to them.
trusted
The trusted namespace stores restricted information in user space. Only pro-
cesses with the CAP_SYS_ADMIN capability can read from or write to these
attributes.
user
The user namespace is the standard namespace for use by regular processes. The
kernel controls access to this namespace via the normal file permission bits. To
read the value from an existing key, a process must have read access to the given
file. To create a new key, or to write a value to an existing key, a process must
have write access to the given file. You can assign extended attributes in the user
namespace only to regular files, not to symbolic links or device files. When
designing a user-space application that uses extended attributes, this is likely the
namespace you want.
Extended attribute operations
POSIX defines four operations that applications may perform on a given file’s
extended attributes:
• Given a file and a key, return the corresponding value.
• Given a file, a key, and a value, assign that value to the key.
• Given a file, return a list of all of the file’s assigned extended attribute keys.
• Given a file and a key, remove that extended attribute from the file.
For each operation, POSIX provides three system calls:
• A version that operates on a given pathname; if the path refers to a symbolic
link, the target of the link is operated upon (the usual behavior).
• A version that operates on a given pathname; if the path refers to a symbolic
link, the link itself is operated upon (the standard l variant of a system call).
• A version that operates on a file descriptor (the standard f variant).
In the following subsections, we will cover all 12 permutations.
Retrieving an extended attribute. The simplest operation is returning the value of an
extended attribute from a file, given the key:
Files and Their Metadata | 207
#include <sys/types.h>
#include <attr/xattr.h>
ssize_t getxattr (const char *path, const char *key,
void *value, size_t size);
ssize_t lgetxattr (const char *path, const char *key,
void *value, size_t size);
ssize_t fgetxattr (int fd, const char *key,
void *value, size_t size);
A successful call to getxattr( ) stores the extended attribute with name key from the
file path in the provided buffer value, which is size bytes in length. It returns the
actual size of the value.
If size is 0, the call returns the size of the value without storing it in value. Thus,
passing 0 allows applications to determine the correct size for the buffer in which to
store the key’s value. Given this size, applications can then allocate or resize the
buffer as needed.
lgetxattr( ) behaves the same as getxattr( ), unless path is a symbolic link, in which
case it returns extended attributes from the link itself rather than the target of the
link. Recall from the previous section that attributes in the user namespace cannot be
applied to symbolic links—thus, this call is rarely used.
fgetxattr( ) operates on the file descriptor fd; otherwise, it behaves the same as
getxattr( ).
On error, all three calls return -1, and set errno to one of the following values:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path (getxattr( ) and lgetxattr( ) only).
EBADF
fd is invalid (fgetxattr( ) only).
EFAULT
path, key, or value is an invalid pointer.
ELOOP
path contains too many symbolic links (getxattr( ) and lgetxattr( ) only).
ENAMETOOLONG
path is too long (getxattr( ) and lgetxattr( ) only).
ENOATTR
The attribute key does not exist, or the process does not have access to the
attribute.
ENOENT
A component in path does not exist (getxattr( ) and lgetxattr( ) only).
ENOMEM
There is insufficient memory available to complete the request.
208 | Chapter 7: File and Directory Management
ENOTDIR
A component in path is not a directory (getxattr( ) and lgetxattr( ) only).
ENOTSUP
The filesystem on which path or fd resides does not support extended attributes.
ERANGE
size is too small to hold the value of key. As previously discussed, the call may
be reissued with size set to 0; the return value will indicate the required buffer
size, and value may be resized appropriately.
Setting an extended attribute. The following three system calls set a given extended
attribute:
#include <sys/types.h>
#include <attr/xattr.h>
int setxattr (const char *path, const char *key,
const void *value, size_t size, int flags);
int lsetxattr (const char *path, const char *key,
const void *value, size_t size, int flags);
int fsetxattr (int fd, const char *key,
const void *value, size_t size, int flags);
A successful call to setxattr( ) sets the extended attribute key on the file path to
value, which is size bytes in length. The flags field modifies the behavior of the call.
If flags is XATTR_CREATE, the call will fail if the extended attribute already exists. If
flags is XATTR_REPLACE, the call will fail if the extended attribute does not exist. The
default behavior—performed if flags is 0—allows both creations and replacements.
Regardless of the value of flags, keys other than key are unaffected.
lsetxattr( ) behaves the same as setxattr( ), unless path is a symbolic link, in which
case it sets the extended attributes on the link itself, rather than on the target of the
link. Recall that attributes in the user namespace cannot be applied to symbolic
links—thus, this call is also rarely used.
fsetxattr( ) operates on the file descriptor fd; otherwise, it behaves the same as
setxattr( ).
On success, all three system calls return 0; on failure, the calls return -1, and set
errno to one of the following:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path (setxattr( ) and lsetxattr( ) only).
EBADF
fd is invalid (fsetxattr( ) only).
EDQUOT
A quota limit prevents the space consumption required by the requested operation.
Files and Their Metadata | 209
EEXIST
XATTR_CREATE was set in flags, and key already exists on the given file.
EFAULT
path, key, or value is an invalid pointer.
EINVAL
flags is invalid.
ELOOP
path contains too many symbolic links (setxattr( ) and lsetxattr( ) only).
ENAMETOOLONG
path is too long (setxattr( ) and lsetxattr( ) only).
ENOATTR
XATTR_REPLACE was set in flags, and key does not exist on the given file.
ENOENT
A component in path does not exist (setxattr( ) and lsetxattr( ) only).
ENOMEM
There is insufficient memory available to complete the request.
ENOSPC
There is insufficient space on the filesystem to store the extended attribute.
ENOTDIR
A component in path is not a directory (setxattr( ) and lsetxattr( ) only).
ENOTSUP
The filesystem on which path or fd resides does not support extended attributes.
Listing the extended attributes on a file. The following three system calls enumerate the
set of extended attribute keys assigned to a given file:
#include <sys/types.h>
#include <attr/xattr.h>
ssize_t listxattr (const char *path,
char *list, size_t size);
ssize_t llistxattr (const char *path,
char *list, size_t size);
ssize_t flistxattr (int fd,
char *list, size_t size);
A successful call to listxattr( ) returns a list of the extended attribute keys associ-
ated with the file denoted by path. The list is stored in the buffer provided by list,
which is size bytes in length. The system call returns the actual size of the list, in
bytes.
Each extended attribute key returned in list is terminated by a null character, so a
list might look like this:
"user.md5_sum\0user.mime_type\0system.posix_acl_default\0"
210 | Chapter 7: File and Directory Management
Thus, although each key is a traditional, null-terminated C string, you need the
length of the entire list (which you can retrieve from the call’s return value) to walk
the list of keys. To find out how large a buffer you need to allocate, call one of the list
functions with a size of 0; this causes the function to return the actual length of the
full list of keys. As with getxattr( ), applications may use this functionality to allo-
cate or resize the buffer to pass for value.
llistxattr( ) behaves the same as listxattr( ), unless path is a symbolic link, in
which case the call enumerates the extended attribute keys associated with the link
itself rather than with the target of the link. Recall that attributes in the user
namespace cannot be applied to symbolic links—thus, this call is rarely used.
flistxattr( ) operates on the file descriptor fd; otherwise, it behaves the same as
listxattr( ).
On failure, all three calls return -1, and set errno to one of the following error codes:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path (listxattr( ) and llistxattr( ) only).
EBADF
fd is invalid (flistxattr( ) only).
EFAULT
path or list is an invalid pointer.
ELOOP
path contains too many symbolic links (listxattr( ) and llistxattr( ) only).
ENAMETOOLONG
path is too long (listxattr( ) and llistxattr( ) only).
ENOENT
A component in path does not exist (listxattr( ) and llistxattr( ) only).
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in path is not a directory (listxattr( ) and llistxattr( ) only).
ENOTSUPP
The filesystem on which path or fd resides does not support extended attributes.
ERANGE
size is nonzero, and is insufficiently large to hold the complete list of keys. The
application may reissue the call with size set to 0 to discover the actual size of
the list. The program may then resize value and reissue the system call.
Removing an extended attribute. Finally, these three system calls remove a given key
from a given file:
Files and Their Metadata | 211
#include <sys/types.h>
#include <attr/xattr.h>
int removexattr (const char *path, const char *key);
int lremovexattr (const char *path, const char *key);
int fremovexattr (int fd, const char *key);
A successful call to removexattr( ) removes the extended attribute key from the file
path. Recall that there is a difference between an undefined key and a defined key
with an empty (zero-length) value.
lremovexattr( ) behaves the same as removexattr( ), unless path is a symbolic link, in
which case the call removes the extended attribute key associated with the link itself
rather than with the target of the link. Recall that attributes in the user namespace
cannot be applied to symbolic links—thus, this call is also rarely used.
fremovexattr( ) operates on the file descriptor fd; otherwise, it behaves the same as
removexattr( ).
On success, all three system calls return 0. On failure, all three calls return -1, and set
errno to one of the following:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path (removexattr( ) and lremovexattr( ) only).
EBADF
fd is invalid (fremovexattr( ) only).
EFAULT
path or key is an invalid pointer.
ELOOP
path contains too many symbolic links (removexattr( ) and lremovexattr( )
only).
ENAMETOOLONG
path is too long (removexattr( ) and lremovexattr( ) only).
ENOATTR
key does not exist on the given file.
ENOENT
A component in path does not exist (removexattr( ) and lremovexattr( ) only).
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in path is not a directory (removexattr( ) and lremovexattr( )
only).
ENOTSUPP
The filesystem on which path or fd resides does not support extended attributes.
212 | Chapter 7: File and Directory Management
Directories
In Unix, a directory is a simple concept: it contains a list of filenames, each of which
maps to an inode number. Each name is called a directory entry, and each name-
to-inode mapping is called a link. A directory’s contents—what the user sees as the
result of an ls—are a listing of all the filenames in that directory. When the user
opens a file in a given directory, the kernel looks up the filename in that directory’s
list to find the corresponding inode number. The kernel then passes that inode num-
ber to the filesystem, which uses it to find the physical location of the file on the
device.
Directories can also contain other directories. A subdirectory is a directory inside of
another directory. Given this definition, all directories are subdirectories of some
parent directory, with the exception of the directory at the very root of the filesystem
tree, /. Not surprisingly, this directory is called the root directory (not to be confused
with root’s home directory, /root).
A pathname consists of a filename along with one or more of its parent directories.
An absolute pathname is a pathname that begins with the root directory—for exam-
ple, /usr/bin/sextant. A relative pathname is a pathname that does not begin with the
root directory, such as bin/sextant. For such a pathname to be useful, the operating
system must know the directory to which the path is relative. The current working
directory (discussed in the next section) is used as the starting point.
File and directory names can contain any character except /, which delineates direc-
tories in a pathname, and null, which terminates the pathname. That said, it is
standard practice to constrain the characters in pathnames to valid printable charac-
ters under the current locale, or even just ASCII. Since neither the kernel nor the C
library enforces this practice, however, it is up to applications to enforce the use of
only valid printable characters.
Older Unix systems limited filenames to 14 characters. Today, all modern Unix file-
systems allow at least 255 bytes for each filename. * Many filesystems under Linux
allow even longer filenames.†
Every directory contains two special directories, . and .. (called dot and dot-dot). The
dot directory is a reference to the directory itself. The dot-dot directory is a reference to
the directory’s parent directory. For example, /home/kidd/gold/.. is the same directory as
/home/kidd. The root directory’s dot and dot-dot directories point to itself—that is, /, /.,
and /.. are all the same directory. Technically speaking, therefore, one could say that
even the root directory is a subdirectory—in this case, of itself.
* Note that this limit is 255 bytes, not 255 characters. Multibyte characters obviously consume more than 1 of
these 255 bytes.
† Of course, older filesystems that Linux provides for backward compatibility, such as FAT, still carry their
own limitations. In the case of FAT, this limitation is eight characters, followed by a dot, followed by three
characters. Yes, enforcing the dot as a special character inside of the filesystem is silly.
Directories | 213
The Current Working Directory
Every process has a current directory, which it initially inherits from its parent pro-
cess. That directory is known as the process’ current working directory (cwd). The
current working directory is the starting point from which the kernel resolves relative
pathnames. For example, if a process’ current working directory is /home/blackbeard,
and that process tries to open parrot.jpg, the kernel will attempt to open /home/
blackbeard/parrot.jpg. Conversely, if the process tries to open /usr/bin/mast, the
kernel will indeed open /usr/bin/mast—the current working directory has no impact
on absolute pathnames (that is, pathnames that start with a slash).
A process can both obtain and change its current working directory.
Obtaining the current working directory
The preferred method for obtaining the current working directory is the getcwd( )
system call, which POSIX standardized:
#include <unistd.h>
char * getcwd (char *buf, size_t size);
A successful call to getcwd( ) copies the current working directory as an absolute
pathname into the buffer pointed at by buf, which is of length size bytes, and returns
a pointer to buf. On failure, the call returns NULL, and sets errno to one of the follow-
ing values:
EFAULT
buf is an invalid pointer.
EINVAL
size is 0, but buf is not NULL.
ENOENT
The current working directory is no longer valid. This can happen if the current
working directory is removed.
ERANGE
size is too small to hold the current working directory in buf. The application
needs to allocate a larger buffer and try again.
Here’s an example of using getcwd( ):
char cwd[BUF_LEN];
if (!getcwd (cwd, BUF_LEN)) {
perror ("getcwd");
exit (EXIT_FAILURE);
}
printf ("cwd = %s\n", cwd);
214 | Chapter 7: File and Directory Management
POSIX dictates that the behavior of getcwd( ) is undefined if buf is NULL. Linux’s C
library, in this case, will allocate a buffer of length size bytes, and store the current
working directory there. If size is 0, the C library will allocate a buffer sufficiently
large to store the current working directory. It is then the application’s responsibility
to free the buffer, via free( ), when it’s done with it. Because this behavior is Linux-
specific, applications that value portability or a strict adherence to POSIX should not
rely on this functionality. This feature, however, does make usage very simple!
Here’s an example:
char *cwd;
cwd = getcwd (NULL, 0);
if (!cwd) {
perror ("getcwd");
exit (EXIT_FAILURE);
}
printf ("cwd = %s\n", cwd);
free (cwd);
Linux’s C library also provides a get_current_dir_name( ) function, which has the
same behavior as getcwd( ) when passed a NULL buf and a size of 0:
#define _GNU_SOURCE
#include <unistd.h>
char * get_current_dir_name (void);
Thus, this snippet behaves the same as the previous one:
char *cwd;
cwd = get_current_dir_name ( );
if (!cwd) {
perror ("get_current_dir_name");
exit (EXIT_FAILURE);
}
printf ("cwd = %s\n", cwd);
free (cwd);
Older BSD systems favored the getwd( ) call, which Linux provides for backward
compatibility:
#define _XOPEN_SOURCE_EXTENDED /* or _BSD_SOURCE */
#include <unistd.h>
char * getwd (char *buf);
A call to getwd( ) copies the current working directory into buf, which must be at
least PATH_MAX bytes in length. The call returns buf on success and NULL on failure. For
example:
Directories | 215
char cwd[PATH_MAX];
if (!getwd (cwd)) {
perror ("getwd");
exit (EXIT_FAILURE);
}
printf ("cwd = %s\n", cwd);
For reasons of both portability and security, applications should not use getwd( );
getcwd( ) is preferred.
Changing the current working directory
When a user first logs into her system, the login process sets her current working
directory to her home directory, as specified in /etc/passwd. Sometimes, however, a
process wants to change its current working directory. For example, a shell may
want to do this when the user types cd.
Linux provides two system calls for changing the current working directory, one that
accepts the pathname of a directory, and another that accepts a file descriptor repre-
senting an open directory:
#include <unistd.h>
int chdir (const char *path);
int fchdir (int fd);
A call to chdir( ) changes the current working directory to the pathname specified by
path, which can be an absolute or a relative pathname. Similarly, a call to fchdir( )
changes the current working directory to the pathname represented by the file
descriptor fd, which must be opened against a directory. On success, both calls
return 0. On failure, both calls return -1.
On failure, chdir( ) also sets errno to one of the following values:
EACCESS
The invoking process lacks search permission for one of the directory compo-
nents of path.
EFAULT
path is not a valid pointer.
EIO
An internal I/O error occurred.
ELOOP
The kernel encountered too many symbolic links while resolving path.
ENAMETOOLONG
path is too long.
ENOENT
The directory pointed at by path does not exist.
216 | Chapter 7: File and Directory Management
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
One or more of the components in path is not a directory.
fchdir( ) sets errno to one of the following values:
EACCESS
The invoking process lacks search permission for the directory referenced by fd
(i.e., the execute bit is not set). This happens if the top-level directory is read-
able, but not executable; open( ) succeeds, but fchdir( ) will not.
EBADF
fd is not an open file descriptor.
Depending on the filesystem, other error values are valid for either call.
These system calls affect only the currently running process. There is no mechanism
in Unix for changing the current working directory of a different process. Therefore,
the cd command found in shells cannot be a separate process (like most commands)
that simply executes chdir( ) on the first command-line argument and then exits.
Instead, cd must be a special built-in command that causes the shell itself to call
chdir( ), changing its own current working directory.
The most common use of getcwd( ) is to save the current working directory so that
the process can return to it later. For example:
char *swd;
int ret;
/* save the current working directory */
swd = getcwd (NULL, 0);
if (!swd) {
perror ("getcwd");
exit (EXIT_FAILURE);
}
/* change to a different directory */
ret = chdir (some_other_dir);
if (ret) {
perror ("chdir");
exit (EXIT_FAILURE);
}
/* do some other work in the new directory... */
/* return to the saved directory */
ret = chdir (swd);
if (ret) {
perror ("chdir");
exit (EXIT_FAILURE);
}
free (swd);
Directories | 217
It’s better, however, to open( ) the current directory, and then fchdir( ) to it later.
This approach is faster because the kernel does not store the pathname of the cur-
rent working directory in memory; it stores only the inode. Consequently, whenever
the user calls getcwd( ), the kernel must generate the pathname by walking the direc-
tory structure. Conversely, opening the current working directory is cheaper because
the kernel already has its inode available and the human-readable pathname is not
needed to open a file. The following snippet uses this approach:
int swd_fd;
swd_fd = open (".", O_RDONLY);
if (swd_fd == -1) {
perror ("open");
exit (EXIT_FAILURE);
}
/* change to a different directory */
ret = chdir (some_other_dir);
if (ret) {
perror ("chdir");
exit (EXIT_FAILURE);
}
/* do some other work in the new directory... */
/* return to the saved directory */
ret = fchdir (swd_fd);
if (ret) {
perror ("fchdir");
exit (EXIT_FAILURE);
}
/* close the directory's fd */
ret = close (swd_fd);
if (ret) {
perror ("close");
exit (EXIT_FAILURE);
}
This is how shells implement the caching of the previous directory (for example,
with cd - in bash).
A process that does not care about its current working directory—such as a dae-
mon—generally sets it to / with the call chdir("/"). An application that interfaces
with a user and his data, such as a word processor, generally sets its current working
directory to the user’s home directory, or to a special documents directory. Because
current working directories are relevant only in the context of relative pathnames,
the current working directory is of most utility to command-line utilities that the
user invokes from the shell.
218 | Chapter 7: File and Directory Management
Creating Directories
Linux provides a single system call, standardized by POSIX, for creating new directories:
#include <sys/stat.h>
#include <sys/types.h>
int mkdir (const char *path, mode_t mode);
A successful call to mkdir( ) creates the directory path, which may be relative or abso-
lute, with the permission bits mode (as modified by the current umask), and returns 0.
The current umask modifies the mode argument in the usual way, plus any operating-
system-specific mode bits: in Linux, the permission bits of the newly created direc-
tory are (mode & ~umask & 01777). In other words, in effect, the umask for the process
imposes restrictions that the mkdir( ) call cannot override. If the new directory’s par-
ent directory has the set group ID (sgid) bit set, or if the filesystem is mounted with
BSD group semantics, the new directory will inherit the group affiliation from its par-
ent. Otherwise, the effective group ID of the process will apply to the new directory.
On failure, mkdir( ) returns -1, and sets errno to one of the following values:
EACCESS
The parent directory is not writable by the current process, or one or more com-
ponents of path are not searchable.
EEXIST
path already exists (and not necessarily as a directory).
EFAULT
path is an invalid pointer.
ELOOP
The kernel encountered too many symbolic links while resolving path.
ENAMETOOLONG
path is too long.
ENOENT
A component in path does not exist or is a dangling symbolic link.
ENOMEM
There is insufficient kernel memory to complete the request.
ENOSPC
The device containing path is out of space, or the user’s disk quota is over the
limit.
ENOTDIR
One or more of the components in path is not a directory.
EPERM
The filesystem containing path does not support the creation of directories.
EROFS
The filesystem containing path is mounted read-only.
Directories | 219
Removing Directories
As the counterpart to mkdir( ), the POSIX-standardized rmdir( ) removes a directory
from the filesystem hierarchy:
#include <unistd.h>
int rmdir (const char *path);
On success, rmdir( ) removes path from the filesystem, and returns 0. The directory
specified by path must be empty, aside from the dot and dot-dot directories. There is
no system call that implements the equivalent of a recursive delete, as with rm -r.
Such a tool must manually perform a depth-first traversal of the filesystem, removing
all files and directories starting with the leaves, and moving back up the filesystem;
rmdir( ) can be used at each stage to remove a directory once its files have been
removed.
On failure, rmdir( ) returns -1, and sets errno to one of the following values:
EACCESS
Write access to the parent directory of path is not allowed, or one of the compo-
nent directories of path is not searchable.
EBUSY
path is currently in use by the system, and cannot be removed. In Linux, this can
happen only if path is a mount point or a root directory (root directories need
not be mount points, thanks to chroot( )!).
EFAULT
path is not a valid pointer.
EINVAL
path has the dot directory as its final component.
ELOOP
The kernel encountered too many symbolic links while resolving path.
ENAMETOOLONG
path is too long.
ENOENT
A component in path does not exist, or is a dangling symbolic link.
ENOMEM
There is insufficient kernel memory to complete the request.
ENOTDIR
One or more of the components in path is not a directory.
ENOTEMPTY
path contains entries other than the special dot and dot-dot directories.
EPERM
The parent directory of path has the sticky bit (S_ISVTX) set, but the process’
effective user ID is neither the user ID of said parent nor of path itself, and the
220 | Chapter 7: File and Directory Management
process does not have the CAP_FOWNER capability. Alternatively, the filesystem
containing path does not allow the removal of directories.
EROFS
The filesystem containing path is mounted read-only.
Usage is simple:
int ret;
/* remove the directory /home/barbary/maps */
ret = rmdir ("/home/barbary/maps");
if (ret)
perror ("rmdir");
Reading a Directory’s Contents
POSIX defines a family of functions for reading the contents of directories—that is,
obtaining a list of the files that reside in a given directory. These functions are useful
if you are implementing ls or a graphical file save dialog, if you need to operate on
every file in a given directory, or if you want to search for files in a directory that
match a given pattern.
To begin reading a directory’s contents you need to create a directory stream, which
is represented by a DIR object:
#include <sys/types.h>
#include <dirent.h>
DIR * opendir (const char *name);
A successful call to opendir( ) creates a directory stream representing the directory
given by name.
A directory stream is little more than a file descriptor representing the open direc-
tory, some metadata, and a buffer to hold the directory’s contents. Consequently, it
is possible to obtain the file descriptor behind a given directory stream:
#define _BSD_SOURCE /* or _SVID_SOURCE */
#include <sys/types.h>
#include <dirent.h>
int dirfd (DIR *dir);
A successful call to dirfd( ) returns the file descriptor backing the directory stream
dir. On error, the call returns -1. As the directory stream functions use this file
descriptor internally, programs should only invoke calls that do not manipulate the
file position. dirfd( ) is a BSD extension, and is not standardized by POSIX; pro-
grammers wishing to proclaim their POSIX compliance should avoid it.
Directories | 221
Reading from a directory stream
Once you have created a directory stream with opendir( ), your program can begin
reading entries from the directory. To do this, use readdir( ), which returns entries
one by one from a given DIR object:
#include <sys/types.h>
#include <dirent.h>
struct dirent * readdir (DIR *dir);
A successful call to readdir( ) returns the next entry in the directory represented by
dir. The dirent structure represents a directory entry. Defined in <dirent.h>, on
Linux, its definition is:
struct dirent {
ino_t d_ino; /* inode number */
off_t d_off; /* offset to the next dirent */
unsigned short d_reclen; /* length of this record */
unsigned char d_type; /* type of file */
char d_name[256]; /* filename */
};
POSIX requires only the d_name field, which is the name of a single file within the
directory. The other fields are optional, or Linux-specific. Applications desiring port-
ability to other systems, or conformance to POSIX should access only d_name.
Applications successively invoke readdir( ), obtaining each file in the directory, until
they find the file they are searching for, or until the entire directory is read, at which
time readdir( ) returns NULL.
On failure, readdir( ) also returns NULL. To differentiate between an error and having
read all of the files, applications must set errno to 0 before each readdir( ) invoca-
tion, and then check both the return value and errno. The only errno value set by
readdir( ) is EBADF, signifying that dir is invalid. Thus, many applications do not
bother to check for errors, and assume that NULL means that no more files remain.
Closing the directory stream
To close a directory stream opened with opendir( ), use closedir( ):
#include <sys/types.h>
#include <dirent.h>
int closedir (DIR *dir);
A successful call to closedir( ) closes the directory stream represented by dir, includ-
ing the backing file descriptor, and returns 0. On failure, the function returns -1, and
sets errno to EBADF, the only possible error code, signifying that dir is not an open
directory stream.
222 | Chapter 7: File and Directory Management
The following snippet implements a function, find_file_in_dir( ), that uses
readdir( ) to search a given directory for a given filename. If the file exists in the
directory, the function returns 0. Otherwise, it returns a nonzero value:
/*
* find_file_in_dir - searches the directory 'path' for a
* file named 'file'.
*
* Returns 0 if 'file' exists in 'path' and a nonzero
* value otherwise.
*/
int find_file_in_dir (const char *path, const char *file)
{
struct dirent *entry;
int ret = 1;
DIR *dir;
dir = opendir (path);
errno = 0;
while ((entry = readdir (dir)) != NULL) {
if (!strcmp(entry->d_name, file)) {
ret = 0;
break;
}
}
if (errno && !entry)
perror ("readdir");
closedir (dir);
return ret;
}
System calls for reading directory contents
The previously discussed functions for reading the contents of directories are stan-
dardized by POSIX, and provided by the C library. Internally, these functions use
one of two system calls, readdir( ) and getdents( ), which are provided here for
completeness:
#include <unistd.h>
#include <linux/types.h>
#include <linux/dirent.h>
#include <linux/unistd.h>
#include <errno.h>
/*
* Not defined for user space: need to
* use the _syscall3( ) macro to access.
*/
Links | 223
int readdir (unsigned int fd,
struct dirent *dirp,
unsigned int count);
int getdents (unsigned int fd,
struct dirent *dirp,
unsigned int count);
You do not want to use these system calls! They are obtuse, and not portable.
Instead, user-space applications should use the C library’s opendir( ), readdir( ), and
closedir( ) system calls.
Links
Recall from our discussion of directories that each name-to-inode mapping in a
directory is called a link. Given this simple definition—that a link is essentially just a
name in a list (a directory) that points at an inode—there would appear to be no rea-
son why multiple links to the same inode could not exist. That is, a single inode (and
thus a single file) could be referenced from, say, both /etc/customs and /var/run/ledger.
Indeed, this is the case, with one catch: because links map to inodes, and inode num-
bers are specific to a particular filesystem, /etc/customs and /var/run/ledger must both
reside on the same filesystem. Within a single filesystem, there can be a large num-
ber of links to any given file. The only limit is in the size of the integer data type used
to hold the number of links. Among various links, no one link is the “original” or the
“primary” link. All of the links enjoy the same status, pointing at the same file.
We call these types of links hard links. Files can have no, one, or many links. Most
files have a link count of 1—that is, they are pointed at by a single directory entry—
but some files have two or even more links. Files with a link count of 0 have no
corresponding directory entries on the filesystem. When a file’s link count reaches 0,
the file is marked as free, and its disk blocks are made available for reuse.* Such a file,
however, remains on the filesystem if a process has the file open. Once no process
has the file open, the file is removed.
The Linux kernel implements this behavior by using a link count and a usage count.
The usage count is a tally of the number of instances where the file is open. A file is
not removed from the filesystem until both the link and the usage counts hit 0.
Another type of link, the symbolic link, is not a filesystem mapping, but a higher-level
pointer that is interpreted at runtime. Such links may span filesystems—we’ll look at
them shortly.
* Finding files with a link count of 0, but whose blocks are marked as allocated is a primary job of fsck, the
filesystem checker. Such a condition can occur when a file is deleted, but remains open, and the system
crashes before the file is closed. The kernel is never able to mark the filesystem blocks as free, and thus the
discrepancy arises. Journaling filesystems eliminate this type of error.
224 | Chapter 7: File and Directory Management
Hard Links
The link( ) system call, one of the original Unix system calls, and now standardized
by POSIX, creates a new link for an existing file:
#include <unistd.h>
int link (const char *oldpath, const char *newpath);
A successful call to link( ) creates a new link under the path newpath for the existing
file oldpath, and then returns 0. Upon completion, both oldpath and newpath refer to
the same file—there is, in fact, no way to even tell which was the “original” link.
On failure, the call returns -1, and sets errno to one of the following:
EACCESS
The invoking process lacks search permission for a component in oldpath, or the
invoking process does not have write permission for the directory containing
newpath.
EEXIST
newpath already exists—link( ) will not overwrite an existing directory entry.
EFAULT
oldpath or newpath is an invalid pointer.
EIO
An internal I/O error occurred (this is bad!).
ELOOP
Too many symbolic links were encountered in resolving oldpath or newpath.
EMLINK
The inode pointed at by oldpath already has the maximum number of links
pointing at it.
ENAMETOOLONG
oldpath or newpath is too long.
ENOENT
A component in oldpath or newpath does not exist.
ENOMEM
There is insufficient memory available to complete the request.
ENOSPC
The device containing newpath has no room for the new directory entry.
ENOTDIR
A component in oldpath or newpath is not a directory.
EPERM
The filesystem containing newpath does not allow the creation of new hard links,
or oldpath is a directory.
Links | 225
EROFS
newpath resides on a read-only filesystem.
EXDEV
newpath and oldpath are not on the same mounted filesystem. (Linux allows a
single filesystem to be mounted in multiple places, but even in this case, hard
links cannot be created across the mount points.)
This example creates a new directory entry, pirate, that maps to the same inode (and
thus the same file) as the existing file privateer, both of which are in /home/kidd:
int ret;
/*
* create a new directory entry,
* '/home/kidd/privateer', that points at
* the same inode as '/home/kidd/pirate'
*/
ret = link ("/home/kidd/privateer", /home/kidd/pirate");
if (ret)
perror ("link");
Symbolic Links
Symbolic links, also known as symlinks or soft links, are similar to hard links in that
both point at files in the filesystem. The symbolic link differs, however, in that it is
not merely an additional directory entry, but a special type of file altogether. This
special file contains the pathname for a different file, called the symbolic link’s tar-
get. At runtime, on the fly, the kernel substitutes this pathname for the symbolic
link’s pathname (unless using the various l versions of system calls, such as lstat( ),
which operate on the link itself, and not the target). Thus, whereas one hard link is
indistinguishable from another hard link to the same file, it is easy to tell the differ-
ence between a symbolic link and its target file.
A symbolic link may be relative or absolute. It may also contain the special dot direc-
tory discussed earlier, referring to the directory in which it is located, or the dot-dot
directory, referring to the parent of this directory.
Soft links, unlike hard links, can span filesystems. They can point anywhere, in fact!
Symbolic links can point at files that exist (the common practice), or at nonexistent
files. The latter type of link is called a dangling symlink. Sometimes, dangling
symlinks are unwanted—such as when the target of the link was deleted, but not the
symlink—but at other times, they are intentional.
The system call for creating a symbolic link is very similar to its hard link cousin:
#include <unistd.h>
int symlink (const char *oldpath, const char *newpath);
226 | Chapter 7: File and Directory Management
A successful call to symlink( ) creates the symbolic link newpath pointing at the tar-
get oldpath, and then returns 0.
On error, symlink( ) returns -1, and sets errno to one of the following:
EACCESS
The invoking process lacks search permission for a component in oldpath, or the
invoking process does not have write permission for the directory containing
newpath.
EEXIST
newpath already exists—symink( ) will not overwrite an existing directory entry.
EFAULT
oldpath or newpath is an invalid pointer.
EIO
An internal I/O error occurred (this is bad!).
ELOOP
Too many symbolic links were encountered in resolving oldpath or newpath.
EMLINK
The inode pointed at by oldpath already has the maximum number of links
pointing at it.
ENAMETOOLONG
oldpath or newpath is too long.
ENOENT
A component in oldpath or newpath does not exist.
ENOMEM
There is insufficient memory available to complete the request.
ENOSPC
The device containing newpath has no room for the new directory entry.
ENOTDIR
A component in oldpath or newpath is not a directory.
EPERM
The filesystem containing newpath does not allow the creation of new symbolic
links.
EROFS
newpath resides on a read-only filesystem.
This snippet is the same as our previous example, but it creates /home/kidd/pirate as
a symbolic link (as opposed to a hard link) to /home/kidd/privateer:
int ret;
/*
* create a symbolic link,
Links | 227
* '/home/kidd/privateer', that
* points at '/home/kidd/pirate'
*/
ret = symlink ("/home/kidd/privateer", "/home/kidd/pirate");
if (ret)
perror ("symlink");
Unlinking
The converse to linking is unlinking, the removal of pathnames from the filesystem.
A single system call, unlink( ), handles this task:
#include <unistd.h>
int unlink (const char *pathname);
A successful call to unlink( ) deletes pathname from the filesystem, and returns 0. If
that name was the last reference to the file, the file is deleted from the filesystem. If,
however, a process has the file open, the kernel will not delete the file from the file-
system until that process closes the file. Once no process has the file open, it is
deleted.
If pathname refers to a symbolic link, the link, not the target, is destroyed.
If pathname refers to another type of special file, such as a device, FIFO, or socket, the
special file is removed from the filesystem, but processes that have the file open may
continue to utilize it.
On error, unlink( ) returns -1, and sets errno to one of the following error codes:
EACCESS
The invoking process does not have write permission for the parent directory of
pathname, or the invoking process does not have search permission for a compo-
nent in pathname.
EFAULT
pathname is an invalid pointer.
EIO
An I/O error occurred (this is bad!).
EISDIR
pathname refers to a directory.
ELOOP
Too many symbolic links were encountered in traversing pathname.
ENAMETOOLONG
pathname is too long.
ENOENT
A component in pathname does not exist.
228 | Chapter 7: File and Directory Management
ENOMEM
There is insufficient memory available to complete the request.
ENOTDIR
A component in pathname is not a directory.
EPERM
The system does not allow the unlinking of files.
EROFS
pathname resides on a read-only filesystem.
unlink( ) does not remove directories. For that, applications should use rmdir( ),
which we discussed earlier (see “Removing Directories”).
To ease the wanton destruction of any type of file, the C language provides the
remove( ) function:
#include <stdio.h>
int remove (const char *path);
A successful call to remove( ) deletes path from the filesystem, and returns 0. If path is
a file, remove( ) invokes unlink( ); if path is a directory, remove( ) calls rmdir( ).
On error, remove( ) returns -1, and sets errno to any of the valid error codes set by
unlink( ) and rmdir( ), as applicable.
Copying and Moving Files
Two of the most basic file manipulation tasks are copying and moving files, com-
monly carried out via the cp and mv commands. At the filesystem level, copying is the
act of duplicating a given file’s contents under a new pathname. This differs from
creating a new hard link to the file in that changes to one file will not affect the
other—that is, there now exist two distinct copies of the file, under (at least) two dif-
ferent directory entries. Moving, conversely, is the act of renaming the directory entry
under which a file is located. This action does not result in the creation of a second
copy.
Copying
Although it is surprising to some, Unix does not include a system or library call to
facilitate the copying of files and directories. Instead, utilities such as cp or
GNOME’s Nautilus file manager perform these tasks manually.
In copying a file src to a file named dst, the steps are as follows:
1. Open src.
2. Open dst, creating it if it does not exist, and truncating it to zero length if it does
exist.
Copying and Moving Files | 229
3. Read a chunk of src into memory.
4. Write the chunk to dst.
5. Continue until all of src has been read and written to dst.
6. Close dst.
7. Close src.
If copying a directory, the individual directory and any subdirectories are created via
mkdir( ); each file therein is then copied individually.
Moving
Unlike for copying, Unix does provide a system call for moving files. The ANSI C
standard introduced the call for files, and POSIX standardized it for both files and
directories:
#include <stdio.h>
int rename (const char *oldpath, const char *newpath);
A successful call to rename( ) renames the pathname oldpath to newpath. The file’s
contents and inode remain the same. Both oldpath and newpath must reside on the
same filesystem* ; if they do not, the call will fail. Utilities such as mv must handle this
case by resorting to a copy and unlink.
On success, rename( ) returns 0, and the file once referenced by oldpath is now refer-
enced by newpath. On failure, the call returns -1, does not touch oldpath or newpath,
and sets errno to one of the following values:
EACCESS
The invoking process lacks write permission for the parent of oldpath or newpath,
search permission for a component of oldpath or newpath, or write permission
for oldpath in the case that oldpath is a directory. The last case is an issue
because rename( ) must update .. in oldpath if it is a directory.
EBUSY
oldpath or newpath is a mount point.
EFAULT
oldpath or newpath is an invalid pointer.
EINVAL
newpath is contained within oldpath, and thus, renaming one to the other would
make oldpath a subdirectory of itself.
EISDIR
newpath exists, and is a directory, but oldpath is not a directory.
* Although Linux allows you to mount a device at multiple points in the directory structure, you still cannot
rename from one of these mount points to another, even though they are backed by the same device.
230 | Chapter 7: File and Directory Management
ELOOP
In resolving oldpath or newpath, too many symbolic links were encountered.
EMLINK
oldpath already has the maximum number of links to itself, or oldpath is a direc-
tory, and newpath already has the maximum number of links to itself.
ENAMETOOLONG
oldpath or newpath is too long.
ENOENT
A component in oldpath or newpath does not exist, or is a dangling symbolic link.
ENOMEM
There is insufficient kernel memory to complete the request.
ENOSPC
There is insufficient space on the device to complete the request.
ENOTDIR
A component (aside from potentially the final component) in oldpath or newpath is
not a directory, or oldpath is a directory, and newpath exists but is not a directory.
ENOTEMPTY
newpath is a directory and is not empty.
EPERM
At least one of the paths specified in the arguments exists, the parent directory
has the sticky bit set, the invoking process’ effective user ID is neither the user
ID of the file, nor that of the parent, and the process is not privileged.
EROFS
The filesystem is marked read-only.
EXDEV
oldpath and newpath are not on the same filesystem.
Table 7-1 reviews the results of moving to and from different types of files.
Table 7-1. Effects of moving to and from different types of files
Destination is a file
Destination is a
directory Destination is a link
Destination does
not exist
Source is a file The destination is
overwritten by the
source.
Failure with
EISDIR.
The file is renamed
and the destination is
overwritten.
The file is renamed.
Source is a directory Failure with
ENOTDIR.
The source is
renamed as the desti-
nation if the destina-
tion is empty; failure
with ENOTEMPTY
otherwise.
The directory is
renamed, and the
destination is over-
written.
The directory is
renamed.
Device Nodes | 231
For all of these cases, regardless of their type, if the source and destination reside on
different filesystems, the call fails and returns EXDEV.
Device Nodes
Device nodes are special files that allow applications to interface with device drivers.
When an application performs the usual Unix I/O—opening, closing, reading, writ-
ing, and so on—on a device node, the kernel does not handle those requests as
normal file I/O. Instead, the kernel passes such requests to a device driver. The
device driver handles the I/O operation, and returns the results to the user. Device
nodes provide device abstraction so that applications do not need to be familiar with
device specifics, or even master special interfaces. Indeed, device nodes are the stan-
dard mechanism for accessing hardware on Unix systems. Network devices are the
rare exception, and over the course of Unix’s history, some have argued that this
exception is a mistake. There is, indeed, an elegant beauty in manipulating all of a
machine’s hardware using read( ), write( ), and mmap( ) calls.
How does the kernel identify the device driver to which it should hand off the
request? Each device node is assigned two numerical values, called a major number,
and a minor number. These major and minor numbers map to a specific device driver
loaded into the kernel. If a device node has a major and minor number that do not
correspond to a device driver in the kernel—which occasionally happens, for a vari-
ety of reasons—an open( ) request on the device node returns -1 with errno set to
ENODEV. We say that such device nodes front nonexistent devices.
Special Device Nodes
Several device nodes are present on all Linux systems. These device nodes are part of
the Linux development environment, and their presence is considered part of the
Linux ABI.
The null device has a major number of 1, and a minor number of 3. It lives at /dev/null.
The device file should be owned by root and be readable and writable by all users. The
kernel silently discards all write requests to the device. All read requests to the file
return end-of-file (EOF).
Source is a link The link is renamed
and the destination is
overwritten.
Failure with
EISDIR.
The link is renamed
and the destination is
overwritten.
The link is renamed.
Source does not
exist
Failure with ENOENT. Failure with ENOENT. Failure with ENOENT. Failure with ENOENT.
Table 7-1. Effects of moving to and from different types of files (continued)
Destination is a file
Destination is a
directory Destination is a link
Destination does
not exist
232 | Chapter 7: File and Directory Management
The zero device lives at /dev/zero, and has a major of 1 and a minor of 5. Like the null
device, the kernel silently discards writes to the zero device. Reading from the device
returns an infinite stream of null bytes.
The full device, with a major of 1, and a minor of 7, lives at /dev/full. As with the zero
device, read requests return null characters (\0). Write requests, however, always
trigger the ENOSPC error, signifying that the underlying device is full.
These devices have varied purposes. They are useful for testing how an application
handles corner and problem cases—a full filesystem, for example. Because the null
and zero devices ignore writes, they also provide a no-overhead way to throw away
unwanted I/O.
The Random Number Generator
The kernel’s random number generator devices live at /dev/random and /dev/urandom.
They have a major number of 1, and minor numbers of 8 and 9, respectively.
The kernel’s random number generator gathers noise from device drivers and other
sources, and the kernel concatenates together and one-way hashes the gathered
noise. The result is then stored in an entropy pool. The kernel keeps an estimate of
the number of bits of entropy in the pool.
Reads from /dev/random return entropy from this pool. The results are suitable for
seeding random number generators, performing key generation, and other tasks that
require cryptographically strong entropy.
In theory, an adversary who was able to obtain enough data from the entropy pool
and successfully break the one-way hash could gain knowledge about the state of the
rest of the entropy pool. Although such an attack is currently only a theoretical pos-
sibility—no such attacks are publicly known to have occurred—the kernel reacts to
this possibility by decrementing its estimate of the amount of entropy in the pool
with each read request. If the estimate reaches zero, the read will block until the sys-
tem generates more entropy, and the entropy estimate is large enough to satisfy the
read.
/dev/urandom does not have this property; reads from the device will succeed even if
the kernel’s entropy estimate is insufficient to complete the request. Since only the
most secure of applications—such as the generation of keys for secure data exchange
in GNUPrivacy Guard—should care about cryptographically strong entropy, most
applications should use /dev/urandom and not /dev/random. Reads to the latter can
potentially block for a very long time if no I/O activity occurs that feeds the kernel’s
entropy pool. This is not uncommon on diskless, headless servers.
Out-of-Band Communication | 233
Out-of-Band Communication
The Unix file model is impressive. With only simple read and write operations, Unix
abstracts nearly any conceivable act one could perform on an object. Sometimes,
however, programmers need to communicate with a file outside of its primary data
stream. For example, consider a serial port device. Reading from the device would
read from the hardware on the far end of the serial port; writing to the device would
send data to that hardware. How would a process read one of the serial port’s spe-
cial status pins, such as the data terminal ready (DTR) signal? Alternatively, how
would a process set the parity of the serial port?
The answer is to use the ioctl( ) system call. ioctl( ), which stands for I/O control,
allows for out-of-band communication:
#include <sys/ioctl.h>
int ioctl (int fd, int request, ...);
The system call requires two parameters:
fd
The file descriptor of a file.
request
A special request code value, predefined and agreed upon by the kernel and the
process, that denotes what operation to perform on the file referenced by fd.
It may also receive one or more untyped optional parameters (usually unsigned inte-
gers or pointers) to pass into the kernel.
The following program uses the CDROMEJECT request to eject the media tray from a CD-
ROM device, which the user provides as the first argument on the program’s
command line. This program thus functions similarly to the standard eject command:
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <sys/ioctl.h>
#include <unistd.h>
#include <linux/cdrom.h>
#include <stdio.h>
int main (int argc, char *argv[])
{
int fd, ret;
if (argc < 2) {
fprintf (stderr,
"usage: %s <device to eject>\n",
argv[0]);
return 1;
}
234 | Chapter 7: File and Directory Management
/*
* Opens the CD-ROM device, read-only. O_NONBLOCK
* tells the kernel that we want to open the device
* even if there is no media present in the drive.
*/
fd = open (argv[1], O_RDONLY | O_NONBLOCK);
if (fd < 0) {
perror ("open");
return 1;
}
/* Send the eject command to the CD-ROM device. */
ret = ioctl (fd, CDROMEJECT, 0);
if (ret) {
perror ("ioctl");
return 1;
}
ret = close (fd);
if (ret) {
perror ("close");
return 1;
}
return 0;
}
The CDROMEJECT request is a feature of Linux’s CD-ROM device driver. When the ker-
nel receives an ioctl( ) request, it finds the filesystem (in the case of real files) or
device driver (in the case of devices nodes) responsible for the file descriptor pro-
vided, and passes on the request for handling. In this case, the CD-ROM device
driver receives the request and physically ejects the drive.
Later in this chapter, we will look at an ioctl( ) example that uses an optional
parameter to return information to the requesting process.
Monitoring File Events
Linux provides an interface, inotify, for monitoring files—for example, to see when
they are moved, read from, written to, or deleted. Imagine that you are writing a
graphical file manager, such as GNOME’s Nautilus. If a file is copied into a direc-
tory while Nautilus is displaying its contents, the file manager’s view of the directory
becomes inconsistent.
One solution is to continually reread the contents of the directory, detecting changes
and updating the display. This imposes a periodic overhead, and is far from a very
clean solution. Worse, there is always a race between when a file is removed from or
added to the directory, and when the file manager rereads the directory.
Monitoring File Events | 235
With inotify, the kernel can push the event to the application the moment it hap-
pens. As soon as a file is deleted, the kernel can notify Nautilus. Nautilus, in
response, can immediately remove the deleted file from the graphical display of the
directory.
Many other applications are also concerned with file events. Consider a backup util-
ity or a data-indexing tool. inotify allows both of these programs to operate in real
time: the moment a file is created, deleted, or written to, the tools can update the
backup archive or data index.
inotify replaces dnotify, an earlier file-monitoring mechanism with a cumbersome sig-
nals-based interface. Applications should always favor inotify over dnotify. inotify,
introduced with kernel 2.6.13, is flexible and easy to use because the same operations
that programs perform on regular files—notably, select( ) and poll( )—work with
inotify. We cover only inotify in this book.
Initializing inotify
Before a process can use inotify, the process must initialize it. The inotify_init( )
system call initializes inotify and returns a file descriptor representing the initialized
instance:
#include <inotify.h>
int inotify_init (void);
On error, inotify_init( ) returns -1, and sets errno to one of the following codes:
EMFILE
The per-user limit on the maximum number of inotify instances has been
reached.
ENFILE
The system-wide limit on the maximum number of file descriptors has been
reached.
ENOMEM
There is insufficient memory available to complete the request.
Let’s initialize inotify so we can use it in subsequent steps:
int fd;
fd = inotify_init ( );
if (fd == -1) {
perror ("inotify_init");
exit (EXIT_FAILURE);
}
236 | Chapter 7: File and Directory Management
Watches
After a process initializes inotify, it sets up watches. A watch, represented by a watch
descriptor, is a standard Unix path, and an associated watch mask, which tells the
kernel what events the process is interested in—for example, reads, writes, or both.
inotify can watch both files and directories. If watching a directory, inotify reports
events that occur on the directory itself, and on any of the files residing in the direc-
tory (but not on files in subdirectories of the watched directory—the watch is not
recursive).
Adding a new watch
The system call inotify_add_watch( ) adds a watch for the event or events described
by mask on the file or directory path to the inotify instance represented by fd:
#include <inotify.h>
int inotify_add_watch (int fd,
const char *path,
uint32_t mask);
On success, the call returns a new watch descriptor. On failure, inotify_add_watch( )
returns -1, and sets errno to one of the following:
EACCESS
Read access to the file specified by path is not permitted. The invoking process
must be able to read the file to add a watch to it.
EBADF
The file descriptor fd is not a valid inotify instance.
EFAULT
The pointer path is not valid.
EINVAL
The watch mask, mask, contains no valid events.
ENOMEM
There is insufficient memory available to complete the request.
ENOSPC
The per-user limit on the total number of inotify watches has been reached.
Watch masks
The watch mask is a binary OR of one or more inotify events, which <inotify.h>
defines:
IN_ACCESS
The file was read from.
IN_MODIFY
The file was written to.
Monitoring File Events | 237
IN_ATTRIB
The file’s metadata (for example, the owner, permissions, or extended
attributes) was changed.
IN_CLOSE_WRITE
The file was closed, and had been open for writing.
IN_CLOSE_NOWRITE
The file was closed, and had not been open for writing.
IN_OPEN
The file was opened.
IN_MOVED_FROM
A file was moved away from the watched directory.
IN_MOVED_TO
A file was moved into the watched directory.
IN_CREATE
A file was created in the watched directory.
IN_DELETE
A file was deleted from the watched directory.
IN_DELETE_SELF
The watched object itself was deleted.
IN_MOVE_SELF
The watched object itself was moved.
The following events are also defined, grouping two or more events into a single value:
IN_ALL_EVENTS
All legal events.
IN_CLOSE
All events related to closing (currently, both IN_CLOSE_WRITE and IN_CLOSE_NOWRITE).
IN_MOVE
All move-related events (currently, both IN_MOVED_FROM and IN_MOVED_TO).
Now, we can look at adding a new watch to an existing inotify instance:
int wd;
wd = inotify_add_watch (fd, "/etc", IN_ACCESS | IN_MODIFY);
if (wd == -1) {
perror ("inotify_add_watch");
exit (EXIT_FAILURE);
}
This example adds a watch for all reads or writes on the directory /etc. If any file in
/etc is written to or read from, inotify sends an event to the inotify file descriptor,
fd, providing the watch descriptor wd. Let’s look at how inotify represents these
events.
238 | Chapter 7: File and Directory Management
inotify Events
The inotify_event structure, defined in <inotify.h>, represents inotify events:
#include <inotify.h>
struct inotify_event {
int wd; /* watch descriptor */
uint32_t mask; /* mask of events */
uint32_t cookie; /* unique cookie */
uint32_t len; /* size of 'name' field */
char name[]; /* null-terminated name */
};
wd identifies the watch descriptor, as obtained by inotify_add_watch( ), and mask rep-
resents the events. If wd identifies a directory and one of the watched-for events
occurred on a file within that directory, name provides the filename relative to the
directory. In this case, len is nonzero. Note that len is not the same as the string
length of name; name can have more than one trailing null character that acts as pad-
ding to ensure that a subsequent inotify_event is properly aligned. Consequently,
you must use len, and not strlen( ), to calculate the offset of the next inotify_event
structure in an array.
For example, if wd represents /home/rlove, and has a mask of IN_ACCESS, and the file
/home/rlove/canon is read from, name will equal canon, and len will be at least 6.
Conversely, if we were watching /home/rlove/canon directly with the same mask,
len would be 0, and name would be zero-length—you must not touch it.
cookie is used to link together two related but disjoint events. We will address it in a
subsequent section.
Reading inotify events
Obtaining inotify events is easy: you just read from the file descriptor associated with
the inotify instance. inotify provides a feature known as slurping, which allows you
to read multiple events—as many as fit in the buffer provided to read( )—with a sin-
gle read request. Because of the variable-length name field, this is the most common
way to read inotify events.
Our previous example instantiated an inotify instance, and added a watch to that
instance. Now, let’s read pending events:
char buf[BUF_LEN]_attribute_((aligned(4)));
ssize_t len, i = 0;
/* read BUF_LEN bytes' worth of events */
len = read (fd, buf, BUF_LEN);
/* loop over every read event until none remain */
while (i < len) {
struct inotify_event *event =
(struct inotify_event *) &buf[i];
Monitoring File Events | 239
printf ("wd=%d mask=%d cookie=%d len=%d dir=%s\n",
event->wd, event->mask,
event->cookie, event->len,
(event->mask & IN_ISDIR) ? "yes" : "no");
/* if there is a name, print it */
if (event->len)
printf ("name=%s\n", event->name);
/* update the index to the start of the next event */
i += sizeof (struct inotify_event) + event->len;
}
Because the inotify file descriptor acts like a regular file, programs can monitor it via
select( ), poll( ), and epoll( ). This allows processes to multiplex inotify events
with other file I/O from a single thread.
Advanced inotify events. In addition to the standard events, inotify can generate other
events:
IN_IGNORED
The watch represented by wd has been removed. This can occur because the user
manually removed the watch, or because the watched object no longer exists.
We will discuss this event in a subsequent section.
IN_ISDIR
The affected object is a directory. (If not set, the affected object is a file.)
IN_Q_OVERFLOW
The inotify queue overflowed. The kernel limits the size of the event queue to
prevent unbounded consumption of kernel memory. Once the number of pend-
ing events reaches one less than the maximum, the kernel generates this event,
and appends it to the tail of the queue. No further events are generated until the
queue is read from, reducing its size below the limit.
IN_UNMOUNT
The device backing the watched object was unmounted. Thus, the object is no
longer available; the kernel will remove the watch, and generate the IN_IGNORED
event.
Any watch can generate these events; the user need not set them explicitly.
Programmers must treat mask as a bitmask of pending events. Consequently, do not
check for events using direct tests of equivalence:
/* Do NOT do this! */
if (event->mask == IN_MODIFY)
printf ("File was written to!\n");
else if (event->mask == IN_Q_OVERFLOW)
printf ("Oops, queue overflowed!\n);
240 | Chapter 7: File and Directory Management
Instead, perform bitwise tests:
if (event->mask & IN_ACCESS)
printf ("The file was read from!\n");
if (event->mask & IN_UNMOUNTED)
printf ("The file's backing device was unmounted!\n);
if (event->mask & IN_ISDIR)
printf ("The file is a directory!\n");
Linking together move events
The IN_MOVED_FROM and IN_MOVED_TO events each represent only half of a move: the
former represents the removal from a given location, while the latter represents the
arrival at a new location. Therefore, to be truly useful to a program that is attempt-
ing to intelligently track files as they move around the filesystem (consider an indexer
with the intention that it not reindex moved files), processes need to be able to link
the two move events together.
Enter the cookie field in the inotify_event structure.
The cookie field, if nonzero, contains a unique value that links two events together.
Consider a process that is watching /bin and /sbin. Assume that /bin has a watch
descriptor of 7, and that /sbin has a watch descriptor of 8. If the file /bin/compass is
moved to /sbin/compass, the kernel will generate two inotify events.
The first event will have wd equal to 7, mask equal to IN_MOVED_FROM, and a name of
compass. The second event will have wd equal to 8, mask equal to IN_MOVED_TO, and a
name of compass. In both events, cookie will be the same—say, 12.
If a file is renamed, the kernel still generates two events. wd is the same for both.
Note that if a file is moved from or to a directory that is not watched, the process will
not receive one of the corresponding events. It is up to the program to notice that the
second event with a matching cookie never arrives.
Advanced Watch Options
When creating a new watch, you can add one or more of the following values to mask
to control the behavior of the watch:
IN_DONT_FOLLOW
If this value is set, and if the target of path or any of its components is a symbolic
link, the link is not followed and inotify_add_watch( ) fails.
IN_MASK_ADD
Normally, if you call inotify_add_watch( ) on a file on which you have an exist-
ing watch, the watch mask is updated to reflect the newly provided mask. If this
flag is set in mask, the provided events are added to the existing mask.
Monitoring File Events | 241
IN_ONESHOT
If this value is set, the kernel automatically removes the watch after generating
the first event against the given object. The watch is, in effect, “one shot.”
IN_ONLYDIR
If this value is set, the watch is added only if the object provided is a directory. If
path represents a file, not a directory, inotify_add_watch( ) fails.
For example, this snippet only adds the watch on /etc/init.d if init.d is a directory, and
if neither /etc nor /etc/init.d is a symbolic link:
int wd;
/*
* Watch '/etc/init.d' to see if it moves, but only if it is a
* directory and no part of its path is a symbolic link.
*/
wd = inotify_add_watch (fd,
"/etc/init.d",
IN_MOVE_SELF |
IN_ONLYDIR |
IN_DONT_FOLLOW);
if (wd == -1)
perror ("inotify_add_watch");
Removing an inotify Watch
As shown in this instance, you can remove a watch from an inotify instance with the
system call inotify_rm_watch( ):
#include <inotify.h>
int inotify_rm_watch (int fd, uint32_t wd);
A successful call to inotify_rm_watch( ) removes the watch represented by the watch
descriptor wd from the inotify instance (represented by the file descriptor) fd and
returns 0.
For example:
int ret;
ret = inotify_rm_watch (fd, wd);
if (ret)
perror ("inotify_rm_watch");
On failure, the system call returns -1, and sets errno to one of the following two
options:
EBADF
fd is not a valid inotify instance.
EINVAL
wd is not a valid watch descriptor on the given inotify instance.
242 | Chapter 7: File and Directory Management
When removing a watch, the kernel generates the IN_IGNORED event. The kernel sends
this event not only during a manual removal, but when destroying the watch as a
side effect of another operation. For example, when a watched file is deleted, any
watches on the file are removed. In all such cases, the kernel sends IN_IGNORED. This
behavior allows applications to consolidate their handling of watch removal in a sin-
gle place: the event handler for IN_IGNORED. This is useful for advanced consumers of
inotify that manage complex data structures backing each inotify watch, such as
GNOME’s Beagle search infrastructure.
Obtaining the Size of the Event Queue
The size of the pending event queue can be obtained via the FIONREAD ioctl on the
inotify instance’s file descriptor. The first argument to the request receives the size of
the queue in bytes, as an unsigned integer:
unsigned int queue_len;
int ret;
ret = ioctl (fd, FIONREAD, &queue_len);
if (ret < 0)
perror ("ioctl");
else
printf ("%u bytes pending in queue\n", queue_len);
Note that the request returns the size of the queue in bytes, and not the number of
events in the queue. A program can estimate the number of events from the number
of bytes, using the known size of the inotify_event structure (obtained via sizeof( )),
and a guess at the average size of the name field. What’s more useful, however, is that
the number of bytes pending gives the process an ideal size to read.
The header <sys/ioctl.h> defines the FIONREAD constant.
Destroying an inotify Instance
Destroying an inotify instance, and any associated watches, is as simple as closing
the instance’s file descriptor:
int ret;
/* 'fd' was obtained via inotify_init( ) */
ret = close (fd);
if (fd == -1)
perror ("close");
Of course, as with any file descriptor, the kernel automatically closes the file descrip-
tor, and cleans up the resource when the process exits.
243
Chapter 8 CHAPTER 8
Memory Management
Memory is among the most basic, but also most essential, resources available to a
process. This chapter covers the management of this resource: the allocation, manip-
ulation, and eventual release of memory.
The verb allocate—the common term for obtaining memory—is a bit misleading, as
it conjures up images of rationing a scarce resource for which demand outstrips
supply. To be sure, many users would love more memory. On modern systems, how-
ever, the problem is not really one of sharing too little among too many, but of
properly using and keeping track of the bounty.
In this chapter, you will learn about all of the approaches to allocating memory in
various regions of a program, including each method’s advantages and disadvan-
tages. We’ll also go over some ways to set and manipulate the contents of arbitrary
memory regions, and look at how to lock memory so it remains in RAM and your
program runs no risk of having to wait for the kernel to page in data from swap
space.
The Process Address Space
Linux, like any modern operating system, virtualizes its physical resource of memory.
Processes do not directly address physical memory. Instead, the kernel associates each
process with a unique virtual address space. This address space is linear, with
addresses starting at zero, and increasing to some maximum value.
Pages and Paging
The virtual address space is composed of pages. The system architecture and
machine type determine the size of a page, which is fixed; typical sizes include 4 KB
244 | Chapter 8: Memory Management
(for 32-bit systems), and 8 KB (for 64-bit systems).* Pages are either valid or invalid. A
valid page is associated with a page in physical memory, or some secondary backing
storage, such as a swap partition or a file on disk. An invalid page is not associated
with anything and represents an unused, unallocated piece of the address space.
Accessing such a page causes a segmentation violation. The address space is not nec-
essarily contiguous. While linearly addressed, it contains plenty of unaddressable
gaps.
A program cannot use a page that is present in secondary storage rather than in phys-
ical memory until it is associated with a page in physical memory. When a process
tries to access an address on such a page, the memory management unit (MMU) gen-
erates a page fault. The kernel then intervenes, transparently paging in the desired
page from secondary storage to physical memory. Because significantly more virtual
than physical memory exists (even, on many systems, in a single virtual address
space!), the kernel is constantly also paging out physical memory to secondary stor-
age to make room for more page-ins. The kernel attempts to page out data that is the
least likely to be used in the near future, thereby optimizing performance.
Sharing and copy-on-write
Multiple pages of virtual memory, even in different virtual address spaces owned by
different processes, may map to a single physical page. This allows different virtual
address spaces to share the data in physical memory. The shared data may be read-
only, or readable and writable.
When a process writes to a shared writable page, one of two things can happen. The
simplest is that the kernel allows the write to occur, in which case all processes shar-
ing the page can see the results of the write operation. Usually, allowing multiple
processes to read from or write to a shared page requires some level of coordination
and synchronization.
Alternatively, however, the MMUmay intercept the write operation, and raise an
exception; the kernel, in response, will transparently create a new copy of the page
for the writing process, and allow the write to continue against the new page. We call
this approach copy-on-write (COW).† Effectively, processes are allowed read access
to shared data, which saves space. When a process wants to write to a shared page, it
receives a unique copy of that page on the fly, thereby allowing the kernel to act as if
the process had always had its own private copy. As copy-on-write occurs on a page-
by-page basis, with this approach, a huge file may be efficiently shared among many
processes, and the individual processes will receive unique physical pages only for
those pages to which they themselves write.
* Some systems support a range of page sizes. For this reason, the page size is not part of the ABI. Applications
must programmatically obtain the page size at runtime. We covered doing so in Chapter 4 and will review
the topic in this chapter.
† Recall from Chapter 5 that fork( ) uses copy-on-write to duplicate and share the parent’s address space with
the child.
Allocating Dynamic Memory | 245
Memory Regions
The kernel arranges pages into blocks that share certain properties, such as access
permissions. These blocks are called memory regions, segments, or mappings. Certain
types of memory regions can be found in every process:
• The text segment contains a process’ program code, string literals, constant vari-
ables, and other read-only data. In Linux, this segment is marked read-only and
is mapped in directly from the object file (the program executable or a library).
• The stack contains the process’ execution stack, which grows and shrinks
dynamically as the stack depth increases and decreases. The execution stack
contains local variables and function return data.
• The data segment, or heap, contains a process’ dynamic memory. This segment is
writable and can grow or shrink in size. This is the memory returned by malloc( )
(discussed in the next section).
• The bss segment* contains uninitialized global variables. These variables contain
special values (essentially, all zeros), per the C standard.
Linux optimizes these variables in two ways. First, because the bss segment is
dedicated to uninitialized data, the linker (ld) does not actually store the special
values in the object file. This reduces the binary’s size. Second, when this seg-
ment is loaded into memory, the kernel simply maps it on a copy-on-write basis
to a page of zeros, efficiently setting the variables to their default values.
• Most address spaces contain a handful of mapped files, such as the program
executable itself, the C and other linked libraries, and data files. Take a look at
/proc/self/maps, or the output from the pmap program for a great example of
the mapped files in a process.
This chapter covers the interfaces that Linux provides to obtain and return memory,
create and destroy new mappings, and everything in between.
Allocating Dynamic Memory
Memory also comes in the form of automatic and static variables, but the founda-
tion of any memory management system is the allocation, use, and eventual return of
dynamic memory. Dynamic memory is allocated at runtime, not compile time, in
sizes that may be unknown until the moment of allocation. As a developer, you need
dynamic memory when the amount of memory that you will need, or how long you
might need it, varies, and is not known before the program runs. For example, you
might want to store in memory the contents of a file or input read in from the key-
board. Because the size of the file is unknown, and the user may type any number of
* The name is historic; it comes from block started by symbol.
246 | Chapter 8: Memory Management
keystrokes, the size of the buffer will vary, and you may need to make it dynamically
larger as you read more and more data.
There is no C variable that is backed by dynamic memory. For example, C does not
provide a mechanism to obtain a struct pirate_ship that exists in dynamic memory.
Instead, C provides a mechanism for allocating dynamic memory sufficient to hold a
pirate_ship structure. The programmer then interacts with the memory via a
pointer—in this case, a struct pirate_ship *.
The classic C interface for obtaining dynamic memory is malloc( ):
#include <stdlib.h>
void * malloc (size_t size);
A successful call to malloc( ) allocates size bytes of memory, and returns a pointer to
the start of the newly allocated region. The contents of the memory are undefined;
do not expect the memory to be zeroed. Upon failure, malloc( ) returns NULL, and
errno is set to ENOMEM.
Usage of malloc( ) may be rather straightforward, as in this example used to allocate
a fixed number of bytes:
char *p;
/* give me 2 KB! */
p = malloc (2048);
if (!p)
perror ("malloc");
or this example used to allocate a structure:
struct treasure_map *map;
/*
* allocate enough memory to hold a treasure_map stucture
* and point 'map' at it
*/
map = malloc (sizeof (struct treasure_map));
if (!map)
perror ("malloc");
C automatically promotes pointers to void to any type on assignment. Thus, these
examples do not need to typecast the return value of malloc( ) to the lvalue’s type
used in the assignments. The C++ programming language, however, does not
perform automatic void pointer promotion. Consequently, users of C++ need to
typecast malloc( )’s return as follows:
char *name;
/* allocate 512 bytes */
name = (char *) malloc (512);
if (!name)
perror ("malloc");
Allocating Dynamic Memory | 247
Some C programmers like to typecast the result of any function that returns a pointer
to void, malloc( ) included. I argue against this practice because it will hide an error
if the return value of the function ever changes to something other than a void
pointer. Moreover, such a typecast also hides a bug if a function is not properly
declared. * While the former is not a risk with malloc( ), the latter certainly is.
Because malloc( ) can return NULL, it is vitally important that developers always check
for and handle error conditions. Many programs define and use a malloc( ) wrapper
that prints an error message and terminates the program if malloc( ) returns NULL. By
convention, developers call this common wrapper xmalloc( ):
/* like malloc( ), but terminates on failure */
void * xmalloc (size_t size)
{
void *p;
p = malloc (size);
if (!p) {
perror ("xmalloc");
exit (EXIT_FAILURE);
}
return p;
}
Allocating Arrays
Dynamic memory allocation may also be quite complex when the specified size is
itself dynamic. One such example is the dynamic allocation of arrays, where the size
of an array element may be fixed, but the number of elements to allocate is dynamic.
To simplify this scenario, C provides the calloc( ) function:
#include <stdlib.h>
void * calloc (size_t nr, size_t size);
A successful call to calloc( ) returns a pointer to a block of memory suitable for
holding an array of nr elements, each of size bytes. Consequently, the amount of
memory requested in these two calls is identical (either may end up returning more
memory than requested, but never less):
int *x, *y;
x = malloc (50 * sizeof (int));
if (!x) {
perror ("malloc");
return -1;
* Undeclared functions default to returning an int. Integer-to-pointer casts are not automatic, and generate a
warning. The typecast will suppress the resulting warning.
248 | Chapter 8: Memory Management
}
y = calloc (50, sizeof (int));
if (!y) {
perror ("calloc");
return -1;
}
The behavior, however, is not identical. Unlike malloc( ), which makes no such guar-
antees about the contents of allocated memory, calloc( ) zeros all bytes in the
returned chunk of memory. Thus, each of the 50 elements in the array of integers y
holds the value of 0, while the contents of the elements in x are undefined. Unless the
program is going to immediately set all 50 values, programmers should use calloc( )
to ensure that the array elements are not filled with gibberish. Note that binary zero
might not be the same as floating-point zero!
Users often want to “zero out” dynamic memory, even when not dealing with arrays.
Later in this chapter, we will consider memset( ), which provides an interface for set-
ting every byte in a chunk of memory to a given value. Letting calloc( ) perform the
zeroing, however, is faster because the kernel can provide memory that is already
zeroed.
On failure, like malloc( ), calloc( ) returns NULL, and sets errno to ENOMEM.
Why the standards bodies never defined an “allocate and zero” function separate
from calloc( ) is a mystery. Developers can easily define their own interface, however:
/* works identically to malloc( ), but memory is zeroed */
void * malloc0 (size_t size)
{
return calloc (1, size);
}
Conveniently, we can combine this malloc0( ) with our previous xmalloc( ):
/* like malloc( ), but zeros memory and terminates on failure */
void * xmalloc0 (size_t size)
{
void *p;
p = calloc (1, size);
if (!p) {
perror ("xmalloc0");
exit (EXIT_FAILURE);
}
return p;
}
Allocating Dynamic Memory | 249
Resizing Allocations
The C language provides an interface for resizing (making larger or smaller) existing
allocations:
#include <stdlib.h>
void * realloc (void *ptr, size_t size);
A successful call to realloc( ) resizes the region of memory pointed at by ptr to a
new size of size bytes. It returns a pointer to the newly sized memory, which may or
may not be the same as ptr—when enlarging a memory region, if realloc( ) is
unable to enlarge the existing chunk of memory by growing the chunk in situ, the
function may allocate a new region of memory size bytes in length, copy the old
region into the new one, and free the old region. On any operation, the contents of
the memory region are preserved up to the minimum of the old and the new sizes.
Because of the potentiality of a copy operation, a realloc( ) operation to enlarge a
memory region can be a relatively costly act.
If size is 0, the effect is the same as an invocation of free( ) on ptr.
If ptr is NULL, the result of the operation is the same as a fresh malloc( ). If ptr is non-
NULL, it must have been returned via a previous call to malloc( ), calloc( ), or realloc( ).
On failure, realloc( ) returns NULL, and sets errno to ENOMEM. The state of the mem-
ory pointed at by ptr is unchanged.
Let’s consider an example of shrinking a memory region. First, we’ll use calloc( ) to
allocate enough memory to hold a two-element array of map structures:
struct map *p;
/* allocate memory for two map structures */
p = calloc (2, sizeof (struct map));
if (!p) {
perror ("calloc");
return -1;
}
/* use p[0] and p[1]... */
Now, let’s assume we’ve found one of the treasures, and no longer need the second
map, so we decide to resize the memory, and give half of the region back to the system
(this wouldn’t generally be a worthwhile operation, but it might be if the map structure
was very large, and we were going to hold the remaining map for a long time):
struct map *r;
/* we now need memory for only one map */
r = realloc (p, sizeof (struct map));
if (!r) {
250 | Chapter 8: Memory Management
/* note that 'p' is still valid! */
perror ("realloc");
return -1;
}
/* use 'r'... */
free (r);
In this example, p[0] is preserved after the realloc( ) call. Whatever data was there
before is still there. If the call returned failure, note that p is untouched, and thus still
valid. We can continue using it, and will eventually need to free it. Conversely, if the
call succeeded, we ignore p, and in lieu use r (which is likely the same as p, as the
region was almost certainly resized in place). We now have the responsibility to free
r when we’re done.
Freeing Dynamic Memory
Unlike automatic allocations, which are automatically reaped when the stack
unwinds, dynamic allocations are permanent parts of the process’ address space until
they are manually freed. The programmer thus bears the responsibility of returning
dynamically allocated memory to the system. (Both static and dynamic allocations,
of course, disappear when the entire process exits.)
Memory allocated with malloc( ), calloc( ), or realloc( ) must be returned to the
system when no longer in use via free( ):
#include <stdlib.h>
void free (void *ptr);
A call to free( ) frees the memory at ptr. The parameter ptr must have been previ-
ously returned by malloc( ), calloc( ), or realloc( ). That is, you cannot use free( )
to free partial chunks of memory—say, half of a chunk of memory—by passing in a
pointer halfway into an allocated block.
ptr may be NULL, in which case free( ) silently returns. Thus, the oft seen practice of
checking ptr for NULL before calling free( ) is redundant.
Let’s look at an example:
void print_chars (int n, char c)
{
int i;
for (i = 0; i < n; i++) {
char *s;
int j;
/*
* Allocate and zero an i+2 element array
* of chars. Note that 'sizeof (char)'
Allocating Dynamic Memory | 251
* is always 1.
*/
s = calloc (i + 2, 1);
if (!s) {
perror ("calloc");
break;
}
for (j = 0; j < i + 1; j++)
s[j] = c;
printf ("%s\n", s);
/* Okay, all done. Hand back the memory. */
free (s);
}
}
This example allocates n arrays of chars containing successively larger numbers of
elements, ranging from two elements (2 bytes) up to n + 1 elements (n + 1 bytes).
Then, for each array, the loop writes the character c into each byte except the last
(leaving the 0 that is already in the last byte), prints the array as a string, and then
frees the dynamically allocated memory.
Invoking print_chars( ) with n equal to 5, and c set to X, we get the following:
X
XX
XXX
XXXX
XXXXX
There are, of course, significantly more efficient ways of implementing this function.
The point, however, is that we can dynamically allocate and free memory even when
the size and the number of said allocations are known only at runtime.
Unix systems such as SunOS and SCO provide a variant of free( )
named cfree( ), which, depending on the system, behaves the same as
free( ), or receives three parameters, mirroring calloc( ). In Linux,
free( ) can handle memory obtained from any of the allocation mech-
anisms we have discussed thus far. cfree( ) should never be used,
except for backward compatibility. The Linux version is the same as
free( ).
Note what the repercussions would be if this example did not invoke free( ). The
program would never return the memory to the system, and, even worse, it would
lose its only reference to the memory—the pointer s—thereby making it impossible
to ever access the memory. We call this type of programming error a memory leak.
Memory leaks and similar dynamic memory mistakes are among the most common,
and, unfortunately, the most detrimental mishaps in C programming. Because the C
252 | Chapter 8: Memory Management
language places full responsibility for managing memory on the programmer, C pro-
grammers must keep a fastidious eye on all memory allocations.
Another common C programming pitfall is use-after-free. This foible occurs when a
block of memory is freed, and then subsequently accessed. Once free( ) is called on
a block of memory, a program must never again access its contents. Programmers
must be particularly careful to watch for dangling pointers, or non-NULL pointers that
nevertheless point at invalid blocks of memory. Two common tools to aid you in this
quest are Electric Fence and valgrind. *
Alignment
The alignment of data refers to the relation between its address and memory chunks
as measured by the hardware. A variable located at a memory address that is a multi-
ple of its size is said to be naturally aligned. For example, a 32-bit variable is naturally
aligned if it is located in memory at an address that is a multiple of 4—that is, if the
address’ lowest two bits are 0. Thus, a type that is 2
n bytes in size must have an
address with the n least-significant bits set to 0.
Rules pertaining to alignment derive from hardware. Some machine architectures
have very stringent requirements on the alignment of data. On some systems, a load
of unaligned data results in a processor trap. On other systems, accessing unaligned
data is safe, but results in a degradation of performance. When writing portable
code, alignment issues must be avoided, and all types should be naturally aligned.
Allocating aligned memory
For the most part, the compiler and the C library transparently handle alignment
concerns. POSIX decrees that the memory returned via malloc( ), calloc( ), and
realloc( ) be properly aligned for use with any of the standard C types. On Linux,
these functions always return memory that is aligned along an 8 byte boundary on
32-bit systems and a 16 byte boundary on 64-bit systems.
Occasionally, programmers require dynamic memory aligned along a larger bound-
ary, such as a page. While motivations vary, the most common is a need to properly
align buffers used in direct block I/O or other software-to-hardware communica-
tion. For this purpose, POSIX 1003.1d provides a function named posix_memalign( ):
/* one or the other -- either suffices */
#define _XOPEN_SOURCE 600
#define _GNU_SOURCE
#include <stdlib.h>
int posix_memalign (void **memptr,
size_t alignment,
size_t size);
* See http://perens.com/FreeSoftware/ElectricFence/ and http://valgrind.org, respectively.
Allocating Dynamic Memory | 253
A successful call to posix_memalign( ) allocates size bytes of dynamic memory, ensur-
ing it is aligned along a memory address that is a multiple of alignment. The parameter
alignment must be a power of 2, and a multiple of the size of a void pointer. The
address of the allocated memory is placed in memptr, and the call returns 0.
On failure, no memory is allocated, memptr is undefined, and the call returns one of
the following error codes:
EINVAL
The parameter alignment is not a power of 2, or is not a multiple of the size of a
void pointer.
ENOMEM
There is insufficient memory available to satisfy the requested allocation.
Note that errno is not set—the function directly returns these errors.
Memory obtained via posix_memalign( ) is freed via free( ). Usage is simple:
char *buf;
int ret;
/* allocate 1 KB along a 256-byte boundary */
ret = posix_memalign (&buf, 256, 1024);
if (ret) {
fprintf (stderr, "posix_memalign: %s\n",
strerror (ret));
return -1;
}
/* use 'buf'... */
free (buf);
Older interfaces. Before POSIX defined posix_memalign( ), BSD and SunOS provided
the following interfaces, respectively:
#include <malloc.h>
void * valloc (size_t size);
void * memalign (size_t boundary, size_t size);
The function valloc( ) operates identically to malloc( ), except that the allocated
memory is aligned along a page boundary. Recall from Chapter 4 that the system’s
page size is easily obtained via getpagesize( ).
The function memalign( ) is similar, but it aligns the allocation along a boundary of
boundary bytes, which must be a power of 2. In this example, both of these alloca-
tions return a block of memory sufficient to hold a ship structure, aligned along a
page boundary:
struct ship *pirate, *hms;
pirate = valloc (sizeof (struct ship));
254 | Chapter 8: Memory Management
if (!pirate) {
perror ("valloc");
return -1;
}
hms = memalign (getpagesize ( ), sizeof (struct ship));
if (!hms) {
perror ("memalign");
free (pirate);
return -1;
}
/* use 'pirate' and 'hms'... */
free (hms);
free (pirate);
On Linux, memory obtained via both of these functions is freeable via free( ). This
may not be the case on other Unix systems, some of which provide no mechanism
for safely freeing memory allocated with these functions. Programs concerned with
portability may have no choice but to not free memory allocated via these interfaces!
Linux programmers should use these two functions only for the purposes of portabil-
ity with older systems; posix_memalign( ) is superior. All three of these interfaces are
needed only if an alignment greater than that provided by malloc( ) is required.
Other alignment concerns
Alignment concerns extend beyond natural alignment of the standard types and
dynamic memory allocations. For example, nonstandard and complex types have
more complex requirements than the standard types. Further, alignment concerns
are doubly important when assigning values between pointers of varying types and
using typecasting.
Nonstandard types. Nonstandard and complex data types possess alignment require-
ments beyond the simple requirement of natural alignment. Four useful rules follow:
• The alignment requirement of a structure is that of its largest constituent type.
For example, if a structure’s largest type is a 32-bit integer that is aligned along a
4 byte boundary, the structure must be aligned along at least a 4 byte boundary
as well.
• Structures also introduce the need for padding, which is used to ensure that each
constituent type is properly aligned to that type’s own requirement. Thus, if a
char (with a probable alignment of one byte) finds itself followed by an int (with
a probable alignment of four bytes), the compiler will insert three bytes of pad-
ding between the two types to ensure that the int lives on a four-byte boundary.
Programmers sometimes order the members of a structure—for example, by
descending size—to minimize the space “wasted” by padding. The GCC option
-Wpadded can aid in this endeavor, as it generates a warning whenever the com-
piler inserts implicit padding.
Managing the Data Segment | 255
• The alignment requirement of a union is that of the largest unionized type.
• The alignment requirement of an array is that of the base type. Thus, arrays
carry no requirement beyond a single instance of their type. This behavior results
in the natural alignment of all members of an array.
Playing with pointers. As the compiler transparently handles most alignment require-
ments, it takes a bit of effort to expose potential issues. It is not unheard of, however,
to encounter alignment concerns when dealing with pointers and casting.
Accessing data via a pointer recast from a lesser-aligned to a larger-aligned block of
data can result in the processor loading data that is not properly aligned for the
larger type. For example, in the following code snippet, the assignment of c to
badnews attempts to read c as an unsigned long:
char greeting[] = "Ahoy Matey";
char *c = greeting[1];
unsigned long badnews = *(unsigned long *) c;
An unsigned long is likely aligned along a four or eight byte boundary; c almost
certainly sits one byte off that same boundary. Consequently, the load of c, when
typecast, causes an alignment violation. Depending on the architecture, this can
cause results ranging from as minor as a performance hit to as major as a program
crash. On machine architectures that can detect but not properly handle alignment
violations, the kernel sends the offending process the SIGBUS signal, which termi-
nates the process. We will discuss signals in Chapter 9.
Examples such as this are more common than one might think. Real-world examples
will not be quite so silly in appearance, but they will likely be less obvious as well.
Managing the Data Segment
Unix systems historically have provided interfaces for directly managing the data seg-
ment. However, most programs have no direct use for these interfaces because
malloc( ) and other allocation schemes are easier to use and more powerful. I’ll cover
these interfaces here to satisfy the curious, and for the rare reader who wants to
implement her own heap-based allocation mechanism:
#include <unistd.h>
int brk (void *end);
void * sbrk (intptr_t increment);
These functions derive their names from old-school Unix systems, where the heap
and the stack lived in the same segment. Dynamic memory allocations in the heap
grew upward from the bottom of the segment; the stack grew downward toward the
heap from the top of the segment. The line of demarcation separating the two was
called the break or the break point. On modern systems where the data segment lives
in its own memory mapping, we continue to label the end address of the mapping
the break point.
256 | Chapter 8: Memory Management
A call to brk( ) sets the break point (the end of the data segment) to the address spec-
ified by end. On success, it returns 0. On failure, it returns -1, and sets errno to
ENOMEM.
A call to sbrk( ) increments the end of the data segment by increment, which may be
a positive or negative delta. sbrk( ) returns the revised break point. Thus, an
increment of 0 prints out the current break point:
printf ("The current break point is %p\n", sbrk (0));
Deliberately, both POSIX and the C standard define neither of these functions.
Nearly all Unix systems, however, support one or both. Portable programs should
stick to the standards-based interfaces.
Anonymous Memory Mappings
Memory allocation in glibc uses the data segment and memory mappings. The clas-
sic method of implementing malloc( ) is to divide the data segment into a series of
power-of-2 partitions, and satisfy allocations by returning the partition that is the
closest fit to the requested size. Freeing memory is as simple marking the partition as
“free.” If adjacent partitions are free, they can be coalesced into a single, larger parti-
tion. If the top of the heap is entirely free, the system can use brk( ) to lower the
break point, shrinking the heap, and returning memory to the kernel.
This algorithm is called a buddy memory allocation scheme. It has the upside of speed
and simplicity, but the downside of introducing two types of fragmentation. Internal
fragmentation occurs when more memory than requested is used to satisfy an alloca-
tion. This results in inefficient use of the available memory. External fragmentation
occurs when sufficient memory is free to satisfy a request, but it is split into two or
more nonadjacent chunks. This can result in inefficient use of memory (because a
larger, less suitable block may be used), or failed memory allocations (if no alterna-
tive block exists).
Moreover, this scheme allows one memory allocation to “pin” another, preventing
glibc from returning freed memory to the kernel. Imagine that two blocks of mem-
ory, block A and block B, are allocated. Block A sits right on the break point, and
block B sits right below A. Even if the program frees B, glibc cannot adjust the break
point until A is likewise freed. In this manner, a long-living allocation can pin all
other allocations in memory.
This is not always a concern because glibc does not routinely return memory to the
system anyway.* Generally, the heap is not shrunk after each free. Instead, glibc
keeps freed memory around for a subsequent allocation. Only when the size of the
* glibc also uses a significantly more advanced memory allocation algorithm than this simple buddy allocation
scheme, called an arena algorithm.
Anonymous Memory Mappings | 257
heap is significantly larger than the amount of allocated memory does glibc shrink
the data segment. A large allocation, however, can prevent this shrinkage.
Consequently, for large allocations, glibc does not use the heap. Instead, glibc cre-
ates an anonymous memory mapping to satisfy the allocation request. Anonymous
memory mappings are similar to the file-based mappings discussed in Chapter 4,
except that they are not backed by any file—hence the “anonymous” moniker.
Instead, an anonymous memory mapping is simply a large, zero-filled block of
memory, ready for your use. Think of it as a brand new heap, solely for a single
allocation. Because these mappings are located outside of the heap, they do not con-
tribute to the data segment’s fragmentation.
Allocating memory via anonymous mappings has several benefits:
• No fragmentation concerns. When the program no longer needs an anonymous
memory mapping, the mapping is unmapped, and the memory is immediately
returned to the system.
• Anonymous memory mappings are resizable, have adjustable permissions, and
can receive advice just like normal mappings (see Chapter 4).
• Each allocation exists in a separate memory mapping. There is no need to man-
age the global heap.
There are also two downsides to using anonymous memory mappings rather than
the heap:
• Each memory mapping is an integer multiple of the system page size in size.
Ergo, allocations that are not integer multiples of pages in size result in wasted
“slack” space. This slack space is more of a concern with small allocations,
where the wasted space is large relative to the allocation size.
• Creating a new memory mapping incurs more overhead than returning memory
from the heap, which may not involve any kernel interaction whatsoever. The
smaller the allocation, the more valid is this observation.
Juggling the pros against the cons, glibc’s malloc( ) uses the data segment to satisfy
small allocations and anonymous memory mappings to satisfy large allocations. The
threshold is configurable (see the section “Advanced Memory Allocation” later in
this chapter), and may change from one glibc release to another. Currently, the
threshold is 128 KB: allocations smaller than or equal to 128 KB derive from the
heap, whereas larger allocations derive from anonymous memory mappings.
Creating Anonymous Memory Mappings
Perhaps because you want to force the use of a memory mapping over the heap for a
specific allocation, or perhaps because you are writing your own memory allocation sys-
tem, you may want to manually create your own anonymous memory mapping—either
258 | Chapter 8: Memory Management
way, Linux makes it easy. Recall from Chapter 4 that the system call mmap( ) creates and
the system call munmap( ) destroys a memory mapping:
#include <sys/mman.h>
void * mmap (void *start,
size_t length,
int prot,
int flags,
int fd,
off_t offset);
int munmap (void *start, size_t length);
Creating an anonymous memory mapping is actually easier than creating a file-
backed mapping, as there is no file to open and manage. The primary difference
between the two types of mappings is the presence of a special flag, signifying that
the mapping is anonymous.
Let’s look at an example:
void *p;
p = mmap (NULL, /* do not care where */
512 * 1024, /* 512 KB */
PROT_READ | PROT_WRITE, /* read/write */
MAP_ANONYMOUS | MAP_PRIVATE, /* anonymous, private */
-1, /* fd (ignored) */
0); /* offset (ignored) */
if (p == MAP_FAILED)
perror ("mmap");
else
/* 'p' points at 512 KB of anonymous memory... */
For most anonymous mappings, the parameters to mmap( ) mirror this example, with
the exception, of course, of passing in whatever size (in bytes) the programmer
desires. The other parameters are generally as follows:
• The first parameter, start, is set to NULL, signifying that the anonymous mapping
may begin anywhere in memory that the kernel wishes. Specifying a non-NULL
value here is possible, so long as it is page-aligned, but limits portability. Rarely
does a program care where mappings exist in memory!
• The prot parameter usually sets both the PROT_READ and PROT_WRITE bits, making
the mapping readable and writable. An empty mapping is of no use if you
cannot read from and write to it. On the other hand, executing code from an
anonymous mapping is rarely desired, and allowing this would create a poten-
tial security hole.
• The flags parameter sets the MAP_ANONYMOUS bit, making this mapping anony-
mous, and the MAP_PRIVATE bit, making this mapping private.
Anonymous Memory Mappings | 259
• The fd and offset parameters are ignored when MAP_ANONYMOUS is set. Some older
systems, however, expect a value of -1 for fd, so it is a good idea to pass that if
portability is a concern.
Memory obtained via an anonymous mapping looks the same as memory obtained
via the heap. One benefit to allocating from anonymous mappings is that the pages
are already filled with zeros. This occurs at no cost, because the kernel maps the
application’s anonymous pages to a zero-filled page via copy-on-write. Thus, there is
no need to memset( ) the returned memory. Indeed, this is one benefit to using
calloc( ) as opposed to malloc( ) followed by memset( ): glibc knows that anony-
mous mappings are already zeroed, and that a calloc( ) satisfied from a mapping
does not require explicit zeroing.
The system call munmap( ) frees an anonymous mapping, returning the allocated
memory to the kernel:
int ret;
/* all done with 'p', so give back the 512 KB mapping */
ret = munmap (p, 512 * 1024);
if (ret)
perror ("munmap");
For a review of mmap( ), munmap( ), and mappings in general, see
Chapter 4.
Mapping /dev/zero
Other Unix systems, such as BSD, do not have a MAP_ANONYMOUS flag. Instead, they
implement a similar solution by mapping a special device file, /dev/zero. This device
file provides identical semantics to anonymous memory. A mapping contains copy-
on-write pages of all zeros; the behavior is thus the same as with anonymous memory.
Linux has always had a /dev/zero device, and provided the ability to map this file and
obtain zero-filled memory. Indeed, before the introduction of MAP_ANONYMOUS, Linux
programmers used this approach. To provide backward compatibility with older ver-
sions of Linux, or portability to other Unix systems, developers can still map /dev/zero
in lieu of creating an anonymous mapping. This is no different from mapping any
other file:
void *p;
int fd;
/* open /dev/zero for reading and writing */
fd = open ("/dev/zero", O_RDWR);
if (fd < 0) {
perror ("open");
return -1;
260 | Chapter 8: Memory Management
}
/* map [0,page size) of /dev/zero */
p = mmap (NULL, /* do not care where */
getpagesize ( ), /* map one page */
PROT_READ | PROT_WRITE, /* map read/write */
MAP_PRIVATE, /* private mapping */
fd, /* map /dev/zero */
0); /* no offset */
if (p == MAP_FAILED) {
perror ("mmap");
if (close (fd))
perror ("close");
return -1;
}
/* close /dev/zero, no longer needed */
if (close (fd))
perror ("close");
/* 'p' points at one page of memory, use it... */
Memory mapped in this manner is, of course, unmapped using munmap( ).
This approach involves the additional system call overhead of opening and closing
the device file. Thus, anonymous memory is a faster solution.
Advanced Memory Allocation
Many of the allocation operations discussed in this chapter are limited and con-
trolled by kernel parameters that the programmer can change. To do so, use the
mallopt( ) call:
#include <malloc.h>
int mallopt (int param, int value);
A call to mallopt( ) sets the memory-management-related parameter specified by
param to the value specified by value. On success, the call returns a nonzero value; on
failure, it returns 0. Note that mallopt( ) does not set errno. It also tends to always
return successfully, so avoid any optimism about getting useful information from the
return value.
Linux currently supports six values for param, all defined in <malloc.h>:
M_CHECK_ACTION
The value of the MALLOC_CHECK_ environment variable (discussed in the next
section).
Advanced Memory Allocation | 261
M_MMAP_MAX
The maximum number of mappings that the system will make to satisfy
dynamic memory requests. When this limit is reached, the data segment will be
used for all allocations, until one of these mappings is freed. A value of 0 dis-
ables all use of anonymous mappings as a basis for dynamic memory allocations.
M_MMAP_THRESHOLD
The size threshold (measured in bytes) over which an allocation request will be
satisfied via an anonymous mapping instead of the data segment. Note that
allocations smaller than this threshold may also be satisfied via anonymous map-
pings at the system’s discretion. A value of 0 enables the use of anonymous
mappings for all allocations, effectively disabling use of the data segment for
dynamic memory allocations.
M_MXFAST
The maximum size (in bytes) of a fast bin. Fast bins are special chunks of mem-
ory in the heap that are never coalesced with adjacent chunks, and never
returned to the system, allowing for very quick allocations at the cost of
increased fragmentation. A value of 0 disables all use of fast bins.
M_TOP_PAD
The amount of padding (in bytes) used when adjusting the size of the data seg-
ment. Whenever glibc uses brk( ) to increase the size of the data segment, it can
ask for more memory than needed, in the hopes of alleviating the need for an
additional brk( ) call in the near future. Likewise, whenever glibc shrinks the size
of the data segment, it can keep extra memory, giving back a little less than it
would otherwise. These extra bytes are the padding. A value of 0 disables all use
of padding.
M_TRIM_THRESHOLD
The minimum amount of free memory (in bytes) allowed at the top of the data
segment. If the amount falls below this threshold, glibc invokes brk( ) to give
back memory to the kernel.
The XPG standard, which loosely defines mallopt( ), specifies three other parame-
ters: M_GRAIN, M_KEEP, and M_NLBLKS. Linux defines these parameters, but setting their
value has no effect. See Table 8-1 for a full listing of all valid parameters, their default
values, and their ranges of accepted values.
Table 8-1. mallopt( ) parameters
Parameter Origin Default value Valid values Special values
M_CHECK_ACTION Linux-specific 0 0 – 2
M_GRAIN XPG standard Unsupported on Linux >= 0
M_KEEP XPG standard Unsupported on Linux >= 0
262 | Chapter 8: Memory Management
Programs must make any invocations of mallopt( ) before their first call to malloc( )
or any other memory allocation interface. Usage is simple:
int ret;
/* use mmap( ) for all allocations over 64 KB */
ret = mallopt (M_MMAP_THRESHOLD, 64 * 1024);
if (!ret)
fprintf (stderr, "mallopt failed!\n");
Fine-Tuning with malloc_usable_size( ) and malloc_trim( )
Linux provides a couple of functions that offer low-level control of glibc’s memory
allocation system. The first such function allows a program to ask how many usable
bytes a given memory allocation contains:
#include <malloc.h>
size_t malloc_usable_size (void *ptr);
A successful call to malloc_usable_size( ) returns the actual allocation size of the
chunk of memory pointed to by ptr. Because glibc may round up allocations to fit
within an existing chunk or anonymous mapping, the usable space in an allocation
can be larger than requested. Of course, the allocation will never be smaller than
requested. Here’s an example of the function’s use:
size_t len = 21;
size_t size;
char *buf;
buf = malloc (len);
if (!buf) {
perror ("malloc");
return -1;
}
size = malloc_usable_size (buf);
/* we can actually use 'size' bytes of 'buf'... */
M_MMAP_MAX Linux-specific 64 * 1024 >= 0 0 disables use of mmap( )
M_MMAP_THRESHOLD Linux-specific 128 * 1024 >= 0 0 disables use of the heap
M_MXFAST XPG standard 64 0 – 80 0 disables fast bins
M_NLBLKS XPG standard Unsupported on Linux >= 0
M_TOP_PAD Linux-specific 0 >= 0 0 disables padding
Table 8-1. mallopt( ) parameters (continued)
Parameter Origin Default value Valid values Special values
Debugging Memory Allocations | 263
The second of the two functions allows a program to force glibc to return all immedi-
ately freeable memory to the kernel:
#include <malloc.h>
int malloc_trim (size_t padding);
A successful call to malloc_trim( ) shrinks the data segment as much as possible,
minus padding bytes, which are reserved. It then returns 1. On failure, the call returns
0. Normally, glibc performs such shrinking automatically, whenever the freeable
memory reaches M_TRIM_THRESHOLD bytes. It uses a padding of M_TOP_PAD.
You’ll almost never want to use these two functions for anything other than debug-
ging or educational purposes. They are not portable, and expose low-level details of
glibc’s memory allocation system to your program.
Debugging Memory Allocations
Programs can set the environment variable MALLOC_CHECK_ to enable enhanced debug-
ging in the memory subsystem. The additional debugging checks come at the
expense of less efficient memory allocations, but the overhead is often worth it dur-
ing the debugging stage of application development.
Because an environment variable controls the debugging, there is no need to recom-
pile your program. For example, you can simply issue a command like the following:
$ MALLOC_CHECK_=1 ./rudder
If MALLOC_CHECK_ is set to 0, the memory subsystem silently ignores any errors. If it is
set to 1, an informative message is printed to stderr. If it is set to 2, the program is
immediately terminated via abort( ). Because MALLOC_CHECK_ changes the behavior of
the running program, setuid programs ignore this variable.
Obtaining Statistics
Linux provides the mallinfo( ) function for obtaining statistics related to the mem-
ory allocation system:
#include <malloc.h>
struct mallinfo mallinfo (void);
A call to mallinfo( ) returns statistics in a mallinfo structure. The structure is
returned by value, not via a pointer. Its contents are also defined in <malloc.h>:
/* all sizes in bytes */
struct mallinfo {
int arena; /* size of data segment used by malloc */
int ordblks; /* number of free chunks */
264 | Chapter 8: Memory Management
int smblks; /* number of fast bins */
int hblks; /* number of anonymous mappings */
int hblkhd; /* size of anonymous mappings */
int usmblks; /* maximum total allocated size */
int fsmblks; /* size of available fast bins */
int uordblks; /* size of total allocated space */
int fordblks; /* size of available chunks */
int keepcost; /* size of trimmable space */
};
Usage is simple:
struct mallinfo m;
m = mallinfo ( );
printf ("free chunks: %d\n", m.ordblks);
Linux also provides the malloc_stats( ) function, which prints memory-related sta-
tistics to stderr:
#include <malloc.h>
void malloc_stats (void);
Invoking malloc_stats( ) in a memory-intensive program yields some big numbers:
Arena 0:
system bytes = 865939456
in use bytes = 851988200
Total (incl. mmap):
system bytes = 3216519168
in use bytes = 3202567912
max mmap regions = 65536
max mmap bytes = 2350579712
Stack-Based Allocations
Thus far, all of the mechanisms for dynamic memory allocation that we have studied
have used the heap or memory mappings to obtain dynamic memory. We should
expect this because the heap and memory mappings are decidedly dynamic in
nature. The other common construct in a program’s address space, the stack, is
where a program’s automatic variables live.
There is no reason, however, that a programmer cannot use the stack for dynamic
memory allocations. So long as the allocation does not overflow the stack, such an
approach should be easy, and should perform quite well. To make a dynamic mem-
ory allocation from the stack, use the alloca( ) system call:
#include <alloca.h>
void * alloca (size_t size);
Stack-Based Allocations | 265
On success, a call to alloca( ) returns a pointer to size bytes of memory. This mem-
ory lives on the stack, and is automatically freed when the invoking function returns.
Some implementations return NULL on failure, but most alloca( ) implementations
cannot fail, or are unable to report failure. Failure is manifested as a stack overflow.
Usage is identical to malloc( ), but you do not need to (indeed, must not) free the
allocated memory. Here is an example of a function that opens a given file in the sys-
tem’s configuration directory, which is probably /etc, but is portably determined at
compile time. The function has to allocate a new buffer, copy the system configuration
directory into the buffer, and then concatenate this buffer with the provided filename:
int open_sysconf (const char *file, int flags, int mode)
{
const char *etc; = SYSCONF_DIR; /* "/etc/" */
char *name;
name = alloca (strlen (etc) + strlen (file) + 1);
strcpy (name, etc);
strcat (name, file);
return open (name, flags, mode);
}
Upon return, the memory allocated with alloca( ) is automatically freed as the stack
unwinds back to the invoking function. This means you cannot use this memory
once the function that calls alloca( ) returns! However, because you don’t have to
do any cleanup by calling free( ), the resulting code is a bit cleaner. Here is the same
function implemented using malloc( ):
int open_sysconf (const char *file, int flags, int mode)
{
const char *etc = SYSCONF_DIR; /* "/etc/" */
char *name;
int fd;
name = malloc (strlen (etc) + strlen (file) + 1);
if (!name) {
perror ("malloc");
return -1;
}
strcpy (name, etc);
strcat (name, file);
fd = open (name, flags, mode);
free (name);
return fd;
}
266 | Chapter 8: Memory Management
Note that you should not use alloca( )-allocated memory in the parameters to a
function call, because the allocated memory will then exist in the middle of the stack
space reserved for the function parameters. For example, the following is off-limits:
/* DO NOT DO THIS! */
ret = foo (x, alloca (10));
The alloca( ) interface has a checkered history. On many systems, it behaved poorly,
or gave way to undefined behavior. On systems with a small and fixed-sized stack,
using alloca( ) was an easy way to overflow the stack, and kill your program. On
still other systems, alloca( ) did not even exist. Over time, the buggy and inconsis-
tent implementations earned alloca( ) a bad reputation.
So, if your program must remain portable, you should avoid alloca( ). On Linux,
however, alloca( ) is a wonderfully useful and underutilized tool. It performs excep-
tionally well—on many architectures, an allocation via alloca( ) does as little as
increment the stack pointer—and handily outperforms malloc( ). For small alloca-
tions in Linux-specific code, alloca( ) can yield excellent performance gains.
Duplicating Strings on the Stack
A very common use of alloca( ) is to temporarily duplicate a string. For example:
/* we want to duplicate 'song' */
char *dup;
dup = alloca (strlen (song) + 1);
strcpy (dup, song);
/* manipulate 'dup'... */
return; /* 'dup' is automatically freed */
Because of the frequency of this need, and the speed benefit that alloca( ) offers,
Linux systems provide variants of strdup( ) that duplicate the given string onto the
stack:
#define _GNU_SOURCE
#include <string.h>
char * strdupa (const char *s);
char * strndupa (const char *s, size_t n);
A call to strdupa( ) returns a duplicate of s. A call to strndupa( ) duplicates up to n
characters of s. If s is longer than n, the duplication stops at n, and the function
appends a null byte. These functions offer the same benefits as alloca( ). The dupli-
cated string is automatically freed when the invoking function returns.
POSIX does not define the alloca( ), strdupa( ), or strndupa( ) functions, and their
record on other operating systems is spotty. If portability is a concern, use of these
functions is highly discouraged. On Linux, however, alloca( ) and friends perform
Stack-Based Allocations | 267
quite well, and can provide an excellent performance boost, replacing the compli-
cated dance of dynamic memory allocation with a mere adjustment of the stack
frame pointer.
Variable-Length Arrays
C99 introduced variable-length arrays (VLAs), which are arrays whose geometry is
set at runtime, and not at compile time. GNUC has supported variable-length arrays
for some time, but now that C99 has standardized them, there is greater incentive for
their use. VLAs avoid the overhead of dynamic memory allocation in much the same
way as alloca( ).
Their use is exactly what you would expect:
for (i = 0; i < n; ++i) {
char foo[i + 1];
/* use 'foo'... */
}
In this snippet, foo is an array of chars of variable size i + 1. On each iteration of the
loop, foo is dynamically created and automatically cleaned up when it falls out of
scope. If we used alloca( ) instead of a VLA, the memory would not be freed until
the function returned. Using a VLA ensures that the memory is freed on every itera-
tion of the loop. Thus, using a VLA consumes at worst n bytes, whereas alloca( )
would consume n*(n+1)/2 bytes.
Using a variable-length array, we can rewrite our open_sysconf( ) function as follows:
int open_sysconf (const char *file, int flags, int mode)
{
const char *etc; = SYSCONF_DIR; /* "/etc/" */
char name[strlen (etc) + strlen (file) + 1];
strcpy (name, etc);
strcat (name, file);
return open (name, flags, mode);
}
The main difference between alloca( ) and variable-length arrays is that memory
obtained via the former exists for the duration of the function, whereas memory
obtained via the latter exists until the holding variable falls out of scope, which can
be before the current function returns. This could be welcome or unwelcome. In the
for loop we just looked at, reclaiming the memory on each loop iteration reduces net
memory consumption without any side effect (we did not need the extra memory
hanging around). However, if for some reason we wanted the memory to persist
longer than a single loop iteration, using alloca( ) would make more sense.
268 | Chapter 8: Memory Management
Mixing alloca( ) and variable-length arrays in a single function can
invite peculiar behavior. Play it safe and use one or the other in a given
function.
Choosing a Memory Allocation Mechanism
The myriad memory allocation options discussed in this chapter may leave
programmers wondering exactly what solution is best for a given job. In the majority of
situations, malloc( ) is your best bet. Sometimes, however, a different approach
provides a better tool. Table 8-2 summarizes guidelines for choosing an allocation
mechanism.
Finally, let us not forget the alternative to all of these options: automatic and static
memory allocations. Allocating automatic variables on the stack, or global variables
on the heap, is often easier, and does not require that the programmer manage point-
ers and worry about freeing the memory.
Table 8-2. Approaches to memory allocation in Linux
Allocation approach Pros Cons
malloc( ) Easy, simple, common. Returned memory not necessarily zeroed.
calloc( ) Makes allocating arrays simple, zeros
returned memory.
Convoluted interface if not allocating
arrays.
realloc( ) Resizes existing allocations. Useful only for resizing existing
allocations.
brk( ) and sbrk( ) Allows intimate control of the heap. Much too low-level for most users.
Anonymous memory mappings Easy to work with, sharable, allow devel-
oper to adjust protection level and provide
advice; optimal for large mappings.
Suboptimal for small allocations;
malloc( ) automatically uses anony-
mous memory mappings when optimal.
posix_memalign( ) Allocates memory aligned to any reason-
able boundary.
Relatively new and thus portability is
questionable; overkill unless alignment
concerns are pressing.
memalign( ) and valloc( ) More common on other Unix systems
than posix_memalign( ).
Not a POSIX standard, offers less alignment
control than posix_memalign( ).
alloca( ) Very fast allocation, no need to explicitly
free memory; great for small allocations.
Unable to return error, no good for large
allocations, broken on some Unix systems.
Variable-length arrays Same as alloca( ), but frees memory
when array falls out of scope, not when
function returns.
Useful only for arrays; alloca( ) free-
ing behavior may be preferable in some
situations; less common on other Unix
systems than alloca( ).
Manipulating Memory | 269
Manipulating Memory
The C language provides a family of functions for manipulating raw bytes of
memory. These functions operate in many ways similarly to string-manipulation
interfaces such as strcmp( ) and strcpy( ), but they rely on a user-provided buffer size
instead of the assumption that strings are null-terminated. Note that none of these
functions can return errors. Preventing errors is up to the programmer—pass in the
wrong memory region, and there is no alternative, except the resulting segmentation
violation!
Setting Bytes
Among the collection of memory-manipulating functions, the most common is eas-
ily memset( ):
#include <string.h>
void * memset (void *s, int c, size_t n);
A call to memset( ) sets the n bytes starting at s to the byte c and returns s. A frequent
use is zeroing a block of memory:
/* zero out [s,s+256) */
memset (s, '\0', 256);
bzero( ) is an older, deprecated interface introduced by BSD for performing the same
task. New code should use memset( ), but Linux provides bzero( ) for backward com-
patibility and portability with other systems:
#include <strings.h>
void bzero (void *s, size_t n);
The following invocation is identical to the preceding memset( ) example:
bzero (s, 256);
Note that bzero( )—along with the other b interfaces—requires the header <strings.h>
and not <string.h>.
Do not use memset( ) if you can use calloc( )! Avoid allocating mem-
ory with malloc( ), and then immediately zeroing it with memset( ).
While the result may be the same, dropping the two functions for a
single calloc( ), which returns zeroed memory, is much better. Not
only will you make one less function call, but calloc( ) may be able to
obtain already zeroed memory from the kernel. In that case, you avoid
manually setting each byte to 0, and improve performance.
270 | Chapter 8: Memory Management
Comparing Bytes
Similar to strcmp( ), memcmp( ) compares two chunks of memory for equivalence:
#include <string.h>
int memcmp (const void *s1, const void *s2, size_t n);
An invocation compares the first n bytes of s1 to s2, and returns 0 if the blocks of
memory are equivalent, a value less than zero if s1 is less than s2, and a value greater
than zero if s1 is greater than s2.
BSD again provides a now-deprecated interface that performs largely the same task:
#include <strings.h>
int bcmp (const void *s1, const void *s2, size_t n);
An invocation of bcmp( ) compares the first n bytes of s1 to s2, returning 0 if the
blocks of memory are equivalent, and a nonzero value if they are different.
Because of structure padding (see “Other alignment concerns” earlier in this chapter),
comparing two structures for equivalence via memcmp( ) or bcmp( ) is unreliable. There
can be uninitialized garbage in the padding that differs between two otherwise identi-
cal instances of a structure. Consequently, code such as the following is not safe:
/* are two dinghies identical? (BROKEN) */
int compare_dinghies (struct dinghy *a, struct dinghy *b)
{
return memcmp (a, b, sizeof (struct dinghy));
}
Instead, programmers who wish to compare structures should compare each ele-
ment of the structures, one by one. This approach allows for some optimization, but
it’s definitely more work than the unsafe memcmp( ) approach. Here’s the equivalent
code:
/* are two dinghies identical? */
int compare_dinghies (struct dinghy *a, struct dinghy *b)
{
int ret;
if (a->nr_oars < b->nr_oars)
return -1;
if (a->nr_oars > b->nr_oars)
return 1;
ret = strcmp (a->boat_name, b->boat_name);
if (ret)
return ret;
/* and so on, for each member... */
}
Manipulating Memory | 271
Moving Bytes
memmove( ) copies the first n bytes of src to dst, returning dst:
#include <string.h>
void * memmove (void *dst, const void *src, size_t n);
Again, BSD provides a deprecated interface for performing the same task:
#include <strings.h>
void bcopy (const void *src, void *dst, size_t n);
Note that although both functions take the same parameters, the order of the first
two is reversed in bcopy( ).
Both bcopy( ) and memmove( ) can safely handle overlapping memory regions (say, if
part of dst is inside of src). This allows bytes of memory to shift up or down within a
given region, for example. As this situation is rare, and a programmer would know if
it were the case, the C standard defines a variant of memmove( ) that does not support
overlapping memory regions. This variant is potentially faster:
#include <string.h>
void * memcpy (void *dst, const void *src, size_t n);
This function behaves identically to memmove( ), except dst and src may not overlap.
If they do, the results are undefined.
Another safe copying function is memccpy( ):
#include <string.h>
void * memccpy (void *dst, const void *src, int c, size_t n);
The memccpy( ) function behaves the same as memcpy( ), except that it stops copying if
the function finds the byte c within the first n bytes of src. The call returns a pointer
to the next byte in dst after c, or NULL if c was not found.
Finally, you can use mempcpy( ) to step through memory:
#define _GNU_SOURCE
#include <string.h>
void * mempcpy (void *dst, const void *src, size_t n);
The mempcpy( ) function performs the same as memcpy( ), except that it returns a
pointer to the next byte after the last byte copied. This is useful if a set of data is to
be copied to consecutive memory locations—but it’s not so much of an improve-
ment because the return value is merely dst + n. This function is GNU-specific.
272 | Chapter 8: Memory Management
Searching Bytes
The functions memchr( ) and memrchr( ) locate a given byte in a block of memory:
#include <string.h>
void * memchr (const void *s, int c, size_t n);
The memchr( ) function scans the n bytes of memory pointed at by s for the character
c, which is interpreted as an unsigned char:
#define _GNU_SOURCE
#include <string.h>
void * memrchr (const void *s, int c, size_t n);
The call returns a pointer to the first byte to match c, or NULL if c is not found.
The memrchr( ) function is the same as the memchr( ) function, except that it searches
backward from the end of the n bytes pointed at by s instead of forward from the
front. Unlike memchr( ), memrchr( ) is a GNU extension, and not part of the C language.
For more complicated search missions, the awfully named function memmem( )
searches a block of memory for an arbitrary array of bytes:
#define _GNU_SOURCE
#include <string.h>
void * memmem (const void *haystack,
size_t haystacklen,
const void *needle,
size_t needlelen);
The memmem( ) function returns a pointer to the first occurrence of the subblock
needle, of length needlelen bytes, within the block of memory haystack, of length
haystacklen bytes. If the function does not find needle in haystack, it returns NULL.
This function is also a GNU extension.
Frobnicating Bytes
The Linux C library provides an interface for trivially convoluting bytes of data:
#define _GNU_SOURCE
#include <string.h>
void * memfrob (void *s, size_t n);
A call to memfrob( ) obscures the first n bytes of memory starting at s by exclusive-
ORing (XORing) each byte with the number 42. The call returns s.
Locking Memory | 273
The effect of a call to memfrob( ) can be reversed by calling memfrob( ) again on the
same region of memory. Thus, the following snippet is a no-op with respect to
secret:
memfrob (memfrob (secret, len), len);
This function is in no way a proper (or even a poor) substitute for encryption; its use
is limited to the trivial obfuscation of strings. It is GNU-specific.
Locking Memory
Linux implements demand paging, which means that pages are swapped in from disk
as needed, and swapped out to disk when no longer needed. This allows the virtual
address spaces of processes on the system to have no direct relationship to the total
amount of physical memory, as the on-disk swap space can provide the illusion of a
nearly infinite supply of physical memory.
This swapping occurs transparently, and applications generally need not be con-
cerned with (or even know about) the Linux kernel’s paging behavior. There are,
however, two situations in which applications may wish to influence the system’s
paging behavior:
Determinism
Applications with timing constraints require deterministic behavior. If some
memory accesses result in page faults—which incur costly disk I/O operations—
applications can overrun their timing needs. By ensuring that the pages it needs
are always in physical memory, and never paged to disk, an application can
guarantee that memory accesses will not result in page faults, providing consis-
tency, determinism, and improved performance.
Security
If private secrets are kept in memory, the secrets can end up being paged out and
stored unencrypted on disk. For example, if a user’s private key is normally
stored encrypted on disk, an unencrypted copy of the key in memory can end up
in the swap file. In a high-security environment, this behavior may be unaccept-
able. Applications for which this might be a problem can ask that the memory
containing the key always remain in physical memory.
Of course, changing the kernel’s behavior can result in a negative impact on overall
system performance. One application’s determinism or security may improve, but
while its pages are locked into memory, another application’s pages will be paged
out instead. The kernel, if we trust its design, always chooses the optimal page to
swap out—that is, the page least likely to be used in the future—so when you change
its behavior, it has to swap out a suboptimal page.
274 | Chapter 8: Memory Management
Locking Part of an Address Space
POSIX 1003.1b-1993 defines two interfaces for “locking” one or more pages into
physical memory, ensuring that they are never paged out to disk. The first locks a
given interval of addresses:
#include <sys/mman.h>
int mlock (const void *addr, size_t len);
A call to mlock( ) locks the virtual memory starting at addr, and extending for len
bytes into physical memory. On success, the call returns 0; on failure, the call returns
-1, and sets errno as appropriate.
A successful call locks all physical pages that contain [addr,addr+len) in memory.
For example, if a call specifies only a single byte, the entire page in which that byte
resides is locked into memory. The POSIX standard dictates that addr should be
aligned to a page boundary. Linux does not enforce this requirement, silently round-
ing addr down to the nearest page if needed. Programs requiring portability to other
systems, however, should ensure that addr sits on a page boundary.
The valid errno codes include:
EINVAL
The parameter len is negative.
ENOMEM
The caller attempted to lock more pages than the RLIMIT_MEMLOCK resource limit
allows (see the later section “Locking Limits”).
EPERM
The RLIMIT_MEMLOCK resource limit was 0, but the process did not possess the
CAP_IPC_LOCK capability (again, see “Locking Limits”).
A child process does not inherit locked memory across a fork( ). Due
to the copy-on-write behavior of address spaces in Linux, however, a
child process’ pages are effectively locked in memory until the child
writes to them.
As an example, assume that a program holds a decrypted string in memory. A pro-
cess can lock the page containing the string with code such as the following:
int ret;
/* lock 'secret' in memory */
ret = mlock (secret, strlen (secret));
if (ret)
perror ("mlock");
Locking Memory | 275
Locking All of an Address Space
If a process wants to lock its entire address space into physical memory, mlock( ) is a
cumbersome interface. For such a purpose—common to real-time applications—
POSIX defines a system call that locks an entire address space:
#include <sys/mman.h>
int mlockall (int flags);
A call to mlockall( ) locks all of the pages in the current process’ address space into
physical memory. The flags parameter, which is a bitwise OR of the following two
values, controls the behavior:
MCL_CURRENT
If set, this value instructs mlockall( ) to lock all currently mapped pages—the
stack, data segment, mapped files, and so on—into the process’ address space.
MCL_FUTURE
If set, this value instructs mlockall( ) to ensure that all pages mapped into the
address space in the future are also locked into memory.
Most applications specify a bitwise OR of both values.
On success, the call returns 0; on failure, it returns -1, and sets errno to one of the
following error codes:
EINVAL
The parameter flags is negative.
ENOMEM
The caller attempted to lock more pages than the RLIMIT_MEMLOCK resource limit
allows (see the later section “Locking Limits”).
EPERM
The RLIMIT_MEMLOCK resource limit was 0, but the process did not possess the
CAP_IPC_LOCK capability (again, see “Locking Limits”).
Unlocking Memory
To unlock pages from physical memory, again allowing the kernel to swap the pages
out to disk as needed, POSIX standardizes two more interfaces:
#include <sys/mman.h>
int munlock (const void *addr, size_t len);
int munlockall (void);
The system call munlock( ) unlocks the pages starting at addr and extending for len
bytes. It undoes the effects of mlock( ). The system call munlockall( ) undoes the
276 | Chapter 8: Memory Management
effects of mlockall( ). Both calls return 0 on success, and on error return -1, and set
errno to one of the following:
EINVAL
The parameter len is invalid (munlock( ) only).
ENOMEM
Some of the specified pages are invalid.
EPERM
The RLIMIT_MEMLOCK resource limit was 0, but the process did not possess the
CAP_IPC_LOCK capability (see the next section, “Locking Limits”).
Memory locks do not nest. Therefore, a single mlock( ) or munlock( ) will unlock a
locked page, regardless of how many times the page was locked via mlock( ) or
mlockall( ).
Locking Limits
Because locking memory can affect the overall performance of the system—indeed, if
too many pages are locked, memory allocations can fail—Linux places limits on how
many pages a process may lock.
Processes possessing the CAP_IPC_LOCK capability may lock any number of pages into
memory. Processes without this capability may lock only RLIMIT_MEMLOCK bytes. By
default, this resource limit is 32 KB—large enough to lock a secret or two in memory,
but not large enough to adversely affect system performance. (Chapter 6 discusses
resource limits, and how to retrieve and change this value.)
Is a Page in Physical Memory?
For debugging and diagnostic purposes, Linux provides the mincore( ) function,
which can be used to determine whether a given range of memory is in physical
memory, or swapped out to disk:
#include <unistd.h>
#include <sys/mman.h>
int mincore (void *start,
size_t length,
unsigned char *vec);
A call to mincore( ) provides a vector delineating which pages of a mapping are in
physical memory at the time of the system call. The call returns the vector via vec,
and describes the pages starting at start (which must be page-aligned) and extend-
ing for length bytes (which need not be page-aligned). Each byte in vec corresponds
to one page in the range provided, starting with the first byte describing the first
page, and moving linearly forward. Consequently, vec must be at least large enough
to contain (length - 1 + page size) / page size bytes. The lowest-order bit in each
Opportunistic Allocation | 277
byte is 1 if the page is resident in physical memory, and 0 if it is not. The other bits
are currently undefined and reserved for future use.
On success, the call returns 0. On failure, it returns -1, and sets errno to one of the
following:
EAGAIN
Insufficient kernel resources are available to carry out the request.
EFAULT
The parameter vec points at an invalid address.
EINVAL
The parameter start is not aligned to a page boundary.
ENOMEM
[address,address+1) contains memory that is not part of a file-based mapping.
Currently, this system call works properly only for file-based mappings created with
MAP_SHARED. This greatly limits the call’s use.
Opportunistic Allocation
Linux employs an opportunistic allocation strategy. When a process requests addi-
tional memory from the kernel—say, by enlarging its data segment, or by creating a
new memory mapping—the kernel commits to the memory without actually providing
any physical storage. Only when the process writes to the newly allocated memory
does the kernel satisfy the commitment by converting the commitment for memory to
a physical allocation of memory. The kernel does this on a page-by-page basis, per-
forming demand paging and copy-on-writes as needed.
This behavior has several advantages. First, lazily allocating memory allows the ker-
nel to defer most of the work until the last possible moment—if indeed it ever has to
satisfy the allocations. Second, because the requests are satisfied page-by-page and
on demand, only physical memory in actual use need consume physical storage.
Finally, the amount of committed memory can far exceed the amount of physical
memory and even swap space available. This last feature is called overcommitment.
Overcommitting and OOM
Overcommitting allows systems to run many more, and much larger, applications
than they could if every requested page of memory had to be backed by physical stor-
age at the point of allocation instead of the point of use. Without overcommitment,
mapping a 2 GB file copy-on-write would require the kernel to set aside 2 GB of stor-
age. With overcommitment, mapping a 2 GB file requires storage only for each page
of data to which the process actually writes. Likewise, without overcommitment,
every fork( ) would require enough free storage to duplicate the address space, even
though the vast majority of pages never undergo copy-on-writes.
278 | Chapter 8: Memory Management
What if, however, processes attempt to satisfy more outstanding commitments than
the system has physical memory and swap space? In that case, one or more of the
satisfactions must fail. Because the kernel has already committed to the memory—
the system call requesting the commitment returned success—and a process is
attempting to use that committed memory, the kernel’s only recourse is to kill a pro-
cess, freeing up available memory.
When overcommitment results in insufficient memory to satisfy a committed
request, we say that an out of memory (OOM) condition has occurred. In response to
an OOM condition, the kernel employs the OOM killer to pick a process “worthy”
of termination. For this purpose, the kernel tries to find the least important process
that is consuming the most memory.
OOM conditions are rare—hence the huge utility in allowing overcommitment in
the first place. To be sure, however, these conditions are unwelcome, and the inde-
terministic termination of a process by the OOM killer is often unacceptable.
For systems where this is the case, the kernel allows the disabling of overcommit-
ment via the file /proc/sys/vm/overcommit_memory, and the analogous sysctl
parameter vm.overcommit_memory.
The default value for this parameter, 0, instructs the kernel to perform a heuristic
overcommitment strategy, overcommitting memory within reason, but disallowing
egregious overcommitments. A value of 1 allows all commitments to succeed, throw-
ing caution to the wind. Certain memory-intensive applications, such as those in the
scientific field, tend to request so much more memory than they ever need satisfied
that such an option makes sense.
A value of 2 disables overcommitments altogether, and enables strict accounting. In
this mode, memory commitments are restricted to the size of the swap area, plus a
configurable percentage of physical memory. The configuration percentage is set via
the file /proc/sys/vm/overcommit_ratio, or the analogous sysctl parameter, which is
vm.overcommit_ratio. The default is 50, which restricts memory commits to the size
of the swap area plus half of the physical memory. Because physical memory con-
tains the kernel, page tables, system-reserved pages, locked pages, and so on, only a
portion of it is actually swappable and guaranteed to be able to satisfy commitments.
Be careful with strict accounting! Many system designers, repulsed by the notion of
the OOM killer, think strict accounting is a panacea. However, applications often
perform many unnecessary allocations that reach far into overcommitment territory,
and allowing this behavior was one of the main motivations behind virtual memory.
279
Chapter 9 CHAPTER 9
Signals
Signals are software interrupts that provide a mechanism for handling asynchronous
events. These events can originate from outside the system—such as when the user
generates the interrupt character (usually via Ctrl-C)—or from activities within the
program or kernel, such as when the process executes code that divides by zero. As a
primitive form of interprocess communication (IPC), one process can also send a sig-
nal to another process.
The key point is not just that the events occur asynchronously—the user, for exam-
ple, can press Ctrl-C at any point in the program’s execution—but also that the
program handles the signals asynchronously. The signal-handling functions are regis-
tered with the kernel, which invokes the functions asynchronously from the rest of
the program when the signals are delivered.
Signals have been part of Unix since the early days. Over time, however, they have
evolved—most noticeably in terms of reliability, as signals could once get lost, and in
terms of functionality, as signals may now carry user-defined payloads. At first, dif-
ferent Unix systems made incompatible changes to signals. Thankfully, POSIX came
to the rescue and standardized signal handling. This standard is what Linux pro-
vides, and is what we’ll discuss here.
In this chapter, we’ll start with an overview of signals, and a discussion of their use
and misuse. We’ll then cover the various Linux interfaces that manage and manipu-
late signals.
Most nontrivial applications interact with signals. Even if you deliberately design
your application to not rely on signals for its communication needs—often a good
idea!—you’ll still be forced to work with signals in certain cases, such as when han-
dling program termination.
280 | Chapter 9: Signals
Signal Concepts
Signals have a very precise lifecycle. First, a signal is raised (we sometimes also say it
is sent or generated). The kernel then stores the signal until it is able to deliver it.
Finally, once it is free to do so, the kernel handles the signal as appropriate. The ker-
nel can perform one of three actions, depending on what the process asked it to do:
Ignore the signal
No action is taken. There are two signals that cannot be ignored: SIGKILL and
SIGSTOP. The reason for this is that the system administrator needs to be able to
kill or stop processes, and it would be a circumvention of that right if a process
could elect to ignore a SIGKILL (making it unkillable), or a SIGSTOP (making it
unstoppable).
Catch and handle the signal
The kernel will suspend execution of the process’ current code path, and jump
to a previously registered function. The process will then execute this function.
Once the process returns from this function, it will jump back to wherever it was
when it caught the signal.
SIGINT and SIGTERM are two commonly caught signals. Processes catch SIGINT to
handle the user generating the interrupt character—for example, a terminal
might catch this signal and return to the main prompt. Processes catch SIGTERM
to perform necessarily cleanup, such as disconnecting from the network, or
removing temporary files, before terminating. SIGKILL and SIGSTOP cannot be
caught.
Perform the default action
This action depends on the signal being sent. The default action is often to ter-
minate the process. This is the case with SIGKILL, for instance. However, many
signals are provided for specific purposes that concern programmers in particu-
lar situations, and these signals are ignored by default because many programs
are not interested in them. We will look at the various signals and their default
actions shortly.
Traditionally, when a signal was delivered, the function that handled the signal had
no information about what had happened except for the fact that a particular signal
had occurred. Nowadays, the kernel can provide a lot of context to programmers
who want to receive it, and signals can even pass user-defined data, like later and
more advanced IPC mechanisms.
Signal Identifiers
Every signal has a symbolic name that starts with the prefix SIG. For example, SIGINT
is the signal sent when the user presses Ctrl-C, SIGABRT is the signal sent when the
process calls the abort( ) function, and SIGKILL is the signal sent when a process is
forcefully terminated.
Signal Concepts | 281
These signals are all defined in a header file included from <signal.h>. The signals are
simply preprocessor definitions that represent positive integers—that is, every signal
is also associated with an integer identifier. The name-to-integer mapping for the sig-
nals is implementation-dependent, and varies among Unix systems, although the first
dozen or so signals are usually mapped the same way (SIGKILL is infamously signal 9,
for example). A good programmer will always use a signal’s human-readable name,
and never its integer value.
The signal numbers start at 1 (generally SIGHUP), and proceed linearly upward. There
are about 31 signals in total, but most programs deal regularly with only a handful of
them. There is no signal with the value 0, which is a special value known as the null
signal. There’s really nothing important about the null signal—it doesn’t deserve a
special name—but some system calls (such as kill( )) use a value of 0 as a special
case.
You can generate a list of signals supported on your system with the command kill -l.
Signals Supported by Linux
Table 9-1 lists the signals that Linux supports.
Table 9-1. Signals
Signal Description Default action
SIGABRT Sent by abort( ) Terminate with core dump
SIGALRM Sent by alarm( ) Terminate
SIGBUS Hardware or alignment error Terminate with core dump
SIGCHLD Child has terminated Ignored
SIGCONT Process has continued after being stopped Ignored
SIGFPE Arithmetic exception Terminate with core dump
SIGHUP Process’s controlling terminal was closed (most frequently, the user logged
out)
Terminate
SIGILL Process tried to execute an illegal instruction Terminate with core dump
SIGINT User generated the interrupt character (Ctrl-C) Terminate
SIGIO Asynchronous I/O event Terminatea
SIGKILL Uncatchable process termination Terminate
SIGPIPE Process wrote to a pipe but there are no readers Terminate
SIGPROF Profiling timer expired Terminate
SIGPWR Power failure Terminate
SIGQUIT User generated the quit character (Ctrl-\) Terminate with core dump
SIGSEGV Memory access violation Terminate with core dump
SIGSTKFLT Coprocessor stack fault Terminateb
SIGSTOP Suspends execution of the process Stop
282 | Chapter 9: Signals
Several other signal values exist, but Linux defines them to be equivalent to other
values: SIGINFO is defined as SIGPWR,* SIGIOT is defined as SIGABRT, and SIGPOLL and
SIGLOST are defined as SIGIO.
Now that we have a table for quick reference, let’s go over each of the signals in
detail:
SIGABRT
The abort( ) function sends this signal to the process that invokes it. The pro-
cess then terminates and generates a core file. In Linux, assertions such as
assert( ) call abort( ) when the conditional fails.
SIGALRM
The alarm( ) and setitimer( ) (with the ITIMER_REAL flag) functions send this
signal to the process that invoked them when an alarm expires. Chapter 10 dis-
cusses these and related functions.
SIGBUS
The kernel raises this signal when the process incurs a hardware fault other than
memory protection, which generates a SIGSEGV. On traditional Unix systems, this
signal represented various irrecoverable errors, such as unaligned memory access.
The Linux kernel, however, fixes most of these errors automatically, without gen-
erating the signal. The kernel does raise this signal when a process improperly
SIGSYS Process tried to execute an invalid system call Terminate with core dump
SIGTERM Catchable process termination Terminate
SIGTRAP Break point encountered Terminate with core dump
SIGTSTP User generated the suspend character (Ctrl-Z) Stop
SIGTTIN Background process read from controlling terminal Stop
SIGTTOU Background process wrote to controlling terminal Stop
SIGURG Urgent I/O pending Ignored
SIGUSR1 Process-defined signal Terminate
SIGUSR2 Process-defined signal Terminate
SIGVTALRM Generated by setitimer( ) when called with the ITIMER_VIRTUAL flag Terminate
SIGWINCH Size of controlling terminal window changed Ignored
SIGXCPU Processor resource limits were exceeded Terminate with core dump
SIGXFSZ File resource limits were exceeded Terminate with core dump
a The behavior on other Unix systems, such as BSD, is to ignore this signal.
b The Linux kernel no longer generates this signal; it remains only for backward compatibility.
* Only the Alpha architecture defines this signal. On all other machine architectures, this signal does not exist.
Table 9-1. Signals (continued)
Signal Description Default action
Signal Concepts | 283
accesses a region of memory created via mmap( ) (see Chapter 8 for a discussion of
memory mappings). Unless this signal is caught, the kernel will terminate the
process, and generate a core dump.
SIGCHLD
Whenever a process terminates or stops, the kernel sends this signal to the pro-
cess’ parent. Because SIGCHLD is ignored by default, processes must explicitly
catch and handle it if they are interested in the lives of their children. A handler
for this signal generally calls wait( ), discussed in Chapter 5, to determine the
child’s pid and exit code.
SIGCONT
The kernel sends this signal to a process when the process is resumed after being
stopped. By default, this signal is ignored, but processes can catch it if they want
to perform an action after being continued. This signal is commonly used by ter-
minals or editors, which wish to refresh the screen.
SIGFPE
Despite its name, this signal represents any arithmetic exception, and not solely
those related to floating-point operations. Exceptions include overflows, under-
flows, and division by zero. The default action is to terminate the process and
generate a core file, but processes may catch and handle this signal if they want.
Note that the behavior of a process and the result of the offending operation are
undefined if the process elects to continue running.
SIGHUP
The kernel sends this signal to the session leader whenever the session’s terminal
disconnects. The kernel also sends this signal to each process in the foreground
process group when the session leader terminates. The default action is to termi-
nate, which makes sense—the signal suggests that the user has logged out.
Daemon processes “overload” this signal with a mechanism to instruct them to
reload their configuration files. Sending SIGHUP to Apache, for example, instructs
it to reread httpd.conf. Using SIGHUP for this purpose is a common convention,
but not mandatory. The practice is safe because daemons do not have control-
ling terminals, and thus should never normally receive this signal.
SIGILL
The kernel sends this signal when a process attempts to execute an illegal
machine instruction. The default action is to terminate the process, and gener-
ate a core dump. Processes may elect to catch and handle SIGILL, but their
behavior is undefined after its occurrence.
SIGINT
This signal is sent to all processes in the foreground process group when the user
enters the interrupt character (usually Ctrl-C). The default behavior is to terminate;
however, processes can elect to catch and handle this signal, and generally do so to
clean up before terminating.
284 | Chapter 9: Signals
SIGIO
This signal is sent when a BSD-style asynchronous I/O event is generated. This
style of I/O is rarely used on Linux. (See Chapter 4 for a discussion of advanced
I/O techniques that are common to Linux.)
SIGKILL
This signal is sent from the kill( ) system call; it exists to provide system admin-
istrators with a surefire way of unconditionally killing a process. This signal
cannot be caught or ignored, and its result is always to terminate the process.
SIGPIPE
If a process writes to a pipe, but the reader has terminated, the kernel raises this
signal. The default action is to terminate the process, but this signal may be
caught and handled.
SIGPROF
The setitimer( ) function, when used with the ITIMER_PROF flag, generates this sig-
nal when a profiling timer expires. The default action is to terminate the process.
SIGPWR
This signal is system-dependent. On Linux, it represents a low-battery condition
(such as in an uninterruptible power supply, or UPS). A UPS monitoring dae-
mon sends this signal to init, which then responds by cleaning up and shutting
down the system—hopefully before the power goes out!
SIGQUIT
The kernel raises this signal for all processes in the foreground process group
when the user provides the terminal quit character (usually Ctrl-\). The default
action is to terminate the processes, and generate a core dump.
SIGSEGV
This signal, whose name derives from segmentation violation, is sent to a process
when it attempts an invalid memory access. This includes accessing unmapped
memory, reading from memory that is not read-enabled, executing code in mem-
ory that is not execute-enabled, or writing to memory that is not write-enabled.
Processes may catch and handle this signal, but the default action is to termi-
nate the process and generate a core dump.
SIGSTOP
This signal is sent only by kill( ). It unconditionally stops a process, and can-
not be caught or ignored.
SIGSYS
The kernel sends this signal to a process when it attempts to invoke an invalid
system call. This can happen if a binary is built on a newer version of the operat-
ing system (with newer versions of system calls), but then runs on an older
version. Properly built binaries that make their system calls through glibc should
never receive this signal. Instead, invalid system calls should return -1, and set
errno to ENOSYS.
Signal Concepts | 285
SIGTERM
This signal is sent only by kill( ); it allows a user to gracefully terminate a pro-
cess (the default action). Processes may elect to catch this signal, and clean up
before terminating, but it is considered rude to catch this signal and not termi-
nate promptly.
SIGTRAP
The kernel sends this signal to a process when it crosses a break point. Gener-
ally, debuggers catch this signal, and other processes ignore it.
SIGTSTP
The kernel sends this signal to all processes in the foreground process group
when the user provides the suspend character (usually Ctrl-Z).
SIGTTIN
This signal is sent to a process that is in the background when it attempts to read
from its controlling terminal. The default action is to stop the process.
SIGTTOU
This signal is sent to a process that is in the background when it attempts to
write to its controlling terminal. The default action is to stop the process.
SIGURG
The kernel sends this signal to a process when out-of-band (OOB) data has
arrived on a socket. Out-of-band data is beyond the scope of this book.
SIGUSR1 and SIGUSR2
These signals are available for user-defined purposes; the kernel never raises
them. Processes may use SIGUSR1 and SIGUSR2 for whatever purpose they like. A
common use is to instruct a daemon process to behave differently. The default
action is to terminate the process.
SIGVTALRM
The setitimer( ) function sends this signal when a timer created with the
ITIMER_VIRTUAL flag expires. Chapter 10 discusses timers.
SIGWINCH
The kernel raises this signal for all processes in the foreground process group
when the size of their terminal window changes. By default, processes ignore this
signal, but they may elect to catch and handle it if they are aware of their termi-
nal’s window size. A good example of a program that catches this signal is top—
try resizing its window while it is running and watch how it responds.
SIGXCPU
The kernel raises this signal when a process exceeds its soft processor limit. The
kernel will continue to raise this signal once per second until the process exits, or
exceeds its hard processor limit. Once the hard limit is exceeded, the kernel
sends the process a SIGKILL.
286 | Chapter 9: Signals
SIGXFSZ
The kernel raises this signal when a process exceeds its file size limit. The default
action is to terminate the process, but if this signal is caught or ignored, the sys-
tem call that would have resulted in the file size limit being exceeded returns -1,
and sets errno to EFBIG.
Basic Signal Management
The simplest and oldest interface for signal management is the signal( ) function.
Defined by the ISO C89 standard, which standardizes only the lowest common
denominator of signal support, this system call is very basic. Linux offers substan-
tially more control over signals via other interfaces, which we’ll cover later in this
chapter. Because signal( ) is the most basic, and, thanks to its presence in ISO C,
quite common, we’ll cover it first:
#include <signal.h>
typedef void (*sighandler_t)(int);
sighandler_t signal (int signo, sighandler_t handler);
A successful call to signal( ) removes the current action taken on receipt of the sig-
nal signo, and instead handles the signal with the signal handler specified by handler.
signo is one of the signal names discussed in the previous section, such as SIGINT or
SIGUSR1. Recall that a process can catch neither SIGKILL nor SIGSTOP, so setting up a
handler for either of these two signals makes no sense.
The handler function must return void, which makes sense because (unlike with nor-
mal functions) there is no standard place in the program for this function to return.
The function takes one argument, an integer, which is the signal identifier (for exam-
ple, SIGUSR2) of the signal being handled. This allows a single function to handle
multiple signals. A prototype has the form:
void my_handler (int signo);
Linux uses a typedef, sighandler_t, to define this prototype. Other Unix systems
directly use the function pointers; some systems have their own types, which may
not be named sighandler_t. Programs seeking portability should not reference the
type directly.
When it raises a signal to a process that has registered a signal handler, the kernel
suspends execution of the program’s regular instruction stream, and calls the signal
handler. The handler is passed the value of the signal, which is the signo originally
provided to signal( ).
You may also use signal( ) to instruct the kernel to ignore a given signal for the cur-
rent process, or to reset the signal to the default behavior. This is done using special
values for the handler parameter:
Basic Signal Management | 287
SIG_DFL
Set the behavior of the signal given by signo to its default. For example, in the
case of SIGPIPE, the process will terminate.
SIG_IGN
Ignore the signal given by signo.
The signal( ) function returns the previous behavior of the signal, which could be a
pointer to a signal handler, SIG_DFL, or SIG_IGN. On error, the function returns SIG_ERR.
It does not set errno.
Waiting for a Signal, Any Signal
Useful for debugging and writing demonstrative code snippets, the POSIX-defined
pause( ) system call puts a process to sleep until it receives a signal that either is han-
dled or terminates the process:
#include <unistd.h>
int pause (void);
pause( ) returns only if a caught signal is received, in which case the signal is han-
dled, and pause( ) returns -1, and sets errno to EINTR. If the kernel raises an ignored
signal, the process does not wake up.
In the Linux kernel, pause( ) is one of the simplest system calls. It performs only two
actions. First, it puts the process in the interruptible sleep state. Next, it calls
schedule( ) to invoke the Linux process scheduler to find another process to run. As
the process is not actually waiting for anything, the kernel will not wake it up unless
it receives a signal. This whole ordeal consumes only two lines of C code. *
Examples
Let’s look at a couple of simple examples. This first one registers a signal handler for
SIGINT that simply prints a message and then terminates the program (as SIGINT
would do anyway):
#include <stdlib.h>
#include <stdio.h>
#include <unistd.h>
#include <signal.h>
/* handler for SIGINT */
static void sigint_handler (int signo)
{
* Thus, pause( ) is only the second-simplest system call. The joint winners are getpid( ) and gettid( ), which
are each only one line.
288 | Chapter 9: Signals
/*
* Technically, you shouldn't use printf( ) in a
* signal handler, but it isn't the end of the
* world. I'll discuss why in the section
* "Reentrancy."
*/
printf ("Caught SIGINT!\n");
exit (EXIT_SUCCESS);
}
int main (void)
{
/*
* Register sigint_handler as our signal handler
* for SIGINT.
*/
if (signal (SIGINT, sigint_handler) == SIG_ERR) {
fprintf (stderr, "Cannot handle SIGINT!\n");
exit (EXIT_FAILURE);
}
for (;;)
pause ( );
return 0;
}
In the following example, we register the same handler for SIGTERM and SIGINT. We
also reset the behavior for SIGPROF to the default (which is to terminate the process)
and ignore SIGHUP (which would otherwise terminate the process):
#include <stdlib.h>
#include <stdio.h>
#include <unistd.h>
#include <signal.h>
/* handler for SIGINT */
static void signal_handler (int signo)
{
if (signo == SIGINT)
printf ("Caught SIGINT!\n");
else if (signo == SIGTERM)
printf ("Caught SIGTERM!\n");
else {
/* this should never happen */
fprintf (stderr, "Unexpected signal!\n");
exit (EXIT_FAILURE);
}
exit (EXIT_SUCCESS);
}
int main (void)
{
Basic Signal Management | 289
/*
* Register signal_handler as our signal handler
* for SIGINT.
*/
if (signal (SIGINT, signal_handler) == SIG_ERR) {
fprintf (stderr, "Cannot handle SIGINT!\n");
exit (EXIT_FAILURE);
}
/*
* Register signal_handler as our signal handler
* for SIGTERM.
*/
if (signal (SIGTERM, signal_handler) == SIG_ERR) {
fprintf (stderr, "Cannot handle SIGTERM!\n");
exit (EXIT_FAILURE);
}
/* Reset SIGPROF's behavior to the default. */
if (signal (SIGPROF, SIG_DFL) == SIG_ERR) {
fprintf (stderr, "Cannot reset SIGPROF!\n");
exit (EXIT_FAILURE);
}
/* Ignore SIGHUP. */
if (signal (SIGHUP, SIG_IGN) == SIG_ERR) {
fprintf (stderr, "Cannot ignore SIGHUP!\n");
exit (EXIT_FAILURE);
}
for (;;)
pause ( );
return 0;
}
Execution and Inheritance
When a process is first executed, all signals are set to their default actions, unless the
parent process (the one executing the new process) is ignoring them; in this case, the
newly created process will also ignore those signals. Put another way, any signal
caught by the parent is reset to the default action in the new process, and all other
signals remain the same. This makes sense because a freshly executed process does
not share the address space of its parent, and thus any registered signal handlers may
not exist.
This behavior on process execution has one notable use: when the shell executes a
process “in the background” (or when another background process executes another
process), the newly executed process should ignore the interrupt and quit characters.
290 | Chapter 9: Signals
Thus, before a shell executes a background process, it should set SIGINT and SIGQUIT
to SIG_IGN. It is therefore common for programs that handle these signals to first
check to make sure they are not ignored. For example:
/* handle SIGINT, but only if it isn't ignored */
if (signal (SIGINT, SIG_IGN) != SIG_IGN) {
if (signal (SIGINT, sigint_handler) == SIG_ERR)
fprintf (stderr, "Failed to handle SIGINT!\n");
}
/* handle SIGQUIT, but only if it isn't ignored */
if (signal (SIGQUIT, SIG_IGN) != SIG_IGN) {
if (signal (SIGQUIT, sigquit_handler) == SIG_ERR)
fprintf (stderr, "Failed to handle SIGQUIT!\n");
}
The need to set a signal behavior to check the signal behavior highlights a deficiency
in the signal( ) interface. Later, we will study a function that does not have this flaw.
The behavior with fork( ) is, as you might expect, different. When a process calls
fork( ), the child inherits the exact same signal semantics as the parent. This also
makes sense, as the child and parent share an address space, and thus the parent’s
signal handlers exist in the child.
Mapping Signal Numbers to Strings
In our examples thus far, we have hardcoded the names of the signals. But some-
times it is more convenient (or even a requirement) that you be able to convert a
signal number to a string representation of its name. There are several ways to do
this. One is to retrieve the string from a statically defined list:
extern const char * const sys_siglist[];
sys_siglist is an array of strings holding the names of the signals supported by the
system, indexed by signal number.
An alternative is the BSD-defined psignal( ) interface, which is common enough that
Linux supports it, too:
#include <signal.h>
void psignal (int signo, const char *msg);
A call to psignal( ) prints to stderr the string you supply as the msg argument, fol-
lowed by a colon, a space, and the name of the signal given by signo. If signo is
invalid, the printed message will say so.
A better interface is strsignal( ). It is not standardized, but Linux and many non-
Linux systems support it:
Sending a Signal | 291
#define _GNU_SOURCE
#include <string.h>
char *strsignal (int signo);
A call to strsignal( ) returns a pointer to a description of the signal given by signo. If
signo is invalid, the returned description typically says so (some Unix systems that
support this function return NULL instead). The returned string is valid only until the
next invocation of strsignal( ), so this function is not thread-safe.
Going with sys_siglist is usually your best bet. Using this approach, we could
rewrite our earlier signal handler as follows:
static void signal_handler (int signo)
{
printf ("Caught %s\n", sys_siglist[signo]);
}
Sending a Signal
The kill( ) system call, the basis of the common kill utility, sends a signal from one
process to another:
#include <sys/types.h>
#include <signal.h>
int kill (pid_t pid, int signo);
In its normal use (i.e., if pid is greater than 0), kill( ) sends the signal signo to the
process identified by pid.
If pid is 0, signo is sent to every process in the invoking process’ process group.
If pid is -1, signo is sent to every process for which the invoking process has permis-
sion to send a signal, except itself and init. We will discuss the permissions regulating
signal delivery in the next subsection.
If pid is less than -1, signo is sent to the process group -pid.
On success, kill( ) returns 0. The call is considered a success so long as a single sig-
nal was sent. On failure (no signals sent), the call returns -1, and sets errno to one
of the following:
EINVAL
The signal specified by signo is invalid.
EPERM
The invoking process lacks sufficient permissions to send a signal to any of the
requested processes.
ESRCH
The process or process group denoted by pid does not exist, or, in the case of a
process, is a zombie.
292 | Chapter 9: Signals
Permissions
In order to send a signal to another process, the sending process needs proper per-
missions. A process with the CAP_KILL capability (usually one owned by root) can
send a signal to any process. Without this capability, the sending process’ effective or
real user ID must be equal to the real or saved user ID of the receiving process. Put
more simply, a user can send a signal only to a process that he or she owns.
Unix systems define an exception for SIGCONT: a process can send this
signal to any other process in the same session. The user ID need not
match.
If signo is 0—the aforementioned null signal—the call does not send a signal, but it
still performs error checking. This is useful to test whether a process has suitable per-
missions to send the provided process or processes a signal.
Examples
Here’s how to send SIGHUP to the process with process ID 1722:
int ret;
ret = kill (1722, SIGHUP);
if (ret)
perror ("kill");
This snippet is effectively the same as the following invocation of the kill utility:
$ kill -HUP 1722
To check that we have permission to send a signal to 1722 without actually sending
any signal, we could do the following:
int ret;
ret = kill (1722, 0);
if (ret)
; /* we lack permission */
else
; /* we have permission */
Sending a Signal to Yourself
The raise( ) function is a simple way for a process to send a signal to itself:
#include <signal.h>
int raise (int signo);
This call:
raise (signo);
Reentrancy | 293
is equivalent to the following call:
kill (getpid ( ), signo);
The call returns 0 on success, and a nonzero value on failure. It does not set errno.
Sending a Signal to an Entire Process Group
Another convenience function makes it easy to send a signal to all processes in a given
process group, in the event that negating the process group ID and using kill( ) is
deemed too taxing:
#include <signal.h>
int killpg (int pgrp, int signo);
This call:
killpg (pgrp, signo);
is equivalent to the following call:
kill (-pgrp, signo);
This holds true even if pgrp is 0, in which case killpg( ) sends the signal signo to
every process in the invoking process’ group.
On success, killpg( ) returns 0. On failure, it returns -1, and sets errno to one of the
following values:
EINVAL
The signal specified by signo is invalid.
EPERM
The invoking process lacks sufficient permissions to send a signal to any of the
requested processes.
ESRCH
The process group denoted by pgrp does not exist.
Reentrancy
When the kernel raises a signal, a process can be executing code anywhere. For
example, it might be in the middle of an important operation that, if interrupted,
would leave the process is an inconsistent state—say, with a data structure only half
updated, or a calculation only partially performed. The process might even be han-
dling another signal.
Signal handlers cannot tell what code the process is executing when a signal hits; the
handler can run in the middle of anything. It is thus very important that any signal
handler your process installs be very careful about the actions it performs and the
data it touches. Signal handlers must take care not to make assumptions about what
294 | Chapter 9: Signals
the process was doing when it was interrupted. In particular, they must practice cau-
tion when modifying global (that is, shared) data. In general, it is a good idea for a
signal handler never to touch global data; in an upcoming section, however, we will
look at a way to temporarily block the delivery of signals, as a way to allow safe
manipulation of data shared by a signal handler and the rest of a process.
What about system calls and other library functions? What if your process is in the
middle of writing to a file or allocating memory, and a signal handler writes to the
same file or also invokes malloc( )? Or what if a process is in the middle of a call to a
function that uses a static buffer, such as strsignal( ), when a signal is delivered?
Some functions are clearly not reentrant. If a program is in the middle of executing a
nonreentrant function, a signal occurs, and the signal handler then invokes that same
nonreentrant function, chaos can ensue. A reentrant function is a function that is safe
to call from within itself (or concurrently, from another thread in the same process).
In order to qualify as reentrant, a function must not manipulate static data, must
manipulate only stack-allocated data or data provided to it by the caller, and must
not invoke any nonreentrant function.
Guaranteed-Reentrant Functions
When writing a signal handler, you have to assume that the interrupted process
could be in the middle of a nonreentrant function (or anything else, for that matter).
Thus, signal handlers must make use only of functions that are reentrant.
Various standards have decreed lists of functions that are signal-safe—that is, reen-
trant, and thus safe to use from within a signal handler. Most notably, POSIX.1-2003
and the Single UNIX Specification dictate a list of functions that are guaranteed to be
reentrant and signal-safe on all compliant platforms. Table 9-2 lists the functions.
Table 9-2. Functions guaranteed to be safely reentrant for use in signals
abort( ) accept( ) access( )
aio_error( ) aio_return( ) aio_suspend( )
alarm( ) bind( ) cfgetispeed( )
cfgetospeed( ) cfsetispeed( ) cfsetospeed( )
chdir( ) chmod( ) chown( )
clock_gettime( ) close( ) connect( )
creat( ) dup( ) dup2( )
execle( ) execve( ) Exit( )
_exit( ) fchmod( ) fchown( )
fcntl( ) fdatasync( ) fork( )
fpathconf( ) fstat( ) fsync( )
ftruncate( ) getegid( ) geteuid( )
getgid( ) getgroups( ) getpeername( )
Signal Sets | 295
Many more functions are safe, but Linux and other POSIX-compliant systems guar-
antee the reentrancy of only these functions.
Signal Sets
Several of the functions we will look at later in this chapter need to manipulate sets
of signals, such as the set of signals blocked by a process, or the set of signals pend-
ing to a process. The signal set operations manage these signal sets:
#include <signal.h>
int sigemptyset (sigset_t *set);
int sigfillset (sigset_t *set);
getpgrp( ) getpid( ) getppid( )
getsockname( ) getsockopt( ) getuid( )
kill( ) link( ) listen( )
lseek( ) lstat( ) mkdir( )
mkfifo( ) open( ) pathconf( )
pause( ) pipe( ) poll( )
posix_trace_event( ) pselect( ) raise( )
read( ) readlink( ) recv( )
recvfrom( ) recvmsg( ) rename( )
rmdir( ) select( ) sem_post( )
send( ) sendmsg( ) sendto( )
setgid( ) setpgid( ) setsid( )
setsockopt( ) setuid( ) shutdown( )
sigaction( ) sigaddset( ) sigdelset( )
sigemptyset( ) sigfillset( ) sigismember( )
signal( ) sigpause( ) sigpending( )
sigprocmask( ) sigqueue( ) sigset( )
sigsuspend( ) sleep( ) socket( )
socketpair( ) stat( ) symlink( )
sysconf( ) tcdrain( ) tcflow( )
tcflush( ) tcgetattr( ) tcgetpgrp( )
tcsendbreak( ) tcsetattr( ) tcsetpgrp( )
time( ) timer_getoverrun( ) timer_gettime( )
timer_settime( ) times( ) umask( )
uname( ) unlink( ) utime( )
wait( ) waitpid( ) write( )
Table 9-2. Functions guaranteed to be safely reentrant for use in signals (continued)
296 | Chapter 9: Signals
int sigaddset (sigset_t *set, int signo);
int sigdelset (sigset_t *set, int signo);
int sigismember (const sigset_t *set, int signo);
sigemptyset( ) initializes the signal set given by set, marking it empty (all signals
excluded from the set). sigfillset( ) initializes the signal set given by set, marking it
full (all signals included in the set). Both functions return 0. You should call one of
these two functions on a signal set before further using the set.
sigaddset( ) adds signo to the signal set given by set, while sigdelset( ) removes
signo from the signal set given by set. Both return 0 on success, or -1 on error, in
which case errno is set to the error code EINVAL, signifying that signo is an invalid sig-
nal identifier.
sigismember( ) returns 1 if signo is in the signal set given by set, 0 if it is not, and -1 on
error. In the latter case, errno is again set to EINVAL, signifying that signo is invalid.
More Signal Set Functions
The preceding functions are all standardized by POSIX, and found on any modern
Unix system. Linux also provides several nonstandard functions:
#define _GNU_SOURCE
#define <signal.h>
int sigisemptyset (sigset_t *set);
int sigorset (sigset_t *dest, sigset_t *left, sigset_t *right);
int sigandset (sigset_t *dest, sigset_t *left, sigset_t *right);
sigisemptyset( ) returns 1 if the signal set given by set is empty, and 0 otherwise.
sigorset( ) places the union (the binary OR) of the signal sets left and right in dest.
sigandset( ) places the intersection (the binary AND) of the signal sets left and
right in dest. Both return 0 on success, and -1 on error, setting errno to EINVAL.
These functions are useful, but programs desiring full POSIX compliance should
avoid them.
Blocking Signals
Earlier, we discussed reentrancy and the issues raised by signal handlers running
asynchronously, at any time. We discussed functions not to call from within a signal
handler because they themselves are not reentrant.
But what if your program needs to share data between a signal handler and elsewhere
in the program? What if there are portions of your program’s execution during which
Blocking Signals | 297
you do not want any interruptions, including from signal handlers? We call such parts
of a program critical regions, and we protect them by temporarily suspending the
delivery of signals. We say that such signals are blocked. Any signals that are raised
while blocked are not handled until they are unblocked. A process may block any
number of signals; the set of signals blocked by a process is called its signal mask.
POSIX defines, and Linux implements, a function for managing a process’ signal
mask:
#include <signal.h>
int sigprocmask (int how,
const sigset_t *set,
sigset_t *oldset);
The behavior of sigprocmask( ) depends on the value of how, which is one of the fol-
lowing flags:
SIG_SETMASK
The signal mask for the invoking process is changed to set.
SIG_BLOCK
The signals in set are added to the invoking process’ signal mask. In other
words, the signal mask is changed to the union (binary OR) of the current mask
and set.
SIG_UNBLOCK
The signals in set are removed from the invoking process’ signal mask. In other
words, the signal is changed to the intersection (binary AND) of the current
mask, and the negation (binary NOT) of set. It is illegal to unblock a signal that
is not blocked.
If oldset is not NULL, the function places the previous signal set in oldset.
If set is NULL, the function ignores how, and does not change the signal mask, but it
does place the signal mask in oldset. In other words, passing a null value as set is
the way to retrieve the current signal mask.
On success, the call returns 0. On failure, it returns -1, and sets errno to either
EINVAL, signifying that how was invalid, or EFAULT, signifying that set or oldset was an
invalid pointer.
Blocking SIGKILL or SIGSTOP is not allowed. sigprocmask( ) silently ignores any
attempt to add either signal to the signal mask.
Retrieving Pending Signals
When the kernel raises a blocked signal, it is not delivered. We call such signals
pending. When a pending signal is unblocked, the kernel then passes it off to the pro-
cess to handle.
298 | Chapter 9: Signals
POSIX defines a function to retrieve the set of pending signals:
#include <signal.h>
int sigpending (sigset_t *set);
A successful call to sigpending( ) places the set of pending signals in set, and returns
0. On failure, the call returns -1, and sets errno to EFAULT, signifying that set is an
invalid pointer.
Waiting for a Set of Signals
A third POSIX-defined function allows a process to temporarily change its signal
mask, and then wait until a signal is raised that either terminates, or is handled by
the process:
#include <signal.h>
int sigsuspend (const sigset_t *set);
If a signal terminates the process, sigsuspend( ) does not return. If a signal is raised
and handled, sigsuspend( ) returns -1 after the signal handler returns, setting errno
to EINTR. If set is an invalid pointer, errno is set to EFAULT.
A common sigsuspend( ) usage scenario is to retrieve signals that might have arrived
and been blocked during a critical region of program execution. The process first
uses sigprocmask( ) to block a set of signals, saving the old mask in oldset. After exit-
ing the critical region, the process then calls sigsuspend( ), providing oldset for set.
Advanced Signal Management
The signal( ) function that we studied at the beginning of this chapter is very basic.
Because it is part of the standard C library, and therefore has to reflect minimal
assumptions about the capabilities of the operating system on which it runs, it can
offer only a lowest common denominator to signal management. As an alternative,
POSIX standardizes the sigaction( ) system call, which provides much greater signal
management capabilities. Among other things, you can use it to block the reception
of specified signals while your handler runs, and to retrieve a wide range of data
about the system and process state at the moment a signal was raised:
#include <signal.h>
int sigaction (int signo,
const struct sigaction *act,
struct sigaction *oldact);
A call to sigaction( ) changes the behavior of the signal identified by signo, which
can be any value except those associated with SIGKILL and SIGSTOP. If act is not NULL,
the system call changes the current behavior of the signal as specified by act. If
Advanced Signal Management | 299
oldact is not NULL, the call stores the previous (or current, if act is NULL) behavior of
the given signal there.
The sigaction structure allows for fine-grained control over signals. The header
<sys/signal.h>, included from <signal.h>, defines the structure as follows:
struct sigaction {
void (*sa_handler)(int); /* signal handler or action */
void (*sa_sigaction)(int, siginfo_t *, void *);
sigset_t sa_mask; /* signals to block */
int sa_flags; /* flags */
void (*sa_restorer)(void); /* obsolete and non-POSIX */
}
The sa_handler field dictates the action to take upon receiving the signal. As with
signal( ), this field may be SIG_DFL, signifying the default action, SIG_IGN, instructing
the kernel to ignore the signal for the process, or a pointer to a signal-handling func-
tion. The function has the same prototype as a signal handler installed by signal( ):
void my_handler (int signo);
If SA_SIGINFO is set in sa_flags, sa_sigaction, and not sa_handler, dictates the signal-
handling function. This function’s prototype is slightly different:
void my_handler (int signo, siginfo_t *si, void *ucontext);
The function receives the signal number as its first parameter, a siginfo_t structure
as its second parameter, and a ucontext_t structure (cast to a void pointer) as its
third parameter. It has no return value. The siginfo_t structure provides an abun-
dance of information to the signal handler; we will look at it shortly.
Note that on some machine architectures (and possibly other Unix systems), sa_handler
and sa_sigaction are in a union, and you should not assign values to both fields.
The sa_mask field provides a set of signals that the system should block for the dura-
tion of the execution of the signal handler. This allows programmers to enforce
proper protection from reentrancy among multiple signal handlers. The signal cur-
rently being handled is also blocked, unless the SA_NODEFER flag is set in sa_flags.
You cannot block SIGKILL or SIGSTOP; the call will silently ignore either in sa_mask.
The sa_flags field is a bitmask of zero, one, or more flags that change the handling
of the signal given by signo. We already looked at the SA_SIGINFO and SA_NODEFER
flags; other values for sa_flags include the following:
SA_NOCLDSTOP
If signo is SIGCHLD, this flag instructs the system to not provide notification when
a child process stops or resumes.
SA_NOCLDWAIT
If signo is SIGCHLD, this flag enables automatic child reaping: children are not con-
verted to zombies on termination, and the parent need not (and cannot) call wait( )
on them. See Chapter 5 for a lively discussion of children, zombies, and wait( ).
300 | Chapter 9: Signals
SA_NOMASK
This flag is an obsolete non-POSIX equivalent to SA_NODEFER (discussed earlier in
this section). Use SA_NODEFER instead of this flag, but be prepared to see this
value turn up in older code.
SA_ONESHOT
This flag is an obsolete non-POSIX equivalent to SA_RESETHAND (discussed later in
this list). Use SA_RESETHAND instead of this flag, but be prepared to see this value
turn up in older code.
SA_ONSTACK
This flag instructs the system to invoke the given signal handler on an alternative
signal stack, as provided by sigaltstack( ). If you do not provide an alternative
stack, the default is used—that is, the system behaves as if you did not provide
this flag. Alternative signal stacks are rare, although they are useful in some
pthreads applications with smaller thread stacks that might be overrun by some
signal handler usage. We do not further discuss sigaltstack( ) in this book.
SA_RESTART
This flag enables BSD-style restarting of system calls that are interrupted by signals.
SA_RESETHAND
This flag enables “one-shot” mode. The behavior of the given signal is reset to
the default once the signal handler returns.
The sa_restorer field is obsolete, and no longer used in Linux. It is not part of
POSIX, anyhow. Pretend that it is not there, and do not touch it.
sigaction( ) returns 0 on success. On failure, the call returns -1, and sets errno to
one of the following error codes:
EFAULT
act or oldact is an invalid pointer.
EINVAL
signo is an invalid signal, SIGKILL, or SIGSTOP.
The siginfo_t Structure
The siginfo_t structure is also defined in <sys/signal.h>, as follows:
typedef struct siginfo_t {
int si_signo; /* signal number */
int si_errno; /* errno value */
int si_code; /* signal code */
pid_t si_pid; /* sending process's PID */
uid_t si_uid; /* sending process's real UID */
int si_status; /* exit value or signal */
clock_t si_utime; /* user time consumed */
clock_t si_stime; /* system time consumed */
sigval_t si_value; /* signal payload value */
Advanced Signal Management | 301
int si_int; /* POSIX.1b signal */
void *si_ptr; /* POSIX.1b signal */
void *si_addr; /* memory location that caused fault */
int si_band; /* band event */
int si_fd; /* file descriptor */
};
This structure is rife with information passed to the signal handler (if you’re using
sa_sigaction in lieu of sa_sighandler). With modern computing, many consider the
Unix signal model an awful method for performing IPC. Perhaps the problem is that
these folks are stuck using signal( ) when they should be using sigaction( ) with
SA_SIGINFO. The sigaction_t structure opens the door for wringing a lot more func-
tionality out of signals.
There’s a lot of interesting data in this structure, including information about the
process that sent the signal, and about the cause of the signal. Here is a detailed
description of each of the fields:
si_signo
The signal number of the signal in question. In your signal handler, the first
argument provides this information as well (and avoids a pointer dereference).
si_errno
If nonzero, the error code associated with this signal. This field is valid for all
signals.
si_code
An explanation of why and from where the process received the signal (for
example, from kill( )). We will go over the possible values in the following sec-
tion. This field is valid for all signals.
si_pid
For SIGCHLD, the PID of the process that terminated.
si_uid
For SIGCHLD, the owning UID of the process that terminated.
si_status
For SIGCHLD, the exit status of the process that terminated.
si_utime
For SIGCHLD, the user time consumed by the process that terminated.
si_stime
For SIGCHLD, the system time consumed by the process that terminated.
si_value
A union of si_int and si_ptr.
si_int
For signals sent via sigqueue( ) (see “Sending a Signal with a Payload” later in
this chapter), the provided payload typed as an integer.
302 | Chapter 9: Signals
si_ptr
For signals sent via sigqueue( ) (see “Sending a Signal with a Payload” later in
this chapter), the provided payload typed as a void pointer.
si_addr
For SIGBUS, SIGFPE, SIGILL, SIGSEGV, and SIGTRAP, this void pointer contains the
address of the offending fault. For example, in the case of SIGSEGV, this field con-
tains the address of the memory access violation (and is thus often NULL!).
si_band
For SIGPOLL, out-of-band and priority information for the file descriptor listed in
si_fd.
si_fd
For SIGPOLL, the file descriptor for the file whose operation completed.
si_value, si_int, and si_ptr are particularly complex topics because a process can
use them to pass arbitrary data to another process. Thus, you can use them to send
either a simple integer or a pointer to a data structure (note that a pointer is not
much help if the processes do not share an address space). These fields are discussed
in the upcoming section “Sending a Signal with a Payload.”
POSIX guarantees that only the first three fields are valid for all signals. The other
fields should be accessed only when handling the applicable signal. You should
access the si_fd field, for example, only if the signal is SIGPOLL.
The Wonderful World of si_code
The si_code field indicates the cause of the signal. For user-sent signals, the field
indicates how the signal was sent. For kernel-sent signals, the field indicates why the
signal was sent.
The following si_code values are valid for any signal. They indicate how/why the sig-
nal was sent:
SI_ASYNCIO
The signal was sent due to the completion of asynchronous I/O (see Chapter 5).
SI_KERNEL
The signal was raised by the kernel.
SI_MESGQ
The signal was sent due to a state change of a POSIX message queue (not cov-
ered in this book).
SI_QUEUE
The signal was sent by sigqueue( ) (see the next section).
SI_TIMER
The signal was sent due to the expiration of a POSIX timer (see Chapter 10).
Advanced Signal Management | 303
SI_TKILL
The signal was sent by tkill( ) or tgkill( ). These system calls are used by
threading libraries, and are not covered in this book.
SI_SIGIO
The signal was sent due to the queuing of SIGIO.
SI_USER
The signal was sent by kill( ) or raise( ).
The following si_code values are valid for SIGBUS only. They indicate the type of
hardware error that occurred:
BUS_ADRALN
The process incurred an alignment error (see Chapter 8 for a discussion of
alignment).
BUS_ADRERR
The process accessed an invalid physical address.
BUS_OBJERR
The process caused some other form of hardware error.
For SIGCHLD, the following values identify what the child did to generate the signal
sent to its parent:
CLD_CONTINUED
The child was stopped but has resumed.
CLD_DUMPED
The child terminated abnormally.
CLD_EXITED
The child terminated normally via exit( ).
CLD_KILLED
The child was killed.
CLD_STOPPED
The child stopped.
CLD_TRAPPED
The child hit a trap.
The following values are valid for SIGFPE only. They explain the type of arithmetic
error that occurred:
FPE_FLTDIV
The process performed a floating-point operation that resulted in division by
zero.
FPE_FLTOVF
The process performed a floating-point operation that resulted in an overflow.
304 | Chapter 9: Signals
FPE_FLTINV
The process performed an invalid floating-point operation.
FPE_FLTRES
The process performed a floating-point operation that yielded an inexact or
invalid result.
FPE_FLTSUB
The process performed a floating-point operation that resulted in an out-of-range
subscript.
FPE_FLTUND
The process performed a floating-point operation that resulted in an underflow.
FPE_INTDIV
The process performed an integer operation that resulted in division by zero.
FPE_INTOVF
The process performed an integer operation that resulted in an overflow.
The following si_code values are valid for SIGILL only. They explain the nature of the
illegal instruction execution:
ILL_ILLADR
The process attempted to enter an illegal addressing mode.
ILL_ILLOPC
The process attempted to execute an illegal opcode.
ILL_ILLOPN
The process attempted to execute on an illegal operand.
ILL_PRVOPC
The process attempted to execute a privileged opcode.
ILL_PRVREG
The process attempted to execute on a privileged register.
ILL_ILLTRP
The process attempted to enter an illegal trap.
For all of these values, si_addr points to the address of the offense.
For SIGPOLL, the following values identify the I/O event that generated the signal:
POLL_ERR
An I/O error occurred.
POLL_HUP
The device hung up or the socket disconnected.
POLL_IN
The file has data available to read.
POLL_MSG
A message is available.
Sending a Signal with a Payload | 305
POLL_OUT
The file is capable of being written to.
POLL_PRI
The file has high-priority data available to read.
The following codes are valid for SIGSEGV, describing the two types of invalid mem-
ory accesses:
SEGV_ACCERR
The process accessed a valid region of memory in an invalid way—that is, the
process violated memory-access permissions.
SEGV_MAPERR
The process accessed an invalid region of memory.
For either of these values, si_addr contains the offending address.
For SIGTRAP, these two si_code values identify the type of trap hit:
TRAP_BRKPT
The process hit a break point.
TRAP_TRACE
The process hit a trace trap.
Note that si_code is a value field and not a bit field.
Sending a Signal with a Payload
As we saw in the previous section, signal handlers registered with the SA_SIGINFO flag
are passed a siginfo_t parameter. This structure contains a field named si_value,
which is an optional payload passed from the signal generator to the signal receiver.
The sigqueue( ) function, defined by POSIX, allows a process to send a signal with
this payload:
#include <signal.h>
int sigqueue (pid_t pid,
int signo,
const union sigval value);
sigqueue( ) works similarly to kill( ). On success, the signal identified by signo is
queued to the process or process group identified by pid, and the function returns 0.
The signal’s payload is given by value, which is a union of an integer and a void
pointer:
union sigval {
int sival_int;
void *sival_ptr;
};
306 | Chapter 9: Signals
On failure, the call returns -1, and sets errno to one of the following:
EINVAL
The signal specified by signo is invalid.
EPERM
The invoking process lacks sufficient permissions to send a signal to any of the
requested processes. The permissions required to send a signal are the same as
with kill( ) (see the section “Sending a Signal” earlier in this chapter).
ESRCH
The process or process group denoted by pid does not exist or, in the case of a
process, is a zombie.
As with kill( ), you may pass the null signal (0) for signo to test permissions.
Example
This example sends the process with pid 1722 the SIGUSR2 signal with a payload of
an integer that has the value 404:
sigval value;
int ret;
value.sival_int = 404;
ret = sigqueue (1722, SIGUSR2, value);
if (ret)
perror ("sigqueue");
If process 1722 handles SIGUSR2 with an SA_SIGINFO handler, it will find signo set to
SIGUSR2, si->si_int set to 404, and si->si_code set to SI_QUEUE.
Conclusion
Signals have a bad reputation among many Unix programmers. They are an old, anti-
quated mechanism for kernel-to-user communication and are, at best, a primitive
form of IPC. In a world of multithreading programs and event loops, signals are
often out of place.
Nevertheless, for better or worse, we need them. Signals are the only way to receive
many notifications (such as the notification of an illegal opcode execution) from the
kernel. Additionally, signals are how Unix (and thus Linux) terminates processes,
and manages the parent/child relationship. Thus, we are stuck with them.
One of the primary reasons for signals’ derogation is that it is hard to write a proper
signal handler that is safe from reentrancy concerns. If you keep your handlers simple,
however, and use only the functions listed in Table 9-2 (if you use any!), they should
be safe.
Conclusion | 307
Another chink in signals’ armor is that many programmers still use signal( ) and
kill( ), rather than sigaction( ) and sigqueue( ), for signal management. As the last
two sections have shown, signals are significantly more powerful and expressive
when SA_SIGINFO-style signal handlers are used. Although I myself am no fan of
signals—I would love to see signals replaced by a file-descriptor-based pollable
mechanism, which is actually something that’s under consideration for future Linux
kernel versions—working around their flaws and using Linux’s advanced signal
interfaces eases much of the pain (if not the whining).
308
Chapter 10CHAPTER 10
Time
Time serves various purposes in a modern operating system, and many programs
need to keep track of it. The kernel measures the passage of time in three different
ways:
Wall time (or real time)
This is the actual time and date in the real world—that is, the time as one would
read it on a clock on the wall. Processes use the wall time when interfacing with
the user or timestamping an event.
Process time
This is the time that a process has consumed, either directly in user-space code,
or indirectly via the kernel working on the process’ behalf. Processes care about
this form of time mostly for profiling and statistics—measuring how long a given
operation took, for example. Wall time is misleading for measuring process
behavior because, given the multitasking nature of Linux, the process time can
be much less than the wall time for a given operation. A process can also spend
significant cycles waiting for I/O (particularly keyboard input).
Monotonic time
This time source is strictly linearly increasing. Most operating systems, Linux
included, use the system’s uptime (time since boot). The wall time can change—
for example, because the user may set it, and because the system continually
adjusts the time for skew—and additional imprecision can be introduced through,
say, leap seconds. The system uptime, the other hand, is a deterministic and
unchangeable representation of time. The important aspect of a monotonic time
source is not the current value, but the guarantee that the time source is strictly
linearly increasing, and thus useful for calculating the difference in time between
two samplings.
Monotonic time, therefore, is suited for calculating relative time, whereas wall
time is ideal for measuring absolute time.
Time | 309
These three measurements of time may be represented in one of two formats:
Relative time
This is a value relative to some benchmark, such as the current instant: for
example, 5 seconds from now, or 10 minutes ago.
Absolute time
This represents time without any such benchmark: say, noon on 25 March 1968.
Both relative and absolute forms of time have uses. A process might need to cancel a
request in 500 milliseconds, refresh the screen 60 times per second, or note that 7
seconds have elapsed since an operation began. All of these call for relative time cal-
culations. Conversely, a calendar application might save the date for the user’s toga
party as 8 February, a filesystem will write out the full date and time when a file is
created (rather than “five seconds ago”), and the user’s clock displays the Gregorian
date, not the number of seconds since the system booted.
Unix systems represent absolute time as the number of elapsed seconds since the
epoch, which is defined as 00:00:00 UTC on the morning of 1 January 1970. UTC
(Universal Time, Coordinated) is roughly GMT (Greenwich Mean Time) or Zulu
time. Curiously, this means that in Unix, even absolute time is, at a low level, rela-
tive. Unix introduces a special data type for storing “seconds since the epoch,” which
we will look at in the next section.
Operating systems track the progression of time via the software clock, a clock main-
tained by the kernel in software. The kernel instantiates a periodic timer, known as
the system timer, that pops at a specific frequency. When a timer interval ends, the
kernel increments the elapsed time by one unit, known as a tick or a jiffy. The
counter of elapsed ticks is known as the jiffies counter. Previously, a 32-bit value, jif-
fies is a 64-bit counter as of the 2.6 Linux kernel.*
On Linux, the frequency of the system timer is called HZ, because a preprocessor
define of the same name represents it. The value of HZ is architecture-specific, and
not part of the Linux ABI—that is, programs cannot depend on or expect any given
value. Historically, the x86 architecture used a value of 100, meaning the system
timer ran 100 times per second (that is, the system timer had a frequency of 100
hertz). This gave each jiffy a value of 0.01 seconds—1/HZ seconds. With the release
of the 2.6 Linux kernel, the kernel developers bumped the value of HZ to 1000, giving
each jiffy a value of 0.001 seconds. However, in version 2.6.13 and later, HZ is 250,
providing each jiffy a value of 0.004 seconds.† There is a tradeoff inherent in the
value of HZ: higher values provide higher resolution, but incur greater timer overhead.
* Future versions of the Linux kernel may go “tickless,” or implement “dynamic ticks,” in which case the ker-
nel will not keep track of an explicit jiffies value. Instead, all time-based kernel operations will execute from
dynamically instantiated timers rather than from the system timer.
† HZ is also now a compile-time kernel option, with the values 100, 250, and 1000 supported on the x86 archi-
tecture. Regardless, user space cannot depend on any particular value for HZ.
310 | Chapter 10: Time
Although processes should not rely on any fixed value of HZ, POSIX defines a mecha-
nism for determining the system timer frequency at runtime:
long hz;
hz = sysconf (_SC_CLK_TCK);
if (hz == -1)
perror ("sysconf"); /* should never occur */
This interface is useful when a program wants to determine the resolution of the sys-
tem’s timer, but it is not needed for converting system time values to seconds
because most POSIX interfaces export measurements of time that are already con-
verted, or that are scaled to a fixed frequency, independent of HZ. Unlike HZ, this fixed
frequency is part of the system ABI; on x86, the value is 100. POSIX functions that
return time in terms of clock ticks use CLOCKS_PER_SEC to represent the fixed frequency.
Occasionally, events conspire to turn off a computer. Sometimes, computers are even
unplugged; yet, upon boot, they have the correct time. This is because most comput-
ers have a battery-powered hardware clock that stores the time and date while the
computer is off. When the kernel boots, it initializes its concept of the current time
from the hardware clock. Likewise, when the user shuts down the system, the kernel
writes the current time back to the hardware clock. The system’s administrator may
synchronize time at other points via the hwclock command.
Managing the passage of time on a Unix system involves several tasks, only some of
which any given process is concerned with: they include setting and retrieving the
current wall time, calculating elapsed time, sleeping for a given amount of time, per-
forming high-precision measurements of time, and controlling timers. This chapter
covers this full range of time-related chores. We’ll begin by looking at the data struc-
tures with which Linux represents time.
Time’s Data Structures
As Unix systems evolved, implementing their own interfaces for managing time, mul-
tiple data structures came to represent the seemingly simple concept of time. These
data structures range from the simple integer to various multifield structures. We’ll
cover them here before we dive into the actual interfaces.
The Original Representation
The simplest data structure is time_t, defined in the header <time.h>. The intention
was for time_t to be an opaque type. However, on most Unix systems—Linux
included—the type is a simple typedef to the C long type:
typedef long time_t;
Time’s Data Structures | 311
time_t represents the number of elapsed seconds since the epoch. “That won’t last
long before overflowing!” is a typical response. In fact, it will last longer than you
might expect, but it indeed will overflow while plenty of Unix systems are still in use.
With a 32-bit long type, time_t can represent up to 2,147,483,647 seconds past the
epoch. This suggests that we will have the Y2K mess all over again—in 2038! With
luck, however, come 22:14:07 on Monday, 18 January 2038, most systems and soft-
ware will be 64-bit.
And Now, Microsecond Precision
Another issue with time_t is that a lot can happen in a single second. The timeval
structure extends time_t to add microsecond precision. The header <sys/time.h>
defines this structure as follows:
#include <sys/time.h>
struct timeval {
time_t tv_sec; /* seconds */
suseconds_t tv_usec; /* microseconds */
};
tv_sec measures seconds, and tv_usec measures microseconds. The confusing
suseconds_t is normally a typedef to an integer type.
Even Better: Nanosecond Precision
Not content with microsecond resolution, the timespec structure ups the ante to
nanoseconds. The header <time.h> defines this structure as follows:
#include <time.h>
struct timespec {
time_t tv_sec; /* seconds */
long tv_nsec; /* nanoseconds */
};
Given the choice, interfaces prefer nanosecond to microsecond resolution.* Conse-
quently, since the introduction of the timespec structure, most time-related interfaces
have switched to it, and thus have gained greater precision. However, as we will see,
one important function still uses timeval.
In practice, neither structure usually offers the stated precision because the system
timer is not providing nanosecond or even microsecond resolution. Nonetheless, it’s
preferable to have the resolution available in the interface so it can accommodate
whatever resolution the system does offer.
* In addition, the timespec structure dropped the silly suseconds_t business, in favor of a simple and unpre-
tentious long.
312 | Chapter 10: Time
Breaking Down Time
Some of the functions that we will cover convert between Unix time and strings, or
programmatically build a string representing a given date. To facilitate this process,
the C standard provides the tm structure for representing “broken-down” time in a
more human-readable format. This structure is also defined in <time.h>:
#include <time.h>
struct tm {
int tm_sec; /* seconds */
int tm_min; /* minutes */
int tm_hour; /* hours */
int tm_mday; /* the day of the month */
int tm_mon; /* the month */
int tm_year; /* the year */
int tm_wday; /* the day of the week */
int tm_yday; /* the day in the year */
int tm_isdst; /* daylight savings time? */
#ifdef _BSD_SOURCE
long tm_gmtoff; /* time zone's offset from GMT */
const char *tm_zone; /* time zone abbreviation */
#endif /* _BSD_SOURCE */
};
The tm structure makes it easier to tell whether a time_t value of, say, 314159 is a Sun-
day or a Saturday (it is the former). In terms of space, it is obviously a poor choice for
representing the date and time, but it is handy for converting to and from user-
oriented values.
The fields are as follows:
tm_sec
The number of seconds after the minute. This value normally ranges from 0 to
59, but it can be as high as 61 to indicate up to two leap seconds.
tm_min
The number of minutes after the hour. This value ranges from 0 to 59.
tm_hour
The number of hours after midnight. This value ranges from 0 to 23.
tm_mday
The day of the month. This value ranges from 0 to 31. POSIX does not specify
the value 0; however, Linux uses it to indicate the last day of the preceding
month.
tm_mon
The number of months since January. This value ranges from 0 to 11.
tm_year
The number of years since 1900.
POSIX Clocks | 313
tm_wday
The number of days since Sunday. This value ranges from 0 to 6.
tm_yday
The number of days since 1 January. This value ranges from 0 to 365.
tm_isdst
A special value indicating whether daylight savings time (DST) is in effect at the
time described by the other fields. If the value is positive, DST is in effect. If it is
0, DST is not in effect. If the value is negative, the state of DST is unknown.
tm_gmtoff
The offset in seconds of the current time zone from Greenwich Mean Time. This
field is present only if _BSD_SOURCE is defined before including <time.h>.
tm_zone
The abbreviation for the current time zone—for example, EST. This field is
present only if _BSD_SOURCE is defined before including <time.h>.
A Type for Process Time
The type clock_t represents clock ticks. It is an integer type, often a long. Depending
on the interface, the ticks that clock_t signify the system’s actual timer frequency (HZ)
or CLOCKS_PER_SEC.
POSIX Clocks
Several of the system calls discussed in this chapter utilize POSIX clocks, a standard
for implementing and representing time sources. The type clockid_t represents a
specific POSIX clock, four of which Linux supports:
CLOCK_MONOTONIC
A monotonically increasing clock that is not settable by any process. It repre-
sents the elapsed time since some unspecified starting point, such as system
boot.
CLOCK_PROCESS_CPUTIME_ID
A high-resolution, per-process clock available from the processor. For example,
on the i386 architecture, this clock uses the timestamp counter (TSC) register.
CLOCK_REALTIME
The system-wide real time (wall time) clock. Setting this clock requires special
privileges.
CLOCK_THREAD_CPUTIME_ID
Similar to the per-process clock, but unique to each thread in a process.
POSIX defines all four of these time sources, but it requires only CLOCK_REALTIME.
Therefore, while Linux reliably provides all four clocks, portable code should rely
only on CLOCK_REALTIME.
314 | Chapter 10: Time
Time Source Resolution
POSIX defines the function clock_getres( ) for obtaining the resolution of a given
time source:
#include <time.h>
int clock_getres (clockid_t clock_id,
struct timespec *res);
A successful call to clock_getres( ) stores the resolution of the clock specified by
clock_id in res, if it is not NULL, and returns 0. On failure, the function returns -1,
and sets errno to one of the following two error codes:
EFAULT
res is an invalid pointer.
EINVAL
clock_id is not a valid time source on this system.
The following example outputs the resolution of the four time sources discussed in
the previous section:
clockid_t clocks[] = {
CLOCK_REALTIME,
CLOCK_MONOTONIC,
CLOCK_PROCESS_CPUTIME_ID,
CLOCK_THREAD_CPUTIME_ID,
(clockid_t) -1 };
int i;
for (i = 0; clocks[i] != (clockid_t) -1; i++) {
struct timespec res;
int ret;
ret = clock_getres (clocks[i], &res);
if (ret)
perror ("clock_getres");
else
printf ("clock=%d sec=%ld nsec=%ld\n",
clocks[i], res.tv_sec, res.tv_nsec);
}
On a modern x86 system, the output resembles the following:
clock=0 sec=0 nsec=4000250
clock=1 sec=0 nsec=4000250
clock=2 sec=0 nsec=1
clock=3 sec=0 nsec=1
Note that 4,000,250 nanoseconds is 4 milliseconds, which is 0.004 seconds. In turn, 0.
004 seconds is the resolution of the x86 system clock given an HZ value of 250, as we
discussed in the first section of this chapter. Thus, we see that both CLOCK_REALTIME
Getting the Current Time of Day | 315
and CLOCK_MONOTONIC are tied to jiffies, and the resolution provided by the system
timer. Conversely, both CLOCK_PROCESS_CPUTIME_ID and CLOCK_PROCESS_CPUTIME_ID uti-
lize a higher-resolution time source—on this x86 machine, the TSC, which we see
provides nanosecond resolution.
On Linux (and most other Unix systems), all of the functions that use POSIX clocks
require linking the resulting object file with librt. For example, if compiling the previ-
ous snippet into a complete executable, you might use the following command:
$ gcc -Wall -W -O2 –lrt -g -o snippet snippet.c
Getting the Current Time of Day
Applications have several reasons for desiring the current time and date: to display it
to the user, to calculate relative or elapsed time, to timestamp an event, and so on.
The simplest and historically most common way of obtaining the current time is the
time( ) function:
#include <time.h>
time_t time (time_t *t);
A call to time( ) returns the current time represented as the number of seconds
elapsed since the epoch. If the parameter t is not NULL, the function also writes the
current time into the provided pointer.
On error, the function returns -1 (typecast to a time_t), and sets errno appropri-
ately. The only possible error is EFAULT, noting that t is an invalid pointer.
For example:
time_t t;
printf ("current time: %ld\n", (long) time (&t));
printf ("the same value: %ld\n", (long) t);
A Naïve Approach to Time
time_t’s representation of “seconds elapsed since the epoch” is not the actual number
of seconds that have passed since that fateful moment in time. The Unix calculation
assumes leap years are all years divisible by four, and ignores leap seconds altogether.
The point of the time_t representation is not that it is accurate, but that it is consis-
tent—and it is.
316 | Chapter 10: Time
A Better Interface
The function gettimeofday( ) extends time( ) by offering microsecond resolution:
#include <sys/time.h>
int gettimeofday (struct timeval *tv,
struct timezone *tz);
A successful call to gettimeofday( ) places the current time in the timeval structure
pointed at by tv, and returns 0. The timezone structure and the tz parameter are
obsolete; neither should be used on Linux. Always pass NULL for tz.
On failure, the call returns -1, and sets errno to EFAULT; this is the only possible error,
signifying that tv or tz is an invalid pointer.
For example:
struct timeval tv;
int ret;
ret = gettimeofday (&tv, NULL);
if (ret)
perror ("gettimeofday");
else
printf ("seconds=%ld useconds=%ld\n",
(long) tv.sec, (long) tv.usec);
The timezone structure is obsolete because the kernel does not manage the time zone,
and glibc refuses to use the timezone structure’s tz_dsttime field. We will look at
manipulating the time zone in a subsequent section.
An Advanced Interface
POSIX provides the clock_gettime( ) interface for obtaining the time of a specific time
source. More useful, however, is that the function allows for nanosecond precision:
#include <time.h>
int clock_gettime (clockid_t clock_id,
struct timespec *ts);
On success, the call returns 0, and stores the current time of the time source speci-
fied by clock_id in ts. On failure, the call returns -1, and sets errno to one of the
following:
EFAULT
ts is an invalid pointer.
EINVAL
clock_id is an invalid time source on this system.
Getting the Current Time of Day | 317
The following example obtains the current time of all four of the standard time
sources:
clockid_t clocks[] = {
CLOCK_REALTIME,
CLOCK_MONOTONIC,
CLOCK_PROCESS_CPUTIME_ID,
CLOCK_THREAD_CPUTIME_ID,
(clockid_t) -1 };
int i;
for (i = 0; clocks[i] != (clockid_t) -1; i++) {
struct timespec ts;
int ret;
ret = clock_gettime (clocks[i], &ts);
if (ret)
perror ("clock_gettime");
else
printf ("clock=%d sec=%ld nsec=%ld\n",
clocks[i], ts.tv_sec, ts.tv_nsec);
}
Getting the Process Time
The times( ) system call retrieves the process time of the running process and its chil-
dren, in clock ticks:
#include <sys/times.h>
struct tms {
clock_t tms_utime; /* user time consumed */
clock_t tms_stime; /* system time consumed */
clock_t tms_cutime; /* user time consumed by children */
clock_t tms_cstime; /* system time consumed by children */
};
clock_t times (struct tms *buf);
On success, the call fills the provided tms structure pointed at by buf with the pro-
cess time consumed by the invoking process and its children. The reported times are
broken into user and system time. User time is the time spent executing code in user
space. System time is the time spent executing code in kernel space—for example,
during a system call, or a page fault. The reported times for each child are included
only after the child terminates, and the parent invokes waitpid( ) (or a related func-
tion) on the process. The call returns the number of clock ticks, monotonically
increasing, since an arbitrary point in the past. This reference point was once system
boot—thus, the times( ) function returned the system uptime, in ticks—but the
reference point is now about 429 million seconds before system boot. The kernel
318 | Chapter 10: Time
developers implemented this change to catch kernel code that could not handle the
system uptime wrapping around and hitting zero. The absolute value of this function’s
return is thus worthless; relative changes between two invocations, however, continue
to have value.
On failure, the call returns -1, and sets errno as appropriate. On Linux, the only pos-
sible error code is EFAULT, signifying that buf is an invalid pointer.
Setting the Current Time of Day
While previous sections have described how to retrieve times, applications occasion-
ally also need to set the current time and date to a provided value. This is almost
always handled by a utility designed solely for this purpose, such as date.
The time-setting counterpart to time( ) is stime( ):
#define _SVID_SOURCE
#include <time.h>
int stime (time_t *t);
A successful call to stime( ) sets the system time to the value pointed at by t and
returns 0. The call requires that the invoking user have the CAP_SYS_TIME capability.
Generally, only the root user has this capability.
On failure, the call returns -1, and sets errno to EFAULT, signifying that t was an invalid
pointer, or EPERM, signifying that the invoking user did not possess the CAP_SYS_TIME
capability.
Usage is very simple:
time_t t = 1;
int ret;
/* set time to one second after the epoch */
ret = stime (&t);
if (ret)
perror ("stime");
We will look at functions that make it easier to convert human-readable forms of
time to a time_t in a subsequent section.
Setting Time with Precision
The counterpart to gettimeofday( ) is settimeofday( ):
#include <sys/time.h>
int settimeofday (const struct timeval *tv ,
const struct timezone *tz);
Setting the Current Time of Day | 319
A successful call to settimeofday( ) sets the system time as given by tv and returns 0.
As with gettimeofday( ), passing NULL for tz is the best practice. On failure, the call
returns -1, and sets errno to one of the following:
EFAULT
tv or tz points at an invalid region of memory.
EINVAL
A field in one of the provided structures is invalid.
EPERM
The calling process lacks the CAP_SYS_TIME capability.
The following example sets the current time to a Saturday in the middle of Decem-
ber 1979:
struct timeval tv = { .tv_sec = 31415926,
.tv_usec = 27182818 };
int ret;
ret = settimeofday (&tv, NULL);
if (ret)
perror ("settimeofday");
An Advanced Interface for Setting the Time
Just as clock_gettime( ) improves on gettimeofday( ), clock_settime( ) obsolesces
settimeofday( ):
#include <time.h>
int clock_settime (clockid_t clock_id,
const struct timespec *ts);
On success, the call returns 0, and the time source specified by clock_id is set to the
time specified by ts. On failure, the call returns -1, and sets errno to one of the
following:
EFAULT
ts is an invalid pointer.
EINVAL
clock_id is an invalid time source on this system.
EPERM
The process lacks the needed permissions to set the specified time source, or the
specified time source may not be set.
On most systems, the only settable time source is CLOCK_REALTIME. Thus, the only
advantage of this function over settimeofday( ) is that it offers nanosecond precision
(along with not having to deal with the worthless timezone structure).
320 | Chapter 10: Time
Playing with Time
Unix systems and the C language provide a family of functions for converting
between broken-down time (an ASCII string representation of time) and time_t.
asctime( ) converts a tm structure—broken-down time—to an ASCII string:
#include <time.h>
char * asctime (const struct tm *tm);
char * asctime_r (const struct tm *tm, char *buf);
It returns a pointer to a statically allocated string. A subsequent call to any time func-
tion may overwrite this string; asctime( ) is not thread-safe.
Thus, multithreaded programs (and developers who loathe poorly designed inter-
faces) should use asctime_r( ). Instead of returning a pointer to a statically allocated
string, this function uses the string provided via buf, which must be at least 26 char-
acters in length.
Both functions return NULL in the case of error.
mktime( ) also converts a tm structure, but it converts it to a time_t:
#include <time.h>
time_t mktime (struct tm *tm);
mktime( ) also sets the time zone via tzset( ), as specified by tm. On error, it returns -1
(typecast to a time_t).
ctime( ) converts a time_t to its ASCII representation:
#include <time.h>
char * ctime (const time_t *timep);
char * ctime_r (const time_t *timep, char *buf);
On failure, it returns NULL. For example:
time_t t = time (NULL);
printf ("the time a mere line ago: %s", ctime (&t));
Note the lack of newline. Perhaps inconveniently, ctime( ) appends a newline to its
returned string.
Like asctime( ), ctime( ) returns a pointer to a static string. As this is not thread-safe,
threaded programs should instead use ctime_r( ), which operates on the buffer pro-
vided by buf. The buffer must be at least 26 characters in length.
gmtime( ) converts the given time_t to a tm structure, expressed in terms of the UTC
time zone:
#include <time.h>
struct tm * gmtime (const time_t *timep);
struct tm * gmtime_r (const time_t *timep, struct tm *result);
Tuning the System Clock | 321
On failure, it returns NULL.
This function statically allocates the returned structure, and, again, is thus thread-
unsafe. Threaded programs should use gmtime_r( ), which operates on the structure
pointed at by result.
localtime( ) and localtime_r( ) perform functions akin to gmtime( ) and gmtime_r( ),
respectively, but they express the given time_t in terms of the user’s time zone:
#include <time.h>
struct tm * localtime (const time_t *timep);
struct tm * localtime_r (const time_t *timep, struct tm *result);
As with mktime( ), a call to localtime( ) also calls tzset( ), and initializes the time
zone. Whether localtime_r( ) performs this step is unspecified.
difftime( ) returns the number of seconds that have elapsed between two time_t val-
ues, cast to a double:
#include <time.h>
double difftime (time_t time1, time_t time0);
On all POSIX systems, time_t is an arithmetic type, and difftime( ) is equivalent to
the following, ignoring detection of overflow in the subtraction:
(double) (time1 - time0)
On Linux, because time_t is an integer type, there is no need for the cast to double.
To remain portable, however, use difftime( ).
Tuning the System Clock
Large and abrupt jumps in the wall clock time can wreak havoc on applications that
depend on absolute time for their operation. Consider as an example make, which
builds software projects as detailed by a Makefile. Each invocation of the program
does not rebuild entire source trees; if it did, in large software projects, a single
changed file could result in hours of rebuilding. Instead, make looks at the file modi-
fication timestamps of the source file (say, wolf.c) versus the object file (wolf.o). If the
source file—or any of its prerequisites, such as wolf.h—is newer than the object file,
make rebuilds the source file into an updated object file. If the source file is not
newer than the object, however, no action is taken.
With this in mind, consider what might happen if the user realized his clock was off
by a couple of hours, and ran date to update the system clock. If the user then
updated and resaved wolf.c, we could have trouble. If the user has moved the current
time backward, wolf.c will look older than wolf.o—even though it isn’t!—and no
rebuild will occur.
322 | Chapter 10: Time
To prevent such a debacle, Unix provides the adjtime( ) function, which gradually
adjusts the current time in the direction of a given delta. The intention is for back-
ground activities such as Network Time Protcol (NTP) daemons, which constantly
adjust the time in correction of clock skew, to use adjtime( ) to minimize their effects
on the system:
#define _BSD_SOURCE
#include <sys/time.h>
int adjtime (const struct timeval *delta,
struct timeval *olddelta);
A successful call to adjtime( ) instructs the kernel to slowly begin adjusting the time
as stipulated by delta, and then returns 0. If the time specified by delta is positive,
the kernel speeds up the system clock by delta until the correction is fully applied. If
the time specified by delta is negative, the kernel slows down the system clock until
the correction is applied. The kernel applies all adjustments such that the clock is
always monotonically increasing and never undergoes an abrupt time change. Even
with a negative delta, the adjustment will not move the clock backward; instead, the
clock slows down until the system time converges with the corrected time.
If delta is not NULL, the kernel stops processing any previously registered correc-
tions. However, the part of the correction already made, if any, is maintained. If
olddelta is not NULL, any previously registered and yet unapplied correction is writ-
ten into the provided timeval structure. Passing a NULL delta and a valid olddelta
allows retrieval of any ongoing correction.
The corrections applied by adjtime( ) should be small—the ideal use case is NTP, as
mentioned earlier, which applies small corrections (a handful of seconds). Linux
maintains minimum and maximum correction thresholds of a few thousand seconds
in either direction.
On error, adjtime( ) returns -1, and sets errno to one of these values:
EFAULT
delta or olddelta is an invalid pointer.
EINVAL
The adjustment delineated by delta is too large or too small.
EPERM
The invoking user does not possess the CAP_SYS_TIME capability.
RFC 1305 defines a significantly more powerful and correspondingly more complex
clock-adjustment algorithm than the gradual correction approach undertaken by
adjtime( ). Linux implements this algorithm with the adjtimex( ) system call:
#include <sys/timex.h>
int adjtimex (struct timex *adj);
Tuning the System Clock | 323
A call to adjtimex( ) reads kernel time-related parameters into the timex structure
pointed at by adj. Optionally, depending on the modes field of this structure, the sys-
tem call may additionally set certain parameters.
The header <sys/timex.h> defines the timex structure as follows:
struct timex {
int modes; /* mode selector */
long offset; /* time offset (usec) */
long freq; /* frequency offset (scaled ppm) */
long maxerror; /* maximum error (usec) */
long esterror; /* estimated error (usec) */
int status; /* clock status */
long constant; /* PLL time constant */
long precision; /* clock precision (usec) */
long tolerance; /* clock frequency tolerance (ppm) */
struct timeval time; /* current time */
long tick; /* usecs between clock ticks */
};
The modes field is a bitwise OR of zero or more of the following flags:
ADJ_OFFSET
Set the time offset via offset.
ADJ_FREQUENCY
Set the frequency offset via freq.
ADJ_MAXERROR
Set the maximum error via maxerror.
ADJ_ESTERROR
Set the estimated error via esterror.
ADJ_STATUS
Set the clock status via status.
ADJ_TIMECONST
Set the phase-locked loop (PLL) time constant via constant.
ADJ_TICK
Set the tick value via tick.
ADJ_OFFSET_SINGLESHOT
Set the time offset via offset once, with a simple algorithm, like adjtime( ).
If modes is 0, no values are set. Only a user with the CAP_SYS_TIME capability may pro-
vide a nonzero modes value; any user may provide 0 for modes, retrieving all of the
parameters, but setting none of them.
On success, adjtimex( ) returns the current clock state, which is one of the following:
TIME_OK
The clock is synchronized.
324 | Chapter 10: Time
TIME_INS
A leap second will be inserted.
TIME_DEL
A leap second will be deleted.
TIME_OOP
A leap second is in progress.
TIME_WAIT
A leap second just occurred.
TIME_BAD
The clock is not synchronized.
On failure, adjtimex( ) returns -1, and sets errno to one of the following error codes:
EFAULT
adj is an invalid pointer.
EINVAL
One or more of modes, offset, or tick is invalid.
EPERM
modes is nonzero, but the invoking user does not possess the CAP_SYS_TIME
capability.
The adjtimex( ) system call is Linux-specific. Applications concerned with portabil-
ity should prefer adjtime( ).
RFC 1305 defines a complex algorithm, so a complete discussion of adjtimex( ) is
outside the scope of this book. For more information, see the RFC.
Sleeping and Waiting
Various functions allow a process to sleep (suspend execution) for a given amount of
time. The first such function, sleep( ), puts the invoking process to sleep for the
number of seconds specified by seconds:
#include <unistd.h>
unsigned int sleep (unsigned int seconds);
The call returns the number of seconds not slept. Thus, a successful call returns 0,
but the function may return other values between 0 and seconds inclusive (if, say, a
signal interrupts the nap). The function does not set errno. Most users of sleep( ) do
not care about how long the process actually slept, and, consequently, do not check
the return value:
sleep (7); /* sleep seven seconds */
If sleeping the entire specified time is truly a concern, you can continue calling
sleep( ) with its return value, until it returns 0:
Sleeping and Waiting | 325
unsigned int s = 5;
/* sleep five seconds: no ifs, ands, or buts about it */
while ((s = sleep (s)))
;
Sleeping with Microsecond Precision
Sleeping with whole-second granularity is pretty lame. A second is an eternity on a
modern system, so programs often want to sleep with subsecond resolution. Enter
usleep( ):
/* BSD version */
#include <unistd.h>
void usleep (unsigned long usec);
/* SUSv2 version */
#define _XOPEN_SOURCE 500
#include <unistd.h>
int usleep (useconds_t usec);
A successful call to usleep( ) puts the invoking process to sleep for usec microseconds.
Unfortunately, BSD and the Single UNIX Specification disagree on the prototype of the
function. The BSD variant receives an unsigned long, and has no return value. The SUS
variant, however, defines usleep( ) to accept a useconds_t type, and return an int.
Linux follows SUS if _XOPEN_SOURCE is defined as 500 or higher. If _XOPEN_SOURCE is
undefined, or set to less than 500, Linux follows BSD.
The SUS version returns 0 on success, and -1 on error. Valid errno values are EINTR, if
the nap was interrupted by a signal, or EINVAL, if usecs was too large (on Linux, the
full range of the type is valid, and thus this error will never occur).
According to the specification, the useconds_t type is an unsigned integer capable of
holding values as high as 1,000,000.
Due to the differences between the conflicting prototypes, and the fact that some
Unix systems may support one or the other, but not both, it is wise never to explic-
itly include the useconds_t type in your code. For maximum portability, assume that
the parameter is an unsigned int, and do not rely on usleep( )’s return value:
void usleep (unsigned int usec);
Usage is then:
unsigned int usecs = 200;
usleep (usecs);
This works with either variant of the function, and checking for errors is still possible:
errno = 0;
usleep (1000);
326 | Chapter 10: Time
if (errno)
perror ("usleep");
Most programs, however, do not check for or care about usleep( ) errors.
Sleeping with Nanosecond Resolution
Linux deprecates the usleep( ) function, replacing it with nanosleep( ), which pro-
vides nanosecond resolution, and a smarter interface:
#define _POSIX_C_SOURCE 199309
#include <time.h>
int nanosleep (const struct timespec *req,
struct timespec *rem);
A successful call to nanosleep( ) puts the invoking process to sleep for the time specified
by req, and then returns 0. On error, the call returns -1, and sets errno appropriately. If
a signal interrupts the sleep, the call can return before the specified time has elapsed. In
that case, nanosleep( ) returns -1, and sets errno to EINTR. If rem is not NULL, the func-
tion places the remaining time to sleep (the amount of req not slept) in rem. The
program may then reissue the call, passing rem for req (as shown later in this section).
Here are the other possible errno values:
EFAULT
req or rem is an invalid pointer.
EINVAL
One of the fields in req is invalid.
In the basic case, usage is simple:
struct timespec req = { .tv_sec = 0,
.tv_nsec = 200 };
/* sleep for 200 ns */
ret = nanosleep (&req, NULL);
if (ret)
perror ("nanosleep");
And here is an example using the second parameter to continue the sleep if interrupted:
struct timespec req = { .tv_sec = 0,
.tv_nsec = 1369 };
struct timespec rem;
int ret;
/* sleep for 1369 ns */
retry:
ret = nanosleep (&req, &rem);
if (ret) {
Sleeping and Waiting | 327
if (errno == EINTR) {
/* retry, with the provided time remaining */
req.tv_sec = rem.tv_sec;
req.tv_nsec = rem.tv_nsec;
goto retry;
}
perror ("nanosleep");
}
Finally, here’s an alternative approach (perhaps more efficient, but less readable)
toward the same goal:
struct timespec req = { .tv_sec = 1,
.tv_nsec = 0 };
struct timespec rem, *a = &req, *b = &rem;
/* sleep for 1s */
while (nanosleep (a, b) && errno == EINTR) {
struct timespec *tmp = a;
a = b;
b = tmp;
}
nanosleep( ) has several advantages over sleep( ) and usleep( ):
• Nanosecond, as opposed to second or microsecond, resolution.
• Standardized by POSIX.1b.
• Not implemented via signals (the pitfalls of which are discussed later).
Despite deprecation, many programs prefer to use usleep( ) rather than nanosleep( )—
thankfully, at least, fewer and fewer applications are now using sleep( ). Because
nanosleep( ) is a POSIX standard, and does not use signals, new programs should
prefer it (or the interface discussed in the next section) to sleep( ) and usleep( ).
An Advanced Approach to Sleep
As with all of the classes of time functions we have thus far studied, the POSIX
clocks family provides the most advanced sleep interface:
#include <time.h>
int clock_nanosleep (clockid_t clock_id,
int flags,
const struct timespec *req,
struct timespec *rem);
clock_nanosleep( ) behaves similarly to nanosleep( ). In fact, this call:
ret = nanosleep (&req, &rem);
is the same as this call:
ret = clock_nanosleep (CLOCK_REALTIME, 0, &req, &rem);
328 | Chapter 10: Time
The difference lies in the clock_id and flags parameters. The former specifies the
time source to measure against. Most time sources are valid, although you cannot
specify the CPUclock of the invoking process (e.g., CLOCK_PROCESS_CPUTIME_ID);
doing so would make no sense because the call suspends execution of the process,
and thus the process time stops increasing.
What time source you specify depends on your program’s goals for sleeping. If you
are sleeping until some absolute time value, CLOCK_REALTIME may make the most
sense. If you are sleeping for a relative amount of time, CLOCK_MONOTONIC definitely is
the ideal time source.
The flags parameter is either TIMER_ABSTIME or 0. If it is TIMER_ABSTIME, the value
specified by req is treated as absolute, and not relative. This solves a potential race con-
dition. To explain the value of this parameter, assume that a process, at time T0, wants
to sleep until time T1. At T0, the process calls clock_gettime( ) to obtain the current time
(T0). It then subtracts T0 from T1, obtaining Y, which it passes to clock_nanosleep( ).
Some amount of time, however, will have passed between the moment at which the
time was obtained, and the moment at which the process goes to sleep. Worse, what if
the process was scheduled off the processor, incurred a page fault, or something simi-
lar? There is always a potential race condition in between obtaining the current time,
calculating the time differential, and actually sleeping.
The TIMER_ABSTIME flag nullifies the race by allowing a process to directly specify T1.
The kernel suspends the process until the specified time source reaches T1. If the
specified time source’s current time already exceeds T1, the call returns immediately.
Let’s look at both relative and absolute sleeping. The following example sleeps for 1.5
seconds:
struct timespec ts = { .tv_sec = 1, .tv_nsec = 500000000 };
int ret;
ret = clock_nanosleep (CLOCK_MONOTONIC, 0, &ts, NULL);
if (ret)
perror ("clock_nanosleep");
Conversely, the following example sleeps until an absolute value of time—which is
exactly one second from what the clock_gettime( ) call returns for the CLOCK_MONOTONIC
time source—is reached:
struct timespec ts;
int ret;
/* we want to sleep until one second from NOW */
ret = clock_gettime (CLOCK_MONOTONIC, &ts);
if (ret) {
perror ("clock_gettime");
return;
}
Sleeping and Waiting | 329
ts.tv_sec += 1;
printf ("We want to sleep until sec=%ld nsec=%ld\n",
ts.tv_sec, ts.tv_nsec);
ret = clock_nanosleep (CLOCK_MONOTONIC, TIMER_ABSTIME,
&ts, NULL);
if (ret)
perror ("clock_nanosleep");
Most programs need only a relative sleep because their sleep needs are not very strict.
Some real-time processes, however, have very exact timing requirements, and need
the absolute sleep to avoid the danger of a potentially devastating race condition.
A Portable Way to Sleep
Recall from Chapter 2 our friend select( ):
#include <sys/select.h>
int select (int n,
fd_set *readfds,
fd_set *writefds,
fd_set *exceptfds,
struct timeval *timeout);
As mentioned in that chapter, select( ) provides a portable way to sleep with sub-
second resolution. For a long time, portable Unix programs were stuck with sleep( )
for their naptime needs: usleep( ) was not widely available, and nanosleep( ) was as
of yet unwritten. Developers discovered that passing select( ) 0 for n, NULL for all
three of the fd_set pointers, and the desired sleep duration for timeout resulted in a
portable and efficient way to put processes to sleep:
struct timeval tv = { .tv_sec = 0,
.tv_usec = 757 };
/* sleep for 757 us */
select (0, NULL, NULL, NULL, &tv);
If portability to older Unix systems is a concern, using select( ) may be your best bet.
Overruns
All of the interfaces discussed in this section guarantee that they will sleep at least as
long as requested (or return an error indicating otherwise). They will never return
success without the requested delay elapsing. It is possible, however, for an interval
longer than the requested delay to pass.
This phenomenon may be due to simple scheduling behavior—the requested time
may have elapsed, and the kernel may have woken up the process on time, but the
scheduler may have selected a different task to run.
330 | Chapter 10: Time
There exists a more insidious cause, however: timer overruns. This occurs when the
granularity of the timer is coarser than the requested time interval. For example,
assume the system timer ticks in 10 ms intervals, and a process requests a 1 ms sleep.
The system is able to measure time and respond to time-related events (such as wak-
ing up a process from sleep) only at 10 ms intervals. If, when the process issues the
sleep request, the timer is 1 ms away from a tick, everything will be fine—in 1 ms,
the requested time (1 ms) will elapse, and the kernel will wake up the process. If,
however, the timer hits right as the process requests the sleep, there won’t be another
timer tick for 10 ms. Subsequently, the process will sleep an extra 9 ms! That is,
there will be nine 1 ms overruns. On average, a timer with a period of X has an over-
run rate of X/2.
The use of high-precision time sources, such as those provided by POSIX clocks, and
higher values for HZ, minimize timer overrun.
Alternatives to Sleeping
If possible, you should avoid sleeping. Often, you cannot, and that’s fine—particu-
larly if your code is sleeping for less than a second. Code laced with sleeps, however,
in order to “busy-wait” for events, is usually of poor design. Code that blocks on a
file descriptor, allowing the kernel to handle the sleep and wake up the process, is
better. Instead of the process spinning in a loop until the event hits, the kernel can
block the process from execution, and wake it up only when needed.
Timers
Timers provide a mechanism for notifying a process when a given amount of time
elapses. The amount of time before a timer expires is called the delay, or the expira-
tion. How the kernel notifies the process that the timer has expired depends on the
timer. The Linux kernel offers several types. We will study them all.
Timers are useful for several reasons. Examples include refreshing the screen 60
times per second, or canceling a pending transaction if it is still ongoing after 500
milliseconds.
Simple Alarms
alarm( ) is the simplest timer interface:
#include <unistd.h>
unsigned int alarm (unsigned int seconds);
Timers | 331
A call to this function schedules the delivery of a SIGALRM signal to the invoking pro-
cess after seconds seconds of real time have elapsed. If a previously scheduled signal
was pending, the call cancels the alarm, replaces it with the newly requested alarm,
and returns the number of seconds remaining in the previous alarm. If seconds is 0,
the previous alarm, if any, is canceled, but no new alarm is scheduled.
Successful use of this function thus also requires registering a signal handler for the
SIGALRM signal. (Signals and signal handlers were covered in the previous chapter.)
Here is a code snippet that registers a SIGALRM handler, alarm_handler( ), and sets an
alarm for five seconds:
void alarm_handler (int signum)
{
printf ("Five seconds passed!\n");
}
void func (void)
{
signal (SIGALRM, alarm_handler);
alarm (5);
pause ( );
}
Interval Timers
Interval timer system calls, which first appeared in 4.2BSD, have since been stan-
dardized in POSIX, and provide more control than alarm( ):
#include <sys/time.h>
int getitimer (int which,
struct itimerval *value);
int setitimer (int which,
const struct itimerval *value,
struct itimerval *ovalue);
Interval timers operate like alarm( ), but optionally can automatically rearm them-
selves, and operate in one of three distinct modes:
ITIMER_REAL
Measures real time. When the specified amount of real time has elapsed, the ker-
nel sends the process a SIGALRM signal.
ITIMER_VIRTUAL
Decrements only while the process’ user-space code is executing. When the
specified amount of process time has elapsed, the kernel sends the process a
SIGVTALRM.
332 | Chapter 10: Time
ITIMER_PROF
Decrements both while the process is executing, and while the kernel is execut-
ing on behalf of the process (for example, completing a system call). When the
specified amount of time has elapsed, the kernel sends the process a SIGPROF sig-
nal. This mode is usually coupled with ITIMER_VIRTUAL, so that the program can
measure user and kernel time spent by the process.
ITIMER_REAL measures the same time as alarm( ); the other two modes are useful for
profiling.
The itimerval structure allows the user to specify the amount of time until the timer
expires, as well as the expiration, if any, with which to rearm the timer upon expiration:
struct itimerval {
struct timeval it_interval; /* next value */
struct timeval it_value; /* current value */
};
Recall from earlier that the timeval structure provides microsecond resolution:
struct timeval {
long tv_sec; /* seconds */
long tv_usec; /* microseconds */
};
setitimer( ) arms a timer of type which with the expiration specified by it_value.
Once the time specified by it_value elapses, the kernel rearms the timer with the
time provided by it_interval. Thus, it_value is the time remaining on the current
timer. Once it_value reaches zero, it is set to it_interval. If the timer expires, and
it_interval is 0, the timer is not rearmed. Similarly, if an active timer’s it_value is
set to 0, the timer is stopped, and not rearmed.
If ovalue is not NULL, the previous values for the interval timer of type which is
returned.
getitimer( ) returns the current values for the interval timer of type which.
Both functions return 0 on success, and -1 on error, in which case errno is set to one
of the following:
EFAULT
value or ovalue is an invalid pointer.
EINVAL
which is not a valid interval timer type.
The following code snippet creates a SIGALRM signal handler (again, see Chapter 9),
and then arms an interval timer with an initial expiration of five seconds, followed by
a subsequent interval of one second:
void alarm_handler (int signo)
{
printf ("Timer hit!\n");
Timers | 333
}
void foo (void) {
struct itimerval delay;
int ret;
signal (SIGALRM, alarm_handler);
delay.it_value.tv_sec = 5;
delay.it_value.tv_usec = 0;
delay.it_interval.tv_sec = 1;
delay.it_interval.tv_usec = 0;
ret = setitimer (ITIMER_REAL, &delay, NULL);
if (ret) {
perror ("setitimer");
return;
}
pause ( );
}
Some Unix systems implement sleep( ) and usleep( ) via SIGALRM—and, obviously,
alarm( ) and setitimer( ) use SIGALRM. Therefore, programmers must be careful not
to overlap calls to these functions; the results are undefined. For the purpose of brief
waits, programmers should use nanosleep( ), which POSIX dictates will not use sig-
nals. For timers, programmers should use setitimer( ) or alarm( ).
Advanced Timers
The most powerful timer interface, not surprisingly, hails from the POSIX clocks
family.
With POSIX clocks-based timers, the acts of instantiating, initializing, and ultimately
deleting a timer are separated into three different functions: timer_create( ) creates
the timer, timer_settime( ) initializes the timer, and timer_delete( ) destroys it.
The POSIX clocks family of timer interfaces is undoubtedly the most
advanced, but also the newest (ergo the least portable), and most com-
plicated to use. If simplicity or portability is a prime motivator,
setitimer( ) is most likely a better choice.
Creating a timer
To create a timer, use timer_create( ):
#include <signal.h>
#include <time.h>
int timer_create (clockid_t clockid,
struct sigevent *evp,
timer_t *timerid);
334 | Chapter 10: Time
A successful call to timer_create( ) creates a new timer associated with the POSIX
clock clockid, stores a unique timer identification in timerid, and returns 0. This call
merely sets up the conditions for running the timer; nothing actually happens until
the timer is armed, as shown in the following section.
The following example creates a new timer keyed off the CLOCK_PROCESS_CPUTIME_ID
POSIX clock, and stores the timer’s ID in timer:
timer_t timer;
int ret;
ret = timer_create (CLOCK_PROCESS_CPUTIME_ID,
NULL,
&timer);
if (ret)
perror ("timer_create");
On failure, the call returns -1, timerid is undefined, and the call sets errno to one of
the following:
EAGAIN
The system lacks sufficient resources to complete the request.
EINVAL
The POSIX clock specified by clockid is invalid.
ENOTSUP
The POSIX clock specified by clockid is valid, but the system does not support
using the clock for timers. POSIX guarantees that all implementations support
the CLOCK_REALTIME clock for timers. Whether other clocks are supported is up to
the implementation.
The evp parameter, if non-NULL, defines the asynchronous notification that occurs
when the timer expires. The header <signal.h> defines the structure. Its contents are
supposed to be opaque to the programmer, but it has at least the following fields:
#include <signal.h>
struct sigevent {
union sigval sigev_value;
int sigev_signo;
int sigev_notify;
void (*sigev_notify_function)(union sigval);
pthread_attr_t *sigev_notify_attributes;
};
union sigval {
int sival_int;
void *sival_ptr;
};
Timers | 335
POSIX clocks-based timers allow much greater control over how the kernel notifies
the process when a timer expires, allowing the process to specify exactly which sig-
nal the kernel will emit, or even allowing the kernel to spawn a thread, and execute a
function in response to timer expiration. A process specifies the behavior on timer
expiration via sigev_notify, which must be one of the following three values:
SIGEV_NONE
A “null” notification. On timer expiration, nothing happens.
SIGEV_SIGNAL
On timer expiration, the kernel sends the process the signal specified by
sigev_signo. In the signal handler, si_value is set to sigev_value.
SIGEV_THREAD
On timer expiration, the kernel spawns a new thread (within this process), and has
it execute sigev_notify_function, passing sigev_value as its sole argument. The
thread terminates when it returns from this function. If sigev_notify_attributes is
not NULL, the provided pthread_attr_t structure defines the behavior of the new
thread.
If evp is NULL, as it was in our earlier example, the timer’s expiration notification is set
up as if sigev_notify were SIGEV_SIGNAL, sigev_signo were SIGALRM, and sigev_value
were the timer’s ID. Thus, by default, these timers notify in a manner similar to
POSIX interval timers. Via customization, however, they can do much, much more!
The following example creates a timer keyed off CLOCK_REALTIME. When the timer
expires, the kernel will issue the SIGUSR1 signal, and set si_value to the address stor-
ing the timer’s ID:
struct sigevent evp;
timer_t timer;
int ret;
evp.sigev_value.sival_ptr = &timer;
evp.sigev_notify = SIGEV_SIGNAL;
evp.sigev_signo = SIGUSR1;
ret = timer_create (CLOCK_REALTIME,
&evp,
&timer);
if (ret)
perror ("timer_create");
Arming a timer
A timer created by timer_create( ) is unarmed. To associate it with an expiration
and start the clock ticking, use timer_settime( ):
#include <time.h>
int timer_settime (timer_t timerid,
int flags,
const struct itimerspec *value,
struct itimerspec *ovalue);
336 | Chapter 10: Time
A successful call to timer_settime( ) arms the timer specified by timerid with the
expiration value, which is an itimerspec structure:
struct itimerspec {
struct timespec it_interval; /* next value */
struct timespec it_value; /* current value */
};
As with setitimer( ), it_value specifies the current timer expiration. When the timer
expires, it_value is refreshed with the value from it_interval. If it_interval is 0,
the timer is not an interval timer, and will disarm once it_value expires.
Recall from earlier that the timespec structure provides nanosecond resolution:
struct timespec {
time_t tv_sec; /* seconds */
long tv_nsec; /* nanoseconds */
};
If flags is TIMER_ABSTIME, the time specified by value is interpreted as absolute (as
opposed to the default interpretation, where the value is relative to the current time).
This modified behavior prevents a race condition during the steps of obtaining the
current time, calculating the relative difference between that time, and a desired
future time, and arming the timer. See the discussion in the earlier section, “An
Advanced Approach to Sleep” for details.
If ovalue is non-NULL, the previous timer expiration is saved in the provided
itimerspec. If the timer was previously disarmed, the structure’s members are all set
to 0.
Using the timer value initialized earlier by timer_create( ), the following example
creates a periodic timer that expires every second:
struct itimerspec ts;
int ret;
ts.it_interval.tv_sec = 1;
ts.it_interval.tv_nsec = 0;
ts.it_value.tv_sec = 1;
ts.it_value.tv_nsec = 0;
ret = timer_settime (timer, 0, &ts, NULL);
if (ret)
perror ("timer_settime");
Obtaining the expiration of a timer
You can get the expiration time of a timer without resetting it, at any time, via
timer_gettime( ):
#include <time.h>
int timer_gettime (timer_t timerid,
struct itimerspec *value);
Timers | 337
A successful call to timer_gettime( ) stores the expiration time of the timer specified
by timerid in the structure pointed at by value, and returns 0. On failure, the call
returns -1, and sets errno to one of the following:
EFAULT
value is an invalid pointer.
EINVAL
timerid is an invalid timer.
For example:
struct itimerspec ts;
int ret;
ret = timer_gettime (timer, &ts);
if (ret)
perror ("timer_gettime");
else {
printf ("current sec=%ld nsec=%ld\n",
ts.it_value.tv_sec, ts.it_value.tv_nsec);
printf ("next sec=%ld nsec=%ld\n",
ts.it_interval.tv_sec, ts.it_interval.tv_nsec);
}
Obtaining the overrun of a timer
POSIX defines an interface for determining how many, if any, overruns occurred on a
given timer:
#include <time.h>
int timer_getoverrun (timer_t timerid);
On success, timer_getoverrun( ) returns the number of additional timer expirations
that have occurred between the initial expiration of the timer and notification to the
process—for example, via a signal—that the timer expired. For instance, in our ear-
lier example, where a 1 ms timer ran for 10 ms, the call would return 9.
If the number of overruns is equal to or greater than DELAYTIMER_MAX, the call returns
DELAYTIMER_MAX.
On failure, the function returns -1, and sets errno to EINVAL, the lone error condi-
tion, signifying that the timer specified by timerid is invalid.
For example:
int ret;
ret = timer_getoverrun (timer);
if (ret == -1)
perror ("timer_getoverrun");
else if (ret == 0)
printf ("no overrun\n");
else
printf ("%d overrun(s)\n", ret);
338 | Chapter 10: Time
Deleting a timer
Deleting a timer is easy:
#include <time.h>
int timer_delete (timer_t timerid);
A successful call to timer_delete( ) destroys the timer associated with timerid, and
returns 0. On failure, the call returns -1, and errno is set to EINVAL, the lone error
condition, signifying that timerid is not a valid timer.
339
Appendix APPENDIX
GCC Extensions to the C Language
The GNUCompiler Collection (GCC) provides many extensions to the C language,
some of which have proven to be of particular value to system programmers. The
majority of the additions to the C language that we’ll cover in this appendix offer
ways for programmers to provide additional information to the compiler about the
behavior and intended use of their code. The compiler, in turn, utilizes this informa-
tion to generate more efficient machine code. Other extensions fill in gaps in the C
programming language, particularly at lower levels.
GCC provides several extensions now available in the latest C standard, ISO C99.
Some of these extensions function similarly to their C99 cousins, but ISO C99 imple-
mented other extensions rather differently. New code should use the ISO C99
variants of these features. We won’t cover such extensions here; we’ll discuss only
GCC-unique additions.
GNU C
The flavor of C supported by GCC is often called GNUC. In the 1990s, GNUC
filled in several gaps in the C language, providing features such as complex vari-
ables, zero-length arrays, inline functions, and named initializers. But after nearly a
decade, C was finally upgraded, and with the standardization of ISO C99, GNUC
extensions became less relevant. Nonetheless, GNUC continues to provide useful
features, and many Linux programmers still use a subset of GNUC—often just an
extension or two—in their C90- or C99-compliant code.
One prominent example of a GCC-specific code base is the Linux kernel, which is
written strictly in GNUC. Recently, however, Intel has invested engineering effort in
allowing the Intel C Compiler (ICC) to understand the GNUC extensions used by
the kernel. Consequently, many of these extensions are now growing less GCC-
specific.
340 | Appendix: GCC Extensions to the C Language
Inline Functions
The compiler copies the entire code of an “inline” function into the site where the
function is called. Instead of storing the function externally and jumping to it when-
ever it is called, it runs the contents of the function directly. Such behavior saves the
overhead of the function call, and allows for potential optimizations at the call site
because the compiler can optimize the caller and callee together. This latter point is
particularly valid if the parameters to the function are constant at the call site. Natu-
rally, however, copying a function into each and every chunk of code that invokes it
can have a detrimental effect on code size. Therefore, functions should be inlined
only if they are small and simple, or are not called in many different places.
For many years, GCC has supported the inline keyword, instructing the compiler to
inline the given function. C99 formalized this keyword:
static inline int foo (void) { /* ... */ }
Technically, however, the keyword is merely a hint—a suggestion to the compiler to
consider inlining the given function. GCC further provides an extension for instruct-
ing the compiler to always inline the designated function:
static inline _ _attribute_ _ ((always_inline)) int foo (void) { /* ... */ }
The most obvious candidate for an inline function is a preprocessor macro. An inline
function in GCC will perform as well as a macro, and, additionally, receives type
checking. For example, instead of this macro:
#define max(a,b) ({ a > b ? a : b; })
one might use the corresponding inline function:
static inline max (int a, int b)
{
if (a > b)
return a;
return b;
}
Programmers tend to overuse inline functions. Function call overhead on most mod-
ern architectures—the x86 in particular—is very, very low. Only the most worthy of
functions should receive consideration!
Suppressing Inlining
In its most aggressive optimization mode, GCC automatically selects functions that
appear suitable for inlining and inlines them. This is normally a good idea, but some-
times the programmer knows that a function will perform incorrectly if inlined. One
possible example of this is when using _ _builtin_return_address (discussed later in
this appendix). To suppress inlining, use the noinline keyword:
_ _attribute_ _ ((noinline)) int foo (void) { /* ... */ }
Constant Functions | 341
Pure Functions
A “pure” function is one that has no effects, and whose return value reflects only the
function’s parameters or nonvolatile global variables. Any parameter or global vari-
able access must be read-only. Loop optimization and subexpression elimination can
be applied to such functions. Functions are marked as pure via the pure keyword:
__attribute_ _ ((pure)) int foo (int val) { /* ... */ }
A common example is strlen( ). Given identical inputs, this function’s return value
is invariant across multiple invocations, and thus it can be pulled out of a loop, and
called just once. For example, consider the following code:
/* character by character, print each letter in 'p' in uppercase */
for (i = 0; i < strlen (p); i++)
printf ("%c", toupper (p[i]));
If the compiler did not know that strlen( ) was pure, it might invoke the function
with each iteration of the loop!
Smart programmers—as well as the compiler, if strlen( ) were marked pure—would
write or generate code like this:
size_t len;
len = strlen (p);
for (i = 0; i < len; i++)
printf ("%c", toupper (p[i]));
Parenthetically, even smarter programmers (such as this book’s readers) would write:
while (*p)
printf ("%c", toupper (*p++));
It is illegal, and indeed makes no sense, for a pure function to return void, as the
return value is the sole point of such functions.
Constant Functions
A “constant” function is a stricter variant of a pure function. Such functions cannot
access global variables, and cannot take pointers as parameters. Thus, the constant
function’s return value reflects nothing but the passed-by-value parameters. Addi-
tional optimizations, on top of those possible with pure functions, are possible for
such functions. Math functions, such as abs( ), are examples of constant functions
(presuming they don’t save state or otherwise pull tricks in the name of optimiza-
tion). A programmer marks a function constant via the const keyword:
_ _attribute_ _ ((const)) int foo (int val) { /* ... */ }
As with pure functions, it makes no sense for a constant function to return void.
342 | Appendix: GCC Extensions to the C Language
Functions That Do Not Return
If a function does not return—perhaps because it invariantly calls exit( )—the
programmer can mark the function with the noreturn keyword, enlightening the
compiler to that fact:
_ _attribute_ _ ((noreturn)) void foo (int val) { /* ... */ }
In turn, the compiler can make additional optimizations, with the understanding
that under no circumstances will the invoked function ever return. It does not make
sense for such a function to return anything but void.
Functions That Allocate Memory
If a function returns a pointer that can never alias * existing memory—almost assur-
edly because the function just allocated fresh memory, and is returning a pointer to
it—the programmer can mark the function as such with the malloc keyword, and the
compiler can in turn perform suitable optimizations:
_ _attribute_ _ ((malloc)) void * get_page (void)
{
int page_size;
page_size = getpagesize ( );
if (page_size <= 0)
return NULL;
return malloc (page_size);
}
Forcing Callers to Check the Return Value
Not an optimization, but a programming aid, the warn_unused_result attribute
instructs the compiler to generate a warning whenever the return value of a function
is not stored or used in a conditional statement:
_ _attribute_ _ ((warn_unused_result)) int foo (void) { /* ... */ }
This allows the programmer to ensure that all callers check and handle the return
value from a function where the value is of particular importance. Functions with
important but oft-ignored return values, such as read( ), make excellent candidates
for this attribute. Such functions cannot return void.
* A memory alias occurs when two or more pointer variables point at the same memory address. This can hap-
pen in trivial cases where a pointer is assigned the value of another pointer, and also in more complex, less
obvious cases. If a function is returning the address of newly allocated memory, no other pointers to that
same address should exist.
Packing a Structure | 343
Marking Functions As Deprecated
The deprecated attribute instructs the compiler to generate a warning at the call site
whenever the function is invoked:
_ _attribute_ _ ((deprecated)) void foo (void) { /* ... */ }
This helps wean programmers off deprecated and obsolete interfaces.
Marking Functions As Used
Occasionally, no code visible to a compiler invokes a particular function. Marking a
function with the used attribute instructs the compiler that the program uses that
function, despite appearances that the function is never referenced:
static _ _attribute_ _ ((used)) void foo (void) { /* ... */ }
The compiler therefore outputs the resulting assembly language, and does not dis-
play a warning about an unused function. This attribute is useful if a static function
is invoked only from handwritten assembly code. Normally, if the compiler is not
aware of any invocation, it will generate a warning, and potentially optimize away
the function.
Marking Functions or Parameters As Unused
The unused attribute tells the compiler that the given function or function parameter
is unused, and instructs it not to issue any corresponding warnings:
int foo (long _ _attribute_ _ ((unused)) value) { /* ... */ }
This is useful if you’re compiling with -W or -Wunused, and you want to catch unused
function parameters, but you occasionally have functions that must match a predeter-
mined signature (as is common in event-driven GUI programming or signal handlers).
Packing a Structure
The packed attribute tells the compiler that a type or variable should be packed into
memory using the minimum amount of space possible, potentially disregarding
alignment requirements. If specified on a struct or union, all variables therein are so
packed. If specified on just one variable, only that specific object is packed.
The following packs all variables within the structure into the minimum amount of
space:
struct _ _attribute_ _ ((packed)) foo { ... };
344 | Appendix: GCC Extensions to the C Language
As an example, a structure containing a char followed by an int would most likely
find the integer aligned to a memory address not immediately following the char,
but, say, three bytes later. The compiler aligns the variables by inserting bytes of
unused padding between them. A packed structure lacks this padding, potentially
consuming less memory, but failing to meet architectural alignment requirements.
Increasing the Alignment of a Variable
As well as allowing packing of variables, GCC also allows programmers to specify an
alternative minimum alignment for a given variable. GCC will then align the speci-
fied variable to at least this value, as opposed to the minimum required alignment
dictated by the architecture and ABI. For example, this statement declares an integer
named beard_length with a minimum alignment of 32 bytes (as opposed to the typi-
cal alignment of 4 bytes on machines with 32-bit integers):
int beard_length _ _attribute_ _ ((aligned (32))) = 0;
Forcing the alignment of a type is generally useful only when dealing with hardware
that may impose greater alignment requirements than the architecture itself, or when
you are hand-mixing C and assembly code, and you want to use instructions that
require specially aligned values. One example where this alignment functionality is
utilized is for storing oft-used variables on processor cache lines to optimize cache
behavior. The Linux kernel makes use of this technique.
As an alternative to specifying a certain minimum alignment, you can ask that GCC
align a given type to the largest minimum alignment that is ever used for any data
type. For example, this instructs GCC to align parrot_height to the largest align-
ment it ever uses, which is probably the alignment of a double:
short parrot_height _ _attribute_ _ ((aligned)) = 5;
This decision generally involves a space/time tradeoff: variables aligned in this man-
ner consume more space, but copying to or from them (along with other complex
manipulations) may be faster because the compiler can issue machine instructions
that deal with the largest amount of memory.
Various aspects of the architecture or the system’s tool chain may impose maximum
limits on a variable’s alignment. For example, on some Linux architectures, the
linker is unable to recognize alignments beyond a rather small default. In that case,
an alignment provided using this keyword is rounded down to the smallest allowed
alignment. For example, if you request an alignment of 32, but the system’s linker is
unable to align to more than 8 bytes, the variable will be aligned along an 8 byte
boundary.
Branch Annotation | 345
Placing Global Variables in a Register
GCC allows programmers to place global variables in a specific machine register,
where the variables will then reside for the duration of the program’s execution.
GCC calls such variables global register variables.
The syntax requires that the programmer specify the machine register. The follow-
ing example uses ebx:
register int *foo asm ("ebx");
The programmer must select a variable that is not function-clobbered: that is, the
selected variable must be usable by local functions, saved and restored on function
call invocation, and not specified for any special purpose by the architecture or oper-
ating system’s ABI. The compiler will generate a warning if the selected register is
inappropriate. If the register is appropriate—ebx, used in this example, is fine for the
x86 architecture—the compiler will in turn stop using the register itself.
Such an optimization can provide huge performance boosts if the variable is fre-
quently used. A good example is with a virtual machine. Placing the variable that
holds, say, the virtual stack frame pointer in a register might lead to substantial
gains. On the other hand, if the architecture is starved of registers to begin with (as
the x86 architecture is), this optimization makes little sense.
Global register variables cannot be used in signal handlers, or by more than one
thread of execution. They also cannot have initial values because there is no mecha-
nism for executable files to supply default contents for registers. Global register
variable declarations should precede any function definitions.
Branch Annotation
GCC allows programmers to annotate the expected value of an expression—for
example, to tell the compiler whether a conditional statement is likely to be true or
false. GCC, in turn, can then perform block reordering, and other optimizations to
improve the performance of conditional branches.
The GCC syntax for branch notation is horrendously ugly. To make branch annota-
tion easier on the eyes, we use preprocessor macros:
#define likely(x) _ _builtin_expect (!!(x), 1)
#define unlikely(x) _ _builtin_expect (!!(x), 0)
Programmers can mark an expression as likely or unlikely true by wrapping it in
likely( ) or unlikely( ), respectively.
The following example marks a branch as unlikely true (that is, likely to be false):
int ret;
ret = close (fd);
346 | Appendix: GCC Extensions to the C Language
if (unlikely (ret))
perror ("close");
Conversely, the following example marks a branch as likely true:
const char *home;
home = getenv ("HOME");
if (likely (home))
printf ("Your home directory is %s\n", home);
else
fprintf (stderr, "Environment variable HOME not set!\n");
As with inline functions, programmers have a tendency to overuse branch annotation.
Once you start anointing expressions, you might be tempted to mark all expressions.
Be careful, though—you should mark branches as likely or unlikely only if you know a
priori and with little doubt that the expressions will be true or false nearly all of the
time (say, with 99 percent certainty). Seldom-occurring errors are good candidates
for unlikely( ). Bear in mind, however, that a false prediction is worse than no pre-
diction at all.
Getting the Type of an Expression
GCC provides the typeof( ) keyword to obtain the type of a given expression.
Semantically, the keyword operates the same as sizeof( ). For example, this expres-
sion returns the type of whatever x points at:
typeof (*x)
We can use this to declare an array, y, of those types:
typeof (*x) y[42];
A popular use for typeof( ) is to write “safe” macros, which can operate on any arith-
metic value, and evaluate its parameters only once:
#define max(a,b) ({ \
typeof (a) _a = (a); \
typeof (b) _b = (b); \
_a > _b ? _a : _b; \
})
Getting the Alignment of a Type
GCC provides the keyword _ _alignof_ _ to obtain the alignment of a given object.
The value is architecture- and ABI-specific. If the current architecture does not have a
required alignment, the keyword returns the ABI’s recommended alignment. Other-
wise, the keyword returns the minimum required alignment.
The syntax is identical to sizeof( ):
_ _alignof_ _(int)
The Offset of a Member Within a Structure | 347
Depending on the architecture, this probably returns 4, as 32-bit integers are gener-
ally aligned along 4 byte boundaries.
The keyword works on lvalues, too. In that case, the returned alignment is the mini-
mum alignment of the backing type, not the actual alignment of the specific lvalue. If
the minimum alignment was changed via the aligned attribute (described earlier, in
“Increasing the Alignment of a Variable”), that change is reflected by _ _alignof_ _.
For example, consider this structure:
struct ship {
int year_built;
char canons;
int mast_height;
};
along with this code snippet:
struct ship my_ship;
printf ("%d\n", _ _alignof_ _(my_ship.canons));
The _ _alignof_ _ in this snippet will return 1, even though structure padding proba-
bly results in canons consuming four bytes.
The Offset of a Member Within a Structure
GCC provides a built-in keyword for obtaining the offset of a member of a structure
within that structure. The offsetof( ) macro, defined in <stddef.h>, is part of the
ISO C standard. Most definitions are horrid, involving obscene pointer arithmetic
and code unfit for minors. The GCC extension is simpler and potentially faster:
#define offsetof(type, member) _ _builtin_offsetof (type, member)
A call returns the offset of member within type—that is, the number of bytes, starting
from zero, from the beginning of the structure to that member. For example,
consider the following structure:
struct rowboat {
char *boat_name;
unsigned int nr_oars;
short length;
};
The actual offsets depend on the size of the variables, and the architecture’s align-
ment requirements and padding behavior, but on a 32-bit machine, we might expect
calling offsetof( ) on struct rowboat and boat_name, nr_oars, and length to return 0,
4, and 8, respectively.
On a Linux system, the offsetof( ) macro should be defined using the GCC key-
word, and need not be redefined.
348 | Appendix: GCC Extensions to the C Language
Obtaining the Return Address of a Function
GCC provides a keyword for obtaining the return address of the current function, or
one of the callers of the current function:
void * _ _builtin_return_address (unsigned int level)
The parameter level specifies the function in the call chain whose address should be
returned. A value of 0 asks for the return address of the current function, a value of 1
asks for the return address of the caller of the current function, a value of 2 asks for
that function’s caller’s return address, and so on.
If the current function is an inline function, the address returned is that of the call-
ing function. If this is unacceptable, use the noinline keyword (described earlier, in
“Suppressing Inlining”) to force the compiler not to inline the function.
There are several uses for the _ _builtin_return_address keyword. One is for debugging
or informational purposes. Another is to unwind a call chain, in order to implement
introspection, a crash dump utility, a debugger, and so on.
Note that some architectures can return only the address of the invoking function.
On such architectures, a nonzero parameter value can result in a random return
value. Thus, any parameter other than 0 is nonportable, and should be used only for
debugging purposes.
Case Ranges
GCC allows case statement labels to specify a range of values for a single block. The
general syntax is as follows:
case low ... high:
For example:
switch (val) {
case 1 ... 10:
/* ... */
break;
case 11 ... 20:
/* ... */
break;
default:
/* ... */
}
This functionality is quite useful for ASCII case ranges, too:
case 'A' ... 'Z':
More Portable and More Beautiful in One Fell Swoop | 349
Note that there should be a space before and after the ellipsis. Otherwise, the com-
piler can become confused, particularly with integer ranges. Always do the following:
case 4 ... 8:
and never this:
case 4...8:
Void and Function Pointer Arithmetic
In GCC, addition and subtraction operations are allowed on pointers of type void,
and pointers to functions. Normally, ISO C does not allow arithmetic on such point-
ers because the size of a “void” is a silly concept, and is dependent on what the
pointer is actually pointing to. To facilitate such arithmetic, GCC treats the size of
the referential object as one byte. Thus, the following snippet advances a by one:
a++; /* a is a void pointer */
The option -Wpointer-arith causes GCC to generate a warning when these exten-
sions are used.
More Portable and More Beautiful in One Fell Swoop
Let’s face it, the _ _attribute_ _ syntax is not pretty. Some of the extensions we’ve
looked at in this chapter essentially require preprocessor macros to make their use
palatable, but all of them can benefit from a sprucing up in appearance.
With a little preprocessor magic, this is not hard. Further, in the same action, we can
make the GCC extensions portable, by defining them away in the case of a non-GCC
compiler (whatever that is).
To do so, stick the following code snippet in a header, and include that header in
your source files:
#if __GNUC_ _ >= 3
# undef inline
# define inline inline __attribute_ _ ((always_inline))
# define __noinline __attribute_ _ ((noinline))
# define __pure __attribute_ _ ((pure))
# define __const __attribute_ _ ((const))
# define __noreturn __attribute_ _ ((noreturn))
# define __malloc __attribute_ _ ((malloc))
# define __must_check __attribute_ _ ((warn_unused_result))
# define __deprecated __attribute_ _ ((deprecated))
# define __used __attribute_ _ ((used))
# define __unused __attribute_ _ ((unused))
350 | Appendix: GCC Extensions to the C Language
# define __packed __attribute_ _ ((packed))
# define __align(x) __attribute_ _ ((aligned (x)))
# define __align_max __attribute_ _ ((aligned))
# define likely(x) _ _builtin_expect (!!(x), 1)
# define unlikely(x) _ _builtin_expect (!!(x), 0)
#else
# define _ _noinline /* no noinline */
# define _ _pure /* no pure */
# define _ _const /* no const */
# define _ _noreturn /* no noreturn */
# define _ _malloc /* no malloc */
# define _ _must_check /* no warn_unused_result */
# define _ _deprecated /* no deprecated */
# define _ _used /* no used */
# define _ _unused /* no unused */
# define _ _packed /* no packed */
# define _ _align(x) /* no aligned */
# define _ _align_max /* no align_max */
# define likely(x) (x)
# define unlikely(x) (x)
#endif
For example, the following marks a function as pure, using our shortcut:
_ _pure int foo (void) { /* ... */
If GCC is in use, the function is marked with the pure attribute. If GCC is not the
compiler, the preprocessor replaces the _ _pure token with a no-op. Note that you
can place multiple attributes on a given definition, and thus you can use more than
one of these defines on a single definition with no problems.
Easier, prettier, and portable!
351
Bibliography
This bibliography presents recommended reading related to system programming,
broken down into four subcategories. None of these works are required reading.
Instead, they represent my take on the top books on the given subject matter. If you
find yourself pining for more information on the topics discussed here, these are my
favorites.
Some of these books address material with which this book assumes the reader is
already conversant, such as the C programming language. Other texts included make
great supplements to this book, such as the works covering gdb, Subversion (svn), or
operating system design. Still others handle topics that are beyond the scope of this
book, such as multithreading of sockets. Whatever the case, I recommend them all.
Of course, these lists are certainly not exhaustive—feel free to explore other
resources.
Books on the C Programming Language
These books document the C programming language, the lingua franca of system
programming. If you do not code C as well as you speak your native tongue, one or
more of the following works (coupled with a lot of practice!) ought to help you in
that direction. If nothing else, the first title—universally known as K&R—is a treat
to read. Its brevity reveals the simplicity of C.
The C Programming Language, 2nd ed. Brian W. Kernighan and Dennis M. Ritchie.
Prentice Hall, 1988.
This book, written by the author of the C programming language and his then-
coworker, is the bible of C programming.
352 | Bibliography
C in a Nutshell. Peter Prinz and Tony Crawford. O’Reilly Media, 2005.
A great book covering both the C language and the standard C library.
C Pocket Reference. Peter Prinz and Ulla Kirch-Prinz. Translated by Tony Crawford.
O’Reilly Media, 2002.
A concise reference to the C language, handily updated for ANSI C99.
Expert C Programming. Peter van der Linden. Prentice Hall, 1994.
A wonderful discussion of lesser-known aspects of the C programming lan-
guage, elucidated with an amazing wit and sense of humor. This book is rife
with nonsequitur jokes, and I love it.
C Programming FAQs: Frequently Asked Questions, 2nd ed. Steve Summit. Addison-
Wesley, 1995.
This beast of a book contains more than 400 frequently asked questions (with
answers) on the C programming language. Many of the FAQs beg obvious
answers in the eyes C masters, but some of the weightier questions and answers
should impress even the most erudite of C programmers. You are a true C ninja
if you can answer all of these bad boys! The only downside is that the book has
not been updated for ANSI C99, and there have definitely been some changes (I
handmade the corrections in my copy). Note there is an online version that has
likely been more recently updated.
Books on Linux Programming
The following texts cover Linux programming, including discussions of topics not
covered in this book (sockets, IPC, and pthreads), and Linux programming tools
(CVS, GNU Make, and Subversion).
Unix Network Programming, Volume 1: The Sockets Networking API, 3rd ed. W. Rich-
ard Stevens et al. Addison-Wesley, 2003.
The definitive tome on the socket API; unfortunately not specific to Linux, but
fortunately recently updated for IPv6.
UNIX Network Programming, Volume 2: Interprocess Communications, 2nd ed.
W. Richard Stevens. Prentice Hall, 1998.
An excellent discussion of interprocess communication (IPC).
PThreads Programming: A POSIX Standard for Better Multiprocessing. Bradford
Nichols et al. O’Reilly Media, 1996.
A review of the POSIX threading API, pthreads.
Books on the Linux Kernel | 353
Managing Projects with GNU Make, 3rd ed. Robert Mecklenburg. O’Reilly Media,
2004.
An excellent treatment on GNUMake, the classic tool for building software
projects on Linux.
Essential CVS, 2nd ed. Jennifer Versperman. O’Reilly Media, 2006.
An excellent treatment on CVS, the classic tool for revision control and source
code management on Unix systems.
Version Control with Subversion. Ben Collins-Sussman et al. O’Reilly Media, 2004.
A phenomenal take on Subversion, the proper tool for revision control and
source code management on Unix systems, by three of Subversion's own
authors.
GDB Pocket Reference. Arnold Robbins. O’Reilly Media, 2005.
A handy pocket guide to gdb, Linux’s debugger.
Linux in a Nutshell, 5th ed. Ellen Siever et al. O’Reilly Media, 2005.
A whirlwind reference to all things Linux, including many of the tools compris-
ing Linux’s development environment.
Books on the Linux Kernel
The two titles listed here cover the Linux kernel. Reasons for investigating this topic
are threefold. First, the kernel provides the system call interface to user space, and is
thus the core of system programming. Second, the behaviors and idiosyncrasies of a
kernel shed light on its interactions with the applications it runs. Finally, the Linux
kernel is a wonderful chunk of code, and these books are fun.
Linux Kernel Development, 2nd ed. Robert Love. Novell Press, 2005.
This work is ideally suited to system programmers who want to know about the
design and implementation of the Linux kernel (and naturally, I would be remiss
not to mention my own treatise on the subject!). Not an API reference, this book
offers a great discussion of the algorithms used and decisions made by the Linux
kernel.
Linux Device Drivers, 3rd ed. Jonathan Corbet et al. O’Reilly Media, 2005.
This is a great guide to writing device drivers for the Linux kernel, with excellent
API references. Although aimed at device drivers, the discussions will benefit pro-
grammers of any persuasion, including system programmers merely seeking more
insight into the machinations of the Linux kernel. A great complement to my own
Linux kernel book.
354 | Bibliography
Books on Operating System Design
These two works, not specific to Linux, address operating system design in the
abstract. As I’ve stressed in this book, a strong understanding of the system you code
on only improves your output.
Operating Systems, 3rd ed. Harvey Deitel et al. Prentice Hall, 2003.
A tour de force on the theory of operating system design coupled with top-notch
case studies putting that theory to practice. Of all the textbooks on operating
system design, this is my favorite: it’s modern, readable, and complete.
UNIX Systems for Modern Architectures: Symmetric Multiprocessing and Caching for
Kernel Programming. Curt Schimmel. Addison-Wesley, 1994.
Despite being only modestly related to system programming, this book offers
such an excellent approach to the perils of concurrency and modern caching that
I recommend it even to dentists.
355
We’d like to hear your suggestions for improving our indexes. Send email to index@oreilly.com.
Index
Symbol
⁄ (forward slash), 11
A
ABIs (application binary interfaces), 4, 5
abort( ) function, 282
absolute pathnames, 11, 212
absolute time, 309
access control lists (ACLs), 18
ACLs (access control lists), 18
adjtime( ) function, 322
adjtimex( ) function, 322–324
aio interfaces, 112
alarm( ) function, 282, 330
alarm_handler( ) function, 331
alignment of data, 252
_ _alignof_ _ keyword, 346
alloca( ) function, 264
duplicating strings on the stack, 266
allocation, 243
anonymous memory mappings, 256–260
creating, 257
mapping /dev/zero, 259
ANSI C, 7
Anticipatory I/O Scheduler, 117
anti-lock braking system (ABS) as real-time
system, 176
APIs (application programming interfaces), 4
append mode, write( ), 34
applications
time dependency and the system
clock, 321
arrays, allocation of, 247
asctime( ) and asctime_r( ) functions, 320
asynchronous events, signals for (see signals)
asynchronous I/O, 112
asynchronous write operations, 111
atexit( ) function, 137
_ _attribute_ _ syntax, beautifying with
preprocessor macros, 349
automatic variables, 264
B
background process groups, 154
batch scheduling policy, 180
bcmp( ) function, 270
bdflush threads, 61
big-oh notation, 163
binary compatibility, 5
binary files and text files, 66
block devices, 13
sectors, 14
blocking reads, 30
blocks, 15, 62
block size, 63
effects on performance, 63
break point, 255
brk( ) function, 256
broken links, 12
bss segment, 245
buddy memory allocation scheme, 256
buffer size, 64
buffered I/O (input/output), 62
associated file descriptors, obtaining, 77
block size, 63
effects on performance, 63
356 | Index
buffered I/O (continued)
controlling the buffering, 77
errors and EOF, 76
opening files, 65
modes, 65
sample program, 72–74
standard I/O, 64
file pointers, 65
limitations, 81
streams
closing, 67
closing all, 67
flushing, 75
opening via file descriptors, 66
seeking a stream, 74
streams, reading from, 67–70
putting the character back, 68
reading an entire line, 68
reading arbitrary strings, 69
reading binary data, 70
reading one character at at time, 67
streams, writing to, 70–72
data alignment, 71
writing a single character, 71
writing a string, 72
writing binary data, 72
thread safety, 79–81
manual file locking, 80
unlocked stream operations, 81
user-buffered I/O, 62–64
buffer_head data structure, 61
buffers, 37, 61
dirty buffers, 60
_ _builtin_return_address keyword, 348
C
C compiler (see gcc)
C language, 7, 64
GNU C, 339
C library (libc), 4
cache effects of process migration, 173
calloc( ) function, 247
capabilities system, 18
CAP_IPC_LOCK, 276
CAP_KILL capability, 292
CAP_SYS_TIME, 318
case statement, 348
cd command, 216
character devices and character device
files, 13
chdir( ) function, 215
child processes, 17, 127
memory inheritance and fork( ), 274
(see also processes)
chmod( ) function, 200
chown( ) function, 201
clearerr( ) function, 76
clock_getres( ) function, 314
clock_gettime( ) function, 316
clockid_t type, 313
clock_nanosleep( ) function, 327
clock_settime( ) function, 319
close( ) function, 41
code examples, permissions, xv
common file model, 58
Complete Fair Queuing (CFQ) I/O
Scheduler, 118
congestion avoidance, 61
const keyword, 341
controlling terminals, 154
cooperative multitasking, 163
yielding, 163, 166–169
legitimate uses, 167
Linux version 2.6, changes in, 168
copy-on-write (COW), 134, 244
CPU_SETSIZE, 174
creat( ) function, 28
critical regions, 79, 297
ctime( ) function and ctime_r( )
functions, 320
current time, getting, 315–318
microsecond resolution, 316
nanosecond resolution, 316
current time, setting, 318, 319
current working directory (cwd), 11,
213–217
changing, 215–217
obtaining, 213–215
D
daemon( ) function, 160
daemons, 159–161
dangling symlinks, 225
data alignment, 71
data segment, 245
data segment management, 255
Deadline I/O Scheduler, 116
defined keys, 204
demand paging, 273
determinism, 187–189
Index | 357
/dev/zero, 259
device nodes, 231–232
major and minor numbers, 231
random number generators, 232
special nodes, 231
devices, 13
/dev/zero, 259
out-of-band communication, 233
difftime( ) function, 321
direct I/O, 40
directories, 11, 212–223
creating, 218
current working directory
(cwd), 213–217
changing, 215–217
obtaining, 213–215
directory entries, 212
directory entry (dentry), 11
directory stream, 220
closing, 221
reading from, 221
links, 212, 223–228
names, legal characters for, 212
names, length of, 212
reading contents of, 220–223
system calls for, 222
removing, 219
subdirectories, 212
dirfd( ) function, 220
dirty buffers, 60
dirty_expire_centiseconds, 37
disk addressing, 114
dnotify function, 235
dynamic memory allocation, 245–255
alignment, 252–255
alignment of nonstandard and
complex types, 254
allocating aligned memory, 252
pointers, 255
allocating arrays, 247
freeing dynamic memory, 250–252
resizing allocations, 249
E
edge-triggered events, 94
effective gid, 17
effective user ID (uid), 17, 150
eject command program, 233
elevator algorithms, 116
end-of-file (see EOF)
entropy pool, 232
EOF (end-of-file), 30
errors and, 76
epoch, 309
epoll facility, 89
epoll interface, 57
epoll_create( ) function, 89
epoll_ctl( ) function, 90–92
epoll_wait( ) function, 93
errno, 19–22
error descriptors, 20
error handling, 19–22
errors and EOF, 76
event poll interface, 89–94
controlling epoll, 90–92
creating an epoll instance, 89
edge-triggered versus level-triggered
events, 94
waiting for events, 93
exec family of functions, 129–132
error values, 131
execl( ) function, 129–130
execute permissions, 18
exit( ) and _exit( ) functions, 136
extended attributes, 203
keys and values, 204
listing, 209
namespaces, 205
operations, 206
removal, 210
retrieval, 206
security namespace, 206
setting, 208
system namespace, 205
trusted namespace, 206
user namespace, 206
external fragmentation, 256
F
fchdir( ) function, 215
fchmod( ) function, 200
fchown( ) function, 202
fclose( ) function, 67
fcloseall( ) function, 67
fd (see file descriptors)
fdatasync( ) function, 37
return values and error codes, 38
feof( ) function, 76
ferror( ) function, 76
fflush( ) function, 75
fgetc( ) function, 67, 69
fgetpos( ) function, 75
358 | Index
fgets( ) function, 68
fgetxattr( ) function, 207
FIFO (first in, first out) class, 179
FIFOs, 13
file descriptors, 9, 23
streams, opening via, 66
file I/O (input/output), 23–61
advice, 108–111
advantages, 110
posix_fadvise( ) function, 108
closing files, 41
direct I/O, 40
event poll interface (see event poll
interface)
I/O schedulers (see I/O schedulers)
kernel internals, 57–61
page cache, 59
page writeback, 60
virtual filesystem, 58
linear output, 84
lseek( ), 42–44
error values, 44
limitations, 44
seeking past the end of a file, 43
memory mapped I/O (see memory
mapped I/O)
multiplexed I/O, 47–57
poll( ) function, 53–56
poll( ) versus select( ), 57
ppoll( ) function, 56
pselect( ) function, 52
select( ) function, 48–53
opening files, 24–29
creat( ) function, 28
open( ) function, 24–26
owners of new files, 26
permissions of new files, 27
return values and error codes, 29
positional reads and writes, 44
error values, 45
readahead( ) function, 110
reading files, 29–33
additional error values, 32
nonblocking reads, 32
reading all the bytes, 31
return values, 30
size limits on read( ), 33
scatter/gather I/O (see scatter/gather I/O)
synchronized I/O, 37–40
fsync( ) and fdatasync( ), 37
O_DSYNC and O_RSYNC flags, 40
O_SYNC flag, 39
sync( ) function, 39
truncating files, 45
write( ), 33–37
additional error codes, 35
append mode, 34
behavior of write( ), 36
nonblocking writes, 35
partial writes, 34
size limits on, 36
file pointers, 65
file table, 23
FILE typedef, 65
fileno( ) function, 77
files, 9–15
access, modification, and change
times, 198
closing files, 41
copying, 228
deleting, 12
device nodes, 231–232
major and minor numbers, 231
random number generators, 232
special nodes, 231
directories (see directories)
extended attributes (see extended
attributes)
file events, monitoring, 234–242
inotify interface, 234
watches, 236–242
file I/O (see file I/O)
file ownership, 26
file permissions, 27
file position or file offset, 9
file truncation, 45
filenames and inodes, 10
inodes, 196
length, 10
links, 11, 223–228
metadata, 196
functions for obtaining, 196
MIME types, storage, 205
mode, legal values for, 200
moving, 229
effects of moving to and from different
types of files, 230
names, legal characters for, 212
names, length of, 212
ownership, 201
permissions, 199
mode argument, 27
regular files, 9
special files, 13
usage count, 223
Index | 359
filesystem gid, 17
filesystem uid, 17
filesystems, 14
blocks, 15
filesystem-agnosticism, 204
links and, 223
mounting and unmounting, 14
supported in Linux, 14
flistxattr( ) function, 210
flockfile( ) function, 80
fopen( ) function, 65
foreground process group, 154
fork( ) function, 17, 132–136, 290
forward slash (⁄), 11
fputc( ) function, 71
fputs( ) function, 72
fremovexattr( ) function, 211
fseek( ) function, 74
fsetpos( ) function, 74
fsetxattr( ) function, 208
fstat( ) function, 197
fsync( ) function, 37, 76
return values and error codes, 38
ftell( ) function, 75
ftruncate( ) function, 46
ftrylockfile( ) function, 80
full device, 232
fully qualified pathnames, 11
functions
constant functions, 341
inline functions, 340
suppressing inlining, 340
marking as deprecated, 343
marking as unused, 343
marking as used, 343
memory allocation functions, 342
nonreturning functions, 342
pure functions, 341
funlockfile( ) function, 80
fwrite( ) function, 72
G
gcc (binary), 4
supported standards, 8
GCC (GNU Compiler Collection), 4
C language extensions, 339–350
branch annotation, 345
case ranges, 348
constant functions, 341
deprecated functions, marking, 343
expression types, getting, 346
forcing functions to check return
values, 342
functions or parameters, marking as
unused, 343
function’s return address,
obtaining, 348
global variables, placing in a
register, 345
GNU C, 339
inline functions, 340
inline functions, suppressing, 340
member offset within a structure, 347
memory allocation functions, 342
nonreturning functions, 342
packing structures, 343
portability, improving, 349
pure functions, 341
type alignment, getting, 346
used functions, marking, 343
variable alignment, increasing, 344
void and pointer arithmetic, 349
get_current_dir_name( ) function, 214
getcwd( ) function, 213, 216
getdents( ) function, 222
getitimer( ) function, 332
getpagesize( ) function, 98
getpgid( ) function, 158
getpgrp( ) function, 158
getpid( ) function, 128
getpriority( ) function, 171
getrlimit( ) functionl, 190
gets( ) function, 81
getsid( ) function, 156
gettimeofday( ) function, 316
getwd( ) function, 214
getxattr( ) function, 207
ghosts, 149
gid (group ID), 17
glibc (GNU libc), 4
memory allocation, 256
global register variables, 345
gmtime( ) and gmtime_r( ) functions, 320
GNU C, 8, 339
GNU Compiler Collection (see gcc)
GNU libc (glibc), 4
group ID (gid), 17
groups, 17
ownership of processes, 127
primary or logon groups, 17
GUI file managers, MIME type sniffing
behaviors, 205
360 | Index
H
hard affinity, 173
hard links, 12, 223, 224
hard real-time systems, 176
hard resource limit, 190
hardware clocks, 310
headers, 19
heap, 245
hwclock command, 310
I
idle processes, 126
idle scheduling policy, 180
IEEE (Institute of Electrical and Electronics
Engineers), 6
init process, 17, 126
inline functions, 340
suppressing inlining, 340
inline keyword, 340
inode number, obtaining, 196
inodes, 10, 196
link count, 12
inotify events, 238–240
advanced events, 239
linking together move events, 240
reading, 238
inotify interface, 234
initializing, 235
inotify_add_watch( ) function, 236, 238
inotify_event structure, 238
inotify_init( ) function, 235
Institute of Electrical and Electronics
Engineers (IEEE), 6
internal fragmentation, 256
International Organization for
Standardization (ISO), 7
interprocess communications (IPCs), 13, 19
interval timers, 331
invalid page, 244
I/O (input/output)
asynchronous I/O, 112
buffered I/O (see buffered I/O)
file I/O (see file I/O)
I/O priorities, 172
I/O schedulers (see I/O schedulers)
I/O wait time, 40
I/O-bound processes, 164
system calls and, 77
I/O schedulers, 114–125
disk addressing, 114
lifecycle, 115
merging and sorting, 115
performance optimization, 119–125
reads, 116–119
Anticipatory I/O Scheduler, 117
Complete Fair Queuing (CFQ) I/O
Scheduler, 118
Deadline I/O Scheduler, 116
Noop I/O Scheduler, 119
scheduling in user space, 120
sorting by inode, 121
sorting by path, 120
sorting by physical block, 122
selection and configuration, 119
ioctl( ) function, 233
IOV_MAX, 85
IPCs (interprocess communications), 13
ISO (International Organization for
Standardization), 7
itimerval structure, 332
J
jiffies counter, 309
jitter, 177
job control, 154
K
kernel
file mapping interface (see memory
mapped I/O)
I/O (input/output), implementation
of, 57–61
page cache, 59
page writeback, 60
virtual filesystem, 58
I/O schedulers (see I/O schedulers), 114
kernel buffering contrasted with
user-buffered I/O, 62
mapping advice and, 106
readahead, 107
system timer, 309
time measurement, 308
usage of file descriptors, 23
user-space applications, communication
with, 3
kernel time, 40
keys, 204
kill( ) function, 284, 291, 307
signal for, 303
kill command, 281
Index | 361
L
latency, 177
lchown( ) function, 201
level-triggered events, 94
lgetxattr( ) function, 207
libc (C library), 4
likely( ) wrapper, 345
linear I/O, 84
link( ) function, 224
links, 11, 212, 223–228
broken links, 12
hard links, 12, 224
link count, 12
symbolic links, 12, 225
unlinking, 227
Linus Elevator, 116
Linux, 1
C standards and, 7
forward compatibility, 8
Linux Standard Base (LSB), 8
Unix compared to, 1
Linux Foundation, 8
Linux system interface, xiii
listxattr( ) function, 209
llistxattr( ) function, 210
load balancing, 173
locality of reference, 59
localtime( ) and localtime_r( ) functions, 321
login, 17
login shell, 17, 154
logon group, 17
lremovexattr( ) function, 211
ls command, 196
LSB (Linux Standard Base), 8
lseek( ) function, 42–44
error values, 44
limitations, 44
seeking past the end of a file, 43
lsetxattr( ) function, 208
lstat( ) function, 197
M
machine register, 3
madvise( ) function, 106–108
return values and error codes, 108
make, time dependency of, 321
mallinfo( ) function, 263
malloc( ) function, 246
xmalloc( ) wrapper for, 247
malloc0( ) function, 248
MALLOC_CHECK_ environment
variable, 263
malloc_usable_size( ) and malloc_trim( )
functions, 262
mallopt( ) function, 260
parameters, 261
mapped files, 245
mappings, 245
maximum buffer age, 37
memchr( ) function, 272
memcmp( ) function, 270
memfrob( ) function, 272
memmem( ) function, 272
memmove( ) function, 271
memory addressing and data alignment, 71
memory allocation, 243
advanced memory allocation, 260–263
malloc_usable_size( ) and malloc_
trim( ) functions, 262
mallopt( ) function, 260
choosing a mechanism, 268
debugging, 263
MALLOC_CHECK_, 263
obtaining statistics, 263
dynamic memory, allocating, 245–255
alignment, 252–255
allocating arrays, 247
freeing dynamic memory, 250–252
resizing allocations, 249
opportunistic allocation, 277
overcommitment and OOM, 277
stack-based allocations, 264–268
duplicating strings on the stack, 266
variable-length arrays, 267
unlocking memory, 275
memory management, 243
anonymous memory mappings, 256–260
creating, 257
mapping /dev/zero, 259
data segment, managing, 255
locking memory, 273–277
demand paging, 273
locking all of an address space, 275
locking limits, 276
locking part of an address space, 274
manipulating memory, 269–273
comparing bytes, 270
frobnicating bytes, 272
moving bytes, 271
searching bytes, 272
setting bytes, 269
362 | Index
memory management (continued)
memory management units, 15
process address space, 243–245
memory regions, 245
pages and paging, 243
sharing and copy-on-write, 244
memory mapped I/O, 95–108
changing the protection of a
mapping, 104
giving advice, 106–108
mmap( ) function, 95–99, 100
advantages, 101
disadvantages, 102
page size, 97–98
munmap( ) function, 99
resizing a mapping, 102
SIGBUS and SIGSEGV signals, 99
synchronizing a file with a mapping, 104
memrchr( ) function, 272
memset( ) function, 269
merging (I/O schedulers), 115
metadata, 196
migration of processes, costs, 173
MIME types, storage, 205
mincore( ) function, 276
mkdir( ) function, 218, 229
mktime( ) function, 320
mlock( ) function, 274
mlockall( ) function, 275
mmap( ) function, 95–99, 258
advantages, 101
disadvantages, 102
example, 100
page size, 97–98
return values and erro codes, 99
mode argument, 27, 65
monotonic time, 308
mount points, 14
mounting, 14
mprotect( ) function, 104
mremap( ) function, 102
return values and error codes, 103
msync( ) function, 105
return values and error codes, 105
multiplexed I/O, 47–57
multitasking, 163
multithreaded programming, 166
munmap( ) function, 99, 258
N
named pipes, 13
namespaces, 14
per-process namespaces, 15
nanosleep( ) function, 326
natural alignment, 71, 252
network filesystems, 14
nice( ) function, 170
nice values, 169
noinline keyword, 340
nonblocking I/O, 32
nonblocking writes, 35
Noop I/O Scheduler, 119
noreturn keyword, 342
null device, 231
O
O(1) process scheduler, 163
O_DSYNC flag, 40
offset, 74
offsetof( ) macro, 347
off_t type, 44
on_exit function, 138
OOM (out of memory) conditions, 278
open( ) function, 24–26
O_DSYNC andO_RSYNC flags, 40
O_SYNC flag, 39
Open Software Foundation (OSF), 7
opendir( ) function, 220
operational deadlines, 176
latency and jitter, 177
opportunistic allocation, 277
origin argument, lseek( ), 42
O_RSYNC flag, 40
OSF (Open Software Foundation), 7
O_SYNC flag, 39
out of memory (OOM) conditions, 278
out-of-band communication, 233
overcommitment, 277
P
packed attribute, 343
pages, 97–98, 243
page cache, 59
page cache readahead, 60
page size, 15
page writeback, 60
PAGE_SIZE macro, 98
parameter passing, 3
Index | 363
parameters, marking as unused, 343
parent directories, 212
parent process, 17
parent processes, 127
(see also processes)
partial writes, 34
path, 11
pathnames, 11, 212
pause( ) function, 287
pdflush threads, 61
pending signals, 297
permission bits, 18
per-process namespaces, 15
perror( ) function, 21
pgid (process group ID), 154
pid (process ID), 16, 126
allocation, 127
pid_t type, 128
pointers, 255
poll( ) function, 53–56
disadvantages, 89
example, 55
return values and error codes, 55
select( ), versus, 57
Portable Operating System Interface (see
POSIX)
POSIX, 6
history, 6
protection bits and architecture, 96
POSIX clocks, 313–315
clockid_t type, 313
time source resolution, 314
POSIX clocks-based timers, 333–338
arming a timer, 335
creating a timer, 333–335
deleting a timer, 338
obtaining timer expiration, 336
obtaining timer overrun, 337
_POSIX_SAVED_IDS macro, 153
posix_fadvise( ) function, 108
return values and error codes, 110
ppoll( ) function, 56
pread( ) function, 44
preemptive multitasking, 163
preemptive scheduling, 165
primary group, 17
process address space, 243–245
mapped files, 245
memory regions, 245
pages and paging, 243
sharing and copy-on-write, 244
process ID (pid), 16
process time, 308
process tree, 17
processes, 15–17, 126
accesses, 18
background process groups, 154
child and parent processes, 127
child processes, waiting for, 139–149
BSD wait3( ) and wait4( )
functions, 145
status pointer macros, 140
wait( ) function, 139
waitid( ) function, 143
waitpid( ) function, 142
copy-on-write (COW), 134
daemons, 159–161
doctrine of least-privileged rights, 150
exec family of functions, 129–132
file descriptors and, 23
foreground process group, 154
fork( ) function, 132–136
hierarchy, 127
initialization processes, 126
I/O-bound processes, 164
launching and waiting for new
processes, 147
migration costs, 173
multitasking, 163
yielding, 166–169
new processes, running, 129
obsolete process group functions, 158
ownership, 127
prioritization (see scheduler,
prioritization)
process group, 128
process group system calls, 157
process groups, 154–155
process group ID (pgid), 154
process hierarchy, 16
process ID (pid), 126
allocation, 127
process IDs and parent process IDs,
obtaining, 128
processor-bound prccesses, 164
reparenting, 149
resource limits, 190–195
default hard and soft limits, 193
Linux, resource limits provided
by, 191–193
setting and retrieving limits, 194
soft and hard limits, 190
runlist, 162
runnable processes, 162
364 | Index
processes (continued)
scheduler (see schedulers)
sessions, 154–157
terminating, 136–139
atexit( ) function, 137
by signal, 137
classic method, 137
exit( ) and _exit( ) functions, 136
kill by kernel, 137
on_exit( ) function, 138
SIGCHILD, 139
threads, 166
timeslices, 162, 164
users and groups, 149–154
changing IDs, BSD methods, 152
changing IDs, HP-UX methods, 152
obtaining user and group IDs, 154
preferred user/group ID
manipulations, 153
real, effective, and saved user and
group IDs, 150
real, effective user or group IDs,
changing, 151
real or saved user and group IDs,
changing, 151
support for saved user IDs, 153
vfork( ) function, 135
zombies, 17, 149
waiting on zombie processes, 139
(see also child processes; parent
processes)
(see also real-time systems)
processor affinity, 172–176
sched_getaffinity( ) and sched_setaffinity
functions, 173–176
programming
multithreaded programming, 166
programming concepts, 9–22
error handling, 19–22
files, 9–15
filesystems and namespaces, 14
headers, 19
interprocess communication, 19
permissions, 18
processes, 15–17
signals, 19
users and groups, 17
programs
critical regions, 297
protection flags and architecture, 96
PROT_READ and PROT_EXEC flags, 96
pselect( ) function, 52
psignal( ) function,, 290
pthreads API, 166
pure functions, 341
pure keyword, 341
pwrite( ) function, 45
R
raise( ) function, 292
signal for, 303
random number generators, 232
read( ) function, 29–33
additional error values, 32
nonblocking reads, 32
positional reads, 44
error values, 45
reading all the bytes, 31
return values, 30
size limits, 33
read FIFO queue, 116
read latency, 116
read permissions, 18
readahead, 60, 107
readahead( ) function, 110
return values and error codes, 110
readdir( ) function, 221, 222
readv( ) function, 84
implementation, 88
return values, 85
real gid, 17
real time, 308
real uid, 17
real user ID, 150
realloc( ) function, 249
real-time systems, 176–189
determinism, 187–189
CPU affinity and real-time
processes, 188
prefaulting data and locking
memory, 187
latency, jitter, and deadlines, 177
real-time processes, precautions with, 186
sched_rr_get_interval, 185
scheduling parameters, setting, 182–185
range of valid priorities,
determining, 184–185
scheduling policy and priorities, 178–182
batch scheduling policy, 180
FIFO class, 179
normal policy, 180
RR (round-robin) class, 179
setting, 180–182
Index | 365
soft versus hard real-time systems, 176
support in Linux, 178
(see also processes; schedulers)
records, 9
reentrancy, 293
guaranteed-reentrant functions, 294
regular files, 9
relative pathnames, 11, 212
relative time format, 309
remove( ) function, 228
removexattr( ) function, 211
rename( ) function, 229
reparenting, 17
reparenting of processes, 149
resource limits of processes, 190–195
default hard and soft limits, 193
Linux, resource limits provided
by, 191–193
setting and retrieving limits, 194
soft and hard limits, 190
rewind( ) function, 74
rlimit structure, 190
RLIMIT_CPU, 190
rmdir( ) function, 219
root directory, 11, 212
root filesystem, 14
root (root user), 17
round-robin (RR) class, 179
run list, 162
runnable processes, 162
S
saved group ID (gid), 17
saved user ID (uid), 17, 151
sbrk( ) function, 256
scatter/gather I/O, 84–89
advantages, 84
readv( ) and writev( ) functions, 84
implementation, 88
return values, 85
SCHED_BATCH, 180
sched_getaffinity( ) and sched_setaffinity
functions, 173–176
sched_getparam( ) and sched_setparam( )
functions, 182–185
error codes, 183
sched_getscheduler( ) and sched_
setscheduler( ) functions, 180–182
SCHED_OTHER, 180
SCHED_RR, 179
sched_rr_get_interval, 185
error codes, 186
schedulers, 162–166
load balancing, 173
multitasking, 163
O(1) process scheduler, 163
preemptive scheduling, 165
process prioritization, 169–172
getpriority( ) and setpriority( )
functions, 171
I/O priorities, 172
nice( ) function, 170
processor affinity, 172–176
sched_getaffinity( ) and sched_
setaffinity functions, 173–176
sched_rr_get_interval, 185
scheduling parameters, setting, 182–185
range of valid priorities,
determining, 184–185
scheduling policy, 178–182
batch scheduling policy, 180
FIFO class, 179
normal policy, 180
RR (round-robin) class, 179
setting, 180–182
(see also processes; real-time systems)
sched_yield( ) function, 166
legitimate uses, 167
Linux version 2.6, changes in, 168
sectors, 14
security namespace, 206
segmentation violations, signal for, 284
segments, 245
select( ) function, 48–53
disadvantages, 89
poll( ), versus, 57
use for sleeping, 329
sequential locality, 60
sessions, 154–157
session system calls, 156
setegid( ) function, 152
seteuid( ) function, 152, 153
setitimer( ) function, 282, 284, 332
setpgid( ) function, 157
setpgrp( ) function, 158
setresuid( ) function, 153
setreuid( ) function, 152
setrlimit( ) function, 190
setsid( ) function, 156
setsize parameter, 174
settimeofday( ) function, 318
366 | Index
setuid( ) function, 151, 153
setxattr( ) function, 208
si_code field, 302
values valid for SIGBUS, 303
sigaction( ) function, 298–300
sigaddset( ) function, 296
sigandset( ) function, 296
SIGBUS signal, 99
SIGCHILD, 139
SIGCONT signal, 292
sigdelset( ) function, 296
sigemptyset( ) function, 296
sigfillset( ) function, 296
SIGHUP, 154
siginfo_t structure, 300–302
SIGINT, 154
sigisemptyset( ) function, 296
sigismember( ) function, 296
signal( ) and sigaction( ) functions, 139
signal( ) function, 286, 307
signals, 19, 279–286
blocking signals, 296–298
retrieving pending signals, 297
waiting for a set of signals, 298
concepts, 280
identifiers, 280
critical regions and, 297
human-readable versus integer
values, 281
Linux, supported by, 281–286
listing with kill -l command, 281
payloads, sending signals with, 305
example, 306
reentrancy, 293
guaranteed-reentrant functions, 294
sending, 291–293
examples, 292
permissions, 292
to a process group, 293
to yourself, 292
SIGINT and SIGTERM, 280
SIGKILL and SIGSTOP, 280
signal management, 286–291, 298–305
examples, 287
execution and inheritance, 289
mapping signal numbers to
strings, 290
si_code field, 302–305
sigaction( ) function, 298–300
siginfo_t structure, 300–302
waiting for signals, 287
signal masks, 297
signal sets, 295
signal-safety, 294
sigorset( ) function, 296
sigpending( ) function, 298
sigprocmask( ) function, 297
sigqueue( ) function, 305
SIGSEGV signal, 99
sigsuspend( ) function, 298
Single Unix Specification (see SUS)
sleep( ) function, 324
sleeping, 324–330
sockets, 13
soft affinity, 173
soft links, 225
soft real-time systems, 176
soft resource limits, 190
software clocks, 309
sorting (I/O schedulers), 115
source compatibility, 5
special files, 13
stack, 245
duplicating strings on, 266
stack-based memory allocations, 264–268
strings, duplicating, 266
variable-length arrays, 267
standard error (stderr), 21
standard I/O, 64
file pointers, 65
limitations, 81
standard I/O library, 64
standards, 6
as dealt with in this book, 8
stat( ) function, 197
stat family, 196–199
stat structure, 197
fields, 197–199
static priority, 178
status pointer, 140
stderr (standard error), 21
stdin, stdout, and stderr file descriptors, 23
stdio, 64
stime( ) function, 318
strdup( ), strdupa( ), and strndupa( )
functions, 266
streams, 65
associated file descriptors, obtaining
for, 77
closing, 67
closing all, 67
file descriptors, opening via, 66
Index | 367
flushing, 75
reading from, 67–70
putting the character back, 68
reading an entire line, 68
reading arbitrary strings, 69
reading binary data, 70
reading one character at at time, 67
seeking a stream, 74
obtaining current stream position, 75
writing to, 70–72
data alignment, 71
writing a single character, 71
writing a string, 72
writing binary data, 72
(see also buffered I/O)
strerror( ) function, 21
strerror_r( ) function, 21
strsignal( ) function, 290
subdirectories, 212
supplemental groups, 17
SUS (Single Unix Specification), 6
history, 6
standards UNIX 95, UNIX 98, and
UNIX 03, 7
symbolic links (symlinks), 12, 223, 225
symlink( ) function, 226
symmetric multiprocessing, 172
sync( ) function, 39
synchronicity of write operations, 112
synchronization, 39
synchronized operations, 111
synchronous write operations, 111
sysconf( ) function, 98
sys_siglist, 290
system calls (syscalls), 3
I/O calls and, 77
system clock, tuning, 321–324
system namespace, 205
system programming, xi, 1–4
C compiler, 4
C library (libc), 4
functions
parameter passing, 3
programming concepts (see programming
concepts)
standards, 6
system calls, 3
invoking, 3
system software, xi, 1
system timer, 309
system timer frequency, 309
T
temporal locality, 59
text files and binary files, 66
text segment, 245
The C Programming Language, xi
The Open Group, 6
thread-based asynchronous I/O, 113
threads, 79, 166
pthreads API, 166
thread safety, 79–81
manual file locking, 80
unlocked stream operations, 81
thread-safety, 79
tick or jiffy, 309
time, 308–310
C language conversion
functions, 320–321
current time, getting, 315–318
microsecond resolution, 316
nanosecond resolution, 316
current time, setting, 318
clock_settime( ) function, 319
data structures, 310–313
clock_t type, 313
timespec (nanosecond precision), 311
time_t, 310
time_t and leap years, 315
timeval (microsecond precision), 311
tm structure for broken-down time
representation, 312
delta, 322
epoch measurement, 309
kernel, measurement by, 308
measurement formats, 309
POSIX clocks, 313–315
clockid_t type, 313
time source resolution, 314
process time, getting, 317
sleeping, 324–330
alternatives to, 330
microsecond precision, 325
nanosecond precision, 326–329
select( ) function for portability, 329
timer overruns, 329
system clock, tuning, 321–324
timers, 330–338
alarms, 330
interval timers, 331–333
POSIX clocks-based timers, 333–338
time( ) function, 315
timer_create( ) function, 334
timer_delete( ) function, 338
368 | Index
timer_getoverrun( ) function, 337
timer_gettime( ) function, 336
timer_settime( ) function, 335
times( ) function, 317
timeslices, 162, 164
time_t type, 321
toolchain, 6
truncate( ) function, 46
truncation, 10
trusted namespace, 206
typeof( ) keyword, 346
U
uid (user ID), 17
umask, 218
undefined keys, 204
Universal Time, Coordinated (UTC), 309
Unix, 1
Unix text editors, xi
unlikely( ) wrapper, 345
unlink( ) function, 227
unlinking, 12
unmounting, 14
unused attribute, 343
user ID (uid), 17
user namespace, 206
user time, 40, 317
user-buffered I/O, 62–64
user-buffered I/O (input/output)
file descriptors, usage of, 23
usernames, 17
users, 17
ownership of processes, 127
user-space applications, communication with
kernel, 3
usleep( ) function, 325
UTC (Universal Time, Coordinated), 309
V
valid page, 244
variable-length arrays (VLAs), 267
variadic functions, 129
vectored I/O, 84, 86
vectors, 85
vfork( ) function, 135
VFS (see virtual filesystems)
virtual address space, 243
virtual file switch, 58
virtual filesystems (VFS), 14, 58
W
wait( ) function, 139
waitid( ) function, 143
waiting on zombie processes, 139
waitpid( ) function, 142
wall time, 308
warn_unused_result attribute, 342
watches, 236–242
adding watches, 236
advanced options, 240
inotify events, 238–240
advanced events, 239
linking together move events, 240
reading, 238
watch masks, 236
whence, 74
word size, 44
-Wpointer-arith option, 349
write( ) function, 33–37
additional error codes, 35
append mode, 34
behavior of write( ), 36
nonblocking writes, 35
partial writes, 34
positional writes, 44
error values, 45
size limits on, 36
write FIFO queue, 116
write ordering, 36
write permissions, 18
writebacks, 36
writes-starving-reads problem, 116
writev( ) function, 85
example, 86
implementation, 88
return values, 85
X
X⁄Open, 7
xattrs (see extended attributes)
xmalloc( ) wrapper, 247
Y
yielding, 163, 166–169
legitimate uses, 167
Linux version 2.6, changes in, 168
Z
zero device, 232
zombies, 17, 149
waiting on zombie processes, 139
About the Author
Robert Love has been a Linux user and hacker since the early days. He is active in—
and passionate about—the Linux kernel and GNOME desktop communities. His
recent contributions to the Linux kernel include work on the kernel event layer and
inotify. GNOME-related contributions include Beagle, GNOME Volume Manager,
NetworkManager, and Project Utopia. Currently, Robert works in the Open Source
Program Office at Google.
As an author, Robert is responsible for Linux Kernel Development (Novell Press),
now in its second edition. He is also a coauthor of the fifth edition of O’Reilly’s
Linux in a Nutshell. A contributing editor for Linux Journal, Robert has written many
articles and has been invited to speak around the world on Linux.
Robert graduated from the University of Florida with a B.A. in mathematics and a
B.S. in computer science. Hailing from south Florida, he now calls Boston home.
Colophon
The image on the cover of Linux System Programming is a man in a flying machine.
Well before the Wright brothers achieved their first controlled heavier-than-air flight
in 1903, people around the world attempted to fly by simple and elaborate machines.
In the second or third century, Zhuge Liang of China reportedly flew in a Kongming
lantern, the first hot air balloon. Around the fifth or sixth centuries, many Chinese
people purportedly attached themselves to large kites to fly through the air.
It is also said that the Chinese created spinning toys that were early versions of heli-
copters, the designs of which may have inspired Leonardo da Vinci in his initial
attempts at a solution to human flight. da Vinci also studied birds and designed para-
chutes, and in 1845, he designed an ornithopter, a wing-flapping machine meant to
carry humans through the air. Though he never built it, the ornithopter’s birdlike
structure influenced the design of flying machines throughout the centuries.
The flying machine depicted on the cover is more elaborate than James Means’
model soaring machine of 1893, which had no propellers. Means later printed an
instruction manual for his soaring machine, which in part states that “the summit of
Mt. Willard, near the Crawford House, N.H., will be found an excellent place” to
experiment with the machines.
But such experimentation was often dangerous. In the late nineteenth century, Otto
Lilienthal built monoplanes, biplanes, and gliders. He was the first to show that
control of human flight was within reach, and he gained the nickname “father of
aerial testing,” as he conducted more than 2,000 glider flights, sometimes traveling
more than a thousand feet. He died in 1896 after breaking his spine during a crash
landing.
Flying machines are also known as mechanical birds and airships, and are occasion-
ally called by more colorful names such as the Artificial Albatross. Enthusiasm for
flying machines remains high, as aeronautical buffs still build early flying machines
today.
The cover image and chapter opening graphics are from the Dover Pictorial Archive.
The cover font is Adobe ITC Garamond. The text font is Linotype Birka; the heading
font is Adobe Myriad Condensed; and the code font is LucasFont’s TheSans Mono
Condensed.
